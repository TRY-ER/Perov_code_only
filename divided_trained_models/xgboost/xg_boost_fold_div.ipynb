{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5-jiYKypEVY",
        "outputId": "5d7bb04b-c493-4a5a-eeaa-5749d1a7d0f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0tPZaeupLWn",
        "outputId": "f81b51a0-459a-4ac6-d0fe-bbc617272817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: xgboost==1.6.1 in /usr/local/lib/python3.7/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.6.1) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.6.1) (1.4.1)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (4.64.0)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.11.0+cu113)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.2.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.8.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.6.0)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.2.0)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.1)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.9.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-tabnet optuna xgboost==1.6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "vRmDYdsCpMT-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "import optuna as opt\n",
        "import torch\n",
        "import os\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "L4HljGyopQs_"
      },
      "outputs": [],
      "source": [
        "def make_save_cv_model(i,model_name,model,best_params,optim,clf_report,accuracy,output_path=\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/xg_boost_output\"):\n",
        "\n",
        "    ''' This function saves cross validation model in the corresponding directory ( if the path does not exist it creates the path for it'''\n",
        "\n",
        "\n",
        "    if os.path.exists(os.path.join(output_path,f\"{i}_{model_name}_{optim}\")):\n",
        "        joblib.dump(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n",
        "        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/model_params.txt\"),\"w+\") as file:file.write(str(best_params))\n",
        "        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/classification_report.txt\"),\"w+\") as file:file.write(str(clf_report))\n",
        "        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/accuracy_score.txt\"),\"w+\") as file:file.write(f\" accuracy :: {str(accuracy)}\")\n",
        "    else:\n",
        "        os.mkdir(os.path.join(output_path,f\"{i}_{model_name}_{optim}\"))\n",
        "        joblib.dump(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n",
        "        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/model_params.txt\"),\"w+\") as file:file.write(str(best_params))\n",
        "        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/classification_report.txt\"),\"w+\") as file:file.write(str(clf_report))\n",
        "        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/accuracy_score.txt\"),\"w+\") as file:file.write(f\" accuracy :: {str(accuracy)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "z_M5FI9PpVA_"
      },
      "outputs": [],
      "source": [
        "def train(fold_dict,fold,model_name,sc_df,tar_col,optim_trial,k_folds=10,tar_cols=\"\",verbose=1):\n",
        "\n",
        "    ''' this function is used to train the model with parameters optimization using optuna and cross validation using stratified k_folds'''\n",
        "\n",
        "    y = sc_df[tar_col]\n",
        "    print(y.shape)\n",
        "    x = sc_df.drop([tar_col],axis=1)\n",
        "    print(x.shape)\n",
        "    model_name = model_name \n",
        "    def objective(trial):\n",
        "      train_index = fold_dict[fold][\"train\"]\n",
        "      test_index = fold_dict[fold][\"test\"]\n",
        "      clf = XGBClassifier(n_estimators=trial.suggest_categorical(\"xgb_est\",[100,200,300,400,500]),\n",
        "                        learning_rate=trial.suggest_categorical(\"xgb_lr\",[0.1,0.01,0.001]),\n",
        "                        booster = trial.suggest_categorical(\"xgb_booster\",[\"gbtree\",\"gblinear\",\"dart\"]),\n",
        "                        tree_method = \"auto\",\n",
        "                        predictor = \"cpu_predictor\")\n",
        "      # print(f\" train_index :: {train_index}\")\n",
        "      # print(f\" test_index :: {test_index}\")\n",
        "      X_train,X_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
        "      # print(X_train.shape, X_test.shape)\n",
        "      X_train, X_test = X_train.to_numpy(dtype=np.float64), X_test.to_numpy(dtype=np.float64)\n",
        "      Y_train, Y_test = y.iloc[train_index].to_numpy(dtype=np.float64), y.iloc[test_index].to_numpy(np.float64)\n",
        "      # Y_train, Y_test = Y_train.to_numpy(dtype=np.float64), Y_test.to_numpy(dtype=np.float64)\n",
        "      print(X_train.shape)\n",
        "      print(Y_train.shape)\n",
        "      print(X_test.shape)\n",
        "      print(Y_test.shape)\n",
        "      clf.fit(X_train, Y_train,\n",
        "              eval_set=[(X_test, Y_test)],\n",
        "              eval_metric=['mlogloss'])\n",
        "      Y_pred = clf.predict(X_test)\n",
        "      print(classification_report(Y_test, Y_pred, labels=[x for x in range(6)]))\n",
        "      acc = accuracy_score(Y_pred, Y_test)\n",
        "      return acc\n",
        "\n",
        "    print(f\"Starting optimization for fold : [{fold}/{k_folds}]\")\n",
        "    study = opt.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=optim_trial)\n",
        "    best_params = study.best_params\n",
        "    print(f\" Best params for fold : [{fold}/{k_folds}]\")\n",
        "    print(best_params)\n",
        "    train_index = fold_dict[fold][\"train\"]\n",
        "    test_index = fold_dict[fold][\"test\"]\n",
        "    X_train,X_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
        "    # print(X_train.shape, X_test.shape)\n",
        "    X_train, X_test = X_train.to_numpy(dtype=np.float64), X_test.to_numpy(dtype=np.float64)\n",
        "    Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    Y_train, Y_test = Y_train.to_numpy(dtype=np.float64), Y_test.to_numpy(dtype=np.float64)\n",
        "    clf_model = XGBClassifier(**study.best_params)\n",
        "    clf_model.fit(X_train,Y_train)\n",
        "    Y_pred = clf_model.predict(X_test)\n",
        "    clf_report = classification_report(Y_test, Y_pred, labels=[x for x in range(6)])\n",
        "    accuracy = accuracy_score(Y_pred, Y_test)\n",
        "    try:\n",
        "        print(\"[++] Saving the model and parameters in corresponding directories\")\n",
        "        make_save_cv_model(fold,model_name,clf_model,best_params,clf_report,accuracy)\n",
        "    except:\n",
        "        print(\"[-] Failed to save the model\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JgKRKxtIbUGk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Total Number of Fold == 20**"
      ],
      "metadata": {
        "id": "J_zckJkrWuzi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "xNlu9Ktsq6VG"
      },
      "outputs": [],
      "source": [
        "use_df = pd.read_csv(\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/data/trainable_scaled_balanced.csv\")\n",
        "tar_col = \"PCE_categorical\"\n",
        "model_name = \"xg_boost\"\n",
        "fold_dict = joblib.load(\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/inputs/fold_vals/fold_data_xg_boost.z\")\n",
        "fold = 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(fold_dict[0][\"train\"]))\n",
        "print(len(fold_dict[0][\"test\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tfs9W8IXz7m",
        "outputId": "1fb2875b-ff7e-4fc0-9b12-9d5c8ffc81f7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44004\n",
            "2316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ9h3wayrIp_",
        "outputId": "b7e35af1-baea-423b-8894-560405c44733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 12:15:17,930]\u001b[0m A new study created in memory with name: no-name-d42c63e0-d5df-4b19-9c82-82cfc66a6272\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(46320,)\n",
            "(46320, 114)\n",
            "Starting optimization for fold : [0/10]\n",
            "(44004, 114)\n",
            "(44004,)\n",
            "(2316, 114)\n",
            "(2316,)\n",
            "[0]\tvalidation_0-mlogloss:1.75719\n",
            "[1]\tvalidation_0-mlogloss:1.72567\n",
            "[2]\tvalidation_0-mlogloss:1.69701\n",
            "[3]\tvalidation_0-mlogloss:1.67098\n",
            "[4]\tvalidation_0-mlogloss:1.64735\n",
            "[5]\tvalidation_0-mlogloss:1.62587\n",
            "[6]\tvalidation_0-mlogloss:1.60633\n",
            "[7]\tvalidation_0-mlogloss:1.58852\n",
            "[8]\tvalidation_0-mlogloss:1.57225\n",
            "[9]\tvalidation_0-mlogloss:1.55735\n",
            "[10]\tvalidation_0-mlogloss:1.54367\n",
            "[11]\tvalidation_0-mlogloss:1.53107\n",
            "[12]\tvalidation_0-mlogloss:1.51944\n",
            "[13]\tvalidation_0-mlogloss:1.50866\n",
            "[14]\tvalidation_0-mlogloss:1.49865\n",
            "[15]\tvalidation_0-mlogloss:1.48932\n",
            "[16]\tvalidation_0-mlogloss:1.48062\n",
            "[17]\tvalidation_0-mlogloss:1.47246\n",
            "[18]\tvalidation_0-mlogloss:1.46481\n",
            "[19]\tvalidation_0-mlogloss:1.4576\n",
            "[20]\tvalidation_0-mlogloss:1.4508\n",
            "[21]\tvalidation_0-mlogloss:1.44437\n",
            "[22]\tvalidation_0-mlogloss:1.43829\n",
            "[23]\tvalidation_0-mlogloss:1.4325\n",
            "[24]\tvalidation_0-mlogloss:1.42701\n",
            "[25]\tvalidation_0-mlogloss:1.42176\n",
            "[26]\tvalidation_0-mlogloss:1.41676\n",
            "[27]\tvalidation_0-mlogloss:1.41197\n",
            "[28]\tvalidation_0-mlogloss:1.40739\n",
            "[29]\tvalidation_0-mlogloss:1.403\n",
            "[30]\tvalidation_0-mlogloss:1.39878\n",
            "[31]\tvalidation_0-mlogloss:1.39472\n",
            "[32]\tvalidation_0-mlogloss:1.39081\n",
            "[33]\tvalidation_0-mlogloss:1.38705\n",
            "[34]\tvalidation_0-mlogloss:1.38342\n",
            "[35]\tvalidation_0-mlogloss:1.3799\n",
            "[36]\tvalidation_0-mlogloss:1.37651\n",
            "[37]\tvalidation_0-mlogloss:1.37322\n",
            "[38]\tvalidation_0-mlogloss:1.37004\n",
            "[39]\tvalidation_0-mlogloss:1.36696\n",
            "[40]\tvalidation_0-mlogloss:1.36397\n",
            "[41]\tvalidation_0-mlogloss:1.36106\n",
            "[42]\tvalidation_0-mlogloss:1.35824\n",
            "[43]\tvalidation_0-mlogloss:1.3555\n",
            "[44]\tvalidation_0-mlogloss:1.35283\n",
            "[45]\tvalidation_0-mlogloss:1.35023\n",
            "[46]\tvalidation_0-mlogloss:1.34771\n",
            "[47]\tvalidation_0-mlogloss:1.34525\n",
            "[48]\tvalidation_0-mlogloss:1.34284\n"
          ]
        }
      ],
      "source": [
        "train(fold_dict = fold_dict,\n",
        "      fold = fold,\n",
        "      model_name=model_name,\n",
        "      sc_df=use_df,\n",
        "      tar_col=tar_col,\n",
        "      optim_trial = 15)\n",
        "print(f\"[++] Ended the training process for fold {fold}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja5dUXmqsCFF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afu4nJyHu-sp"
      },
      "source": [
        "Fold 0 has started running on 20-05-22 \n",
        "\n",
        "\n",
        "Fold 0 has completed sucessfully on 17:00 20-05-22\n",
        "\n",
        "Fold 1 has started running at 15:15 21-05-22\n",
        "\n",
        "Fold 2 has started running at 09:45 22-05-22\n",
        "\n",
        "Fold 2 has completed sucessfully on 10:58 22-05-22\n",
        "\n",
        "Fold 3 has started running at 18:40 22-05-22\n",
        "\n",
        "Fold 3 has completed sucessfully on 22-05-22\n",
        "\n",
        "Fold 4 completed sucessfully on 21:04 on 22-05-22\n",
        "\n",
        "Fold 5 started at 18:21 on 23-05-22\n",
        "\n",
        "Fold 5 completed sucessfully on 19:44 on 23-05-22\n",
        "\n",
        "Fold 6 started at 12:53 on 24-05-22\n",
        "\n",
        "Fold 6 has completed at 14:14 on 24-05-22\n",
        "\n",
        "Fold 7 started at 14:18 on 24-05-22\n",
        "\n",
        "Fold 7 execution failed due to colab gpu time limit\n",
        "\n",
        "Fold 7 trial 1 started at 11:00 on 25-05-22\n",
        "\n",
        "Fold 7 has completed sucessfully at 12:14 on 25-05-22 \n",
        "\n",
        "Fold 8 has started at 9:38 on 26-05-22\n",
        "\n",
        "Fold 8 filed due to interrupted internet connection\n",
        "\n",
        "Fold 8 trial 1 started at 13:38 on 26-05-22\n",
        "\n",
        "Fold 8 has successfully executed at 15:33 on 26-05-22\n",
        "\n",
        "Fold 9 has started at 13:35 on 27-05-22\n",
        "\n",
        "Fold 9 has completed at 14:55 on 27-05-22"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me85YLlzpUM8"
      },
      "source": [
        "Editing with rectified dataset witout duplicacy because of space values\n",
        "\n",
        "Fold 0 started at 13:21 on 28-05-22\n",
        "\n",
        "Fold 0 completed sucessfully at 14:46 on 28-05-22\n",
        "\n",
        "Fold 1 Failed to run due to some index error\n",
        "\n",
        "_____ Restarting the training process again due to data distribution failure____\n",
        "\n",
        "\n",
        "\n",
        "Fold 0 started at 10:47 on 30-05-22\n",
        "\n",
        "Fold 0 completed successfully at 12:30 on 30-05-22\n",
        "\n",
        "Fold 1 started at 8:27 on 31-05-22\n",
        "\n",
        "Fold 1 execution failed due to runtime disconnection\n",
        "\n",
        "Fold 1 started again at 9:38 on 31-05-22\n",
        "\n",
        "Fold 1 execution failed due to gpu disconnect \n",
        "\n",
        "Fold 1 started again at 8:36 on 1-06-22\n",
        "\n",
        "Fold 1 execution failed due to network disconnection\n",
        "\n",
        "Fold 1 started again at 13:11 on 01-06-22\n",
        "\n",
        "Fold 1 has succesfully executed at 14:25 on 01-06-22\n",
        "\n",
        "Fold 2 started at 14:29 on 01-06-22\n",
        "\n",
        "Fold 2 completed succesfully at 16:00 on 01-06-22\n",
        "\n",
        "Fold 3 started at 09:43 on 02-06-22\n",
        "\n",
        "Fold 3 execution failed due to gpu server disconnection \n",
        "\n",
        "Fold 3 started again at 13:34 on 02-06-22\n",
        "\n",
        "Fold 3 ran successfully at 14:47 on 02-06-22\n",
        "\n",
        "Fold 4 started at 14:48 on 02-06-22\n",
        "\n",
        "Fold 4 ran successfully at 04:01 on 02-06-22\n",
        "\n",
        "Fold 5 started at 13:51 on 03-06-22\n",
        "\n",
        "Fold 5 ran successfully at 03:06 on 02-06-22\n",
        "\n",
        "Fold 6 started at 15:11 on 03-06-22"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zICGdYlFNr13"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "xg_boost_fold_div.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}