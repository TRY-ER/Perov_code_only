{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5-jiYKypEVY",
        "outputId": "60a4ca52-ae15-4411-d92f-e5d7d832b307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun  1 07:41:04 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0tPZaeupLWn",
        "outputId": "0c37a1cc-4db4-41d5-c4a2-272788d507a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-3.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 53.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.4.1)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (4.64.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.21.6)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.11.0+cu113)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.2.0)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.8.0-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 67.7 MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 11.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 60.8 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 71.7 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=9239689881f9346f520965c2edd3b2e7a7d08ead8003b1fb00965a6788e5a0d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, pytorch-tabnet, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.8.0 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.0 pbr-5.9.0 pyperclip-1.8.2 pytorch-tabnet-3.1.1 stevedore-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-tabnet optuna "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vRmDYdsCpMT-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "import optuna as opt\n",
        "import torch\n",
        "import os\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L4HljGyopQs_"
      },
      "outputs": [],
      "source": [
        "def make_save_cv_model(i,model_name,model,best_params,optim,output_path=\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/cross_validated_models\"):\n",
        "\n",
        "    ''' This function saves cross validation model in the corresponding directory ( if the path does not exist it creates the path for it'''\n",
        "\n",
        "\n",
        "    if os.path.exists(os.path.join(output_path,f\"{i}_{model_name}_{optim}\")):\n",
        "        joblib.dump(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n",
        "        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/model_params.txt\"),\"w+\") as file:\n",
        "            file.write(str(best_params))\n",
        "    else:\n",
        "        os.mkdir(os.path.join(output_path,f\"{i}_{model_name}_{optim}\"))\n",
        "        joblib.dump(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n",
        "        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/model_params.txt\"),\"w+\") as file:\n",
        "            file.write(str(best_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z_M5FI9PpVA_"
      },
      "outputs": [],
      "source": [
        "def train(fold_dict,fold,model_name,sc_df,tar_col,optim,optim_trial,k_folds=10,tar_cols=\"\",verbose=1):\n",
        "\n",
        "    ''' this function is used to train the model with parameters optimization using optuna and cross validation using stratified k_folds'''\n",
        "\n",
        "    y = sc_df[tar_col]\n",
        "    x = sc_df.drop([tar_col],axis=1)\n",
        "    model_name = model_name \n",
        "    def objective(trial):\n",
        "      train_index = fold_dict[fold][\"train\"]\n",
        "      test_index = fold_dict[fold][\"test\"]\n",
        "      clf = TabNetClassifier(n_d=trial.suggest_int(\"n_d\", 8, 64),\n",
        "                              n_a =trial.suggest_int(\"n_a\", 8, 64),\n",
        "                              n_steps = trial.suggest_int(\"n_steps\",3,10),\n",
        "                              gamma =trial.suggest_float(\"gamma\", 1.0, 2.0),\n",
        "                              n_independent = trial.suggest_int(\"n_independent\",1,5),\n",
        "                              n_shared = trial.suggest_int(\"n_shared\",1,5),\n",
        "                              momentum = trial.suggest_float(\"momentum\", 0.01, 0.4),\n",
        "                              optimizer_fn = torch.optim.Adam,\n",
        "                              # scheduler_fn = torch.optim.lr_scheduler,\n",
        "                              # scheduler_params = {\"gamma\" :trial.suggest_float(\"sch-gamma\", 0.5, 0.95), \"step_size\": trial.suggest_int(\"sch_step_size\", 10, 20, 2)},\n",
        "                              verbose = verbose,\n",
        "                              device_name = \"auto\"\n",
        "                              )\n",
        "      # print(f\" train_index :: {train_index}\")\n",
        "      # print(f\" test_index :: {test_index}\")\n",
        "      X_train,X_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
        "      # print(X_train.shape, X_test.shape)\n",
        "      X_train, X_test = X_train.to_numpy(dtype=np.float64), X_test.to_numpy(dtype=np.float64)\n",
        "      Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "      Y_train, Y_test = Y_train.to_numpy(dtype=np.float64), Y_test.to_numpy(dtype=np.float64)\n",
        "      print(Y_train.shape, Y_test.shape)\n",
        "      clf.fit(X_train, Y_train,\n",
        "              eval_set=[(X_test, Y_test)],\n",
        "              eval_metric=['accuracy'])\n",
        "      Y_pred = clf.predict(X_test)\n",
        "      print(classification_report(Y_test, Y_pred, labels=[x for x in range(6)]))\n",
        "      acc = accuracy_score(Y_pred, Y_test)\n",
        "      return acc\n",
        "\n",
        "    print(f\"Starting optimization for fold : [{fold}/{k_folds}]\")\n",
        "    study = opt.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=optim_trial)\n",
        "    best_params = study.best_params\n",
        "    print(f\" Best params for fold : [{fold}/{k_folds}]\")\n",
        "    print(best_params)\n",
        "    joblib.dump(best_params,f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/best_params/comp/fold_{fold}_best_params.z\")\n",
        "    with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/best_params/fold_{fold}_best_params.txt\", \"w+\") as file:file.write(str(best_params))\n",
        "    print(f\"Saved best_params at : outputs/{model_name}/best_params/fold_{fold}_best_params.txt\")\n",
        "    train_index = fold_dict[fold][\"train\"]\n",
        "    test_index = fold_dict[fold][\"test\"]\n",
        "    X_train,X_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
        "    # print(X_train.shape, X_test.shape)\n",
        "    X_train, X_test = X_train.to_numpy(dtype=np.float64), X_test.to_numpy(dtype=np.float64)\n",
        "    Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    Y_train, Y_test = Y_train.to_numpy(dtype=np.float64), Y_test.to_numpy(dtype=np.float64)\n",
        "    clf_model = TabNetClassifier(**study.best_params)\n",
        "    clf_model.fit(X_train,Y_train)\n",
        "    Y_pred = clf_model.predict(X_test)\n",
        "    clf_report = classification_report(Y_test, Y_pred, labels=[x for x in range(6)])\n",
        "    with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/classification_report/{model_name}_{fold}_classification_report.txt\",\"w+\") as file:file.write(str(clf_report))\n",
        "    accuracy = accuracy_score(Y_pred, Y_test)\n",
        "    with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/{model_name}_{fold}_accuracy_score.txt\",\"w+\") as file:file.write(f\" accuracy :: {str(accuracy)}\")\n",
        "    try:\n",
        "        print(\"[++] Saving the model and parameters in corresponding directories\")\n",
        "        make_save_cv_model(fold,model_name,clf_model,best_params,optim=optim)\n",
        "    except:\n",
        "        print(\"[-] Failed to save the model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xNlu9Ktsq6VG"
      },
      "outputs": [],
      "source": [
        "use_df = pd.read_csv(\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/data/trainable_scaled_balanced.csv\")\n",
        "tar_col = \"PCE_categorical\"\n",
        "model_name = \"pytorch_tabnet\"\n",
        "optimizer = \"Adam\"\n",
        "fold_dict = joblib.load(\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/inputs/fold_vals/fold_data.z\")\n",
        "fold = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ9h3wayrIp_",
        "outputId": "e00f4818-c4ad-4f3c-e7b6-fd36af04aa64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 07:41:22,945]\u001b[0m A new study created in memory with name: no-name-5c45f491-6d83-48f4-99b8-9d8f97ba46ab\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting optimization for fold : [1/10]\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.22036 | val_0_accuracy: 0.60125 |  0:00:02s\n",
            "epoch 1  | loss: 0.88052 | val_0_accuracy: 0.60471 |  0:00:04s\n",
            "epoch 2  | loss: 0.84606 | val_0_accuracy: 0.63968 |  0:00:06s\n",
            "epoch 3  | loss: 0.78967 | val_0_accuracy: 0.66019 |  0:00:08s\n",
            "epoch 4  | loss: 0.74945 | val_0_accuracy: 0.66321 |  0:00:10s\n",
            "epoch 5  | loss: 0.74237 | val_0_accuracy: 0.67703 |  0:00:12s\n",
            "epoch 6  | loss: 0.73309 | val_0_accuracy: 0.6766  |  0:00:14s\n",
            "epoch 7  | loss: 0.72491 | val_0_accuracy: 0.66991 |  0:00:16s\n",
            "epoch 8  | loss: 0.71649 | val_0_accuracy: 0.67098 |  0:00:18s\n",
            "epoch 9  | loss: 0.69516 | val_0_accuracy: 0.69041 |  0:00:22s\n",
            "epoch 10 | loss: 0.6845  | val_0_accuracy: 0.70315 |  0:00:26s\n",
            "epoch 11 | loss: 0.67932 | val_0_accuracy: 0.70099 |  0:00:28s\n",
            "epoch 12 | loss: 0.6752  | val_0_accuracy: 0.69646 |  0:00:30s\n",
            "epoch 13 | loss: 0.66516 | val_0_accuracy: 0.70682 |  0:00:32s\n",
            "epoch 14 | loss: 0.6571  | val_0_accuracy: 0.70272 |  0:00:34s\n",
            "epoch 15 | loss: 0.65069 | val_0_accuracy: 0.71503 |  0:00:36s\n",
            "epoch 16 | loss: 0.65223 | val_0_accuracy: 0.70423 |  0:00:38s\n",
            "epoch 17 | loss: 0.64223 | val_0_accuracy: 0.71351 |  0:00:40s\n",
            "epoch 18 | loss: 0.64253 | val_0_accuracy: 0.71718 |  0:00:43s\n",
            "epoch 19 | loss: 0.63343 | val_0_accuracy: 0.71028 |  0:00:45s\n",
            "epoch 20 | loss: 0.63878 | val_0_accuracy: 0.71092 |  0:00:47s\n",
            "epoch 21 | loss: 0.63547 | val_0_accuracy: 0.72755 |  0:00:49s\n",
            "epoch 22 | loss: 0.6196  | val_0_accuracy: 0.7364  |  0:00:51s\n",
            "epoch 23 | loss: 0.61181 | val_0_accuracy: 0.73359 |  0:00:53s\n",
            "epoch 24 | loss: 0.61474 | val_0_accuracy: 0.73338 |  0:00:55s\n",
            "epoch 25 | loss: 0.60817 | val_0_accuracy: 0.73985 |  0:00:57s\n",
            "epoch 26 | loss: 0.59903 | val_0_accuracy: 0.73079 |  0:00:59s\n",
            "epoch 27 | loss: 0.59608 | val_0_accuracy: 0.72733 |  0:01:01s\n",
            "epoch 28 | loss: 0.58906 | val_0_accuracy: 0.74201 |  0:01:03s\n",
            "epoch 29 | loss: 0.58212 | val_0_accuracy: 0.7418  |  0:01:05s\n",
            "epoch 30 | loss: 0.57585 | val_0_accuracy: 0.7446  |  0:01:07s\n",
            "epoch 31 | loss: 0.57696 | val_0_accuracy: 0.74028 |  0:01:10s\n",
            "epoch 32 | loss: 0.57401 | val_0_accuracy: 0.74676 |  0:01:12s\n",
            "epoch 33 | loss: 0.56701 | val_0_accuracy: 0.75324 |  0:01:14s\n",
            "epoch 34 | loss: 0.56836 | val_0_accuracy: 0.74244 |  0:01:16s\n",
            "epoch 35 | loss: 0.57723 | val_0_accuracy: 0.74633 |  0:01:18s\n",
            "epoch 36 | loss: 0.56358 | val_0_accuracy: 0.75345 |  0:01:20s\n",
            "epoch 37 | loss: 0.56409 | val_0_accuracy: 0.75108 |  0:01:22s\n",
            "epoch 38 | loss: 0.55932 | val_0_accuracy: 0.75389 |  0:01:24s\n",
            "epoch 39 | loss: 0.5549  | val_0_accuracy: 0.76058 |  0:01:26s\n",
            "epoch 40 | loss: 0.54775 | val_0_accuracy: 0.75475 |  0:01:28s\n",
            "epoch 41 | loss: 0.55037 | val_0_accuracy: 0.75259 |  0:01:30s\n",
            "epoch 42 | loss: 0.54768 | val_0_accuracy: 0.74957 |  0:01:32s\n",
            "epoch 43 | loss: 0.54403 | val_0_accuracy: 0.75777 |  0:01:34s\n",
            "epoch 44 | loss: 0.53536 | val_0_accuracy: 0.75756 |  0:01:37s\n",
            "epoch 45 | loss: 0.53567 | val_0_accuracy: 0.75864 |  0:01:39s\n",
            "epoch 46 | loss: 0.52876 | val_0_accuracy: 0.76101 |  0:01:41s\n",
            "epoch 47 | loss: 0.52254 | val_0_accuracy: 0.76533 |  0:01:43s\n",
            "epoch 48 | loss: 0.52259 | val_0_accuracy: 0.75907 |  0:01:45s\n",
            "epoch 49 | loss: 0.5239  | val_0_accuracy: 0.76619 |  0:01:47s\n",
            "epoch 50 | loss: 0.52909 | val_0_accuracy: 0.75907 |  0:01:49s\n",
            "epoch 51 | loss: 0.5269  | val_0_accuracy: 0.76533 |  0:01:51s\n",
            "epoch 52 | loss: 0.51416 | val_0_accuracy: 0.76878 |  0:01:53s\n",
            "epoch 53 | loss: 0.52318 | val_0_accuracy: 0.75972 |  0:01:55s\n",
            "epoch 54 | loss: 0.51533 | val_0_accuracy: 0.75281 |  0:01:57s\n",
            "epoch 55 | loss: 0.51401 | val_0_accuracy: 0.769   |  0:01:59s\n",
            "epoch 56 | loss: 0.50287 | val_0_accuracy: 0.76533 |  0:02:01s\n",
            "epoch 57 | loss: 0.50926 | val_0_accuracy: 0.77396 |  0:02:03s\n",
            "epoch 58 | loss: 0.50029 | val_0_accuracy: 0.76576 |  0:02:06s\n",
            "epoch 59 | loss: 0.51465 | val_0_accuracy: 0.76878 |  0:02:08s\n",
            "epoch 60 | loss: 0.50186 | val_0_accuracy: 0.77332 |  0:02:10s\n",
            "epoch 61 | loss: 0.48913 | val_0_accuracy: 0.7772  |  0:02:12s\n",
            "epoch 62 | loss: 0.48594 | val_0_accuracy: 0.77958 |  0:02:14s\n",
            "epoch 63 | loss: 0.48258 | val_0_accuracy: 0.77202 |  0:02:16s\n",
            "epoch 64 | loss: 0.48374 | val_0_accuracy: 0.78174 |  0:02:18s\n",
            "epoch 65 | loss: 0.48502 | val_0_accuracy: 0.77288 |  0:02:20s\n",
            "epoch 66 | loss: 0.47572 | val_0_accuracy: 0.77807 |  0:02:22s\n",
            "epoch 67 | loss: 0.47489 | val_0_accuracy: 0.78001 |  0:02:24s\n",
            "epoch 68 | loss: 0.47431 | val_0_accuracy: 0.7813  |  0:02:26s\n",
            "epoch 69 | loss: 0.4668  | val_0_accuracy: 0.78735 |  0:02:28s\n",
            "epoch 70 | loss: 0.47176 | val_0_accuracy: 0.77655 |  0:02:30s\n",
            "epoch 71 | loss: 0.4675  | val_0_accuracy: 0.78389 |  0:02:32s\n",
            "epoch 72 | loss: 0.46097 | val_0_accuracy: 0.79059 |  0:02:34s\n",
            "epoch 73 | loss: 0.46412 | val_0_accuracy: 0.78282 |  0:02:36s\n",
            "epoch 74 | loss: 0.45726 | val_0_accuracy: 0.78627 |  0:02:38s\n",
            "epoch 75 | loss: 0.45618 | val_0_accuracy: 0.78886 |  0:02:40s\n",
            "epoch 76 | loss: 0.45816 | val_0_accuracy: 0.78238 |  0:02:42s\n",
            "epoch 77 | loss: 0.45679 | val_0_accuracy: 0.78584 |  0:02:44s\n",
            "epoch 78 | loss: 0.45629 | val_0_accuracy: 0.78087 |  0:02:46s\n",
            "epoch 79 | loss: 0.45247 | val_0_accuracy: 0.79037 |  0:02:48s\n",
            "epoch 80 | loss: 0.44528 | val_0_accuracy: 0.78951 |  0:02:50s\n",
            "epoch 81 | loss: 0.45043 | val_0_accuracy: 0.78584 |  0:02:52s\n",
            "epoch 82 | loss: 0.44719 | val_0_accuracy: 0.78217 |  0:02:54s\n",
            "\n",
            "Early stopping occurred at epoch 82 with best_epoch = 72 and best_val_0_accuracy = 0.79059\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 07:44:35,674]\u001b[0m Trial 0 finished with value: 0.790587219343696 and parameters: {'n_d': 47, 'n_a': 39, 'n_steps': 5, 'gamma': 1.2195459451766517, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.015289150352253908}. Best is trial 0 with value: 0.790587219343696.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.65      0.60      0.63       826\n",
            "           2       0.82      0.92      0.87       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.54      0.54      0.54       761\n",
            "           5       0.67      0.64      0.66       619\n",
            "\n",
            "    accuracy                           0.79      4632\n",
            "   macro avg       0.78      0.78      0.78      4632\n",
            "weighted avg       0.79      0.79      0.79      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.7586  | val_0_accuracy: 0.46438 |  0:00:04s\n",
            "epoch 1  | loss: 1.1732  | val_0_accuracy: 0.54879 |  0:00:09s\n",
            "epoch 2  | loss: 1.11059 | val_0_accuracy: 0.52051 |  0:00:14s\n",
            "epoch 3  | loss: 1.03727 | val_0_accuracy: 0.58614 |  0:00:19s\n",
            "epoch 4  | loss: 0.88532 | val_0_accuracy: 0.61161 |  0:00:24s\n",
            "epoch 5  | loss: 0.83696 | val_0_accuracy: 0.644   |  0:00:29s\n",
            "epoch 6  | loss: 0.7946  | val_0_accuracy: 0.65242 |  0:00:33s\n",
            "epoch 7  | loss: 0.76479 | val_0_accuracy: 0.66278 |  0:00:39s\n",
            "epoch 8  | loss: 0.74568 | val_0_accuracy: 0.66278 |  0:00:44s\n",
            "epoch 9  | loss: 0.74428 | val_0_accuracy: 0.6671  |  0:00:49s\n",
            "epoch 10 | loss: 0.73075 | val_0_accuracy: 0.67185 |  0:00:53s\n",
            "epoch 11 | loss: 0.72342 | val_0_accuracy: 0.68199 |  0:00:58s\n",
            "epoch 12 | loss: 0.716   | val_0_accuracy: 0.68027 |  0:01:03s\n",
            "epoch 13 | loss: 0.71246 | val_0_accuracy: 0.66775 |  0:01:08s\n",
            "epoch 14 | loss: 0.71053 | val_0_accuracy: 0.67897 |  0:01:13s\n",
            "epoch 15 | loss: 0.69449 | val_0_accuracy: 0.68696 |  0:01:17s\n",
            "epoch 16 | loss: 0.69873 | val_0_accuracy: 0.68912 |  0:01:22s\n",
            "epoch 17 | loss: 0.6885  | val_0_accuracy: 0.69927 |  0:01:27s\n",
            "epoch 18 | loss: 0.68428 | val_0_accuracy: 0.69063 |  0:01:32s\n",
            "epoch 19 | loss: 0.67265 | val_0_accuracy: 0.68286 |  0:01:37s\n",
            "epoch 20 | loss: 0.67757 | val_0_accuracy: 0.70056 |  0:01:41s\n",
            "epoch 21 | loss: 0.66507 | val_0_accuracy: 0.70445 |  0:01:47s\n",
            "epoch 22 | loss: 0.65572 | val_0_accuracy: 0.70229 |  0:01:52s\n",
            "epoch 23 | loss: 0.65285 | val_0_accuracy: 0.71459 |  0:01:57s\n",
            "epoch 24 | loss: 0.64669 | val_0_accuracy: 0.71373 |  0:02:02s\n",
            "epoch 25 | loss: 0.64062 | val_0_accuracy: 0.71287 |  0:02:06s\n",
            "epoch 26 | loss: 0.64578 | val_0_accuracy: 0.61291 |  0:02:11s\n",
            "epoch 27 | loss: 0.69351 | val_0_accuracy: 0.69365 |  0:02:16s\n",
            "epoch 28 | loss: 0.68195 | val_0_accuracy: 0.70078 |  0:02:21s\n",
            "epoch 29 | loss: 0.65782 | val_0_accuracy: 0.7038  |  0:02:25s\n",
            "epoch 30 | loss: 0.65157 | val_0_accuracy: 0.70833 |  0:02:30s\n",
            "epoch 31 | loss: 0.63889 | val_0_accuracy: 0.72193 |  0:02:35s\n",
            "epoch 32 | loss: 0.63358 | val_0_accuracy: 0.71265 |  0:02:40s\n",
            "epoch 33 | loss: 0.62737 | val_0_accuracy: 0.70877 |  0:02:44s\n",
            "epoch 34 | loss: 0.62614 | val_0_accuracy: 0.71805 |  0:02:49s\n",
            "epoch 35 | loss: 0.61857 | val_0_accuracy: 0.7282  |  0:02:54s\n",
            "epoch 36 | loss: 0.61188 | val_0_accuracy: 0.72085 |  0:02:58s\n",
            "epoch 37 | loss: 0.61219 | val_0_accuracy: 0.72841 |  0:03:03s\n",
            "epoch 38 | loss: 0.60832 | val_0_accuracy: 0.7187  |  0:03:08s\n",
            "epoch 39 | loss: 0.60731 | val_0_accuracy: 0.72604 |  0:03:13s\n",
            "epoch 40 | loss: 0.60415 | val_0_accuracy: 0.73187 |  0:03:18s\n",
            "epoch 41 | loss: 0.59956 | val_0_accuracy: 0.73877 |  0:03:22s\n",
            "epoch 42 | loss: 0.59597 | val_0_accuracy: 0.71049 |  0:03:27s\n",
            "epoch 43 | loss: 0.59621 | val_0_accuracy: 0.73402 |  0:03:32s\n",
            "epoch 44 | loss: 0.58878 | val_0_accuracy: 0.73122 |  0:03:36s\n",
            "epoch 45 | loss: 0.59235 | val_0_accuracy: 0.73467 |  0:03:41s\n",
            "epoch 46 | loss: 0.58586 | val_0_accuracy: 0.73338 |  0:03:46s\n",
            "epoch 47 | loss: 0.57755 | val_0_accuracy: 0.74028 |  0:03:51s\n",
            "epoch 48 | loss: 0.57148 | val_0_accuracy: 0.73014 |  0:03:55s\n",
            "epoch 49 | loss: 0.59082 | val_0_accuracy: 0.73921 |  0:04:00s\n",
            "epoch 50 | loss: 0.59138 | val_0_accuracy: 0.73921 |  0:04:05s\n",
            "epoch 51 | loss: 0.57334 | val_0_accuracy: 0.74396 |  0:04:10s\n",
            "epoch 52 | loss: 0.56474 | val_0_accuracy: 0.74892 |  0:04:15s\n",
            "epoch 53 | loss: 0.55625 | val_0_accuracy: 0.73014 |  0:04:19s\n",
            "epoch 54 | loss: 0.57263 | val_0_accuracy: 0.74892 |  0:04:24s\n",
            "epoch 55 | loss: 0.55889 | val_0_accuracy: 0.74374 |  0:04:29s\n",
            "epoch 56 | loss: 0.55209 | val_0_accuracy: 0.75194 |  0:04:34s\n",
            "epoch 57 | loss: 0.56402 | val_0_accuracy: 0.75043 |  0:04:39s\n",
            "epoch 58 | loss: 0.58157 | val_0_accuracy: 0.74611 |  0:04:43s\n",
            "epoch 59 | loss: 0.5576  | val_0_accuracy: 0.75389 |  0:04:48s\n",
            "epoch 60 | loss: 0.54847 | val_0_accuracy: 0.75518 |  0:04:53s\n",
            "epoch 61 | loss: 0.54699 | val_0_accuracy: 0.75302 |  0:04:58s\n",
            "epoch 62 | loss: 0.55402 | val_0_accuracy: 0.75648 |  0:05:03s\n",
            "epoch 63 | loss: 0.54542 | val_0_accuracy: 0.76382 |  0:05:07s\n",
            "epoch 64 | loss: 0.53302 | val_0_accuracy: 0.76166 |  0:05:12s\n",
            "epoch 65 | loss: 0.52632 | val_0_accuracy: 0.76101 |  0:05:17s\n",
            "epoch 66 | loss: 0.52516 | val_0_accuracy: 0.7595  |  0:05:22s\n",
            "epoch 67 | loss: 0.52743 | val_0_accuracy: 0.76317 |  0:05:27s\n",
            "epoch 68 | loss: 0.51972 | val_0_accuracy: 0.76727 |  0:05:31s\n",
            "epoch 69 | loss: 0.51588 | val_0_accuracy: 0.7677  |  0:05:36s\n",
            "epoch 70 | loss: 0.52377 | val_0_accuracy: 0.76641 |  0:05:41s\n",
            "epoch 71 | loss: 0.51635 | val_0_accuracy: 0.76921 |  0:05:46s\n",
            "epoch 72 | loss: 0.51175 | val_0_accuracy: 0.77396 |  0:05:50s\n",
            "epoch 73 | loss: 0.50758 | val_0_accuracy: 0.77483 |  0:05:55s\n",
            "epoch 74 | loss: 0.50359 | val_0_accuracy: 0.77396 |  0:06:00s\n",
            "epoch 75 | loss: 0.5067  | val_0_accuracy: 0.76878 |  0:06:05s\n",
            "epoch 76 | loss: 0.50018 | val_0_accuracy: 0.7731  |  0:06:10s\n",
            "epoch 77 | loss: 0.51137 | val_0_accuracy: 0.76166 |  0:06:17s\n",
            "epoch 78 | loss: 0.52563 | val_0_accuracy: 0.76857 |  0:06:22s\n",
            "epoch 79 | loss: 0.52225 | val_0_accuracy: 0.76835 |  0:06:27s\n",
            "epoch 80 | loss: 0.51145 | val_0_accuracy: 0.77116 |  0:06:32s\n",
            "epoch 81 | loss: 0.49924 | val_0_accuracy: 0.78217 |  0:06:37s\n",
            "epoch 82 | loss: 0.49227 | val_0_accuracy: 0.7785  |  0:06:41s\n",
            "epoch 83 | loss: 0.4888  | val_0_accuracy: 0.77785 |  0:06:46s\n",
            "epoch 84 | loss: 0.48423 | val_0_accuracy: 0.7813  |  0:06:51s\n",
            "epoch 85 | loss: 0.48444 | val_0_accuracy: 0.7826  |  0:06:56s\n",
            "epoch 86 | loss: 0.48119 | val_0_accuracy: 0.78325 |  0:07:03s\n",
            "epoch 87 | loss: 0.4784  | val_0_accuracy: 0.7772  |  0:07:08s\n",
            "epoch 88 | loss: 0.47851 | val_0_accuracy: 0.78238 |  0:07:12s\n",
            "epoch 89 | loss: 0.47109 | val_0_accuracy: 0.78238 |  0:07:17s\n",
            "epoch 90 | loss: 0.4706  | val_0_accuracy: 0.78497 |  0:07:22s\n",
            "epoch 91 | loss: 0.47004 | val_0_accuracy: 0.78821 |  0:07:27s\n",
            "epoch 92 | loss: 0.47043 | val_0_accuracy: 0.78497 |  0:07:31s\n",
            "epoch 93 | loss: 0.46943 | val_0_accuracy: 0.78713 |  0:07:36s\n",
            "epoch 94 | loss: 0.47106 | val_0_accuracy: 0.78886 |  0:07:41s\n",
            "epoch 95 | loss: 0.46796 | val_0_accuracy: 0.78692 |  0:07:47s\n",
            "epoch 96 | loss: 0.46518 | val_0_accuracy: 0.7867  |  0:07:51s\n",
            "epoch 97 | loss: 0.46017 | val_0_accuracy: 0.79339 |  0:07:56s\n",
            "epoch 98 | loss: 0.45925 | val_0_accuracy: 0.78994 |  0:08:01s\n",
            "epoch 99 | loss: 0.45532 | val_0_accuracy: 0.78951 |  0:08:06s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 97 and best_val_0_accuracy = 0.79339\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 07:52:44,211]\u001b[0m Trial 1 finished with value: 0.7933937823834197 and parameters: {'n_d': 8, 'n_a': 52, 'n_steps': 7, 'gamma': 1.4712770362880545, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.26200944992984126}. Best is trial 1 with value: 0.7933937823834197.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.67      0.56      0.61       826\n",
            "           2       0.81      0.95      0.87       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.53      0.62      0.57       761\n",
            "           5       0.75      0.58      0.65       619\n",
            "\n",
            "    accuracy                           0.79      4632\n",
            "   macro avg       0.79      0.78      0.78      4632\n",
            "weighted avg       0.80      0.79      0.79      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.34167 | val_0_accuracy: 0.58528 |  0:00:01s\n",
            "epoch 1  | loss: 0.89607 | val_0_accuracy: 0.63277 |  0:00:02s\n",
            "epoch 2  | loss: 0.80633 | val_0_accuracy: 0.65199 |  0:00:04s\n",
            "epoch 3  | loss: 0.76294 | val_0_accuracy: 0.66947 |  0:00:05s\n",
            "epoch 4  | loss: 0.73019 | val_0_accuracy: 0.67681 |  0:00:07s\n",
            "epoch 5  | loss: 0.71498 | val_0_accuracy: 0.69408 |  0:00:08s\n",
            "epoch 6  | loss: 0.70251 | val_0_accuracy: 0.69408 |  0:00:10s\n",
            "epoch 7  | loss: 0.68903 | val_0_accuracy: 0.70056 |  0:00:11s\n",
            "epoch 8  | loss: 0.68161 | val_0_accuracy: 0.69668 |  0:00:12s\n",
            "epoch 9  | loss: 0.66814 | val_0_accuracy: 0.70596 |  0:00:14s\n",
            "epoch 10 | loss: 0.673   | val_0_accuracy: 0.70164 |  0:00:15s\n",
            "epoch 11 | loss: 0.66345 | val_0_accuracy: 0.70725 |  0:00:17s\n",
            "epoch 12 | loss: 0.65761 | val_0_accuracy: 0.70488 |  0:00:18s\n",
            "epoch 13 | loss: 0.64439 | val_0_accuracy: 0.71416 |  0:00:19s\n",
            "epoch 14 | loss: 0.63628 | val_0_accuracy: 0.72258 |  0:00:21s\n",
            "epoch 15 | loss: 0.63036 | val_0_accuracy: 0.72193 |  0:00:22s\n",
            "epoch 16 | loss: 0.61885 | val_0_accuracy: 0.72625 |  0:00:24s\n",
            "epoch 17 | loss: 0.61991 | val_0_accuracy: 0.72388 |  0:00:25s\n",
            "epoch 18 | loss: 0.60878 | val_0_accuracy: 0.72927 |  0:00:26s\n",
            "epoch 19 | loss: 0.60427 | val_0_accuracy: 0.72798 |  0:00:28s\n",
            "epoch 20 | loss: 0.59481 | val_0_accuracy: 0.74201 |  0:00:29s\n",
            "epoch 21 | loss: 0.60101 | val_0_accuracy: 0.73856 |  0:00:31s\n",
            "epoch 22 | loss: 0.58848 | val_0_accuracy: 0.73964 |  0:00:32s\n",
            "epoch 23 | loss: 0.58701 | val_0_accuracy: 0.73402 |  0:00:33s\n",
            "epoch 24 | loss: 0.57934 | val_0_accuracy: 0.74201 |  0:00:35s\n",
            "epoch 25 | loss: 0.58941 | val_0_accuracy: 0.74158 |  0:00:36s\n",
            "epoch 26 | loss: 0.58409 | val_0_accuracy: 0.74655 |  0:00:37s\n",
            "epoch 27 | loss: 0.59    | val_0_accuracy: 0.73856 |  0:00:39s\n",
            "epoch 28 | loss: 0.58269 | val_0_accuracy: 0.73402 |  0:00:40s\n",
            "epoch 29 | loss: 0.56809 | val_0_accuracy: 0.76382 |  0:00:42s\n",
            "epoch 30 | loss: 0.56483 | val_0_accuracy: 0.7487  |  0:00:43s\n",
            "epoch 31 | loss: 0.56138 | val_0_accuracy: 0.75259 |  0:00:44s\n",
            "epoch 32 | loss: 0.55352 | val_0_accuracy: 0.75432 |  0:00:46s\n",
            "epoch 33 | loss: 0.55032 | val_0_accuracy: 0.73424 |  0:00:47s\n",
            "epoch 34 | loss: 0.55094 | val_0_accuracy: 0.75734 |  0:00:49s\n",
            "epoch 35 | loss: 0.54864 | val_0_accuracy: 0.75734 |  0:00:50s\n",
            "epoch 36 | loss: 0.53881 | val_0_accuracy: 0.75432 |  0:00:51s\n",
            "epoch 37 | loss: 0.54027 | val_0_accuracy: 0.75972 |  0:00:53s\n",
            "epoch 38 | loss: 0.53877 | val_0_accuracy: 0.76231 |  0:00:54s\n",
            "epoch 39 | loss: 0.53069 | val_0_accuracy: 0.76554 |  0:00:56s\n",
            "epoch 40 | loss: 0.53025 | val_0_accuracy: 0.76079 |  0:00:57s\n",
            "epoch 41 | loss: 0.53106 | val_0_accuracy: 0.76684 |  0:00:58s\n",
            "epoch 42 | loss: 0.528   | val_0_accuracy: 0.77224 |  0:01:00s\n",
            "epoch 43 | loss: 0.52556 | val_0_accuracy: 0.769   |  0:01:01s\n",
            "epoch 44 | loss: 0.52237 | val_0_accuracy: 0.77375 |  0:01:03s\n",
            "epoch 45 | loss: 0.52379 | val_0_accuracy: 0.76965 |  0:01:04s\n",
            "epoch 46 | loss: 0.51939 | val_0_accuracy: 0.76857 |  0:01:05s\n",
            "epoch 47 | loss: 0.51307 | val_0_accuracy: 0.76921 |  0:01:07s\n",
            "epoch 48 | loss: 0.51163 | val_0_accuracy: 0.7772  |  0:01:08s\n",
            "epoch 49 | loss: 0.51317 | val_0_accuracy: 0.76986 |  0:01:10s\n",
            "epoch 50 | loss: 0.51077 | val_0_accuracy: 0.76813 |  0:01:11s\n",
            "epoch 51 | loss: 0.50668 | val_0_accuracy: 0.77828 |  0:01:13s\n",
            "epoch 52 | loss: 0.49989 | val_0_accuracy: 0.77634 |  0:01:14s\n",
            "epoch 53 | loss: 0.4975  | val_0_accuracy: 0.77245 |  0:01:15s\n",
            "epoch 54 | loss: 0.50168 | val_0_accuracy: 0.77526 |  0:01:17s\n",
            "epoch 55 | loss: 0.498   | val_0_accuracy: 0.77958 |  0:01:18s\n",
            "epoch 56 | loss: 0.49231 | val_0_accuracy: 0.77073 |  0:01:20s\n",
            "epoch 57 | loss: 0.50795 | val_0_accuracy: 0.78001 |  0:01:21s\n",
            "epoch 58 | loss: 0.49709 | val_0_accuracy: 0.77245 |  0:01:22s\n",
            "epoch 59 | loss: 0.49288 | val_0_accuracy: 0.77569 |  0:01:24s\n",
            "epoch 60 | loss: 0.49507 | val_0_accuracy: 0.77893 |  0:01:25s\n",
            "epoch 61 | loss: 0.48959 | val_0_accuracy: 0.7785  |  0:01:27s\n",
            "epoch 62 | loss: 0.48486 | val_0_accuracy: 0.77958 |  0:01:28s\n",
            "epoch 63 | loss: 0.48412 | val_0_accuracy: 0.77763 |  0:01:29s\n",
            "epoch 64 | loss: 0.47769 | val_0_accuracy: 0.77958 |  0:01:31s\n",
            "epoch 65 | loss: 0.47804 | val_0_accuracy: 0.78649 |  0:01:32s\n",
            "epoch 66 | loss: 0.47655 | val_0_accuracy: 0.7813  |  0:01:33s\n",
            "epoch 67 | loss: 0.48075 | val_0_accuracy: 0.77461 |  0:01:35s\n",
            "epoch 68 | loss: 0.47862 | val_0_accuracy: 0.7744  |  0:01:36s\n",
            "epoch 69 | loss: 0.47169 | val_0_accuracy: 0.78346 |  0:01:38s\n",
            "epoch 70 | loss: 0.47376 | val_0_accuracy: 0.78864 |  0:01:39s\n",
            "epoch 71 | loss: 0.46692 | val_0_accuracy: 0.77504 |  0:01:40s\n",
            "epoch 72 | loss: 0.47101 | val_0_accuracy: 0.78649 |  0:01:42s\n",
            "epoch 73 | loss: 0.47006 | val_0_accuracy: 0.78886 |  0:01:43s\n",
            "epoch 74 | loss: 0.46652 | val_0_accuracy: 0.7826  |  0:01:45s\n",
            "epoch 75 | loss: 0.46248 | val_0_accuracy: 0.78346 |  0:01:46s\n",
            "epoch 76 | loss: 0.46781 | val_0_accuracy: 0.7921  |  0:01:47s\n",
            "epoch 77 | loss: 0.46079 | val_0_accuracy: 0.78433 |  0:01:49s\n",
            "epoch 78 | loss: 0.46069 | val_0_accuracy: 0.78001 |  0:01:50s\n",
            "epoch 79 | loss: 0.46375 | val_0_accuracy: 0.78238 |  0:01:51s\n",
            "epoch 80 | loss: 0.45868 | val_0_accuracy: 0.7908  |  0:01:53s\n",
            "epoch 81 | loss: 0.45482 | val_0_accuracy: 0.78994 |  0:01:54s\n",
            "epoch 82 | loss: 0.4468  | val_0_accuracy: 0.78605 |  0:01:56s\n",
            "epoch 83 | loss: 0.46951 | val_0_accuracy: 0.77396 |  0:01:57s\n",
            "epoch 84 | loss: 0.46799 | val_0_accuracy: 0.78411 |  0:01:58s\n",
            "epoch 85 | loss: 0.45448 | val_0_accuracy: 0.78174 |  0:02:00s\n",
            "epoch 86 | loss: 0.45515 | val_0_accuracy: 0.79577 |  0:02:01s\n",
            "epoch 87 | loss: 0.44997 | val_0_accuracy: 0.7921  |  0:02:02s\n",
            "epoch 88 | loss: 0.44297 | val_0_accuracy: 0.78325 |  0:02:04s\n",
            "epoch 89 | loss: 0.4463  | val_0_accuracy: 0.77547 |  0:02:05s\n",
            "epoch 90 | loss: 0.45392 | val_0_accuracy: 0.78713 |  0:02:07s\n",
            "epoch 91 | loss: 0.45022 | val_0_accuracy: 0.78821 |  0:02:08s\n",
            "epoch 92 | loss: 0.4431  | val_0_accuracy: 0.78735 |  0:02:09s\n",
            "epoch 93 | loss: 0.44292 | val_0_accuracy: 0.78713 |  0:02:11s\n",
            "epoch 94 | loss: 0.43993 | val_0_accuracy: 0.79123 |  0:02:12s\n",
            "epoch 95 | loss: 0.43924 | val_0_accuracy: 0.78001 |  0:02:13s\n",
            "epoch 96 | loss: 0.43903 | val_0_accuracy: 0.78843 |  0:02:15s\n",
            "\n",
            "Early stopping occurred at epoch 96 with best_epoch = 86 and best_val_0_accuracy = 0.79577\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 07:55:00,169]\u001b[0m Trial 2 finished with value: 0.7957685664939551 and parameters: {'n_d': 55, 'n_a': 22, 'n_steps': 4, 'gamma': 1.730139346844563, 'n_independent': 1, 'n_shared': 1, 'momentum': 0.3922372978142319}. Best is trial 2 with value: 0.7957685664939551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.65      0.58      0.61       826\n",
            "           2       0.82      0.94      0.87       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.55      0.58      0.57       761\n",
            "           5       0.71      0.63      0.67       619\n",
            "\n",
            "    accuracy                           0.80      4632\n",
            "   macro avg       0.79      0.79      0.79      4632\n",
            "weighted avg       0.79      0.80      0.79      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.093   | val_0_accuracy: 0.606   |  0:00:01s\n",
            "epoch 1  | loss: 0.82953 | val_0_accuracy: 0.63687 |  0:00:02s\n",
            "epoch 2  | loss: 0.77717 | val_0_accuracy: 0.66192 |  0:00:04s\n",
            "epoch 3  | loss: 0.73974 | val_0_accuracy: 0.68502 |  0:00:05s\n",
            "epoch 4  | loss: 0.70489 | val_0_accuracy: 0.68199 |  0:00:07s\n",
            "epoch 5  | loss: 0.69356 | val_0_accuracy: 0.69819 |  0:00:08s\n",
            "epoch 6  | loss: 0.67394 | val_0_accuracy: 0.70035 |  0:00:09s\n",
            "epoch 7  | loss: 0.66571 | val_0_accuracy: 0.71157 |  0:00:11s\n",
            "epoch 8  | loss: 0.65303 | val_0_accuracy: 0.70423 |  0:00:12s\n",
            "epoch 9  | loss: 0.64748 | val_0_accuracy: 0.71891 |  0:00:14s\n",
            "epoch 10 | loss: 0.64276 | val_0_accuracy: 0.70855 |  0:00:15s\n",
            "epoch 11 | loss: 0.63498 | val_0_accuracy: 0.72668 |  0:00:16s\n",
            "epoch 12 | loss: 0.62842 | val_0_accuracy: 0.72301 |  0:00:18s\n",
            "epoch 13 | loss: 0.62016 | val_0_accuracy: 0.72668 |  0:00:19s\n",
            "epoch 14 | loss: 0.61365 | val_0_accuracy: 0.72949 |  0:00:21s\n",
            "epoch 15 | loss: 0.61133 | val_0_accuracy: 0.72798 |  0:00:22s\n",
            "epoch 16 | loss: 0.60214 | val_0_accuracy: 0.73791 |  0:00:23s\n",
            "epoch 17 | loss: 0.60187 | val_0_accuracy: 0.73446 |  0:00:25s\n",
            "epoch 18 | loss: 0.59131 | val_0_accuracy: 0.73618 |  0:00:26s\n",
            "epoch 19 | loss: 0.59656 | val_0_accuracy: 0.73532 |  0:00:28s\n",
            "epoch 20 | loss: 0.5856  | val_0_accuracy: 0.73079 |  0:00:29s\n",
            "epoch 21 | loss: 0.58439 | val_0_accuracy: 0.74115 |  0:00:30s\n",
            "epoch 22 | loss: 0.57661 | val_0_accuracy: 0.7459  |  0:00:32s\n",
            "epoch 23 | loss: 0.57591 | val_0_accuracy: 0.74158 |  0:00:33s\n",
            "epoch 24 | loss: 0.56716 | val_0_accuracy: 0.74374 |  0:00:35s\n",
            "epoch 25 | loss: 0.57313 | val_0_accuracy: 0.74611 |  0:00:36s\n",
            "epoch 26 | loss: 0.5674  | val_0_accuracy: 0.73985 |  0:00:38s\n",
            "epoch 27 | loss: 0.56129 | val_0_accuracy: 0.75453 |  0:00:39s\n",
            "epoch 28 | loss: 0.55561 | val_0_accuracy: 0.75712 |  0:00:40s\n",
            "epoch 29 | loss: 0.55308 | val_0_accuracy: 0.76058 |  0:00:42s\n",
            "epoch 30 | loss: 0.54535 | val_0_accuracy: 0.7636  |  0:00:43s\n",
            "epoch 31 | loss: 0.54327 | val_0_accuracy: 0.75367 |  0:00:45s\n",
            "epoch 32 | loss: 0.54243 | val_0_accuracy: 0.76511 |  0:00:46s\n",
            "epoch 33 | loss: 0.53661 | val_0_accuracy: 0.75648 |  0:00:47s\n",
            "epoch 34 | loss: 0.53241 | val_0_accuracy: 0.76403 |  0:00:49s\n",
            "epoch 35 | loss: 0.52167 | val_0_accuracy: 0.76252 |  0:00:50s\n",
            "epoch 36 | loss: 0.53414 | val_0_accuracy: 0.7649  |  0:00:52s\n",
            "epoch 37 | loss: 0.52245 | val_0_accuracy: 0.77159 |  0:00:53s\n",
            "epoch 38 | loss: 0.51003 | val_0_accuracy: 0.77245 |  0:00:54s\n",
            "epoch 39 | loss: 0.51347 | val_0_accuracy: 0.77008 |  0:00:56s\n",
            "epoch 40 | loss: 0.5141  | val_0_accuracy: 0.77159 |  0:00:57s\n",
            "epoch 41 | loss: 0.52049 | val_0_accuracy: 0.76576 |  0:00:59s\n",
            "epoch 42 | loss: 0.51216 | val_0_accuracy: 0.76662 |  0:01:00s\n",
            "epoch 43 | loss: 0.51531 | val_0_accuracy: 0.7595  |  0:01:01s\n",
            "epoch 44 | loss: 0.5114  | val_0_accuracy: 0.76813 |  0:01:03s\n",
            "epoch 45 | loss: 0.49966 | val_0_accuracy: 0.77893 |  0:01:04s\n",
            "epoch 46 | loss: 0.49353 | val_0_accuracy: 0.7731  |  0:01:06s\n",
            "epoch 47 | loss: 0.49339 | val_0_accuracy: 0.77396 |  0:01:07s\n",
            "epoch 48 | loss: 0.48775 | val_0_accuracy: 0.7731  |  0:01:09s\n",
            "epoch 49 | loss: 0.49309 | val_0_accuracy: 0.77353 |  0:01:10s\n",
            "epoch 50 | loss: 0.4824  | val_0_accuracy: 0.78282 |  0:01:11s\n",
            "epoch 51 | loss: 0.48329 | val_0_accuracy: 0.77418 |  0:01:13s\n",
            "epoch 52 | loss: 0.47887 | val_0_accuracy: 0.78152 |  0:01:14s\n",
            "epoch 53 | loss: 0.47443 | val_0_accuracy: 0.78692 |  0:01:16s\n",
            "epoch 54 | loss: 0.49987 | val_0_accuracy: 0.78174 |  0:01:17s\n",
            "epoch 55 | loss: 0.48655 | val_0_accuracy: 0.78044 |  0:01:19s\n",
            "epoch 56 | loss: 0.48097 | val_0_accuracy: 0.77785 |  0:01:20s\n",
            "epoch 57 | loss: 0.47519 | val_0_accuracy: 0.78476 |  0:01:21s\n",
            "epoch 58 | loss: 0.47291 | val_0_accuracy: 0.78951 |  0:01:23s\n",
            "epoch 59 | loss: 0.47415 | val_0_accuracy: 0.78994 |  0:01:24s\n",
            "epoch 60 | loss: 0.4685  | val_0_accuracy: 0.78843 |  0:01:26s\n",
            "epoch 61 | loss: 0.46475 | val_0_accuracy: 0.78195 |  0:01:27s\n",
            "epoch 62 | loss: 0.45834 | val_0_accuracy: 0.78843 |  0:01:28s\n",
            "epoch 63 | loss: 0.45921 | val_0_accuracy: 0.78001 |  0:01:30s\n",
            "epoch 64 | loss: 0.4574  | val_0_accuracy: 0.78821 |  0:01:31s\n",
            "epoch 65 | loss: 0.45667 | val_0_accuracy: 0.78735 |  0:01:33s\n",
            "epoch 66 | loss: 0.45294 | val_0_accuracy: 0.78886 |  0:01:34s\n",
            "epoch 67 | loss: 0.4489  | val_0_accuracy: 0.78929 |  0:01:35s\n",
            "epoch 68 | loss: 0.45188 | val_0_accuracy: 0.79318 |  0:01:37s\n",
            "epoch 69 | loss: 0.44545 | val_0_accuracy: 0.79231 |  0:01:38s\n",
            "epoch 70 | loss: 0.44406 | val_0_accuracy: 0.79771 |  0:01:40s\n",
            "epoch 71 | loss: 0.43844 | val_0_accuracy: 0.78433 |  0:01:41s\n",
            "epoch 72 | loss: 0.44161 | val_0_accuracy: 0.79102 |  0:01:43s\n",
            "epoch 73 | loss: 0.44033 | val_0_accuracy: 0.7921  |  0:01:44s\n",
            "epoch 74 | loss: 0.44295 | val_0_accuracy: 0.79016 |  0:01:45s\n",
            "epoch 75 | loss: 0.44036 | val_0_accuracy: 0.79339 |  0:01:47s\n",
            "epoch 76 | loss: 0.43746 | val_0_accuracy: 0.79339 |  0:01:48s\n",
            "epoch 77 | loss: 0.4424  | val_0_accuracy: 0.79858 |  0:01:50s\n",
            "epoch 78 | loss: 0.43004 | val_0_accuracy: 0.79965 |  0:01:51s\n",
            "epoch 79 | loss: 0.42706 | val_0_accuracy: 0.79793 |  0:01:52s\n",
            "epoch 80 | loss: 0.42712 | val_0_accuracy: 0.79598 |  0:01:54s\n",
            "epoch 81 | loss: 0.44125 | val_0_accuracy: 0.78756 |  0:01:55s\n",
            "epoch 82 | loss: 0.44326 | val_0_accuracy: 0.7921  |  0:01:57s\n",
            "epoch 83 | loss: 0.44414 | val_0_accuracy: 0.78886 |  0:01:58s\n",
            "epoch 84 | loss: 0.42564 | val_0_accuracy: 0.79922 |  0:02:00s\n",
            "epoch 85 | loss: 0.42361 | val_0_accuracy: 0.80009 |  0:02:01s\n",
            "epoch 86 | loss: 0.4245  | val_0_accuracy: 0.79793 |  0:02:02s\n",
            "epoch 87 | loss: 0.41931 | val_0_accuracy: 0.79663 |  0:02:04s\n",
            "epoch 88 | loss: 0.41445 | val_0_accuracy: 0.8003  |  0:02:05s\n",
            "epoch 89 | loss: 0.41255 | val_0_accuracy: 0.80376 |  0:02:07s\n",
            "epoch 90 | loss: 0.41948 | val_0_accuracy: 0.79663 |  0:02:08s\n",
            "epoch 91 | loss: 0.4136  | val_0_accuracy: 0.80354 |  0:02:09s\n",
            "epoch 92 | loss: 0.43378 | val_0_accuracy: 0.79534 |  0:02:11s\n",
            "epoch 93 | loss: 0.42019 | val_0_accuracy: 0.80095 |  0:02:12s\n",
            "epoch 94 | loss: 0.40869 | val_0_accuracy: 0.79706 |  0:02:14s\n",
            "epoch 95 | loss: 0.41486 | val_0_accuracy: 0.79944 |  0:02:15s\n",
            "epoch 96 | loss: 0.40918 | val_0_accuracy: 0.79836 |  0:02:17s\n",
            "epoch 97 | loss: 0.40506 | val_0_accuracy: 0.79858 |  0:02:18s\n",
            "epoch 98 | loss: 0.40689 | val_0_accuracy: 0.80052 |  0:02:19s\n",
            "epoch 99 | loss: 0.40671 | val_0_accuracy: 0.79512 |  0:02:21s\n",
            "\n",
            "Early stopping occurred at epoch 99 with best_epoch = 89 and best_val_0_accuracy = 0.80376\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 07:57:22,255]\u001b[0m Trial 3 finished with value: 0.8037564766839378 and parameters: {'n_d': 17, 'n_a': 55, 'n_steps': 3, 'gamma': 1.2906043466163537, 'n_independent': 2, 'n_shared': 1, 'momentum': 0.3578040087905696}. Best is trial 3 with value: 0.8037564766839378.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.67      0.65      0.66       826\n",
            "           2       0.82      0.97      0.89       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.58      0.52      0.55       761\n",
            "           5       0.68      0.64      0.66       619\n",
            "\n",
            "    accuracy                           0.80      4632\n",
            "   macro avg       0.79      0.80      0.79      4632\n",
            "weighted avg       0.80      0.80      0.80      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 2.34669 | val_0_accuracy: 0.44085 |  0:00:05s\n",
            "epoch 1  | loss: 1.40715 | val_0_accuracy: 0.48791 |  0:00:11s\n",
            "epoch 2  | loss: 1.31351 | val_0_accuracy: 0.4022  |  0:00:17s\n",
            "epoch 3  | loss: 1.15326 | val_0_accuracy: 0.6032  |  0:00:23s\n",
            "epoch 4  | loss: 0.87115 | val_0_accuracy: 0.62263 |  0:00:28s\n",
            "epoch 5  | loss: 0.80607 | val_0_accuracy: 0.65652 |  0:00:34s\n",
            "epoch 6  | loss: 0.75905 | val_0_accuracy: 0.66343 |  0:00:40s\n",
            "epoch 7  | loss: 0.73996 | val_0_accuracy: 0.66839 |  0:00:46s\n",
            "epoch 8  | loss: 0.7263  | val_0_accuracy: 0.67768 |  0:00:52s\n",
            "epoch 9  | loss: 0.71502 | val_0_accuracy: 0.68718 |  0:00:58s\n",
            "epoch 10 | loss: 0.71012 | val_0_accuracy: 0.68631 |  0:01:04s\n",
            "epoch 11 | loss: 0.70841 | val_0_accuracy: 0.68351 |  0:01:10s\n",
            "epoch 12 | loss: 0.70493 | val_0_accuracy: 0.68307 |  0:01:16s\n",
            "epoch 13 | loss: 0.70296 | val_0_accuracy: 0.66753 |  0:01:22s\n",
            "epoch 14 | loss: 0.70609 | val_0_accuracy: 0.67595 |  0:01:27s\n",
            "epoch 15 | loss: 0.68893 | val_0_accuracy: 0.69991 |  0:01:33s\n",
            "epoch 16 | loss: 0.68243 | val_0_accuracy: 0.69495 |  0:01:39s\n",
            "epoch 17 | loss: 0.67265 | val_0_accuracy: 0.7025  |  0:01:44s\n",
            "epoch 18 | loss: 0.66548 | val_0_accuracy: 0.69754 |  0:01:50s\n",
            "epoch 19 | loss: 0.67123 | val_0_accuracy: 0.69624 |  0:01:56s\n",
            "epoch 20 | loss: 0.68384 | val_0_accuracy: 0.70898 |  0:02:02s\n",
            "epoch 21 | loss: 0.66749 | val_0_accuracy: 0.70294 |  0:02:08s\n",
            "epoch 22 | loss: 0.66684 | val_0_accuracy: 0.70747 |  0:02:14s\n",
            "epoch 23 | loss: 0.65516 | val_0_accuracy: 0.7038  |  0:02:19s\n",
            "epoch 24 | loss: 0.64881 | val_0_accuracy: 0.71611 |  0:02:25s\n",
            "epoch 25 | loss: 0.64045 | val_0_accuracy: 0.71114 |  0:02:31s\n",
            "epoch 26 | loss: 0.6413  | val_0_accuracy: 0.71697 |  0:02:37s\n",
            "epoch 27 | loss: 0.63241 | val_0_accuracy: 0.71071 |  0:02:42s\n",
            "epoch 28 | loss: 0.63229 | val_0_accuracy: 0.71351 |  0:02:48s\n",
            "epoch 29 | loss: 0.63153 | val_0_accuracy: 0.71179 |  0:02:54s\n",
            "epoch 30 | loss: 0.62843 | val_0_accuracy: 0.71503 |  0:02:59s\n",
            "epoch 31 | loss: 0.61836 | val_0_accuracy: 0.71308 |  0:03:05s\n",
            "epoch 32 | loss: 0.63051 | val_0_accuracy: 0.72712 |  0:03:11s\n",
            "epoch 33 | loss: 0.62094 | val_0_accuracy: 0.72129 |  0:03:17s\n",
            "epoch 34 | loss: 0.61143 | val_0_accuracy: 0.72042 |  0:03:23s\n",
            "epoch 35 | loss: 0.61259 | val_0_accuracy: 0.72064 |  0:03:28s\n",
            "epoch 36 | loss: 0.60949 | val_0_accuracy: 0.72107 |  0:03:34s\n",
            "epoch 37 | loss: 0.61505 | val_0_accuracy: 0.7133  |  0:03:40s\n",
            "epoch 38 | loss: 0.61541 | val_0_accuracy: 0.72755 |  0:03:46s\n",
            "epoch 39 | loss: 0.60966 | val_0_accuracy: 0.74115 |  0:03:51s\n",
            "epoch 40 | loss: 0.60134 | val_0_accuracy: 0.73424 |  0:03:57s\n",
            "epoch 41 | loss: 0.60924 | val_0_accuracy: 0.73208 |  0:04:03s\n",
            "epoch 42 | loss: 0.59341 | val_0_accuracy: 0.72474 |  0:04:09s\n",
            "epoch 43 | loss: 0.59144 | val_0_accuracy: 0.74072 |  0:04:14s\n",
            "epoch 44 | loss: 0.59504 | val_0_accuracy: 0.73705 |  0:04:20s\n",
            "epoch 45 | loss: 0.5866  | val_0_accuracy: 0.73424 |  0:04:26s\n",
            "epoch 46 | loss: 0.58786 | val_0_accuracy: 0.73985 |  0:04:31s\n",
            "epoch 47 | loss: 0.58498 | val_0_accuracy: 0.74719 |  0:04:37s\n",
            "epoch 48 | loss: 0.57925 | val_0_accuracy: 0.73942 |  0:04:43s\n",
            "epoch 49 | loss: 0.57909 | val_0_accuracy: 0.74093 |  0:04:48s\n",
            "epoch 50 | loss: 0.57981 | val_0_accuracy: 0.73877 |  0:04:54s\n",
            "epoch 51 | loss: 0.5728  | val_0_accuracy: 0.74396 |  0:05:00s\n",
            "epoch 52 | loss: 0.57119 | val_0_accuracy: 0.7487  |  0:05:05s\n",
            "epoch 53 | loss: 0.56994 | val_0_accuracy: 0.73985 |  0:05:11s\n",
            "epoch 54 | loss: 0.56794 | val_0_accuracy: 0.73597 |  0:05:17s\n",
            "epoch 55 | loss: 0.58446 | val_0_accuracy: 0.73424 |  0:05:22s\n",
            "epoch 56 | loss: 0.58396 | val_0_accuracy: 0.75194 |  0:05:28s\n",
            "epoch 57 | loss: 0.56513 | val_0_accuracy: 0.75237 |  0:05:34s\n",
            "epoch 58 | loss: 0.55911 | val_0_accuracy: 0.74784 |  0:05:40s\n",
            "epoch 59 | loss: 0.55686 | val_0_accuracy: 0.74611 |  0:05:45s\n",
            "epoch 60 | loss: 0.55344 | val_0_accuracy: 0.75108 |  0:05:51s\n",
            "epoch 61 | loss: 0.55846 | val_0_accuracy: 0.74741 |  0:05:57s\n",
            "epoch 62 | loss: 0.54967 | val_0_accuracy: 0.74957 |  0:06:02s\n",
            "epoch 63 | loss: 0.55945 | val_0_accuracy: 0.74072 |  0:06:08s\n",
            "epoch 64 | loss: 0.54502 | val_0_accuracy: 0.75885 |  0:06:14s\n",
            "epoch 65 | loss: 0.5409  | val_0_accuracy: 0.75173 |  0:06:19s\n",
            "epoch 66 | loss: 0.55189 | val_0_accuracy: 0.74611 |  0:06:25s\n",
            "epoch 67 | loss: 0.54742 | val_0_accuracy: 0.75583 |  0:06:31s\n",
            "epoch 68 | loss: 0.53714 | val_0_accuracy: 0.75237 |  0:06:37s\n",
            "epoch 69 | loss: 0.54118 | val_0_accuracy: 0.76079 |  0:06:42s\n",
            "epoch 70 | loss: 0.53611 | val_0_accuracy: 0.75691 |  0:06:48s\n",
            "epoch 71 | loss: 0.52845 | val_0_accuracy: 0.75885 |  0:06:54s\n",
            "epoch 72 | loss: 0.52706 | val_0_accuracy: 0.7513  |  0:07:00s\n",
            "epoch 73 | loss: 0.52756 | val_0_accuracy: 0.76425 |  0:07:05s\n",
            "epoch 74 | loss: 0.52625 | val_0_accuracy: 0.75907 |  0:07:11s\n",
            "epoch 75 | loss: 0.52168 | val_0_accuracy: 0.75259 |  0:07:18s\n",
            "epoch 76 | loss: 0.51568 | val_0_accuracy: 0.75864 |  0:07:23s\n",
            "epoch 77 | loss: 0.51442 | val_0_accuracy: 0.76468 |  0:07:29s\n",
            "epoch 78 | loss: 0.51212 | val_0_accuracy: 0.76857 |  0:07:35s\n",
            "epoch 79 | loss: 0.50944 | val_0_accuracy: 0.76662 |  0:07:41s\n",
            "epoch 80 | loss: 0.50724 | val_0_accuracy: 0.76878 |  0:07:46s\n",
            "epoch 81 | loss: 0.5084  | val_0_accuracy: 0.77159 |  0:07:52s\n",
            "epoch 82 | loss: 0.50913 | val_0_accuracy: 0.77159 |  0:07:58s\n",
            "epoch 83 | loss: 0.50592 | val_0_accuracy: 0.76684 |  0:08:04s\n",
            "epoch 84 | loss: 0.51375 | val_0_accuracy: 0.77612 |  0:08:09s\n",
            "epoch 85 | loss: 0.50592 | val_0_accuracy: 0.76425 |  0:08:15s\n",
            "epoch 86 | loss: 0.50472 | val_0_accuracy: 0.76317 |  0:08:21s\n",
            "epoch 87 | loss: 0.49621 | val_0_accuracy: 0.77288 |  0:08:27s\n",
            "epoch 88 | loss: 0.49768 | val_0_accuracy: 0.7677  |  0:08:32s\n",
            "epoch 89 | loss: 0.49297 | val_0_accuracy: 0.7772  |  0:08:38s\n",
            "epoch 90 | loss: 0.48856 | val_0_accuracy: 0.7731  |  0:08:44s\n",
            "epoch 91 | loss: 0.48854 | val_0_accuracy: 0.7867  |  0:08:50s\n",
            "epoch 92 | loss: 0.48705 | val_0_accuracy: 0.7813  |  0:08:56s\n",
            "epoch 93 | loss: 0.48557 | val_0_accuracy: 0.77915 |  0:09:01s\n",
            "epoch 94 | loss: 0.48014 | val_0_accuracy: 0.77677 |  0:09:07s\n",
            "epoch 95 | loss: 0.48488 | val_0_accuracy: 0.77008 |  0:09:13s\n",
            "epoch 96 | loss: 0.4818  | val_0_accuracy: 0.77612 |  0:09:19s\n",
            "epoch 97 | loss: 0.48538 | val_0_accuracy: 0.75259 |  0:09:25s\n",
            "epoch 98 | loss: 0.50131 | val_0_accuracy: 0.78519 |  0:09:31s\n",
            "epoch 99 | loss: 0.48997 | val_0_accuracy: 0.77073 |  0:09:37s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 91 and best_val_0_accuracy = 0.7867\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 08:07:02,059]\u001b[0m Trial 4 finished with value: 0.7867012089810017 and parameters: {'n_d': 16, 'n_a': 19, 'n_steps': 10, 'gamma': 1.8042903690915453, 'n_independent': 5, 'n_shared': 1, 'momentum': 0.026501522737466518}. Best is trial 3 with value: 0.8037564766839378.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.61      0.63      0.62       826\n",
            "           2       0.82      0.91      0.86       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.54      0.59      0.56       761\n",
            "           5       0.76      0.53      0.62       619\n",
            "\n",
            "    accuracy                           0.79      4632\n",
            "   macro avg       0.79      0.78      0.78      4632\n",
            "weighted avg       0.79      0.79      0.78      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.7344  | val_0_accuracy: 0.52591 |  0:00:03s\n",
            "epoch 1  | loss: 1.13975 | val_0_accuracy: 0.53864 |  0:00:07s\n",
            "epoch 2  | loss: 1.09488 | val_0_accuracy: 0.53109 |  0:00:11s\n",
            "epoch 3  | loss: 1.03848 | val_0_accuracy: 0.54965 |  0:00:14s\n",
            "epoch 4  | loss: 0.99013 | val_0_accuracy: 0.5842  |  0:00:18s\n",
            "epoch 5  | loss: 0.98549 | val_0_accuracy: 0.58204 |  0:00:22s\n",
            "epoch 6  | loss: 0.91462 | val_0_accuracy: 0.62824 |  0:00:26s\n",
            "epoch 7  | loss: 0.84545 | val_0_accuracy: 0.64098 |  0:00:29s\n",
            "epoch 8  | loss: 0.8159  | val_0_accuracy: 0.63299 |  0:00:33s\n",
            "epoch 9  | loss: 0.79106 | val_0_accuracy: 0.66256 |  0:00:37s\n",
            "epoch 10 | loss: 0.76842 | val_0_accuracy: 0.65436 |  0:00:41s\n",
            "epoch 11 | loss: 0.75488 | val_0_accuracy: 0.66408 |  0:00:44s\n",
            "epoch 12 | loss: 0.74964 | val_0_accuracy: 0.65825 |  0:00:48s\n",
            "epoch 13 | loss: 0.74519 | val_0_accuracy: 0.66883 |  0:00:52s\n",
            "epoch 14 | loss: 0.74276 | val_0_accuracy: 0.6563  |  0:00:56s\n",
            "epoch 15 | loss: 0.76924 | val_0_accuracy: 0.65889 |  0:00:59s\n",
            "epoch 16 | loss: 0.75483 | val_0_accuracy: 0.66105 |  0:01:03s\n",
            "epoch 17 | loss: 0.74513 | val_0_accuracy: 0.66688 |  0:01:07s\n",
            "epoch 18 | loss: 0.72675 | val_0_accuracy: 0.66883 |  0:01:11s\n",
            "epoch 19 | loss: 0.73913 | val_0_accuracy: 0.66537 |  0:01:14s\n",
            "epoch 20 | loss: 0.73807 | val_0_accuracy: 0.66041 |  0:01:18s\n",
            "epoch 21 | loss: 0.73566 | val_0_accuracy: 0.6794  |  0:01:22s\n",
            "epoch 22 | loss: 0.73121 | val_0_accuracy: 0.67509 |  0:01:26s\n",
            "epoch 23 | loss: 0.72696 | val_0_accuracy: 0.67314 |  0:01:29s\n",
            "epoch 24 | loss: 0.71697 | val_0_accuracy: 0.68415 |  0:01:33s\n",
            "epoch 25 | loss: 0.7176  | val_0_accuracy: 0.6848  |  0:01:37s\n",
            "epoch 26 | loss: 0.7024  | val_0_accuracy: 0.69085 |  0:01:41s\n",
            "epoch 27 | loss: 0.69549 | val_0_accuracy: 0.69495 |  0:01:44s\n",
            "epoch 28 | loss: 0.68967 | val_0_accuracy: 0.68005 |  0:01:48s\n",
            "epoch 29 | loss: 0.69696 | val_0_accuracy: 0.69819 |  0:01:52s\n",
            "epoch 30 | loss: 0.70254 | val_0_accuracy: 0.68437 |  0:01:56s\n",
            "epoch 31 | loss: 0.68583 | val_0_accuracy: 0.70121 |  0:01:59s\n",
            "epoch 32 | loss: 0.67902 | val_0_accuracy: 0.70337 |  0:02:03s\n",
            "epoch 33 | loss: 0.68744 | val_0_accuracy: 0.69322 |  0:02:07s\n",
            "epoch 34 | loss: 0.68087 | val_0_accuracy: 0.6997  |  0:02:11s\n",
            "epoch 35 | loss: 0.6708  | val_0_accuracy: 0.70337 |  0:02:14s\n",
            "epoch 36 | loss: 0.66324 | val_0_accuracy: 0.70898 |  0:02:18s\n",
            "epoch 37 | loss: 0.66014 | val_0_accuracy: 0.70984 |  0:02:22s\n",
            "epoch 38 | loss: 0.65871 | val_0_accuracy: 0.70769 |  0:02:26s\n",
            "epoch 39 | loss: 0.6575  | val_0_accuracy: 0.7025  |  0:02:30s\n",
            "epoch 40 | loss: 0.66222 | val_0_accuracy: 0.71114 |  0:02:33s\n",
            "epoch 41 | loss: 0.66143 | val_0_accuracy: 0.70574 |  0:02:37s\n",
            "epoch 42 | loss: 0.65696 | val_0_accuracy: 0.71351 |  0:02:41s\n",
            "epoch 43 | loss: 0.6545  | val_0_accuracy: 0.70984 |  0:02:45s\n",
            "epoch 44 | loss: 0.66063 | val_0_accuracy: 0.70358 |  0:02:49s\n",
            "epoch 45 | loss: 0.65383 | val_0_accuracy: 0.70855 |  0:02:52s\n",
            "epoch 46 | loss: 0.65202 | val_0_accuracy: 0.70661 |  0:02:56s\n",
            "epoch 47 | loss: 0.63756 | val_0_accuracy: 0.71762 |  0:03:00s\n",
            "epoch 48 | loss: 0.63236 | val_0_accuracy: 0.71265 |  0:03:04s\n",
            "epoch 49 | loss: 0.62838 | val_0_accuracy: 0.70466 |  0:03:07s\n",
            "epoch 50 | loss: 0.6254  | val_0_accuracy: 0.72193 |  0:03:11s\n",
            "epoch 51 | loss: 0.62058 | val_0_accuracy: 0.71762 |  0:03:14s\n",
            "epoch 52 | loss: 0.62741 | val_0_accuracy: 0.71071 |  0:03:18s\n",
            "epoch 53 | loss: 0.62098 | val_0_accuracy: 0.71028 |  0:03:22s\n",
            "epoch 54 | loss: 0.61499 | val_0_accuracy: 0.71589 |  0:03:25s\n",
            "epoch 55 | loss: 0.61113 | val_0_accuracy: 0.73122 |  0:03:29s\n",
            "epoch 56 | loss: 0.60911 | val_0_accuracy: 0.7323  |  0:03:32s\n",
            "epoch 57 | loss: 0.60185 | val_0_accuracy: 0.71611 |  0:03:36s\n",
            "epoch 58 | loss: 0.5991  | val_0_accuracy: 0.73489 |  0:03:40s\n",
            "epoch 59 | loss: 0.59217 | val_0_accuracy: 0.73251 |  0:03:44s\n",
            "epoch 60 | loss: 0.5884  | val_0_accuracy: 0.7351  |  0:03:48s\n",
            "epoch 61 | loss: 0.58787 | val_0_accuracy: 0.73834 |  0:03:51s\n",
            "epoch 62 | loss: 0.58704 | val_0_accuracy: 0.73877 |  0:03:55s\n",
            "epoch 63 | loss: 0.58364 | val_0_accuracy: 0.73402 |  0:03:59s\n",
            "epoch 64 | loss: 0.59064 | val_0_accuracy: 0.73467 |  0:04:02s\n",
            "epoch 65 | loss: 0.579   | val_0_accuracy: 0.73726 |  0:04:06s\n",
            "epoch 66 | loss: 0.57976 | val_0_accuracy: 0.74093 |  0:04:09s\n",
            "epoch 67 | loss: 0.57324 | val_0_accuracy: 0.74309 |  0:04:13s\n",
            "epoch 68 | loss: 0.57156 | val_0_accuracy: 0.73921 |  0:04:17s\n",
            "epoch 69 | loss: 0.57189 | val_0_accuracy: 0.74007 |  0:04:21s\n",
            "epoch 70 | loss: 0.58734 | val_0_accuracy: 0.74028 |  0:04:24s\n",
            "epoch 71 | loss: 0.57689 | val_0_accuracy: 0.74827 |  0:04:28s\n",
            "epoch 72 | loss: 0.57687 | val_0_accuracy: 0.74633 |  0:04:32s\n",
            "epoch 73 | loss: 0.57797 | val_0_accuracy: 0.74568 |  0:04:35s\n",
            "epoch 74 | loss: 0.56357 | val_0_accuracy: 0.74374 |  0:04:39s\n",
            "epoch 75 | loss: 0.56249 | val_0_accuracy: 0.74784 |  0:04:42s\n",
            "epoch 76 | loss: 0.5623  | val_0_accuracy: 0.74914 |  0:04:46s\n",
            "epoch 77 | loss: 0.55822 | val_0_accuracy: 0.75712 |  0:04:50s\n",
            "epoch 78 | loss: 0.57142 | val_0_accuracy: 0.73856 |  0:04:54s\n",
            "epoch 79 | loss: 0.59074 | val_0_accuracy: 0.74892 |  0:04:58s\n",
            "epoch 80 | loss: 0.57173 | val_0_accuracy: 0.7459  |  0:05:01s\n",
            "epoch 81 | loss: 0.56685 | val_0_accuracy: 0.74935 |  0:05:05s\n",
            "epoch 82 | loss: 0.56052 | val_0_accuracy: 0.75842 |  0:05:09s\n",
            "epoch 83 | loss: 0.55595 | val_0_accuracy: 0.75777 |  0:05:13s\n",
            "epoch 84 | loss: 0.55361 | val_0_accuracy: 0.76101 |  0:05:16s\n",
            "epoch 85 | loss: 0.54541 | val_0_accuracy: 0.76339 |  0:05:20s\n",
            "epoch 86 | loss: 0.54408 | val_0_accuracy: 0.76554 |  0:05:24s\n",
            "epoch 87 | loss: 0.54389 | val_0_accuracy: 0.76231 |  0:05:28s\n",
            "epoch 88 | loss: 0.5374  | val_0_accuracy: 0.77008 |  0:05:31s\n",
            "epoch 89 | loss: 0.53698 | val_0_accuracy: 0.76576 |  0:05:35s\n",
            "epoch 90 | loss: 0.55424 | val_0_accuracy: 0.76468 |  0:05:39s\n",
            "epoch 91 | loss: 0.54723 | val_0_accuracy: 0.75756 |  0:05:43s\n",
            "epoch 92 | loss: 0.54261 | val_0_accuracy: 0.76857 |  0:05:46s\n",
            "epoch 93 | loss: 0.53905 | val_0_accuracy: 0.76015 |  0:05:50s\n",
            "epoch 94 | loss: 0.56046 | val_0_accuracy: 0.76576 |  0:05:54s\n",
            "epoch 95 | loss: 0.5362  | val_0_accuracy: 0.76749 |  0:05:57s\n",
            "epoch 96 | loss: 0.53537 | val_0_accuracy: 0.76554 |  0:06:01s\n",
            "epoch 97 | loss: 0.52816 | val_0_accuracy: 0.7636  |  0:06:05s\n",
            "epoch 98 | loss: 0.52446 | val_0_accuracy: 0.77116 |  0:06:09s\n",
            "epoch 99 | loss: 0.52799 | val_0_accuracy: 0.77073 |  0:06:12s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 98 and best_val_0_accuracy = 0.77116\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 08:13:16,835]\u001b[0m Trial 5 finished with value: 0.7711571675302246 and parameters: {'n_d': 8, 'n_a': 41, 'n_steps': 7, 'gamma': 1.4346107151381284, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.07928344577885986}. Best is trial 3 with value: 0.8037564766839378.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.58      0.60      0.59       826\n",
            "           2       0.81      0.92      0.86       822\n",
            "           3       0.99      1.00      1.00       779\n",
            "           4       0.50      0.58      0.54       761\n",
            "           5       0.78      0.45      0.57       619\n",
            "\n",
            "    accuracy                           0.77      4632\n",
            "   macro avg       0.78      0.76      0.76      4632\n",
            "weighted avg       0.78      0.77      0.77      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 2.32596 | val_0_accuracy: 0.33225 |  0:00:03s\n",
            "epoch 1  | loss: 1.32399 | val_0_accuracy: 0.50972 |  0:00:07s\n",
            "epoch 2  | loss: 1.12157 | val_0_accuracy: 0.55117 |  0:00:10s\n",
            "epoch 3  | loss: 1.04494 | val_0_accuracy: 0.56174 |  0:00:14s\n",
            "epoch 4  | loss: 0.94657 | val_0_accuracy: 0.59585 |  0:00:18s\n",
            "epoch 5  | loss: 0.84775 | val_0_accuracy: 0.62435 |  0:00:21s\n",
            "epoch 6  | loss: 0.79224 | val_0_accuracy: 0.64206 |  0:00:25s\n",
            "epoch 7  | loss: 0.77155 | val_0_accuracy: 0.65479 |  0:00:29s\n",
            "epoch 8  | loss: 0.77051 | val_0_accuracy: 0.65134 |  0:00:32s\n",
            "epoch 9  | loss: 0.75764 | val_0_accuracy: 0.66429 |  0:00:36s\n",
            "epoch 10 | loss: 0.75353 | val_0_accuracy: 0.6766  |  0:00:40s\n",
            "epoch 11 | loss: 0.74482 | val_0_accuracy: 0.66429 |  0:00:43s\n",
            "epoch 12 | loss: 0.7325  | val_0_accuracy: 0.67098 |  0:00:47s\n",
            "epoch 13 | loss: 0.72269 | val_0_accuracy: 0.66947 |  0:00:50s\n",
            "epoch 14 | loss: 0.7142  | val_0_accuracy: 0.67854 |  0:00:54s\n",
            "epoch 15 | loss: 0.72729 | val_0_accuracy: 0.67832 |  0:00:58s\n",
            "epoch 16 | loss: 0.71859 | val_0_accuracy: 0.68372 |  0:01:01s\n",
            "epoch 17 | loss: 0.70128 | val_0_accuracy: 0.68135 |  0:01:05s\n",
            "epoch 18 | loss: 0.69317 | val_0_accuracy: 0.69171 |  0:01:09s\n",
            "epoch 19 | loss: 0.68666 | val_0_accuracy: 0.69668 |  0:01:12s\n",
            "epoch 20 | loss: 0.679   | val_0_accuracy: 0.69948 |  0:01:16s\n",
            "epoch 21 | loss: 0.67036 | val_0_accuracy: 0.70272 |  0:01:19s\n",
            "epoch 22 | loss: 0.6645  | val_0_accuracy: 0.70121 |  0:01:23s\n",
            "epoch 23 | loss: 0.66218 | val_0_accuracy: 0.71611 |  0:01:27s\n",
            "epoch 24 | loss: 0.65981 | val_0_accuracy: 0.70035 |  0:01:30s\n",
            "epoch 25 | loss: 0.65131 | val_0_accuracy: 0.70769 |  0:01:34s\n",
            "epoch 26 | loss: 0.64627 | val_0_accuracy: 0.71826 |  0:01:38s\n",
            "epoch 27 | loss: 0.64171 | val_0_accuracy: 0.71697 |  0:01:41s\n",
            "epoch 28 | loss: 0.64041 | val_0_accuracy: 0.70963 |  0:01:45s\n",
            "epoch 29 | loss: 0.63867 | val_0_accuracy: 0.72258 |  0:01:49s\n",
            "epoch 30 | loss: 0.62728 | val_0_accuracy: 0.72582 |  0:01:52s\n",
            "epoch 31 | loss: 0.62526 | val_0_accuracy: 0.7282  |  0:01:56s\n",
            "epoch 32 | loss: 0.63393 | val_0_accuracy: 0.71891 |  0:01:59s\n",
            "epoch 33 | loss: 0.64071 | val_0_accuracy: 0.72625 |  0:02:03s\n",
            "epoch 34 | loss: 0.64785 | val_0_accuracy: 0.72453 |  0:02:07s\n",
            "epoch 35 | loss: 0.62301 | val_0_accuracy: 0.731   |  0:02:10s\n",
            "epoch 36 | loss: 0.61978 | val_0_accuracy: 0.73575 |  0:02:14s\n",
            "epoch 37 | loss: 0.61284 | val_0_accuracy: 0.73122 |  0:02:18s\n",
            "epoch 38 | loss: 0.60926 | val_0_accuracy: 0.73705 |  0:02:21s\n",
            "epoch 39 | loss: 0.60141 | val_0_accuracy: 0.72409 |  0:02:25s\n",
            "epoch 40 | loss: 0.60006 | val_0_accuracy: 0.74503 |  0:02:28s\n",
            "epoch 41 | loss: 0.59564 | val_0_accuracy: 0.74806 |  0:02:32s\n",
            "epoch 42 | loss: 0.59027 | val_0_accuracy: 0.7459  |  0:02:36s\n",
            "epoch 43 | loss: 0.58721 | val_0_accuracy: 0.73834 |  0:02:39s\n",
            "epoch 44 | loss: 0.59073 | val_0_accuracy: 0.74223 |  0:02:43s\n",
            "epoch 45 | loss: 0.59532 | val_0_accuracy: 0.73921 |  0:02:46s\n",
            "epoch 46 | loss: 0.5864  | val_0_accuracy: 0.7487  |  0:02:50s\n",
            "epoch 47 | loss: 0.5804  | val_0_accuracy: 0.74719 |  0:02:54s\n",
            "epoch 48 | loss: 0.57781 | val_0_accuracy: 0.74827 |  0:02:57s\n",
            "epoch 49 | loss: 0.57761 | val_0_accuracy: 0.75    |  0:03:01s\n",
            "epoch 50 | loss: 0.57162 | val_0_accuracy: 0.75561 |  0:03:05s\n",
            "epoch 51 | loss: 0.57051 | val_0_accuracy: 0.75324 |  0:03:08s\n",
            "epoch 52 | loss: 0.57162 | val_0_accuracy: 0.75324 |  0:03:12s\n",
            "epoch 53 | loss: 0.56882 | val_0_accuracy: 0.7595  |  0:03:15s\n",
            "epoch 54 | loss: 0.56696 | val_0_accuracy: 0.74914 |  0:03:19s\n",
            "epoch 55 | loss: 0.56966 | val_0_accuracy: 0.75389 |  0:03:23s\n",
            "epoch 56 | loss: 0.56373 | val_0_accuracy: 0.75799 |  0:03:26s\n",
            "epoch 57 | loss: 0.55868 | val_0_accuracy: 0.75799 |  0:03:30s\n",
            "epoch 58 | loss: 0.55698 | val_0_accuracy: 0.76123 |  0:03:33s\n",
            "epoch 59 | loss: 0.55699 | val_0_accuracy: 0.75734 |  0:03:38s\n",
            "epoch 60 | loss: 0.56134 | val_0_accuracy: 0.75518 |  0:03:42s\n",
            "epoch 61 | loss: 0.55322 | val_0_accuracy: 0.7541  |  0:03:45s\n",
            "epoch 62 | loss: 0.54519 | val_0_accuracy: 0.7677  |  0:03:49s\n",
            "epoch 63 | loss: 0.54606 | val_0_accuracy: 0.7718  |  0:03:52s\n",
            "epoch 64 | loss: 0.53751 | val_0_accuracy: 0.75993 |  0:03:56s\n",
            "epoch 65 | loss: 0.53678 | val_0_accuracy: 0.76943 |  0:04:00s\n",
            "epoch 66 | loss: 0.54634 | val_0_accuracy: 0.75972 |  0:04:03s\n",
            "epoch 67 | loss: 0.53926 | val_0_accuracy: 0.76123 |  0:04:07s\n",
            "epoch 68 | loss: 0.53124 | val_0_accuracy: 0.76792 |  0:04:10s\n",
            "epoch 69 | loss: 0.52932 | val_0_accuracy: 0.76749 |  0:04:14s\n",
            "epoch 70 | loss: 0.52199 | val_0_accuracy: 0.7677  |  0:04:17s\n",
            "epoch 71 | loss: 0.5252  | val_0_accuracy: 0.77418 |  0:04:21s\n",
            "epoch 72 | loss: 0.5222  | val_0_accuracy: 0.78195 |  0:04:25s\n",
            "epoch 73 | loss: 0.51968 | val_0_accuracy: 0.76727 |  0:04:28s\n",
            "epoch 74 | loss: 0.51695 | val_0_accuracy: 0.76533 |  0:04:32s\n",
            "epoch 75 | loss: 0.51296 | val_0_accuracy: 0.77504 |  0:04:36s\n",
            "epoch 76 | loss: 0.51107 | val_0_accuracy: 0.7731  |  0:04:39s\n",
            "epoch 77 | loss: 0.51194 | val_0_accuracy: 0.76684 |  0:04:43s\n",
            "epoch 78 | loss: 0.5171  | val_0_accuracy: 0.77893 |  0:04:46s\n",
            "epoch 79 | loss: 0.51    | val_0_accuracy: 0.76403 |  0:04:50s\n",
            "epoch 80 | loss: 0.50714 | val_0_accuracy: 0.77224 |  0:04:54s\n",
            "epoch 81 | loss: 0.51068 | val_0_accuracy: 0.76986 |  0:04:57s\n",
            "epoch 82 | loss: 0.5093  | val_0_accuracy: 0.77655 |  0:05:01s\n",
            "\n",
            "Early stopping occurred at epoch 82 with best_epoch = 72 and best_val_0_accuracy = 0.78195\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 08:18:19,889]\u001b[0m Trial 6 finished with value: 0.781951640759931 and parameters: {'n_d': 33, 'n_a': 19, 'n_steps': 10, 'gamma': 1.9607393008236027, 'n_independent': 2, 'n_shared': 1, 'momentum': 0.21184888017036255}. Best is trial 3 with value: 0.8037564766839378.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       825\n",
            "           1       0.60      0.63      0.61       826\n",
            "           2       0.81      0.92      0.87       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.53      0.51      0.52       761\n",
            "           5       0.72      0.57      0.63       619\n",
            "\n",
            "    accuracy                           0.78      4632\n",
            "   macro avg       0.78      0.77      0.77      4632\n",
            "weighted avg       0.78      0.78      0.78      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.27533 | val_0_accuracy: 0.56261 |  0:00:01s\n",
            "epoch 1  | loss: 0.84067 | val_0_accuracy: 0.65155 |  0:00:03s\n",
            "epoch 2  | loss: 0.77407 | val_0_accuracy: 0.66775 |  0:00:05s\n",
            "epoch 3  | loss: 0.73978 | val_0_accuracy: 0.65522 |  0:00:07s\n",
            "epoch 4  | loss: 0.72292 | val_0_accuracy: 0.67012 |  0:00:09s\n",
            "epoch 5  | loss: 0.70906 | val_0_accuracy: 0.69516 |  0:00:11s\n",
            "epoch 6  | loss: 0.69971 | val_0_accuracy: 0.68782 |  0:00:13s\n",
            "epoch 7  | loss: 0.6822  | val_0_accuracy: 0.70337 |  0:00:15s\n",
            "epoch 8  | loss: 0.66766 | val_0_accuracy: 0.70855 |  0:00:17s\n",
            "epoch 9  | loss: 0.66131 | val_0_accuracy: 0.70358 |  0:00:19s\n",
            "epoch 10 | loss: 0.64866 | val_0_accuracy: 0.71438 |  0:00:21s\n",
            "epoch 11 | loss: 0.64221 | val_0_accuracy: 0.70963 |  0:00:23s\n",
            "epoch 12 | loss: 0.63438 | val_0_accuracy: 0.71632 |  0:00:25s\n",
            "epoch 13 | loss: 0.63755 | val_0_accuracy: 0.71675 |  0:00:27s\n",
            "epoch 14 | loss: 0.6232  | val_0_accuracy: 0.72366 |  0:00:29s\n",
            "epoch 15 | loss: 0.6187  | val_0_accuracy: 0.72323 |  0:00:31s\n",
            "epoch 16 | loss: 0.63543 | val_0_accuracy: 0.71373 |  0:00:33s\n",
            "epoch 17 | loss: 0.63449 | val_0_accuracy: 0.72625 |  0:00:35s\n",
            "epoch 18 | loss: 0.61789 | val_0_accuracy: 0.7282  |  0:00:37s\n",
            "epoch 19 | loss: 0.60822 | val_0_accuracy: 0.72474 |  0:00:39s\n",
            "epoch 20 | loss: 0.60002 | val_0_accuracy: 0.73208 |  0:00:41s\n",
            "epoch 21 | loss: 0.59627 | val_0_accuracy: 0.7405  |  0:00:42s\n",
            "epoch 22 | loss: 0.59017 | val_0_accuracy: 0.74201 |  0:00:44s\n",
            "epoch 23 | loss: 0.58208 | val_0_accuracy: 0.74028 |  0:00:46s\n",
            "epoch 24 | loss: 0.57951 | val_0_accuracy: 0.7446  |  0:00:48s\n",
            "epoch 25 | loss: 0.58173 | val_0_accuracy: 0.74547 |  0:00:50s\n",
            "epoch 26 | loss: 0.57664 | val_0_accuracy: 0.74655 |  0:00:52s\n",
            "epoch 27 | loss: 0.56561 | val_0_accuracy: 0.75281 |  0:00:54s\n",
            "epoch 28 | loss: 0.56618 | val_0_accuracy: 0.74892 |  0:00:56s\n",
            "epoch 29 | loss: 0.55582 | val_0_accuracy: 0.7541  |  0:00:58s\n",
            "epoch 30 | loss: 0.55038 | val_0_accuracy: 0.75022 |  0:01:00s\n",
            "epoch 31 | loss: 0.55073 | val_0_accuracy: 0.74957 |  0:01:02s\n",
            "epoch 32 | loss: 0.55523 | val_0_accuracy: 0.75928 |  0:01:04s\n",
            "epoch 33 | loss: 0.54464 | val_0_accuracy: 0.76209 |  0:01:06s\n",
            "epoch 34 | loss: 0.55176 | val_0_accuracy: 0.75669 |  0:01:08s\n",
            "epoch 35 | loss: 0.5526  | val_0_accuracy: 0.76727 |  0:01:10s\n",
            "epoch 36 | loss: 0.53898 | val_0_accuracy: 0.75604 |  0:01:12s\n",
            "epoch 37 | loss: 0.53742 | val_0_accuracy: 0.76684 |  0:01:14s\n",
            "epoch 38 | loss: 0.53576 | val_0_accuracy: 0.7636  |  0:01:15s\n",
            "epoch 39 | loss: 0.55259 | val_0_accuracy: 0.76058 |  0:01:17s\n",
            "epoch 40 | loss: 0.53056 | val_0_accuracy: 0.76533 |  0:01:19s\n",
            "epoch 41 | loss: 0.52603 | val_0_accuracy: 0.76015 |  0:01:21s\n",
            "epoch 42 | loss: 0.5265  | val_0_accuracy: 0.77008 |  0:01:23s\n",
            "epoch 43 | loss: 0.52993 | val_0_accuracy: 0.76079 |  0:01:25s\n",
            "epoch 44 | loss: 0.52463 | val_0_accuracy: 0.77094 |  0:01:27s\n",
            "epoch 45 | loss: 0.51106 | val_0_accuracy: 0.76986 |  0:01:29s\n",
            "epoch 46 | loss: 0.51008 | val_0_accuracy: 0.7649  |  0:01:31s\n",
            "epoch 47 | loss: 0.50878 | val_0_accuracy: 0.76641 |  0:01:33s\n",
            "epoch 48 | loss: 0.50921 | val_0_accuracy: 0.76468 |  0:01:35s\n",
            "epoch 49 | loss: 0.51712 | val_0_accuracy: 0.76835 |  0:01:37s\n",
            "epoch 50 | loss: 0.5109  | val_0_accuracy: 0.77267 |  0:01:39s\n",
            "epoch 51 | loss: 0.49896 | val_0_accuracy: 0.77029 |  0:01:41s\n",
            "epoch 52 | loss: 0.49669 | val_0_accuracy: 0.77202 |  0:01:42s\n",
            "epoch 53 | loss: 0.49311 | val_0_accuracy: 0.77742 |  0:01:44s\n",
            "epoch 54 | loss: 0.49384 | val_0_accuracy: 0.77116 |  0:01:46s\n",
            "epoch 55 | loss: 0.49631 | val_0_accuracy: 0.77979 |  0:01:48s\n",
            "epoch 56 | loss: 0.48903 | val_0_accuracy: 0.77353 |  0:01:50s\n",
            "epoch 57 | loss: 0.48734 | val_0_accuracy: 0.7718  |  0:01:52s\n",
            "epoch 58 | loss: 0.48255 | val_0_accuracy: 0.77828 |  0:01:54s\n",
            "epoch 59 | loss: 0.47809 | val_0_accuracy: 0.77699 |  0:01:56s\n",
            "epoch 60 | loss: 0.48855 | val_0_accuracy: 0.77375 |  0:01:58s\n",
            "epoch 61 | loss: 0.49377 | val_0_accuracy: 0.76943 |  0:02:00s\n",
            "epoch 62 | loss: 0.48638 | val_0_accuracy: 0.77936 |  0:02:02s\n",
            "epoch 63 | loss: 0.47618 | val_0_accuracy: 0.77504 |  0:02:04s\n",
            "epoch 64 | loss: 0.4755  | val_0_accuracy: 0.77375 |  0:02:05s\n",
            "epoch 65 | loss: 0.48736 | val_0_accuracy: 0.77159 |  0:02:07s\n",
            "\n",
            "Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_0_accuracy = 0.77979\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 08:20:28,736]\u001b[0m Trial 7 finished with value: 0.7797927461139896 and parameters: {'n_d': 26, 'n_a': 37, 'n_steps': 3, 'gamma': 1.537844677093673, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.24149089045347172}. Best is trial 3 with value: 0.8037564766839378.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.59      0.62      0.60       826\n",
            "           2       0.83      0.91      0.87       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.53      0.52      0.53       761\n",
            "           5       0.70      0.57      0.63       619\n",
            "\n",
            "    accuracy                           0.78      4632\n",
            "   macro avg       0.77      0.77      0.77      4632\n",
            "weighted avg       0.78      0.78      0.78      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.31998 | val_0_accuracy: 0.60902 |  0:00:02s\n",
            "epoch 1  | loss: 0.87404 | val_0_accuracy: 0.63623 |  0:00:04s\n",
            "epoch 2  | loss: 0.82286 | val_0_accuracy: 0.64573 |  0:00:07s\n",
            "epoch 3  | loss: 0.79545 | val_0_accuracy: 0.65501 |  0:00:09s\n",
            "epoch 4  | loss: 0.77266 | val_0_accuracy: 0.66667 |  0:00:11s\n",
            "epoch 5  | loss: 0.75916 | val_0_accuracy: 0.67206 |  0:00:14s\n",
            "epoch 6  | loss: 0.74575 | val_0_accuracy: 0.67768 |  0:00:16s\n",
            "epoch 7  | loss: 0.73053 | val_0_accuracy: 0.67832 |  0:00:18s\n",
            "epoch 8  | loss: 0.72133 | val_0_accuracy: 0.67595 |  0:00:21s\n",
            "epoch 9  | loss: 0.71189 | val_0_accuracy: 0.6861  |  0:00:23s\n",
            "epoch 10 | loss: 0.70698 | val_0_accuracy: 0.69883 |  0:00:26s\n",
            "epoch 11 | loss: 0.69875 | val_0_accuracy: 0.69775 |  0:00:28s\n",
            "epoch 12 | loss: 0.69466 | val_0_accuracy: 0.69819 |  0:00:30s\n",
            "epoch 13 | loss: 0.68332 | val_0_accuracy: 0.69948 |  0:00:33s\n",
            "epoch 14 | loss: 0.67561 | val_0_accuracy: 0.70531 |  0:00:35s\n",
            "epoch 15 | loss: 0.67307 | val_0_accuracy: 0.70769 |  0:00:38s\n",
            "epoch 16 | loss: 0.67159 | val_0_accuracy: 0.70725 |  0:00:40s\n",
            "epoch 17 | loss: 0.66211 | val_0_accuracy: 0.71244 |  0:00:42s\n",
            "epoch 18 | loss: 0.65355 | val_0_accuracy: 0.71438 |  0:00:45s\n",
            "epoch 19 | loss: 0.64834 | val_0_accuracy: 0.712   |  0:00:47s\n",
            "epoch 20 | loss: 0.64037 | val_0_accuracy: 0.7079  |  0:00:50s\n",
            "epoch 21 | loss: 0.6385  | val_0_accuracy: 0.70877 |  0:00:52s\n",
            "epoch 22 | loss: 0.63216 | val_0_accuracy: 0.71438 |  0:00:54s\n",
            "epoch 23 | loss: 0.6384  | val_0_accuracy: 0.71718 |  0:00:57s\n",
            "epoch 24 | loss: 0.62965 | val_0_accuracy: 0.72496 |  0:00:59s\n",
            "epoch 25 | loss: 0.62338 | val_0_accuracy: 0.73187 |  0:01:02s\n",
            "epoch 26 | loss: 0.61604 | val_0_accuracy: 0.72668 |  0:01:04s\n",
            "epoch 27 | loss: 0.61723 | val_0_accuracy: 0.72668 |  0:01:06s\n",
            "epoch 28 | loss: 0.60575 | val_0_accuracy: 0.73294 |  0:01:09s\n",
            "epoch 29 | loss: 0.60145 | val_0_accuracy: 0.73057 |  0:01:11s\n",
            "epoch 30 | loss: 0.6064  | val_0_accuracy: 0.7323  |  0:01:13s\n",
            "epoch 31 | loss: 0.60364 | val_0_accuracy: 0.72733 |  0:01:16s\n",
            "epoch 32 | loss: 0.59442 | val_0_accuracy: 0.74028 |  0:01:18s\n",
            "epoch 33 | loss: 0.58833 | val_0_accuracy: 0.73446 |  0:01:21s\n",
            "epoch 34 | loss: 0.59702 | val_0_accuracy: 0.73791 |  0:01:23s\n",
            "epoch 35 | loss: 0.59611 | val_0_accuracy: 0.73921 |  0:01:25s\n",
            "epoch 36 | loss: 0.58924 | val_0_accuracy: 0.73554 |  0:01:28s\n",
            "epoch 37 | loss: 0.5944  | val_0_accuracy: 0.731   |  0:01:30s\n",
            "epoch 38 | loss: 0.58632 | val_0_accuracy: 0.73035 |  0:01:32s\n",
            "epoch 39 | loss: 0.58343 | val_0_accuracy: 0.74007 |  0:01:35s\n",
            "epoch 40 | loss: 0.57969 | val_0_accuracy: 0.74288 |  0:01:37s\n",
            "epoch 41 | loss: 0.58606 | val_0_accuracy: 0.7351  |  0:01:40s\n",
            "epoch 42 | loss: 0.59307 | val_0_accuracy: 0.73489 |  0:01:42s\n",
            "epoch 43 | loss: 0.58551 | val_0_accuracy: 0.73834 |  0:01:44s\n",
            "epoch 44 | loss: 0.58098 | val_0_accuracy: 0.73251 |  0:01:47s\n",
            "epoch 45 | loss: 0.57654 | val_0_accuracy: 0.74935 |  0:01:49s\n",
            "epoch 46 | loss: 0.56754 | val_0_accuracy: 0.74676 |  0:01:51s\n",
            "epoch 47 | loss: 0.57225 | val_0_accuracy: 0.75151 |  0:01:54s\n",
            "epoch 48 | loss: 0.57144 | val_0_accuracy: 0.74396 |  0:01:56s\n",
            "epoch 49 | loss: 0.56388 | val_0_accuracy: 0.75237 |  0:01:59s\n",
            "epoch 50 | loss: 0.56009 | val_0_accuracy: 0.75043 |  0:02:01s\n",
            "epoch 51 | loss: 0.55949 | val_0_accuracy: 0.75777 |  0:02:03s\n",
            "epoch 52 | loss: 0.55421 | val_0_accuracy: 0.75065 |  0:02:06s\n",
            "epoch 53 | loss: 0.55259 | val_0_accuracy: 0.73985 |  0:02:08s\n",
            "epoch 54 | loss: 0.56675 | val_0_accuracy: 0.74482 |  0:02:10s\n",
            "epoch 55 | loss: 0.55581 | val_0_accuracy: 0.75043 |  0:02:13s\n",
            "epoch 56 | loss: 0.54592 | val_0_accuracy: 0.73834 |  0:02:15s\n",
            "epoch 57 | loss: 0.5469  | val_0_accuracy: 0.74676 |  0:02:18s\n",
            "epoch 58 | loss: 0.54267 | val_0_accuracy: 0.75928 |  0:02:20s\n",
            "epoch 59 | loss: 0.54658 | val_0_accuracy: 0.75302 |  0:02:22s\n",
            "epoch 60 | loss: 0.53999 | val_0_accuracy: 0.76079 |  0:02:25s\n",
            "epoch 61 | loss: 0.53567 | val_0_accuracy: 0.75626 |  0:02:27s\n",
            "epoch 62 | loss: 0.53092 | val_0_accuracy: 0.7582  |  0:02:30s\n",
            "epoch 63 | loss: 0.52703 | val_0_accuracy: 0.75972 |  0:02:33s\n",
            "epoch 64 | loss: 0.53441 | val_0_accuracy: 0.75259 |  0:02:35s\n",
            "epoch 65 | loss: 0.53568 | val_0_accuracy: 0.7595  |  0:02:38s\n",
            "epoch 66 | loss: 0.52369 | val_0_accuracy: 0.75842 |  0:02:40s\n",
            "epoch 67 | loss: 0.52089 | val_0_accuracy: 0.76662 |  0:02:42s\n",
            "epoch 68 | loss: 0.51872 | val_0_accuracy: 0.75907 |  0:02:45s\n",
            "epoch 69 | loss: 0.5209  | val_0_accuracy: 0.76749 |  0:02:47s\n",
            "epoch 70 | loss: 0.51515 | val_0_accuracy: 0.76835 |  0:02:49s\n",
            "epoch 71 | loss: 0.51188 | val_0_accuracy: 0.74741 |  0:02:52s\n",
            "epoch 72 | loss: 0.51917 | val_0_accuracy: 0.75864 |  0:02:54s\n",
            "epoch 73 | loss: 0.51423 | val_0_accuracy: 0.7677  |  0:02:57s\n",
            "epoch 74 | loss: 0.51008 | val_0_accuracy: 0.76274 |  0:02:59s\n",
            "epoch 75 | loss: 0.50961 | val_0_accuracy: 0.76965 |  0:03:01s\n",
            "epoch 76 | loss: 0.50801 | val_0_accuracy: 0.76662 |  0:03:04s\n",
            "epoch 77 | loss: 0.50554 | val_0_accuracy: 0.7636  |  0:03:06s\n",
            "epoch 78 | loss: 0.50806 | val_0_accuracy: 0.77547 |  0:03:08s\n",
            "epoch 79 | loss: 0.50838 | val_0_accuracy: 0.76706 |  0:03:11s\n",
            "epoch 80 | loss: 0.50537 | val_0_accuracy: 0.76533 |  0:03:13s\n",
            "epoch 81 | loss: 0.50359 | val_0_accuracy: 0.769   |  0:03:16s\n",
            "epoch 82 | loss: 0.50818 | val_0_accuracy: 0.77483 |  0:03:18s\n",
            "epoch 83 | loss: 0.49696 | val_0_accuracy: 0.77202 |  0:03:20s\n",
            "epoch 84 | loss: 0.49915 | val_0_accuracy: 0.77807 |  0:03:23s\n",
            "epoch 85 | loss: 0.51037 | val_0_accuracy: 0.77159 |  0:03:25s\n",
            "epoch 86 | loss: 0.49979 | val_0_accuracy: 0.77504 |  0:03:27s\n",
            "epoch 87 | loss: 0.4913  | val_0_accuracy: 0.77526 |  0:03:30s\n",
            "epoch 88 | loss: 0.49225 | val_0_accuracy: 0.77461 |  0:03:32s\n",
            "epoch 89 | loss: 0.48797 | val_0_accuracy: 0.78022 |  0:03:35s\n",
            "epoch 90 | loss: 0.48879 | val_0_accuracy: 0.77871 |  0:03:37s\n",
            "epoch 91 | loss: 0.4947  | val_0_accuracy: 0.769   |  0:03:39s\n",
            "epoch 92 | loss: 0.4922  | val_0_accuracy: 0.77353 |  0:03:42s\n",
            "epoch 93 | loss: 0.49083 | val_0_accuracy: 0.77828 |  0:03:44s\n",
            "epoch 94 | loss: 0.48399 | val_0_accuracy: 0.77137 |  0:03:46s\n",
            "epoch 95 | loss: 0.48545 | val_0_accuracy: 0.7826  |  0:03:49s\n",
            "epoch 96 | loss: 0.48094 | val_0_accuracy: 0.78001 |  0:03:51s\n",
            "epoch 97 | loss: 0.48587 | val_0_accuracy: 0.76943 |  0:03:54s\n",
            "epoch 98 | loss: 0.48493 | val_0_accuracy: 0.78325 |  0:03:56s\n",
            "epoch 99 | loss: 0.48247 | val_0_accuracy: 0.78433 |  0:03:58s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_accuracy = 0.78433\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 08:24:28,732]\u001b[0m Trial 8 finished with value: 0.7843264248704663 and parameters: {'n_d': 53, 'n_a': 9, 'n_steps': 4, 'gamma': 1.0708029007484234, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.20437654559875879}. Best is trial 3 with value: 0.8037564766839378.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.61      0.63      0.62       826\n",
            "           2       0.82      0.91      0.87       822\n",
            "           3       1.00      0.99      1.00       779\n",
            "           4       0.53      0.53      0.53       761\n",
            "           5       0.70      0.58      0.63       619\n",
            "\n",
            "    accuracy                           0.78      4632\n",
            "   macro avg       0.78      0.77      0.77      4632\n",
            "weighted avg       0.78      0.78      0.78      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 6.29523 | val_0_accuracy: 0.14875 |  0:00:07s\n",
            "epoch 1  | loss: 1.77258 | val_0_accuracy: 0.36723 |  0:00:16s\n",
            "epoch 2  | loss: 1.44417 | val_0_accuracy: 0.50777 |  0:00:24s\n",
            "epoch 3  | loss: 1.33574 | val_0_accuracy: 0.51986 |  0:00:32s\n",
            "epoch 4  | loss: 1.17821 | val_0_accuracy: 0.56434 |  0:00:40s\n",
            "epoch 5  | loss: 0.93018 | val_0_accuracy: 0.60838 |  0:00:48s\n",
            "epoch 6  | loss: 0.90547 | val_0_accuracy: 0.58269 |  0:00:56s\n",
            "epoch 7  | loss: 0.99081 | val_0_accuracy: 0.57103 |  0:01:04s\n",
            "epoch 8  | loss: 0.8638  | val_0_accuracy: 0.61809 |  0:01:12s\n",
            "epoch 9  | loss: 0.81753 | val_0_accuracy: 0.62932 |  0:01:20s\n",
            "epoch 10 | loss: 0.8043  | val_0_accuracy: 0.63644 |  0:01:28s\n",
            "epoch 11 | loss: 0.79371 | val_0_accuracy: 0.64983 |  0:01:36s\n",
            "epoch 12 | loss: 0.7676  | val_0_accuracy: 0.66235 |  0:01:44s\n",
            "epoch 13 | loss: 0.75353 | val_0_accuracy: 0.63968 |  0:01:53s\n",
            "epoch 14 | loss: 0.81619 | val_0_accuracy: 0.62975 |  0:02:00s\n",
            "epoch 15 | loss: 0.79731 | val_0_accuracy: 0.65112 |  0:02:08s\n",
            "epoch 16 | loss: 0.75494 | val_0_accuracy: 0.66472 |  0:02:16s\n",
            "epoch 17 | loss: 0.74189 | val_0_accuracy: 0.66408 |  0:02:25s\n",
            "epoch 18 | loss: 0.73404 | val_0_accuracy: 0.68199 |  0:02:33s\n",
            "epoch 19 | loss: 0.74397 | val_0_accuracy: 0.6658  |  0:02:41s\n",
            "epoch 20 | loss: 0.73321 | val_0_accuracy: 0.67509 |  0:02:49s\n",
            "epoch 21 | loss: 0.71604 | val_0_accuracy: 0.65415 |  0:02:57s\n",
            "epoch 22 | loss: 0.74154 | val_0_accuracy: 0.66991 |  0:03:05s\n",
            "epoch 23 | loss: 0.71502 | val_0_accuracy: 0.67854 |  0:03:13s\n",
            "epoch 24 | loss: 0.70488 | val_0_accuracy: 0.67984 |  0:03:21s\n",
            "epoch 25 | loss: 0.70139 | val_0_accuracy: 0.68912 |  0:03:29s\n",
            "epoch 26 | loss: 0.6887  | val_0_accuracy: 0.69538 |  0:03:37s\n",
            "epoch 27 | loss: 0.68074 | val_0_accuracy: 0.70164 |  0:03:45s\n",
            "epoch 28 | loss: 0.68822 | val_0_accuracy: 0.69149 |  0:03:53s\n",
            "epoch 29 | loss: 0.68163 | val_0_accuracy: 0.70272 |  0:04:01s\n",
            "epoch 30 | loss: 0.70249 | val_0_accuracy: 0.69344 |  0:04:09s\n",
            "epoch 31 | loss: 0.67691 | val_0_accuracy: 0.69149 |  0:04:17s\n",
            "epoch 32 | loss: 0.67667 | val_0_accuracy: 0.69624 |  0:04:25s\n",
            "epoch 33 | loss: 0.67313 | val_0_accuracy: 0.70596 |  0:04:33s\n",
            "epoch 34 | loss: 0.66655 | val_0_accuracy: 0.69927 |  0:04:41s\n",
            "epoch 35 | loss: 0.6724  | val_0_accuracy: 0.71136 |  0:04:50s\n",
            "epoch 36 | loss: 0.65531 | val_0_accuracy: 0.6766  |  0:04:58s\n",
            "epoch 37 | loss: 0.6678  | val_0_accuracy: 0.71222 |  0:05:06s\n",
            "epoch 38 | loss: 0.64846 | val_0_accuracy: 0.71308 |  0:05:14s\n",
            "epoch 39 | loss: 0.64471 | val_0_accuracy: 0.70747 |  0:05:22s\n",
            "epoch 40 | loss: 0.63821 | val_0_accuracy: 0.71244 |  0:05:30s\n",
            "epoch 41 | loss: 0.63492 | val_0_accuracy: 0.71244 |  0:05:38s\n",
            "epoch 42 | loss: 0.62285 | val_0_accuracy: 0.72172 |  0:05:46s\n",
            "epoch 43 | loss: 0.61839 | val_0_accuracy: 0.72258 |  0:05:54s\n",
            "epoch 44 | loss: 0.61416 | val_0_accuracy: 0.72712 |  0:06:02s\n",
            "epoch 45 | loss: 0.6124  | val_0_accuracy: 0.73338 |  0:06:10s\n",
            "epoch 46 | loss: 0.63427 | val_0_accuracy: 0.7133  |  0:06:19s\n",
            "epoch 47 | loss: 0.61682 | val_0_accuracy: 0.72388 |  0:06:27s\n",
            "epoch 48 | loss: 0.60856 | val_0_accuracy: 0.71092 |  0:06:35s\n",
            "epoch 49 | loss: 0.60497 | val_0_accuracy: 0.71805 |  0:06:43s\n",
            "epoch 50 | loss: 0.59833 | val_0_accuracy: 0.73813 |  0:06:51s\n",
            "epoch 51 | loss: 0.59842 | val_0_accuracy: 0.73208 |  0:06:59s\n",
            "epoch 52 | loss: 0.5947  | val_0_accuracy: 0.72193 |  0:07:07s\n",
            "epoch 53 | loss: 0.58927 | val_0_accuracy: 0.74007 |  0:07:15s\n",
            "epoch 54 | loss: 0.58278 | val_0_accuracy: 0.73251 |  0:07:23s\n",
            "epoch 55 | loss: 0.57778 | val_0_accuracy: 0.7405  |  0:07:31s\n",
            "epoch 56 | loss: 0.57415 | val_0_accuracy: 0.74719 |  0:07:39s\n",
            "epoch 57 | loss: 0.57096 | val_0_accuracy: 0.73402 |  0:07:47s\n",
            "epoch 58 | loss: 0.57784 | val_0_accuracy: 0.72949 |  0:07:55s\n",
            "epoch 59 | loss: 0.58012 | val_0_accuracy: 0.73985 |  0:08:03s\n",
            "epoch 60 | loss: 0.5644  | val_0_accuracy: 0.75086 |  0:08:11s\n",
            "epoch 61 | loss: 0.5595  | val_0_accuracy: 0.74719 |  0:08:19s\n",
            "epoch 62 | loss: 0.55242 | val_0_accuracy: 0.74763 |  0:08:27s\n",
            "epoch 63 | loss: 0.54902 | val_0_accuracy: 0.75561 |  0:08:35s\n",
            "epoch 64 | loss: 0.54569 | val_0_accuracy: 0.75756 |  0:08:43s\n",
            "epoch 65 | loss: 0.54382 | val_0_accuracy: 0.74698 |  0:08:51s\n",
            "epoch 66 | loss: 0.56928 | val_0_accuracy: 0.75604 |  0:08:59s\n",
            "epoch 67 | loss: 0.55909 | val_0_accuracy: 0.76166 |  0:09:07s\n",
            "epoch 68 | loss: 0.54316 | val_0_accuracy: 0.75345 |  0:09:15s\n",
            "epoch 69 | loss: 0.54112 | val_0_accuracy: 0.75345 |  0:09:23s\n",
            "epoch 70 | loss: 0.53351 | val_0_accuracy: 0.76036 |  0:09:31s\n",
            "epoch 71 | loss: 0.56141 | val_0_accuracy: 0.75604 |  0:09:39s\n",
            "epoch 72 | loss: 0.55443 | val_0_accuracy: 0.76231 |  0:09:47s\n",
            "epoch 73 | loss: 0.53943 | val_0_accuracy: 0.76403 |  0:09:55s\n",
            "epoch 74 | loss: 0.54325 | val_0_accuracy: 0.7677  |  0:10:03s\n",
            "epoch 75 | loss: 0.53142 | val_0_accuracy: 0.76403 |  0:10:11s\n",
            "epoch 76 | loss: 0.52204 | val_0_accuracy: 0.76857 |  0:10:19s\n",
            "epoch 77 | loss: 0.51908 | val_0_accuracy: 0.76382 |  0:10:28s\n",
            "epoch 78 | loss: 0.51288 | val_0_accuracy: 0.77073 |  0:10:36s\n",
            "epoch 79 | loss: 0.5077  | val_0_accuracy: 0.76468 |  0:10:44s\n",
            "epoch 80 | loss: 0.5104  | val_0_accuracy: 0.75345 |  0:10:52s\n",
            "epoch 81 | loss: 0.50161 | val_0_accuracy: 0.77828 |  0:11:00s\n",
            "epoch 82 | loss: 0.49677 | val_0_accuracy: 0.78368 |  0:11:09s\n",
            "epoch 83 | loss: 0.49497 | val_0_accuracy: 0.77591 |  0:11:17s\n",
            "epoch 84 | loss: 0.49741 | val_0_accuracy: 0.77245 |  0:11:25s\n",
            "epoch 85 | loss: 0.49241 | val_0_accuracy: 0.78109 |  0:11:33s\n",
            "epoch 86 | loss: 0.50119 | val_0_accuracy: 0.77051 |  0:11:41s\n",
            "epoch 87 | loss: 0.49026 | val_0_accuracy: 0.77828 |  0:11:49s\n",
            "epoch 88 | loss: 0.48342 | val_0_accuracy: 0.74806 |  0:11:57s\n",
            "epoch 89 | loss: 0.48354 | val_0_accuracy: 0.79037 |  0:12:05s\n",
            "epoch 90 | loss: 0.49263 | val_0_accuracy: 0.76965 |  0:12:13s\n",
            "epoch 91 | loss: 0.5223  | val_0_accuracy: 0.7785  |  0:12:21s\n",
            "epoch 92 | loss: 0.5715  | val_0_accuracy: 0.73035 |  0:12:29s\n",
            "epoch 93 | loss: 0.58837 | val_0_accuracy: 0.73618 |  0:12:37s\n",
            "epoch 94 | loss: 0.58029 | val_0_accuracy: 0.74914 |  0:12:45s\n",
            "epoch 95 | loss: 0.551   | val_0_accuracy: 0.74827 |  0:12:53s\n",
            "epoch 96 | loss: 0.57885 | val_0_accuracy: 0.74892 |  0:13:01s\n",
            "epoch 97 | loss: 0.54919 | val_0_accuracy: 0.76425 |  0:13:09s\n",
            "epoch 98 | loss: 0.51883 | val_0_accuracy: 0.76252 |  0:13:17s\n",
            "epoch 99 | loss: 0.5251  | val_0_accuracy: 0.76317 |  0:13:25s\n",
            "\n",
            "Early stopping occurred at epoch 99 with best_epoch = 89 and best_val_0_accuracy = 0.79037\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 08:37:58,234]\u001b[0m Trial 9 finished with value: 0.7903713298791019 and parameters: {'n_d': 62, 'n_a': 48, 'n_steps': 10, 'gamma': 1.4439169904586713, 'n_independent': 4, 'n_shared': 5, 'momentum': 0.23332780455205618}. Best is trial 3 with value: 0.8037564766839378.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.66      0.57      0.61       826\n",
            "           2       0.80      0.96      0.87       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.52      0.64      0.58       761\n",
            "           5       0.79      0.49      0.61       619\n",
            "\n",
            "    accuracy                           0.79      4632\n",
            "   macro avg       0.80      0.78      0.78      4632\n",
            "weighted avg       0.80      0.79      0.79      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.37995 | val_0_accuracy: 0.54836 |  0:00:03s\n",
            "epoch 1  | loss: 0.94758 | val_0_accuracy: 0.61615 |  0:00:06s\n",
            "epoch 2  | loss: 0.93463 | val_0_accuracy: 0.5747  |  0:00:10s\n",
            "epoch 3  | loss: 0.92033 | val_0_accuracy: 0.61507 |  0:00:13s\n",
            "epoch 4  | loss: 0.859   | val_0_accuracy: 0.61744 |  0:00:16s\n",
            "epoch 5  | loss: 0.84141 | val_0_accuracy: 0.62327 |  0:00:20s\n",
            "epoch 6  | loss: 0.78935 | val_0_accuracy: 0.66451 |  0:00:23s\n",
            "epoch 7  | loss: 0.75985 | val_0_accuracy: 0.65976 |  0:00:26s\n",
            "epoch 8  | loss: 0.74744 | val_0_accuracy: 0.66645 |  0:00:29s\n",
            "epoch 9  | loss: 0.74164 | val_0_accuracy: 0.67617 |  0:00:33s\n",
            "epoch 10 | loss: 0.73849 | val_0_accuracy: 0.67832 |  0:00:36s\n",
            "epoch 11 | loss: 0.71819 | val_0_accuracy: 0.68459 |  0:00:40s\n",
            "epoch 12 | loss: 0.7103  | val_0_accuracy: 0.6861  |  0:00:43s\n",
            "epoch 13 | loss: 0.712   | val_0_accuracy: 0.67271 |  0:00:46s\n",
            "epoch 14 | loss: 0.70595 | val_0_accuracy: 0.68977 |  0:00:49s\n",
            "epoch 15 | loss: 0.71871 | val_0_accuracy: 0.67509 |  0:00:53s\n",
            "epoch 16 | loss: 0.69908 | val_0_accuracy: 0.68329 |  0:00:56s\n",
            "epoch 17 | loss: 0.69089 | val_0_accuracy: 0.69581 |  0:01:00s\n",
            "epoch 18 | loss: 0.67394 | val_0_accuracy: 0.70358 |  0:01:03s\n",
            "epoch 19 | loss: 0.6709  | val_0_accuracy: 0.70099 |  0:01:06s\n",
            "epoch 20 | loss: 0.66456 | val_0_accuracy: 0.70142 |  0:01:10s\n",
            "epoch 21 | loss: 0.65927 | val_0_accuracy: 0.70574 |  0:01:13s\n",
            "epoch 22 | loss: 0.65913 | val_0_accuracy: 0.71114 |  0:01:16s\n",
            "epoch 23 | loss: 0.65076 | val_0_accuracy: 0.71395 |  0:01:20s\n",
            "epoch 24 | loss: 0.63829 | val_0_accuracy: 0.71934 |  0:01:23s\n",
            "epoch 25 | loss: 0.63783 | val_0_accuracy: 0.72604 |  0:01:27s\n",
            "epoch 26 | loss: 0.63159 | val_0_accuracy: 0.72129 |  0:01:30s\n",
            "epoch 27 | loss: 0.62757 | val_0_accuracy: 0.72971 |  0:01:33s\n",
            "epoch 28 | loss: 0.6216  | val_0_accuracy: 0.71762 |  0:01:37s\n",
            "epoch 29 | loss: 0.61912 | val_0_accuracy: 0.72323 |  0:01:40s\n",
            "epoch 30 | loss: 0.61794 | val_0_accuracy: 0.72906 |  0:01:44s\n",
            "epoch 31 | loss: 0.61704 | val_0_accuracy: 0.71891 |  0:01:47s\n",
            "epoch 32 | loss: 0.60454 | val_0_accuracy: 0.73187 |  0:01:50s\n",
            "epoch 33 | loss: 0.59616 | val_0_accuracy: 0.73597 |  0:01:54s\n",
            "epoch 34 | loss: 0.59631 | val_0_accuracy: 0.72798 |  0:01:57s\n",
            "epoch 35 | loss: 0.5932  | val_0_accuracy: 0.74374 |  0:02:00s\n",
            "epoch 36 | loss: 0.58705 | val_0_accuracy: 0.74201 |  0:02:04s\n",
            "epoch 37 | loss: 0.58882 | val_0_accuracy: 0.74136 |  0:02:07s\n",
            "epoch 38 | loss: 0.58555 | val_0_accuracy: 0.73359 |  0:02:10s\n",
            "epoch 39 | loss: 0.58625 | val_0_accuracy: 0.73726 |  0:02:13s\n",
            "epoch 40 | loss: 0.58176 | val_0_accuracy: 0.73661 |  0:02:17s\n",
            "epoch 41 | loss: 0.58834 | val_0_accuracy: 0.73122 |  0:02:20s\n",
            "epoch 42 | loss: 0.59289 | val_0_accuracy: 0.73618 |  0:02:23s\n",
            "epoch 43 | loss: 0.58427 | val_0_accuracy: 0.74417 |  0:02:27s\n",
            "epoch 44 | loss: 0.57552 | val_0_accuracy: 0.73575 |  0:02:30s\n",
            "epoch 45 | loss: 0.5773  | val_0_accuracy: 0.74201 |  0:02:33s\n",
            "epoch 46 | loss: 0.56743 | val_0_accuracy: 0.74396 |  0:02:37s\n",
            "epoch 47 | loss: 0.56009 | val_0_accuracy: 0.73554 |  0:02:40s\n",
            "epoch 48 | loss: 0.56997 | val_0_accuracy: 0.73143 |  0:02:43s\n",
            "epoch 49 | loss: 0.57196 | val_0_accuracy: 0.74935 |  0:02:47s\n",
            "epoch 50 | loss: 0.55587 | val_0_accuracy: 0.75086 |  0:02:50s\n",
            "epoch 51 | loss: 0.56807 | val_0_accuracy: 0.73856 |  0:02:54s\n",
            "epoch 52 | loss: 0.59808 | val_0_accuracy: 0.72949 |  0:02:57s\n",
            "epoch 53 | loss: 0.60194 | val_0_accuracy: 0.73834 |  0:03:00s\n",
            "epoch 54 | loss: 0.58887 | val_0_accuracy: 0.73187 |  0:03:04s\n",
            "epoch 55 | loss: 0.57513 | val_0_accuracy: 0.73877 |  0:03:07s\n",
            "epoch 56 | loss: 0.55601 | val_0_accuracy: 0.74806 |  0:03:10s\n",
            "epoch 57 | loss: 0.54943 | val_0_accuracy: 0.75345 |  0:03:14s\n",
            "epoch 58 | loss: 0.54486 | val_0_accuracy: 0.75842 |  0:03:17s\n",
            "epoch 59 | loss: 0.53866 | val_0_accuracy: 0.76101 |  0:03:20s\n",
            "epoch 60 | loss: 0.53468 | val_0_accuracy: 0.76425 |  0:03:24s\n",
            "epoch 61 | loss: 0.54839 | val_0_accuracy: 0.75237 |  0:03:27s\n",
            "epoch 62 | loss: 0.54047 | val_0_accuracy: 0.75885 |  0:03:30s\n",
            "epoch 63 | loss: 0.54009 | val_0_accuracy: 0.76123 |  0:03:34s\n",
            "epoch 64 | loss: 0.53023 | val_0_accuracy: 0.7636  |  0:03:37s\n",
            "epoch 65 | loss: 0.52559 | val_0_accuracy: 0.77116 |  0:03:40s\n",
            "epoch 66 | loss: 0.52621 | val_0_accuracy: 0.76468 |  0:03:44s\n",
            "epoch 67 | loss: 0.58426 | val_0_accuracy: 0.72258 |  0:03:47s\n",
            "epoch 68 | loss: 0.60267 | val_0_accuracy: 0.74072 |  0:03:50s\n",
            "epoch 69 | loss: 0.55475 | val_0_accuracy: 0.75864 |  0:03:54s\n",
            "epoch 70 | loss: 0.55282 | val_0_accuracy: 0.76123 |  0:03:57s\n",
            "epoch 71 | loss: 0.53659 | val_0_accuracy: 0.76619 |  0:04:01s\n",
            "epoch 72 | loss: 0.52973 | val_0_accuracy: 0.76878 |  0:04:05s\n",
            "epoch 73 | loss: 0.52606 | val_0_accuracy: 0.77073 |  0:04:08s\n",
            "epoch 74 | loss: 0.51994 | val_0_accuracy: 0.77008 |  0:04:11s\n",
            "epoch 75 | loss: 0.51603 | val_0_accuracy: 0.77224 |  0:04:15s\n",
            "epoch 76 | loss: 0.50651 | val_0_accuracy: 0.77569 |  0:04:18s\n",
            "epoch 77 | loss: 0.50357 | val_0_accuracy: 0.78152 |  0:04:21s\n",
            "epoch 78 | loss: 0.5026  | val_0_accuracy: 0.78109 |  0:04:25s\n",
            "epoch 79 | loss: 0.49835 | val_0_accuracy: 0.77008 |  0:04:28s\n",
            "epoch 80 | loss: 0.4999  | val_0_accuracy: 0.78174 |  0:04:31s\n",
            "epoch 81 | loss: 0.49515 | val_0_accuracy: 0.77483 |  0:04:35s\n",
            "epoch 82 | loss: 0.48864 | val_0_accuracy: 0.78584 |  0:04:38s\n",
            "epoch 83 | loss: 0.48791 | val_0_accuracy: 0.78454 |  0:04:41s\n",
            "epoch 84 | loss: 0.48513 | val_0_accuracy: 0.77332 |  0:04:45s\n",
            "epoch 85 | loss: 0.48107 | val_0_accuracy: 0.78087 |  0:04:48s\n",
            "epoch 86 | loss: 0.47696 | val_0_accuracy: 0.78389 |  0:04:51s\n",
            "epoch 87 | loss: 0.47708 | val_0_accuracy: 0.78109 |  0:04:55s\n",
            "epoch 88 | loss: 0.47538 | val_0_accuracy: 0.78497 |  0:04:58s\n",
            "epoch 89 | loss: 0.47135 | val_0_accuracy: 0.78368 |  0:05:01s\n",
            "epoch 90 | loss: 0.47089 | val_0_accuracy: 0.78174 |  0:05:05s\n",
            "epoch 91 | loss: 0.46707 | val_0_accuracy: 0.79253 |  0:05:08s\n",
            "epoch 92 | loss: 0.46571 | val_0_accuracy: 0.78454 |  0:05:11s\n",
            "epoch 93 | loss: 0.46484 | val_0_accuracy: 0.78325 |  0:05:15s\n",
            "epoch 94 | loss: 0.46694 | val_0_accuracy: 0.79059 |  0:05:18s\n",
            "epoch 95 | loss: 0.46265 | val_0_accuracy: 0.79383 |  0:05:21s\n",
            "epoch 96 | loss: 0.45408 | val_0_accuracy: 0.78713 |  0:05:25s\n",
            "epoch 97 | loss: 0.4508  | val_0_accuracy: 0.78389 |  0:05:28s\n",
            "epoch 98 | loss: 0.4534  | val_0_accuracy: 0.79123 |  0:05:31s\n",
            "epoch 99 | loss: 0.45165 | val_0_accuracy: 0.78735 |  0:05:35s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 95 and best_val_0_accuracy = 0.79383\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 08:43:34,886]\u001b[0m Trial 10 finished with value: 0.793825561312608 and parameters: {'n_d': 23, 'n_a': 64, 'n_steps': 6, 'gamma': 1.2095499207288203, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.3905036342678237}. Best is trial 3 with value: 0.8037564766839378.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.64      0.63      0.63       826\n",
            "           2       0.83      0.91      0.87       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.55      0.56      0.56       761\n",
            "           5       0.71      0.61      0.65       619\n",
            "\n",
            "    accuracy                           0.79      4632\n",
            "   macro avg       0.79      0.79      0.79      4632\n",
            "weighted avg       0.79      0.79      0.79      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.16506 | val_0_accuracy: 0.60579 |  0:00:01s\n",
            "epoch 1  | loss: 0.83066 | val_0_accuracy: 0.64162 |  0:00:02s\n",
            "epoch 2  | loss: 0.77213 | val_0_accuracy: 0.65954 |  0:00:04s\n",
            "epoch 3  | loss: 0.73934 | val_0_accuracy: 0.67509 |  0:00:05s\n",
            "epoch 4  | loss: 0.7186  | val_0_accuracy: 0.67552 |  0:00:07s\n",
            "epoch 5  | loss: 0.69969 | val_0_accuracy: 0.67142 |  0:00:08s\n",
            "epoch 6  | loss: 0.69049 | val_0_accuracy: 0.69452 |  0:00:10s\n",
            "epoch 7  | loss: 0.68043 | val_0_accuracy: 0.70574 |  0:00:11s\n",
            "epoch 8  | loss: 0.66983 | val_0_accuracy: 0.69927 |  0:00:13s\n",
            "epoch 9  | loss: 0.65978 | val_0_accuracy: 0.70855 |  0:00:14s\n",
            "epoch 10 | loss: 0.65511 | val_0_accuracy: 0.70596 |  0:00:15s\n",
            "epoch 11 | loss: 0.65058 | val_0_accuracy: 0.71826 |  0:00:17s\n",
            "epoch 12 | loss: 0.64056 | val_0_accuracy: 0.71157 |  0:00:18s\n",
            "epoch 13 | loss: 0.63834 | val_0_accuracy: 0.7092  |  0:00:20s\n",
            "epoch 14 | loss: 0.62688 | val_0_accuracy: 0.7187  |  0:00:21s\n",
            "epoch 15 | loss: 0.62437 | val_0_accuracy: 0.72625 |  0:00:22s\n",
            "epoch 16 | loss: 0.61508 | val_0_accuracy: 0.73877 |  0:00:24s\n",
            "epoch 17 | loss: 0.60709 | val_0_accuracy: 0.73079 |  0:00:25s\n",
            "epoch 18 | loss: 0.60527 | val_0_accuracy: 0.72884 |  0:00:27s\n",
            "epoch 19 | loss: 0.60016 | val_0_accuracy: 0.73877 |  0:00:28s\n",
            "epoch 20 | loss: 0.60917 | val_0_accuracy: 0.71826 |  0:00:29s\n",
            "epoch 21 | loss: 0.61133 | val_0_accuracy: 0.73661 |  0:00:31s\n",
            "epoch 22 | loss: 0.59105 | val_0_accuracy: 0.73381 |  0:00:32s\n",
            "epoch 23 | loss: 0.58368 | val_0_accuracy: 0.73554 |  0:00:34s\n",
            "epoch 24 | loss: 0.57879 | val_0_accuracy: 0.73856 |  0:00:35s\n",
            "epoch 25 | loss: 0.57564 | val_0_accuracy: 0.75194 |  0:00:36s\n",
            "epoch 26 | loss: 0.56852 | val_0_accuracy: 0.74482 |  0:00:38s\n",
            "epoch 27 | loss: 0.56358 | val_0_accuracy: 0.7487  |  0:00:39s\n",
            "epoch 28 | loss: 0.56035 | val_0_accuracy: 0.74266 |  0:00:41s\n",
            "epoch 29 | loss: 0.55853 | val_0_accuracy: 0.74935 |  0:00:42s\n",
            "epoch 30 | loss: 0.55109 | val_0_accuracy: 0.75777 |  0:00:43s\n",
            "epoch 31 | loss: 0.55414 | val_0_accuracy: 0.76187 |  0:00:45s\n",
            "epoch 32 | loss: 0.55003 | val_0_accuracy: 0.75173 |  0:00:46s\n",
            "epoch 33 | loss: 0.54185 | val_0_accuracy: 0.76079 |  0:00:48s\n",
            "epoch 34 | loss: 0.54101 | val_0_accuracy: 0.76943 |  0:00:49s\n",
            "epoch 35 | loss: 0.5378  | val_0_accuracy: 0.76339 |  0:00:50s\n",
            "epoch 36 | loss: 0.53325 | val_0_accuracy: 0.76662 |  0:00:52s\n",
            "epoch 37 | loss: 0.52959 | val_0_accuracy: 0.76598 |  0:00:53s\n",
            "epoch 38 | loss: 0.5225  | val_0_accuracy: 0.75691 |  0:00:55s\n",
            "epoch 39 | loss: 0.52224 | val_0_accuracy: 0.77288 |  0:00:56s\n",
            "epoch 40 | loss: 0.51724 | val_0_accuracy: 0.76339 |  0:00:58s\n",
            "epoch 41 | loss: 0.51751 | val_0_accuracy: 0.76986 |  0:00:59s\n",
            "epoch 42 | loss: 0.51965 | val_0_accuracy: 0.76252 |  0:01:00s\n",
            "epoch 43 | loss: 0.51087 | val_0_accuracy: 0.76749 |  0:01:02s\n",
            "epoch 44 | loss: 0.51022 | val_0_accuracy: 0.77094 |  0:01:03s\n",
            "epoch 45 | loss: 0.50331 | val_0_accuracy: 0.77245 |  0:01:05s\n",
            "epoch 46 | loss: 0.4995  | val_0_accuracy: 0.77612 |  0:01:06s\n",
            "epoch 47 | loss: 0.5015  | val_0_accuracy: 0.77202 |  0:01:08s\n",
            "epoch 48 | loss: 0.49328 | val_0_accuracy: 0.77655 |  0:01:09s\n",
            "epoch 49 | loss: 0.49711 | val_0_accuracy: 0.76986 |  0:01:10s\n",
            "epoch 50 | loss: 0.49607 | val_0_accuracy: 0.77828 |  0:01:12s\n",
            "epoch 51 | loss: 0.49504 | val_0_accuracy: 0.769   |  0:01:13s\n",
            "epoch 52 | loss: 0.4968  | val_0_accuracy: 0.77763 |  0:01:15s\n",
            "epoch 53 | loss: 0.50787 | val_0_accuracy: 0.77267 |  0:01:16s\n",
            "epoch 54 | loss: 0.48817 | val_0_accuracy: 0.77677 |  0:01:17s\n",
            "epoch 55 | loss: 0.48014 | val_0_accuracy: 0.77699 |  0:01:19s\n",
            "epoch 56 | loss: 0.48313 | val_0_accuracy: 0.77591 |  0:01:20s\n",
            "epoch 57 | loss: 0.4828  | val_0_accuracy: 0.78087 |  0:01:22s\n",
            "epoch 58 | loss: 0.47585 | val_0_accuracy: 0.78346 |  0:01:23s\n",
            "epoch 59 | loss: 0.482   | val_0_accuracy: 0.78238 |  0:01:24s\n",
            "epoch 60 | loss: 0.47843 | val_0_accuracy: 0.78044 |  0:01:26s\n",
            "epoch 61 | loss: 0.47414 | val_0_accuracy: 0.78454 |  0:01:27s\n",
            "epoch 62 | loss: 0.46757 | val_0_accuracy: 0.7744  |  0:01:29s\n",
            "epoch 63 | loss: 0.47662 | val_0_accuracy: 0.77936 |  0:01:30s\n",
            "epoch 64 | loss: 0.46944 | val_0_accuracy: 0.78368 |  0:01:32s\n",
            "epoch 65 | loss: 0.46383 | val_0_accuracy: 0.7867  |  0:01:33s\n",
            "epoch 66 | loss: 0.45879 | val_0_accuracy: 0.78692 |  0:01:34s\n",
            "epoch 67 | loss: 0.45675 | val_0_accuracy: 0.7813  |  0:01:36s\n",
            "epoch 68 | loss: 0.45954 | val_0_accuracy: 0.78476 |  0:01:37s\n",
            "epoch 69 | loss: 0.45291 | val_0_accuracy: 0.78605 |  0:01:39s\n",
            "epoch 70 | loss: 0.45474 | val_0_accuracy: 0.78519 |  0:01:40s\n",
            "epoch 71 | loss: 0.45231 | val_0_accuracy: 0.78174 |  0:01:41s\n",
            "epoch 72 | loss: 0.44868 | val_0_accuracy: 0.79383 |  0:01:43s\n",
            "epoch 73 | loss: 0.44965 | val_0_accuracy: 0.79188 |  0:01:44s\n",
            "epoch 74 | loss: 0.45125 | val_0_accuracy: 0.78627 |  0:01:46s\n",
            "epoch 75 | loss: 0.44698 | val_0_accuracy: 0.79318 |  0:01:47s\n",
            "epoch 76 | loss: 0.44671 | val_0_accuracy: 0.78994 |  0:01:48s\n",
            "epoch 77 | loss: 0.44372 | val_0_accuracy: 0.79145 |  0:01:50s\n",
            "epoch 78 | loss: 0.44351 | val_0_accuracy: 0.78972 |  0:01:51s\n",
            "epoch 79 | loss: 0.4427  | val_0_accuracy: 0.78584 |  0:01:53s\n",
            "epoch 80 | loss: 0.43811 | val_0_accuracy: 0.78994 |  0:01:54s\n",
            "epoch 81 | loss: 0.43979 | val_0_accuracy: 0.79534 |  0:01:55s\n",
            "epoch 82 | loss: 0.44406 | val_0_accuracy: 0.79318 |  0:01:57s\n",
            "epoch 83 | loss: 0.4395  | val_0_accuracy: 0.79404 |  0:01:58s\n",
            "epoch 84 | loss: 0.44308 | val_0_accuracy: 0.7921  |  0:02:00s\n",
            "epoch 85 | loss: 0.43944 | val_0_accuracy: 0.79598 |  0:02:01s\n",
            "epoch 86 | loss: 0.4337  | val_0_accuracy: 0.79534 |  0:02:02s\n",
            "epoch 87 | loss: 0.43387 | val_0_accuracy: 0.79296 |  0:02:04s\n",
            "epoch 88 | loss: 0.42672 | val_0_accuracy: 0.79944 |  0:02:05s\n",
            "epoch 89 | loss: 0.42925 | val_0_accuracy: 0.78821 |  0:02:07s\n",
            "epoch 90 | loss: 0.42437 | val_0_accuracy: 0.79944 |  0:02:08s\n",
            "epoch 91 | loss: 0.42366 | val_0_accuracy: 0.79383 |  0:02:10s\n",
            "epoch 92 | loss: 0.43397 | val_0_accuracy: 0.79512 |  0:02:11s\n",
            "epoch 93 | loss: 0.43881 | val_0_accuracy: 0.79318 |  0:02:12s\n",
            "epoch 94 | loss: 0.42579 | val_0_accuracy: 0.79253 |  0:02:14s\n",
            "epoch 95 | loss: 0.41952 | val_0_accuracy: 0.8016  |  0:02:15s\n",
            "epoch 96 | loss: 0.41531 | val_0_accuracy: 0.79987 |  0:02:17s\n",
            "epoch 97 | loss: 0.41544 | val_0_accuracy: 0.79426 |  0:02:18s\n",
            "epoch 98 | loss: 0.41663 | val_0_accuracy: 0.79965 |  0:02:20s\n",
            "epoch 99 | loss: 0.4178  | val_0_accuracy: 0.80052 |  0:02:21s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 95 and best_val_0_accuracy = 0.8016\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 08:45:57,227]\u001b[0m Trial 11 finished with value: 0.8015975820379966 and parameters: {'n_d': 42, 'n_a': 25, 'n_steps': 3, 'gamma': 1.6978844384619884, 'n_independent': 2, 'n_shared': 1, 'momentum': 0.39414256231552214}. Best is trial 3 with value: 0.8037564766839378.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.66      0.62      0.64       826\n",
            "           2       0.83      0.95      0.88       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.58      0.54      0.56       761\n",
            "           5       0.67      0.67      0.67       619\n",
            "\n",
            "    accuracy                           0.80      4632\n",
            "   macro avg       0.79      0.79      0.79      4632\n",
            "weighted avg       0.80      0.80      0.80      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.12854 | val_0_accuracy: 0.62198 |  0:00:01s\n",
            "epoch 1  | loss: 0.81164 | val_0_accuracy: 0.64745 |  0:00:02s\n",
            "epoch 2  | loss: 0.74589 | val_0_accuracy: 0.68027 |  0:00:04s\n",
            "epoch 3  | loss: 0.72158 | val_0_accuracy: 0.68243 |  0:00:05s\n",
            "epoch 4  | loss: 0.70428 | val_0_accuracy: 0.68826 |  0:00:07s\n",
            "epoch 5  | loss: 0.69136 | val_0_accuracy: 0.69214 |  0:00:08s\n",
            "epoch 6  | loss: 0.68034 | val_0_accuracy: 0.7025  |  0:00:09s\n",
            "epoch 7  | loss: 0.6729  | val_0_accuracy: 0.69149 |  0:00:11s\n",
            "epoch 8  | loss: 0.65722 | val_0_accuracy: 0.70423 |  0:00:12s\n",
            "epoch 9  | loss: 0.65294 | val_0_accuracy: 0.70164 |  0:00:14s\n",
            "epoch 10 | loss: 0.64984 | val_0_accuracy: 0.71287 |  0:00:15s\n",
            "epoch 11 | loss: 0.63033 | val_0_accuracy: 0.72064 |  0:00:17s\n",
            "epoch 12 | loss: 0.6401  | val_0_accuracy: 0.71395 |  0:00:18s\n",
            "epoch 13 | loss: 0.63791 | val_0_accuracy: 0.71611 |  0:00:19s\n",
            "epoch 14 | loss: 0.62877 | val_0_accuracy: 0.7187  |  0:00:21s\n",
            "epoch 15 | loss: 0.61437 | val_0_accuracy: 0.72517 |  0:00:22s\n",
            "epoch 16 | loss: 0.60404 | val_0_accuracy: 0.71416 |  0:00:24s\n",
            "epoch 17 | loss: 0.63623 | val_0_accuracy: 0.70769 |  0:00:25s\n",
            "epoch 18 | loss: 0.64355 | val_0_accuracy: 0.71934 |  0:00:27s\n",
            "epoch 19 | loss: 0.63565 | val_0_accuracy: 0.72107 |  0:00:28s\n",
            "epoch 20 | loss: 0.61404 | val_0_accuracy: 0.73273 |  0:00:29s\n",
            "epoch 21 | loss: 0.60395 | val_0_accuracy: 0.73079 |  0:00:31s\n",
            "epoch 22 | loss: 0.59588 | val_0_accuracy: 0.73661 |  0:00:32s\n",
            "epoch 23 | loss: 0.59374 | val_0_accuracy: 0.73359 |  0:00:34s\n",
            "epoch 24 | loss: 0.59198 | val_0_accuracy: 0.74136 |  0:00:35s\n",
            "epoch 25 | loss: 0.61829 | val_0_accuracy: 0.72906 |  0:00:37s\n",
            "epoch 26 | loss: 0.60725 | val_0_accuracy: 0.72949 |  0:00:38s\n",
            "epoch 27 | loss: 0.61289 | val_0_accuracy: 0.73143 |  0:00:39s\n",
            "epoch 28 | loss: 0.60305 | val_0_accuracy: 0.7282  |  0:00:41s\n",
            "epoch 29 | loss: 0.59441 | val_0_accuracy: 0.73834 |  0:00:42s\n",
            "epoch 30 | loss: 0.58341 | val_0_accuracy: 0.73791 |  0:00:43s\n",
            "epoch 31 | loss: 0.58063 | val_0_accuracy: 0.74374 |  0:00:45s\n",
            "epoch 32 | loss: 0.57209 | val_0_accuracy: 0.74503 |  0:00:46s\n",
            "epoch 33 | loss: 0.58559 | val_0_accuracy: 0.74028 |  0:00:48s\n",
            "epoch 34 | loss: 0.58744 | val_0_accuracy: 0.73489 |  0:00:49s\n",
            "epoch 35 | loss: 0.60537 | val_0_accuracy: 0.72453 |  0:00:51s\n",
            "epoch 36 | loss: 0.60128 | val_0_accuracy: 0.74352 |  0:00:52s\n",
            "epoch 37 | loss: 0.58128 | val_0_accuracy: 0.73316 |  0:00:54s\n",
            "epoch 38 | loss: 0.5968  | val_0_accuracy: 0.7323  |  0:00:55s\n",
            "epoch 39 | loss: 0.58256 | val_0_accuracy: 0.74072 |  0:00:56s\n",
            "epoch 40 | loss: 0.58045 | val_0_accuracy: 0.74935 |  0:00:58s\n",
            "epoch 41 | loss: 0.58125 | val_0_accuracy: 0.73187 |  0:00:59s\n",
            "epoch 42 | loss: 0.57389 | val_0_accuracy: 0.73834 |  0:01:01s\n",
            "epoch 43 | loss: 0.60281 | val_0_accuracy: 0.73813 |  0:01:02s\n",
            "epoch 44 | loss: 0.57897 | val_0_accuracy: 0.72388 |  0:01:04s\n",
            "epoch 45 | loss: 0.58883 | val_0_accuracy: 0.72798 |  0:01:05s\n",
            "epoch 46 | loss: 0.5917  | val_0_accuracy: 0.71913 |  0:01:07s\n",
            "epoch 47 | loss: 0.59098 | val_0_accuracy: 0.7351  |  0:01:08s\n",
            "epoch 48 | loss: 0.60646 | val_0_accuracy: 0.73381 |  0:01:09s\n",
            "epoch 49 | loss: 0.59228 | val_0_accuracy: 0.73251 |  0:01:11s\n",
            "epoch 50 | loss: 0.59285 | val_0_accuracy: 0.72539 |  0:01:12s\n",
            "\n",
            "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_accuracy = 0.74935\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 08:47:10,583]\u001b[0m Trial 12 finished with value: 0.7493523316062176 and parameters: {'n_d': 40, 'n_a': 62, 'n_steps': 3, 'gamma': 1.6769688640173515, 'n_independent': 2, 'n_shared': 1, 'momentum': 0.32224454844106504}. Best is trial 3 with value: 0.8037564766839378.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       825\n",
            "           1       0.56      0.53      0.54       826\n",
            "           2       0.82      0.84      0.83       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.47      0.58      0.52       761\n",
            "           5       0.65      0.49      0.56       619\n",
            "\n",
            "    accuracy                           0.75      4632\n",
            "   macro avg       0.75      0.74      0.74      4632\n",
            "weighted avg       0.75      0.75      0.75      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.36335 | val_0_accuracy: 0.59909 |  0:00:02s\n",
            "epoch 1  | loss: 0.93431 | val_0_accuracy: 0.60622 |  0:00:04s\n",
            "epoch 2  | loss: 0.85742 | val_0_accuracy: 0.63731 |  0:00:07s\n",
            "epoch 3  | loss: 0.84112 | val_0_accuracy: 0.63212 |  0:00:09s\n",
            "epoch 4  | loss: 0.82779 | val_0_accuracy: 0.61874 |  0:00:11s\n",
            "epoch 5  | loss: 0.81333 | val_0_accuracy: 0.65458 |  0:00:14s\n",
            "epoch 6  | loss: 0.77883 | val_0_accuracy: 0.66127 |  0:00:16s\n",
            "epoch 7  | loss: 0.75328 | val_0_accuracy: 0.67206 |  0:00:19s\n",
            "epoch 8  | loss: 0.73266 | val_0_accuracy: 0.66969 |  0:00:21s\n",
            "epoch 9  | loss: 0.71753 | val_0_accuracy: 0.68307 |  0:00:23s\n",
            "epoch 10 | loss: 0.71385 | val_0_accuracy: 0.67444 |  0:00:26s\n",
            "epoch 11 | loss: 0.70528 | val_0_accuracy: 0.68307 |  0:00:28s\n",
            "epoch 12 | loss: 0.69272 | val_0_accuracy: 0.69516 |  0:00:31s\n",
            "epoch 13 | loss: 0.69113 | val_0_accuracy: 0.69408 |  0:00:33s\n",
            "epoch 14 | loss: 0.68579 | val_0_accuracy: 0.69214 |  0:00:36s\n",
            "epoch 15 | loss: 0.70209 | val_0_accuracy: 0.69171 |  0:00:38s\n",
            "epoch 16 | loss: 0.68538 | val_0_accuracy: 0.69279 |  0:00:40s\n",
            "epoch 17 | loss: 0.67821 | val_0_accuracy: 0.69236 |  0:00:43s\n",
            "epoch 18 | loss: 0.67646 | val_0_accuracy: 0.70445 |  0:00:45s\n",
            "epoch 19 | loss: 0.67232 | val_0_accuracy: 0.69991 |  0:00:48s\n",
            "epoch 20 | loss: 0.67767 | val_0_accuracy: 0.70596 |  0:00:50s\n",
            "epoch 21 | loss: 0.67254 | val_0_accuracy: 0.69538 |  0:00:52s\n",
            "epoch 22 | loss: 0.66357 | val_0_accuracy: 0.71222 |  0:00:55s\n",
            "epoch 23 | loss: 0.65409 | val_0_accuracy: 0.70855 |  0:00:57s\n",
            "epoch 24 | loss: 0.64526 | val_0_accuracy: 0.70229 |  0:01:00s\n",
            "epoch 25 | loss: 0.6497  | val_0_accuracy: 0.70898 |  0:01:02s\n",
            "epoch 26 | loss: 0.64311 | val_0_accuracy: 0.70488 |  0:01:04s\n",
            "epoch 27 | loss: 0.65173 | val_0_accuracy: 0.71092 |  0:01:07s\n",
            "epoch 28 | loss: 0.64329 | val_0_accuracy: 0.69322 |  0:01:09s\n",
            "epoch 29 | loss: 0.65287 | val_0_accuracy: 0.70898 |  0:01:11s\n",
            "epoch 30 | loss: 0.6371  | val_0_accuracy: 0.7187  |  0:01:14s\n",
            "epoch 31 | loss: 0.63443 | val_0_accuracy: 0.712   |  0:01:17s\n",
            "epoch 32 | loss: 0.62863 | val_0_accuracy: 0.72042 |  0:01:20s\n",
            "epoch 33 | loss: 0.62482 | val_0_accuracy: 0.72366 |  0:01:22s\n",
            "epoch 34 | loss: 0.62028 | val_0_accuracy: 0.71805 |  0:01:24s\n",
            "epoch 35 | loss: 0.6211  | val_0_accuracy: 0.72085 |  0:01:27s\n",
            "epoch 36 | loss: 0.62263 | val_0_accuracy: 0.71416 |  0:01:29s\n",
            "epoch 37 | loss: 0.62606 | val_0_accuracy: 0.72323 |  0:01:32s\n",
            "epoch 38 | loss: 0.62681 | val_0_accuracy: 0.71244 |  0:01:34s\n",
            "epoch 39 | loss: 0.62648 | val_0_accuracy: 0.71136 |  0:01:36s\n",
            "epoch 40 | loss: 0.63047 | val_0_accuracy: 0.71632 |  0:01:39s\n",
            "epoch 41 | loss: 0.625   | val_0_accuracy: 0.73035 |  0:01:41s\n",
            "epoch 42 | loss: 0.61977 | val_0_accuracy: 0.73122 |  0:01:43s\n",
            "epoch 43 | loss: 0.6123  | val_0_accuracy: 0.73446 |  0:01:46s\n",
            "epoch 44 | loss: 0.6078  | val_0_accuracy: 0.71136 |  0:01:48s\n",
            "epoch 45 | loss: 0.62125 | val_0_accuracy: 0.72107 |  0:01:50s\n",
            "epoch 46 | loss: 0.622   | val_0_accuracy: 0.731   |  0:01:53s\n",
            "epoch 47 | loss: 0.6298  | val_0_accuracy: 0.71848 |  0:01:55s\n",
            "epoch 48 | loss: 0.60549 | val_0_accuracy: 0.73618 |  0:01:58s\n",
            "epoch 49 | loss: 0.59258 | val_0_accuracy: 0.73489 |  0:02:00s\n",
            "epoch 50 | loss: 0.58872 | val_0_accuracy: 0.73316 |  0:02:03s\n",
            "epoch 51 | loss: 0.58736 | val_0_accuracy: 0.74244 |  0:02:05s\n",
            "epoch 52 | loss: 0.57989 | val_0_accuracy: 0.7418  |  0:02:07s\n",
            "epoch 53 | loss: 0.5783  | val_0_accuracy: 0.74525 |  0:02:10s\n",
            "epoch 54 | loss: 0.57882 | val_0_accuracy: 0.73035 |  0:02:12s\n",
            "epoch 55 | loss: 0.57738 | val_0_accuracy: 0.7446  |  0:02:14s\n",
            "epoch 56 | loss: 0.57318 | val_0_accuracy: 0.7418  |  0:02:17s\n",
            "epoch 57 | loss: 0.57933 | val_0_accuracy: 0.74698 |  0:02:19s\n",
            "epoch 58 | loss: 0.56879 | val_0_accuracy: 0.74115 |  0:02:22s\n",
            "epoch 59 | loss: 0.5638  | val_0_accuracy: 0.74763 |  0:02:24s\n",
            "epoch 60 | loss: 0.56049 | val_0_accuracy: 0.74396 |  0:02:26s\n",
            "epoch 61 | loss: 0.57778 | val_0_accuracy: 0.74568 |  0:02:29s\n",
            "epoch 62 | loss: 0.56209 | val_0_accuracy: 0.75497 |  0:02:31s\n",
            "epoch 63 | loss: 0.55334 | val_0_accuracy: 0.75043 |  0:02:33s\n",
            "epoch 64 | loss: 0.5558  | val_0_accuracy: 0.75518 |  0:02:36s\n",
            "epoch 65 | loss: 0.54763 | val_0_accuracy: 0.76036 |  0:02:38s\n",
            "epoch 66 | loss: 0.54187 | val_0_accuracy: 0.7541  |  0:02:41s\n",
            "epoch 67 | loss: 0.55185 | val_0_accuracy: 0.75712 |  0:02:43s\n",
            "epoch 68 | loss: 0.54363 | val_0_accuracy: 0.75907 |  0:02:45s\n",
            "epoch 69 | loss: 0.54127 | val_0_accuracy: 0.76425 |  0:02:48s\n",
            "epoch 70 | loss: 0.54178 | val_0_accuracy: 0.73791 |  0:02:50s\n",
            "epoch 71 | loss: 0.54528 | val_0_accuracy: 0.76576 |  0:02:53s\n",
            "epoch 72 | loss: 0.53263 | val_0_accuracy: 0.76123 |  0:02:55s\n",
            "epoch 73 | loss: 0.53709 | val_0_accuracy: 0.76231 |  0:02:57s\n",
            "epoch 74 | loss: 0.52713 | val_0_accuracy: 0.76101 |  0:03:00s\n",
            "epoch 75 | loss: 0.5262  | val_0_accuracy: 0.76533 |  0:03:02s\n",
            "epoch 76 | loss: 0.52244 | val_0_accuracy: 0.7677  |  0:03:05s\n",
            "epoch 77 | loss: 0.52162 | val_0_accuracy: 0.76209 |  0:03:07s\n",
            "epoch 78 | loss: 0.52986 | val_0_accuracy: 0.76123 |  0:03:09s\n",
            "epoch 79 | loss: 0.52525 | val_0_accuracy: 0.76295 |  0:03:12s\n",
            "epoch 80 | loss: 0.51607 | val_0_accuracy: 0.77051 |  0:03:14s\n",
            "epoch 81 | loss: 0.51305 | val_0_accuracy: 0.76943 |  0:03:16s\n",
            "epoch 82 | loss: 0.51191 | val_0_accuracy: 0.76943 |  0:03:19s\n",
            "epoch 83 | loss: 0.51199 | val_0_accuracy: 0.7677  |  0:03:21s\n",
            "epoch 84 | loss: 0.53925 | val_0_accuracy: 0.75086 |  0:03:23s\n",
            "epoch 85 | loss: 0.53276 | val_0_accuracy: 0.76403 |  0:03:26s\n",
            "epoch 86 | loss: 0.5223  | val_0_accuracy: 0.76986 |  0:03:28s\n",
            "epoch 87 | loss: 0.51576 | val_0_accuracy: 0.76857 |  0:03:30s\n",
            "epoch 88 | loss: 0.52525 | val_0_accuracy: 0.73661 |  0:03:33s\n",
            "epoch 89 | loss: 0.53149 | val_0_accuracy: 0.75518 |  0:03:35s\n",
            "epoch 90 | loss: 0.50594 | val_0_accuracy: 0.76446 |  0:03:38s\n",
            "\n",
            "Early stopping occurred at epoch 90 with best_epoch = 80 and best_val_0_accuracy = 0.77051\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 08:50:49,924]\u001b[0m Trial 13 finished with value: 0.7705094991364422 and parameters: {'n_d': 35, 'n_a': 29, 'n_steps': 5, 'gamma': 1.2472486283743442, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.3304379753219197}. Best is trial 3 with value: 0.8037564766839378.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       825\n",
            "           1       0.59      0.57      0.58       826\n",
            "           2       0.81      0.91      0.86       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.50      0.49      0.50       761\n",
            "           5       0.67      0.60      0.63       619\n",
            "\n",
            "    accuracy                           0.77      4632\n",
            "   macro avg       0.76      0.76      0.76      4632\n",
            "weighted avg       0.77      0.77      0.77      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.28427 | val_0_accuracy: 0.57535 |  0:00:02s\n",
            "epoch 1  | loss: 0.93214 | val_0_accuracy: 0.60881 |  0:00:04s\n",
            "epoch 2  | loss: 0.84403 | val_0_accuracy: 0.62435 |  0:00:07s\n",
            "epoch 3  | loss: 0.8033  | val_0_accuracy: 0.63644 |  0:00:09s\n",
            "epoch 4  | loss: 0.76119 | val_0_accuracy: 0.67206 |  0:00:12s\n",
            "epoch 5  | loss: 0.73806 | val_0_accuracy: 0.67422 |  0:00:14s\n",
            "epoch 6  | loss: 0.7199  | val_0_accuracy: 0.68502 |  0:00:16s\n",
            "epoch 7  | loss: 0.71133 | val_0_accuracy: 0.68566 |  0:00:19s\n",
            "epoch 8  | loss: 0.706   | val_0_accuracy: 0.68847 |  0:00:21s\n",
            "epoch 9  | loss: 0.69564 | val_0_accuracy: 0.67358 |  0:00:24s\n",
            "epoch 10 | loss: 0.69207 | val_0_accuracy: 0.68674 |  0:00:26s\n",
            "epoch 11 | loss: 0.68171 | val_0_accuracy: 0.6889  |  0:00:29s\n",
            "epoch 12 | loss: 0.66827 | val_0_accuracy: 0.69948 |  0:00:31s\n",
            "epoch 13 | loss: 0.66249 | val_0_accuracy: 0.70099 |  0:00:33s\n",
            "epoch 14 | loss: 0.6556  | val_0_accuracy: 0.6997  |  0:00:36s\n",
            "epoch 15 | loss: 0.64969 | val_0_accuracy: 0.70229 |  0:00:38s\n",
            "epoch 16 | loss: 0.64292 | val_0_accuracy: 0.70531 |  0:00:41s\n",
            "epoch 17 | loss: 0.6412  | val_0_accuracy: 0.70877 |  0:00:43s\n",
            "epoch 18 | loss: 0.63348 | val_0_accuracy: 0.70661 |  0:00:46s\n",
            "epoch 19 | loss: 0.62503 | val_0_accuracy: 0.72042 |  0:00:48s\n",
            "epoch 20 | loss: 0.63578 | val_0_accuracy: 0.71351 |  0:00:50s\n",
            "epoch 21 | loss: 0.62688 | val_0_accuracy: 0.72604 |  0:00:53s\n",
            "epoch 22 | loss: 0.61741 | val_0_accuracy: 0.7025  |  0:00:55s\n",
            "epoch 23 | loss: 0.6087  | val_0_accuracy: 0.73618 |  0:00:58s\n",
            "epoch 24 | loss: 0.60573 | val_0_accuracy: 0.72409 |  0:01:00s\n",
            "epoch 25 | loss: 0.60721 | val_0_accuracy: 0.73143 |  0:01:03s\n",
            "epoch 26 | loss: 0.60451 | val_0_accuracy: 0.72776 |  0:01:05s\n",
            "epoch 27 | loss: 0.59552 | val_0_accuracy: 0.73467 |  0:01:07s\n",
            "epoch 28 | loss: 0.58769 | val_0_accuracy: 0.73748 |  0:01:10s\n",
            "epoch 29 | loss: 0.58361 | val_0_accuracy: 0.73467 |  0:01:12s\n",
            "epoch 30 | loss: 0.59319 | val_0_accuracy: 0.73877 |  0:01:15s\n",
            "epoch 31 | loss: 0.58589 | val_0_accuracy: 0.74028 |  0:01:17s\n",
            "epoch 32 | loss: 0.58462 | val_0_accuracy: 0.73985 |  0:01:19s\n",
            "epoch 33 | loss: 0.57223 | val_0_accuracy: 0.7256  |  0:01:22s\n",
            "epoch 34 | loss: 0.57093 | val_0_accuracy: 0.73014 |  0:01:24s\n",
            "epoch 35 | loss: 0.56586 | val_0_accuracy: 0.75259 |  0:01:27s\n",
            "epoch 36 | loss: 0.56455 | val_0_accuracy: 0.73575 |  0:01:29s\n",
            "epoch 37 | loss: 0.56657 | val_0_accuracy: 0.73187 |  0:01:31s\n",
            "epoch 38 | loss: 0.55974 | val_0_accuracy: 0.75065 |  0:01:34s\n",
            "epoch 39 | loss: 0.55304 | val_0_accuracy: 0.75022 |  0:01:36s\n",
            "epoch 40 | loss: 0.54862 | val_0_accuracy: 0.74914 |  0:01:39s\n",
            "epoch 41 | loss: 0.55533 | val_0_accuracy: 0.74935 |  0:01:41s\n",
            "epoch 42 | loss: 0.55498 | val_0_accuracy: 0.75259 |  0:01:43s\n",
            "epoch 43 | loss: 0.55164 | val_0_accuracy: 0.75475 |  0:01:46s\n",
            "epoch 44 | loss: 0.55685 | val_0_accuracy: 0.74978 |  0:01:48s\n",
            "epoch 45 | loss: 0.55048 | val_0_accuracy: 0.75281 |  0:01:51s\n",
            "epoch 46 | loss: 0.53873 | val_0_accuracy: 0.74698 |  0:01:53s\n",
            "epoch 47 | loss: 0.53374 | val_0_accuracy: 0.75281 |  0:01:56s\n",
            "epoch 48 | loss: 0.52825 | val_0_accuracy: 0.76274 |  0:01:58s\n",
            "epoch 49 | loss: 0.53138 | val_0_accuracy: 0.76231 |  0:02:00s\n",
            "epoch 50 | loss: 0.52805 | val_0_accuracy: 0.76921 |  0:02:03s\n",
            "epoch 51 | loss: 0.52228 | val_0_accuracy: 0.76295 |  0:02:05s\n",
            "epoch 52 | loss: 0.51892 | val_0_accuracy: 0.76101 |  0:02:08s\n",
            "epoch 53 | loss: 0.52553 | val_0_accuracy: 0.75972 |  0:02:10s\n",
            "epoch 54 | loss: 0.51588 | val_0_accuracy: 0.76576 |  0:02:13s\n",
            "epoch 55 | loss: 0.5228  | val_0_accuracy: 0.75626 |  0:02:15s\n",
            "epoch 56 | loss: 0.51122 | val_0_accuracy: 0.7582  |  0:02:18s\n",
            "epoch 57 | loss: 0.51156 | val_0_accuracy: 0.76123 |  0:02:20s\n",
            "epoch 58 | loss: 0.51035 | val_0_accuracy: 0.7677  |  0:02:22s\n",
            "epoch 59 | loss: 0.50293 | val_0_accuracy: 0.76727 |  0:02:25s\n",
            "epoch 60 | loss: 0.50346 | val_0_accuracy: 0.76878 |  0:02:27s\n",
            "\n",
            "Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_accuracy = 0.76921\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 08:53:18,852]\u001b[0m Trial 14 finished with value: 0.7692141623488774 and parameters: {'n_d': 44, 'n_a': 29, 'n_steps': 3, 'gamma': 1.6184874724169172, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.32071202667105614}. Best is trial 3 with value: 0.8037564766839378.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.57      0.55      0.56       826\n",
            "           2       0.82      0.88      0.85       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.51      0.55      0.53       761\n",
            "           5       0.69      0.58      0.63       619\n",
            "\n",
            "    accuracy                           0.77      4632\n",
            "   macro avg       0.76      0.76      0.76      4632\n",
            "weighted avg       0.77      0.77      0.77      4632\n",
            "\n",
            " Best params for fold : [1/10]\n",
            "{'n_d': 17, 'n_a': 55, 'n_steps': 3, 'gamma': 1.2906043466163537, 'n_independent': 2, 'n_shared': 1, 'momentum': 0.3578040087905696}\n",
            "Saved best_params at : outputs/pytorch_tabnet/best_params/fold_1_best_params.txt\n",
            "Device used : cuda\n",
            "No early stopping will be performed, last training weights will be used.\n",
            "epoch 0  | loss: 1.093   |  0:00:01s\n",
            "epoch 1  | loss: 0.8258  |  0:00:02s\n",
            "epoch 2  | loss: 0.76969 |  0:00:03s\n",
            "epoch 3  | loss: 0.73682 |  0:00:05s\n",
            "epoch 4  | loss: 0.70948 |  0:00:06s\n",
            "epoch 5  | loss: 0.69576 |  0:00:07s\n",
            "epoch 6  | loss: 0.6803  |  0:00:09s\n",
            "epoch 7  | loss: 0.67294 |  0:00:10s\n",
            "epoch 8  | loss: 0.66985 |  0:00:11s\n",
            "epoch 9  | loss: 0.65548 |  0:00:13s\n",
            "epoch 10 | loss: 0.64786 |  0:00:14s\n",
            "epoch 11 | loss: 0.63835 |  0:00:15s\n",
            "epoch 12 | loss: 0.63461 |  0:00:17s\n",
            "epoch 13 | loss: 0.6254  |  0:00:18s\n",
            "epoch 14 | loss: 0.62911 |  0:00:19s\n",
            "epoch 15 | loss: 0.61927 |  0:00:21s\n",
            "epoch 16 | loss: 0.60982 |  0:00:22s\n",
            "epoch 17 | loss: 0.60159 |  0:00:23s\n",
            "epoch 18 | loss: 0.59659 |  0:00:25s\n",
            "epoch 19 | loss: 0.59308 |  0:00:26s\n",
            "epoch 20 | loss: 0.58739 |  0:00:27s\n",
            "epoch 21 | loss: 0.57991 |  0:00:29s\n",
            "epoch 22 | loss: 0.57859 |  0:00:30s\n",
            "epoch 23 | loss: 0.58395 |  0:00:31s\n",
            "epoch 24 | loss: 0.58346 |  0:00:33s\n",
            "epoch 25 | loss: 0.5775  |  0:00:34s\n",
            "epoch 26 | loss: 0.56987 |  0:00:35s\n",
            "epoch 27 | loss: 0.56344 |  0:00:37s\n",
            "epoch 28 | loss: 0.55884 |  0:00:38s\n",
            "epoch 29 | loss: 0.55653 |  0:00:40s\n",
            "epoch 30 | loss: 0.54974 |  0:00:41s\n",
            "epoch 31 | loss: 0.54866 |  0:00:42s\n",
            "epoch 32 | loss: 0.54363 |  0:00:44s\n",
            "epoch 33 | loss: 0.54071 |  0:00:45s\n",
            "epoch 34 | loss: 0.54378 |  0:00:46s\n",
            "epoch 35 | loss: 0.54076 |  0:00:48s\n",
            "epoch 36 | loss: 0.53786 |  0:00:49s\n",
            "epoch 37 | loss: 0.52816 |  0:00:50s\n",
            "epoch 38 | loss: 0.52059 |  0:00:52s\n",
            "epoch 39 | loss: 0.52249 |  0:00:53s\n",
            "epoch 40 | loss: 0.52505 |  0:00:54s\n",
            "epoch 41 | loss: 0.52466 |  0:00:56s\n",
            "epoch 42 | loss: 0.521   |  0:00:57s\n",
            "epoch 43 | loss: 0.52183 |  0:00:58s\n",
            "epoch 44 | loss: 0.52458 |  0:01:00s\n",
            "epoch 45 | loss: 0.52577 |  0:01:01s\n",
            "epoch 46 | loss: 0.51026 |  0:01:02s\n",
            "epoch 47 | loss: 0.50502 |  0:01:04s\n",
            "epoch 48 | loss: 0.50272 |  0:01:05s\n",
            "epoch 49 | loss: 0.49723 |  0:01:06s\n",
            "epoch 50 | loss: 0.49677 |  0:01:08s\n",
            "epoch 51 | loss: 0.48738 |  0:01:09s\n",
            "epoch 52 | loss: 0.49082 |  0:01:10s\n",
            "epoch 53 | loss: 0.49266 |  0:01:12s\n",
            "epoch 54 | loss: 0.49327 |  0:01:13s\n",
            "epoch 55 | loss: 0.48701 |  0:01:14s\n",
            "epoch 56 | loss: 0.4837  |  0:01:16s\n",
            "epoch 57 | loss: 0.4915  |  0:01:17s\n",
            "epoch 58 | loss: 0.48256 |  0:01:18s\n",
            "epoch 59 | loss: 0.47613 |  0:01:20s\n",
            "epoch 60 | loss: 0.47723 |  0:01:21s\n",
            "epoch 61 | loss: 0.48198 |  0:01:22s\n",
            "epoch 62 | loss: 0.47179 |  0:01:24s\n",
            "epoch 63 | loss: 0.47043 |  0:01:25s\n",
            "epoch 64 | loss: 0.46674 |  0:01:26s\n",
            "epoch 65 | loss: 0.46018 |  0:01:28s\n",
            "epoch 66 | loss: 0.46454 |  0:01:29s\n",
            "epoch 67 | loss: 0.45693 |  0:01:30s\n",
            "epoch 68 | loss: 0.45429 |  0:01:32s\n",
            "epoch 69 | loss: 0.45283 |  0:01:33s\n",
            "epoch 70 | loss: 0.44669 |  0:01:34s\n",
            "epoch 71 | loss: 0.45104 |  0:01:36s\n",
            "epoch 72 | loss: 0.45944 |  0:01:37s\n",
            "epoch 73 | loss: 0.45076 |  0:01:38s\n",
            "epoch 74 | loss: 0.44679 |  0:01:40s\n",
            "epoch 75 | loss: 0.44263 |  0:01:41s\n",
            "epoch 76 | loss: 0.44226 |  0:01:42s\n",
            "epoch 77 | loss: 0.4429  |  0:01:44s\n",
            "epoch 78 | loss: 0.43518 |  0:01:46s\n",
            "epoch 79 | loss: 0.43803 |  0:01:47s\n",
            "epoch 80 | loss: 0.4359  |  0:01:48s\n",
            "epoch 81 | loss: 0.44416 |  0:01:50s\n",
            "epoch 82 | loss: 0.44571 |  0:01:51s\n",
            "epoch 83 | loss: 0.4339  |  0:01:53s\n",
            "epoch 84 | loss: 0.42731 |  0:01:54s\n",
            "epoch 85 | loss: 0.42606 |  0:01:55s\n",
            "epoch 86 | loss: 0.42571 |  0:01:56s\n",
            "epoch 87 | loss: 0.42188 |  0:01:58s\n",
            "epoch 88 | loss: 0.42751 |  0:01:59s\n",
            "epoch 89 | loss: 0.4285  |  0:02:00s\n",
            "epoch 90 | loss: 0.42743 |  0:02:02s\n",
            "epoch 91 | loss: 0.42303 |  0:02:03s\n",
            "epoch 92 | loss: 0.41673 |  0:02:04s\n",
            "epoch 93 | loss: 0.42187 |  0:02:06s\n",
            "epoch 94 | loss: 0.41557 |  0:02:07s\n",
            "epoch 95 | loss: 0.41435 |  0:02:08s\n",
            "epoch 96 | loss: 0.41292 |  0:02:10s\n",
            "epoch 97 | loss: 0.42039 |  0:02:11s\n",
            "epoch 98 | loss: 0.43917 |  0:02:12s\n",
            "epoch 99 | loss: 0.42327 |  0:02:14s\n",
            "[++] Saving the model and parameters in corresponding directories\n",
            "[++] Ended the training process for fold 1\n"
          ]
        }
      ],
      "source": [
        "train(fold_dict = fold_dict,\n",
        "      fold = fold,\n",
        "      model_name=model_name,\n",
        "      sc_df=use_df,\n",
        "      tar_col=tar_col,\n",
        "      optim=optimizer,\n",
        "      optim_trial = 15)\n",
        "print(f\"[++] Ended the training process for fold {fold}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ja5dUXmqsCFF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afu4nJyHu-sp"
      },
      "source": [
        "Fold 0 has started running on 20-05-22 \n",
        "\n",
        "\n",
        "Fold 0 has completed sucessfully on 17:00 20-05-22\n",
        "\n",
        "Fold 1 has started running at 15:15 21-05-22\n",
        "\n",
        "Fold 2 has started running at 09:45 22-05-22\n",
        "\n",
        "Fold 2 has completed sucessfully on 10:58 22-05-22\n",
        "\n",
        "Fold 3 has started running at 18:40 22-05-22\n",
        "\n",
        "Fold 3 has completed sucessfully on 22-05-22\n",
        "\n",
        "Fold 4 completed sucessfully on 21:04 on 22-05-22\n",
        "\n",
        "Fold 5 started at 18:21 on 23-05-22\n",
        "\n",
        "Fold 5 completed sucessfully on 19:44 on 23-05-22\n",
        "\n",
        "Fold 6 started at 12:53 on 24-05-22\n",
        "\n",
        "Fold 6 has completed at 14:14 on 24-05-22\n",
        "\n",
        "Fold 7 started at 14:18 on 24-05-22\n",
        "\n",
        "Fold 7 execution failed due to colab gpu time limit\n",
        "\n",
        "Fold 7 trial 1 started at 11:00 on 25-05-22\n",
        "\n",
        "Fold 7 has completed sucessfully at 12:14 on 25-05-22 \n",
        "\n",
        "Fold 8 has started at 9:38 on 26-05-22\n",
        "\n",
        "Fold 8 filed due to interrupted internet connection\n",
        "\n",
        "Fold 8 trial 1 started at 13:38 on 26-05-22\n",
        "\n",
        "Fold 8 has successfully executed at 15:33 on 26-05-22\n",
        "\n",
        "Fold 9 has started at 13:35 on 27-05-22\n",
        "\n",
        "Fold 9 has completed at 14:55 on 27-05-22"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me85YLlzpUM8"
      },
      "source": [
        "Editing with rectified dataset witout duplicacy because of space values\n",
        "\n",
        "Fold 0 started at 13:21 on 28-05-22\n",
        "\n",
        "Fold 0 completed sucessfully at 14:46 on 28-05-22\n",
        "\n",
        "Fold 1 Failed to run due to some index error\n",
        "\n",
        "_____ Restarting the training process again due to data distribution failure____\n",
        "\n",
        "\n",
        "\n",
        "Fold 0 started at 10:47 on 30-05-22\n",
        "\n",
        "Fold 0 completed successfully at 12:30 on 30-05-22\n",
        "\n",
        "Fold 1 started at 8:27 on 31-05-22\n",
        "\n",
        "Fold 1 execution failed due to runtime disconnection\n",
        "\n",
        "Fold 1 started again at 9:38 on 31-05-22\n",
        "\n",
        "Fold 1 execution failed due to gpu disconnect \n",
        "\n",
        "Fold 1 started again at 8:36 on 1-06-22\n",
        "\n",
        "Fold 1 execution failed due to network disconnection\n",
        "\n",
        "Fold 1 started again at 13:11 on 01-06-22\n",
        "\n",
        "Fold 1 has succesfully executed at 14:25 on 01-06-22"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zICGdYlFNr13"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "train_tabnet_fold_div.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}