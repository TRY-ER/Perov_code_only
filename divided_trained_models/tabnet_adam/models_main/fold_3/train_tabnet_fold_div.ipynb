{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5-jiYKypEVY",
        "outputId": "70e2e70e-42ce-41de-8551-bb7120d4d1f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun  2 08:04:21 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0tPZaeupLWn",
        "outputId": "0086e282-cabd-4a9e-df73-710966f05c39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-3.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 39.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.11.0+cu113)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.0.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.21.6)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.4.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (4.64.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.2.0)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.8.0-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 73.9 MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 10.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.4)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 74.4 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 58.9 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=d085145e23d99c8bf81c1ba3d72b24bef10345a9a60f9811074749e599202774\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, pytorch-tabnet, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.8.0 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.0 pbr-5.9.0 pyperclip-1.8.2 pytorch-tabnet-3.1.1 stevedore-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-tabnet optuna "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vRmDYdsCpMT-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "import optuna as opt\n",
        "import torch\n",
        "import os\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L4HljGyopQs_"
      },
      "outputs": [],
      "source": [
        "def make_save_cv_model(i,model_name,model,best_params,optim,output_path=\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/cross_validated_models\"):\n",
        "\n",
        "    ''' This function saves cross validation model in the corresponding directory ( if the path does not exist it creates the path for it'''\n",
        "\n",
        "\n",
        "    if os.path.exists(os.path.join(output_path,f\"{i}_{model_name}_{optim}\")):\n",
        "        joblib.dump(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n",
        "        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/model_params.txt\"),\"w+\") as file:\n",
        "            file.write(str(best_params))\n",
        "    else:\n",
        "        os.mkdir(os.path.join(output_path,f\"{i}_{model_name}_{optim}\"))\n",
        "        joblib.dump(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n",
        "        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/model_params.txt\"),\"w+\") as file:\n",
        "            file.write(str(best_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z_M5FI9PpVA_"
      },
      "outputs": [],
      "source": [
        "def train(fold_dict,fold,model_name,sc_df,tar_col,optim,optim_trial,k_folds=10,tar_cols=\"\",verbose=1):\n",
        "\n",
        "    ''' this function is used to train the model with parameters optimization using optuna and cross validation using stratified k_folds'''\n",
        "\n",
        "    y = sc_df[tar_col]\n",
        "    x = sc_df.drop([tar_col],axis=1)\n",
        "    model_name = model_name \n",
        "    def objective(trial):\n",
        "      train_index = fold_dict[fold][\"train\"]\n",
        "      test_index = fold_dict[fold][\"test\"]\n",
        "      clf = TabNetClassifier(n_d=trial.suggest_int(\"n_d\", 8, 64),\n",
        "                              n_a =trial.suggest_int(\"n_a\", 8, 64),\n",
        "                              n_steps = trial.suggest_int(\"n_steps\",3,10),\n",
        "                              gamma =trial.suggest_float(\"gamma\", 1.0, 2.0),\n",
        "                              n_independent = trial.suggest_int(\"n_independent\",1,5),\n",
        "                              n_shared = trial.suggest_int(\"n_shared\",1,5),\n",
        "                              momentum = trial.suggest_float(\"momentum\", 0.01, 0.4),\n",
        "                              optimizer_fn = torch.optim.Adam,\n",
        "                              # scheduler_fn = torch.optim.lr_scheduler,\n",
        "                              # scheduler_params = {\"gamma\" :trial.suggest_float(\"sch-gamma\", 0.5, 0.95), \"step_size\": trial.suggest_int(\"sch_step_size\", 10, 20, 2)},\n",
        "                              verbose = verbose,\n",
        "                              device_name = \"auto\"\n",
        "                              )\n",
        "      # print(f\" train_index :: {train_index}\")\n",
        "      # print(f\" test_index :: {test_index}\")\n",
        "      X_train,X_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
        "      # print(X_train.shape, X_test.shape)\n",
        "      X_train, X_test = X_train.to_numpy(dtype=np.float64), X_test.to_numpy(dtype=np.float64)\n",
        "      Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "      Y_train, Y_test = Y_train.to_numpy(dtype=np.float64), Y_test.to_numpy(dtype=np.float64)\n",
        "      print(Y_train.shape, Y_test.shape)\n",
        "      clf.fit(X_train, Y_train,\n",
        "              eval_set=[(X_test, Y_test)],\n",
        "              eval_metric=['accuracy'])\n",
        "      Y_pred = clf.predict(X_test)\n",
        "      print(classification_report(Y_test, Y_pred, labels=[x for x in range(6)]))\n",
        "      acc = accuracy_score(Y_pred, Y_test)\n",
        "      return acc\n",
        "\n",
        "    print(f\"Starting optimization for fold : [{fold}/{k_folds}]\")\n",
        "    study = opt.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=optim_trial)\n",
        "    best_params = study.best_params\n",
        "    print(f\" Best params for fold : [{fold}/{k_folds}]\")\n",
        "    print(best_params)\n",
        "    joblib.dump(best_params,f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/best_params/comp/fold_{fold}_best_params.z\")\n",
        "    with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/best_params/fold_{fold}_best_params.txt\", \"w+\") as file:file.write(str(best_params))\n",
        "    print(f\"Saved best_params at : outputs/{model_name}/best_params/fold_{fold}_best_params.txt\")\n",
        "    train_index = fold_dict[fold][\"train\"]\n",
        "    test_index = fold_dict[fold][\"test\"]\n",
        "    X_train,X_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
        "    # print(X_train.shape, X_test.shape)\n",
        "    X_train, X_test = X_train.to_numpy(dtype=np.float64), X_test.to_numpy(dtype=np.float64)\n",
        "    Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    Y_train, Y_test = Y_train.to_numpy(dtype=np.float64), Y_test.to_numpy(dtype=np.float64)\n",
        "    clf_model = TabNetClassifier(**study.best_params)\n",
        "    clf_model.fit(X_train,Y_train)\n",
        "    Y_pred = clf_model.predict(X_test)\n",
        "    clf_report = classification_report(Y_test, Y_pred, labels=[x for x in range(6)])\n",
        "    with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/classification_report/{model_name}_{fold}_classification_report.txt\",\"w+\") as file:file.write(str(clf_report))\n",
        "    accuracy = accuracy_score(Y_pred, Y_test)\n",
        "    with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/{model_name}_{fold}_accuracy_score.txt\",\"w+\") as file:file.write(f\" accuracy :: {str(accuracy)}\")\n",
        "    try:\n",
        "        print(\"[++] Saving the model and parameters in corresponding directories\")\n",
        "        make_save_cv_model(fold,model_name,clf_model,best_params,optim=optim)\n",
        "    except:\n",
        "        print(\"[-] Failed to save the model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xNlu9Ktsq6VG"
      },
      "outputs": [],
      "source": [
        "use_df = pd.read_csv(\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/data/trainable_scaled_balanced.csv\")\n",
        "tar_col = \"PCE_categorical\"\n",
        "model_name = \"pytorch_tabnet\"\n",
        "optimizer = \"Adam\"\n",
        "fold_dict = joblib.load(\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/inputs/fold_vals/fold_data.z\")\n",
        "fold = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ9h3wayrIp_",
        "outputId": "4e591bb4-4d15-4a5c-dbb6-8c7487b2d961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-02 08:04:42,475]\u001b[0m A new study created in memory with name: no-name-9cf4f005-ba01-4931-9cf9-feea32e86a2b\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting optimization for fold : [3/10]\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.54568 | val_0_accuracy: 0.53389 |  0:00:02s\n",
            "epoch 1  | loss: 1.05868 | val_0_accuracy: 0.56326 |  0:00:05s\n",
            "epoch 2  | loss: 1.07907 | val_0_accuracy: 0.56865 |  0:00:08s\n",
            "epoch 3  | loss: 0.97592 | val_0_accuracy: 0.60104 |  0:00:10s\n",
            "epoch 4  | loss: 0.87919 | val_0_accuracy: 0.60276 |  0:00:13s\n",
            "epoch 5  | loss: 0.85306 | val_0_accuracy: 0.63169 |  0:00:15s\n",
            "epoch 6  | loss: 0.82034 | val_0_accuracy: 0.61485 |  0:00:18s\n",
            "epoch 7  | loss: 0.79201 | val_0_accuracy: 0.62997 |  0:00:21s\n",
            "epoch 8  | loss: 0.78825 | val_0_accuracy: 0.64054 |  0:00:23s\n",
            "epoch 9  | loss: 0.77016 | val_0_accuracy: 0.63903 |  0:00:26s\n",
            "epoch 10 | loss: 0.75284 | val_0_accuracy: 0.64378 |  0:00:29s\n",
            "epoch 11 | loss: 0.74234 | val_0_accuracy: 0.65112 |  0:00:31s\n",
            "epoch 12 | loss: 0.73369 | val_0_accuracy: 0.65652 |  0:00:34s\n",
            "epoch 13 | loss: 0.72198 | val_0_accuracy: 0.68221 |  0:00:37s\n",
            "epoch 14 | loss: 0.70642 | val_0_accuracy: 0.67228 |  0:00:39s\n",
            "epoch 15 | loss: 0.71184 | val_0_accuracy: 0.67552 |  0:00:42s\n",
            "epoch 16 | loss: 0.69107 | val_0_accuracy: 0.67984 |  0:00:44s\n",
            "epoch 17 | loss: 0.68773 | val_0_accuracy: 0.68955 |  0:00:47s\n",
            "epoch 18 | loss: 0.70017 | val_0_accuracy: 0.6794  |  0:00:50s\n",
            "epoch 19 | loss: 0.69439 | val_0_accuracy: 0.69538 |  0:00:52s\n",
            "epoch 20 | loss: 0.69617 | val_0_accuracy: 0.67487 |  0:00:55s\n",
            "epoch 21 | loss: 0.6811  | val_0_accuracy: 0.6984  |  0:00:57s\n",
            "epoch 22 | loss: 0.66919 | val_0_accuracy: 0.69581 |  0:01:00s\n",
            "epoch 23 | loss: 0.66393 | val_0_accuracy: 0.70294 |  0:01:03s\n",
            "epoch 24 | loss: 0.65928 | val_0_accuracy: 0.70682 |  0:01:05s\n",
            "epoch 25 | loss: 0.65625 | val_0_accuracy: 0.69711 |  0:01:08s\n",
            "epoch 26 | loss: 0.64363 | val_0_accuracy: 0.70812 |  0:01:10s\n",
            "epoch 27 | loss: 0.64273 | val_0_accuracy: 0.70639 |  0:01:13s\n",
            "epoch 28 | loss: 0.63607 | val_0_accuracy: 0.71481 |  0:01:16s\n",
            "epoch 29 | loss: 0.62904 | val_0_accuracy: 0.70941 |  0:01:18s\n",
            "epoch 30 | loss: 0.62759 | val_0_accuracy: 0.70315 |  0:01:21s\n",
            "epoch 31 | loss: 0.6362  | val_0_accuracy: 0.71675 |  0:01:23s\n",
            "epoch 32 | loss: 0.61983 | val_0_accuracy: 0.71589 |  0:01:26s\n",
            "epoch 33 | loss: 0.61837 | val_0_accuracy: 0.71826 |  0:01:29s\n",
            "epoch 34 | loss: 0.61649 | val_0_accuracy: 0.71114 |  0:01:31s\n",
            "epoch 35 | loss: 0.61954 | val_0_accuracy: 0.72301 |  0:01:34s\n",
            "epoch 36 | loss: 0.61039 | val_0_accuracy: 0.72496 |  0:01:37s\n",
            "epoch 37 | loss: 0.61061 | val_0_accuracy: 0.72042 |  0:01:39s\n",
            "epoch 38 | loss: 0.61029 | val_0_accuracy: 0.72107 |  0:01:42s\n",
            "epoch 39 | loss: 0.61107 | val_0_accuracy: 0.72042 |  0:01:45s\n",
            "epoch 40 | loss: 0.59763 | val_0_accuracy: 0.7228  |  0:01:47s\n",
            "epoch 41 | loss: 0.59196 | val_0_accuracy: 0.73381 |  0:01:50s\n",
            "epoch 42 | loss: 0.58833 | val_0_accuracy: 0.73165 |  0:01:53s\n",
            "epoch 43 | loss: 0.58097 | val_0_accuracy: 0.7446  |  0:01:56s\n",
            "epoch 44 | loss: 0.58058 | val_0_accuracy: 0.73359 |  0:01:59s\n",
            "epoch 45 | loss: 0.58088 | val_0_accuracy: 0.73359 |  0:02:01s\n",
            "epoch 46 | loss: 0.57496 | val_0_accuracy: 0.73402 |  0:02:04s\n",
            "epoch 47 | loss: 0.57149 | val_0_accuracy: 0.73554 |  0:02:06s\n",
            "epoch 48 | loss: 0.56537 | val_0_accuracy: 0.73618 |  0:02:09s\n",
            "epoch 49 | loss: 0.56464 | val_0_accuracy: 0.7256  |  0:02:11s\n",
            "epoch 50 | loss: 0.5582  | val_0_accuracy: 0.74396 |  0:02:14s\n",
            "epoch 51 | loss: 0.55266 | val_0_accuracy: 0.74503 |  0:02:17s\n",
            "epoch 52 | loss: 0.56263 | val_0_accuracy: 0.74676 |  0:02:19s\n",
            "epoch 53 | loss: 0.55513 | val_0_accuracy: 0.73834 |  0:02:22s\n",
            "epoch 54 | loss: 0.55149 | val_0_accuracy: 0.74676 |  0:02:25s\n",
            "epoch 55 | loss: 0.54345 | val_0_accuracy: 0.75712 |  0:02:27s\n",
            "epoch 56 | loss: 0.5431  | val_0_accuracy: 0.75086 |  0:02:30s\n",
            "epoch 57 | loss: 0.54239 | val_0_accuracy: 0.75281 |  0:02:32s\n",
            "epoch 58 | loss: 0.55109 | val_0_accuracy: 0.73748 |  0:02:35s\n",
            "epoch 59 | loss: 0.54349 | val_0_accuracy: 0.73964 |  0:02:38s\n",
            "epoch 60 | loss: 0.53573 | val_0_accuracy: 0.74957 |  0:02:40s\n",
            "epoch 61 | loss: 0.53208 | val_0_accuracy: 0.75281 |  0:02:43s\n",
            "epoch 62 | loss: 0.53896 | val_0_accuracy: 0.75669 |  0:02:45s\n",
            "epoch 63 | loss: 0.53221 | val_0_accuracy: 0.75712 |  0:02:48s\n",
            "epoch 64 | loss: 0.5286  | val_0_accuracy: 0.75799 |  0:02:51s\n",
            "epoch 65 | loss: 0.52159 | val_0_accuracy: 0.76252 |  0:02:53s\n",
            "epoch 66 | loss: 0.51697 | val_0_accuracy: 0.76943 |  0:02:56s\n",
            "epoch 67 | loss: 0.51723 | val_0_accuracy: 0.77094 |  0:02:58s\n",
            "epoch 68 | loss: 0.5306  | val_0_accuracy: 0.7595  |  0:03:01s\n",
            "epoch 69 | loss: 0.52988 | val_0_accuracy: 0.75389 |  0:03:04s\n",
            "epoch 70 | loss: 0.5293  | val_0_accuracy: 0.76015 |  0:03:06s\n",
            "epoch 71 | loss: 0.521   | val_0_accuracy: 0.7731  |  0:03:09s\n",
            "epoch 72 | loss: 0.50757 | val_0_accuracy: 0.76036 |  0:03:12s\n",
            "epoch 73 | loss: 0.51    | val_0_accuracy: 0.769   |  0:03:14s\n",
            "epoch 74 | loss: 0.50556 | val_0_accuracy: 0.76706 |  0:03:17s\n",
            "epoch 75 | loss: 0.51176 | val_0_accuracy: 0.76403 |  0:03:19s\n",
            "epoch 76 | loss: 0.50821 | val_0_accuracy: 0.75928 |  0:03:22s\n",
            "epoch 77 | loss: 0.50114 | val_0_accuracy: 0.76727 |  0:03:24s\n",
            "epoch 78 | loss: 0.50019 | val_0_accuracy: 0.77137 |  0:03:27s\n",
            "epoch 79 | loss: 0.4991  | val_0_accuracy: 0.77375 |  0:03:30s\n",
            "epoch 80 | loss: 0.49448 | val_0_accuracy: 0.75691 |  0:03:32s\n",
            "epoch 81 | loss: 0.51984 | val_0_accuracy: 0.76813 |  0:03:35s\n",
            "epoch 82 | loss: 0.52114 | val_0_accuracy: 0.75669 |  0:03:38s\n",
            "epoch 83 | loss: 0.53409 | val_0_accuracy: 0.75324 |  0:03:40s\n",
            "epoch 84 | loss: 0.53715 | val_0_accuracy: 0.74374 |  0:03:43s\n",
            "epoch 85 | loss: 0.53044 | val_0_accuracy: 0.75777 |  0:03:45s\n",
            "epoch 86 | loss: 0.51148 | val_0_accuracy: 0.76187 |  0:03:48s\n",
            "epoch 87 | loss: 0.51671 | val_0_accuracy: 0.75151 |  0:03:51s\n",
            "epoch 88 | loss: 0.50724 | val_0_accuracy: 0.77094 |  0:03:53s\n",
            "epoch 89 | loss: 0.49262 | val_0_accuracy: 0.76857 |  0:03:56s\n",
            "\n",
            "Early stopping occurred at epoch 89 with best_epoch = 79 and best_val_0_accuracy = 0.77375\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-02 08:08:55,786]\u001b[0m Trial 0 finished with value: 0.7737478411053541 and parameters: {'n_d': 39, 'n_a': 64, 'n_steps': 9, 'gamma': 1.4848772542673783, 'n_independent': 1, 'n_shared': 1, 'momentum': 0.38569493500371094}. Best is trial 0 with value: 0.7737478411053541.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.60      0.56      0.58       825\n",
            "           2       0.82      0.89      0.86       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.51      0.63      0.56       761\n",
            "           5       0.72      0.49      0.59       619\n",
            "\n",
            "    accuracy                           0.77      4632\n",
            "   macro avg       0.78      0.76      0.76      4632\n",
            "weighted avg       0.78      0.77      0.77      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.16468 | val_0_accuracy: 0.63061 |  0:00:01s\n",
            "epoch 1  | loss: 0.78955 | val_0_accuracy: 0.64357 |  0:00:02s\n",
            "epoch 2  | loss: 0.73911 | val_0_accuracy: 0.67681 |  0:00:04s\n",
            "epoch 3  | loss: 0.71021 | val_0_accuracy: 0.67163 |  0:00:05s\n",
            "epoch 4  | loss: 0.69039 | val_0_accuracy: 0.69819 |  0:00:07s\n",
            "epoch 5  | loss: 0.67707 | val_0_accuracy: 0.69041 |  0:00:08s\n",
            "epoch 6  | loss: 0.66463 | val_0_accuracy: 0.69516 |  0:00:10s\n",
            "epoch 7  | loss: 0.6544  | val_0_accuracy: 0.70639 |  0:00:11s\n",
            "epoch 8  | loss: 0.64729 | val_0_accuracy: 0.70898 |  0:00:13s\n",
            "epoch 9  | loss: 0.63538 | val_0_accuracy: 0.70445 |  0:00:14s\n",
            "epoch 10 | loss: 0.6295  | val_0_accuracy: 0.7228  |  0:00:15s\n",
            "epoch 11 | loss: 0.61753 | val_0_accuracy: 0.71891 |  0:00:17s\n",
            "epoch 12 | loss: 0.60953 | val_0_accuracy: 0.71762 |  0:00:18s\n",
            "epoch 13 | loss: 0.63251 | val_0_accuracy: 0.71697 |  0:00:20s\n",
            "epoch 14 | loss: 0.613   | val_0_accuracy: 0.71956 |  0:00:21s\n",
            "epoch 15 | loss: 0.59866 | val_0_accuracy: 0.72388 |  0:00:22s\n",
            "epoch 16 | loss: 0.59024 | val_0_accuracy: 0.73381 |  0:00:24s\n",
            "epoch 17 | loss: 0.58394 | val_0_accuracy: 0.73381 |  0:00:25s\n",
            "epoch 18 | loss: 0.58095 | val_0_accuracy: 0.73964 |  0:00:27s\n",
            "epoch 19 | loss: 0.5745  | val_0_accuracy: 0.74439 |  0:00:28s\n",
            "epoch 20 | loss: 0.57055 | val_0_accuracy: 0.74525 |  0:00:29s\n",
            "epoch 21 | loss: 0.56239 | val_0_accuracy: 0.74136 |  0:00:31s\n",
            "epoch 22 | loss: 0.55452 | val_0_accuracy: 0.74115 |  0:00:32s\n",
            "epoch 23 | loss: 0.56027 | val_0_accuracy: 0.74028 |  0:00:34s\n",
            "epoch 24 | loss: 0.55583 | val_0_accuracy: 0.74957 |  0:00:35s\n",
            "epoch 25 | loss: 0.54263 | val_0_accuracy: 0.74914 |  0:00:36s\n",
            "epoch 26 | loss: 0.54146 | val_0_accuracy: 0.74935 |  0:00:38s\n",
            "epoch 27 | loss: 0.53209 | val_0_accuracy: 0.74719 |  0:00:39s\n",
            "epoch 28 | loss: 0.53229 | val_0_accuracy: 0.75799 |  0:00:41s\n",
            "epoch 29 | loss: 0.53065 | val_0_accuracy: 0.75712 |  0:00:42s\n",
            "epoch 30 | loss: 0.52307 | val_0_accuracy: 0.75885 |  0:00:44s\n",
            "epoch 31 | loss: 0.52359 | val_0_accuracy: 0.75497 |  0:00:45s\n",
            "epoch 32 | loss: 0.52214 | val_0_accuracy: 0.76166 |  0:00:46s\n",
            "epoch 33 | loss: 0.51107 | val_0_accuracy: 0.76339 |  0:00:48s\n",
            "epoch 34 | loss: 0.51618 | val_0_accuracy: 0.75734 |  0:00:49s\n",
            "epoch 35 | loss: 0.51074 | val_0_accuracy: 0.76317 |  0:00:51s\n",
            "epoch 36 | loss: 0.50287 | val_0_accuracy: 0.76619 |  0:00:52s\n",
            "epoch 37 | loss: 0.5034  | val_0_accuracy: 0.77029 |  0:00:54s\n",
            "epoch 38 | loss: 0.49482 | val_0_accuracy: 0.76641 |  0:00:55s\n",
            "epoch 39 | loss: 0.48971 | val_0_accuracy: 0.77159 |  0:00:56s\n",
            "epoch 40 | loss: 0.48772 | val_0_accuracy: 0.76598 |  0:00:58s\n",
            "epoch 41 | loss: 0.48502 | val_0_accuracy: 0.77526 |  0:00:59s\n",
            "epoch 42 | loss: 0.48313 | val_0_accuracy: 0.77116 |  0:01:01s\n",
            "epoch 43 | loss: 0.47802 | val_0_accuracy: 0.77742 |  0:01:02s\n",
            "epoch 44 | loss: 0.47556 | val_0_accuracy: 0.77699 |  0:01:04s\n",
            "epoch 45 | loss: 0.46945 | val_0_accuracy: 0.77569 |  0:01:05s\n",
            "epoch 46 | loss: 0.47239 | val_0_accuracy: 0.78044 |  0:01:06s\n",
            "epoch 47 | loss: 0.46488 | val_0_accuracy: 0.77958 |  0:01:08s\n",
            "epoch 48 | loss: 0.46561 | val_0_accuracy: 0.76792 |  0:01:09s\n",
            "epoch 49 | loss: 0.46561 | val_0_accuracy: 0.77655 |  0:01:11s\n",
            "epoch 50 | loss: 0.45953 | val_0_accuracy: 0.78174 |  0:01:12s\n",
            "epoch 51 | loss: 0.45272 | val_0_accuracy: 0.77979 |  0:01:13s\n",
            "epoch 52 | loss: 0.45891 | val_0_accuracy: 0.77418 |  0:01:15s\n",
            "epoch 53 | loss: 0.45361 | val_0_accuracy: 0.77828 |  0:01:16s\n",
            "epoch 54 | loss: 0.45861 | val_0_accuracy: 0.77634 |  0:01:17s\n",
            "epoch 55 | loss: 0.44964 | val_0_accuracy: 0.78389 |  0:01:19s\n",
            "epoch 56 | loss: 0.45188 | val_0_accuracy: 0.77915 |  0:01:20s\n",
            "epoch 57 | loss: 0.45029 | val_0_accuracy: 0.7826  |  0:01:22s\n",
            "epoch 58 | loss: 0.44166 | val_0_accuracy: 0.78562 |  0:01:24s\n",
            "epoch 59 | loss: 0.43849 | val_0_accuracy: 0.7813  |  0:01:25s\n",
            "epoch 60 | loss: 0.43475 | val_0_accuracy: 0.78497 |  0:01:27s\n",
            "epoch 61 | loss: 0.43263 | val_0_accuracy: 0.78109 |  0:01:28s\n",
            "epoch 62 | loss: 0.42965 | val_0_accuracy: 0.78994 |  0:01:30s\n",
            "epoch 63 | loss: 0.44615 | val_0_accuracy: 0.77245 |  0:01:31s\n",
            "epoch 64 | loss: 0.45241 | val_0_accuracy: 0.78109 |  0:01:33s\n",
            "epoch 65 | loss: 0.4389  | val_0_accuracy: 0.77871 |  0:01:34s\n",
            "epoch 66 | loss: 0.43023 | val_0_accuracy: 0.78001 |  0:01:35s\n",
            "epoch 67 | loss: 0.42596 | val_0_accuracy: 0.78497 |  0:01:37s\n",
            "epoch 68 | loss: 0.42641 | val_0_accuracy: 0.79253 |  0:01:38s\n",
            "epoch 69 | loss: 0.42078 | val_0_accuracy: 0.78389 |  0:01:40s\n",
            "epoch 70 | loss: 0.41855 | val_0_accuracy: 0.78519 |  0:01:41s\n",
            "epoch 71 | loss: 0.425   | val_0_accuracy: 0.78972 |  0:01:43s\n",
            "epoch 72 | loss: 0.42015 | val_0_accuracy: 0.79383 |  0:01:44s\n",
            "epoch 73 | loss: 0.41812 | val_0_accuracy: 0.78778 |  0:01:45s\n",
            "epoch 74 | loss: 0.41271 | val_0_accuracy: 0.79404 |  0:01:47s\n",
            "epoch 75 | loss: 0.40909 | val_0_accuracy: 0.78843 |  0:01:48s\n",
            "epoch 76 | loss: 0.4074  | val_0_accuracy: 0.79383 |  0:01:50s\n",
            "epoch 77 | loss: 0.403   | val_0_accuracy: 0.79145 |  0:01:51s\n",
            "epoch 78 | loss: 0.40073 | val_0_accuracy: 0.79188 |  0:01:52s\n",
            "epoch 79 | loss: 0.40358 | val_0_accuracy: 0.7921  |  0:01:54s\n",
            "epoch 80 | loss: 0.40231 | val_0_accuracy: 0.7921  |  0:01:55s\n",
            "epoch 81 | loss: 0.39642 | val_0_accuracy: 0.79577 |  0:01:57s\n",
            "epoch 82 | loss: 0.39692 | val_0_accuracy: 0.79728 |  0:01:58s\n",
            "epoch 83 | loss: 0.39815 | val_0_accuracy: 0.78541 |  0:02:00s\n",
            "epoch 84 | loss: 0.39123 | val_0_accuracy: 0.79469 |  0:02:01s\n",
            "epoch 85 | loss: 0.39166 | val_0_accuracy: 0.79145 |  0:02:02s\n",
            "epoch 86 | loss: 0.39502 | val_0_accuracy: 0.78951 |  0:02:04s\n",
            "epoch 87 | loss: 0.39889 | val_0_accuracy: 0.7921  |  0:02:05s\n",
            "epoch 88 | loss: 0.39107 | val_0_accuracy: 0.79534 |  0:02:07s\n",
            "epoch 89 | loss: 0.38997 | val_0_accuracy: 0.79642 |  0:02:08s\n",
            "epoch 90 | loss: 0.38696 | val_0_accuracy: 0.79836 |  0:02:09s\n",
            "epoch 91 | loss: 0.385   | val_0_accuracy: 0.79361 |  0:02:11s\n",
            "epoch 92 | loss: 0.3943  | val_0_accuracy: 0.79706 |  0:02:12s\n",
            "epoch 93 | loss: 0.38603 | val_0_accuracy: 0.80009 |  0:02:14s\n",
            "epoch 94 | loss: 0.39147 | val_0_accuracy: 0.78886 |  0:02:15s\n",
            "epoch 95 | loss: 0.39346 | val_0_accuracy: 0.79447 |  0:02:17s\n",
            "epoch 96 | loss: 0.38606 | val_0_accuracy: 0.79965 |  0:02:18s\n",
            "epoch 97 | loss: 0.38417 | val_0_accuracy: 0.79728 |  0:02:19s\n",
            "epoch 98 | loss: 0.38702 | val_0_accuracy: 0.78929 |  0:02:21s\n",
            "epoch 99 | loss: 0.38985 | val_0_accuracy: 0.79965 |  0:02:22s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 93 and best_val_0_accuracy = 0.80009\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-02 08:11:19,108]\u001b[0m Trial 1 finished with value: 0.8000863557858376 and parameters: {'n_d': 43, 'n_a': 53, 'n_steps': 3, 'gamma': 1.473431800730167, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.19414592575862027}. Best is trial 1 with value: 0.8000863557858376.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.68      0.58      0.62       825\n",
            "           2       0.84      0.94      0.89       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.57      0.51      0.54       761\n",
            "           5       0.65      0.75      0.69       619\n",
            "\n",
            "    accuracy                           0.80      4632\n",
            "   macro avg       0.79      0.80      0.79      4632\n",
            "weighted avg       0.80      0.80      0.80      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.10403 | val_0_accuracy: 0.62414 |  0:00:01s\n",
            "epoch 1  | loss: 0.79194 | val_0_accuracy: 0.64918 |  0:00:03s\n",
            "epoch 2  | loss: 0.74175 | val_0_accuracy: 0.65415 |  0:00:05s\n",
            "epoch 3  | loss: 0.71723 | val_0_accuracy: 0.6725  |  0:00:07s\n",
            "epoch 4  | loss: 0.69358 | val_0_accuracy: 0.68221 |  0:00:09s\n",
            "epoch 5  | loss: 0.68402 | val_0_accuracy: 0.68588 |  0:00:11s\n",
            "epoch 6  | loss: 0.67089 | val_0_accuracy: 0.68437 |  0:00:13s\n",
            "epoch 7  | loss: 0.6805  | val_0_accuracy: 0.69668 |  0:00:15s\n",
            "epoch 8  | loss: 0.66146 | val_0_accuracy: 0.69408 |  0:00:17s\n",
            "epoch 9  | loss: 0.64752 | val_0_accuracy: 0.70013 |  0:00:19s\n",
            "epoch 10 | loss: 0.63926 | val_0_accuracy: 0.70531 |  0:00:21s\n",
            "epoch 11 | loss: 0.62983 | val_0_accuracy: 0.70488 |  0:00:23s\n",
            "epoch 12 | loss: 0.62135 | val_0_accuracy: 0.72647 |  0:00:25s\n",
            "epoch 13 | loss: 0.61857 | val_0_accuracy: 0.71459 |  0:00:27s\n",
            "epoch 14 | loss: 0.63196 | val_0_accuracy: 0.71848 |  0:00:29s\n",
            "epoch 15 | loss: 0.61997 | val_0_accuracy: 0.71675 |  0:00:31s\n",
            "epoch 16 | loss: 0.62286 | val_0_accuracy: 0.71438 |  0:00:33s\n",
            "epoch 17 | loss: 0.61219 | val_0_accuracy: 0.7269  |  0:00:35s\n",
            "epoch 18 | loss: 0.60393 | val_0_accuracy: 0.72301 |  0:00:37s\n",
            "epoch 19 | loss: 0.59037 | val_0_accuracy: 0.72604 |  0:00:39s\n",
            "epoch 20 | loss: 0.58392 | val_0_accuracy: 0.73208 |  0:00:41s\n",
            "epoch 21 | loss: 0.57953 | val_0_accuracy: 0.731   |  0:00:43s\n",
            "epoch 22 | loss: 0.57616 | val_0_accuracy: 0.73964 |  0:00:45s\n",
            "epoch 23 | loss: 0.56775 | val_0_accuracy: 0.74288 |  0:00:47s\n",
            "epoch 24 | loss: 0.56657 | val_0_accuracy: 0.74266 |  0:00:49s\n",
            "epoch 25 | loss: 0.55516 | val_0_accuracy: 0.74158 |  0:00:51s\n",
            "epoch 26 | loss: 0.55348 | val_0_accuracy: 0.74417 |  0:00:53s\n",
            "epoch 27 | loss: 0.55489 | val_0_accuracy: 0.74892 |  0:00:54s\n",
            "epoch 28 | loss: 0.54152 | val_0_accuracy: 0.74503 |  0:00:56s\n",
            "epoch 29 | loss: 0.53896 | val_0_accuracy: 0.75475 |  0:00:58s\n",
            "epoch 30 | loss: 0.55172 | val_0_accuracy: 0.74827 |  0:01:00s\n",
            "epoch 31 | loss: 0.55122 | val_0_accuracy: 0.74784 |  0:01:02s\n",
            "epoch 32 | loss: 0.53774 | val_0_accuracy: 0.74741 |  0:01:04s\n",
            "epoch 33 | loss: 0.5289  | val_0_accuracy: 0.75777 |  0:01:06s\n",
            "epoch 34 | loss: 0.52334 | val_0_accuracy: 0.76727 |  0:01:08s\n",
            "epoch 35 | loss: 0.52647 | val_0_accuracy: 0.76317 |  0:01:10s\n",
            "epoch 36 | loss: 0.52028 | val_0_accuracy: 0.75691 |  0:01:12s\n",
            "epoch 37 | loss: 0.5108  | val_0_accuracy: 0.75626 |  0:01:14s\n",
            "epoch 38 | loss: 0.50534 | val_0_accuracy: 0.76554 |  0:01:16s\n",
            "epoch 39 | loss: 0.49949 | val_0_accuracy: 0.7677  |  0:01:18s\n",
            "epoch 40 | loss: 0.49715 | val_0_accuracy: 0.76662 |  0:01:20s\n",
            "epoch 41 | loss: 0.49634 | val_0_accuracy: 0.76511 |  0:01:22s\n",
            "epoch 42 | loss: 0.48965 | val_0_accuracy: 0.7731  |  0:01:24s\n",
            "epoch 43 | loss: 0.48909 | val_0_accuracy: 0.77332 |  0:01:26s\n",
            "epoch 44 | loss: 0.48228 | val_0_accuracy: 0.77979 |  0:01:28s\n",
            "epoch 45 | loss: 0.47573 | val_0_accuracy: 0.77699 |  0:01:30s\n",
            "epoch 46 | loss: 0.47911 | val_0_accuracy: 0.78087 |  0:01:32s\n",
            "epoch 47 | loss: 0.47678 | val_0_accuracy: 0.77526 |  0:01:34s\n",
            "epoch 48 | loss: 0.47411 | val_0_accuracy: 0.77224 |  0:01:36s\n",
            "epoch 49 | loss: 0.46601 | val_0_accuracy: 0.78541 |  0:01:38s\n",
            "epoch 50 | loss: 0.46557 | val_0_accuracy: 0.77504 |  0:01:40s\n",
            "epoch 51 | loss: 0.46563 | val_0_accuracy: 0.77634 |  0:01:41s\n",
            "epoch 52 | loss: 0.46242 | val_0_accuracy: 0.77526 |  0:01:43s\n",
            "epoch 53 | loss: 0.45741 | val_0_accuracy: 0.78044 |  0:01:45s\n",
            "epoch 54 | loss: 0.45067 | val_0_accuracy: 0.78411 |  0:01:47s\n",
            "epoch 55 | loss: 0.44657 | val_0_accuracy: 0.77958 |  0:01:49s\n",
            "epoch 56 | loss: 0.45763 | val_0_accuracy: 0.78001 |  0:01:51s\n",
            "epoch 57 | loss: 0.45146 | val_0_accuracy: 0.77785 |  0:01:53s\n",
            "epoch 58 | loss: 0.45951 | val_0_accuracy: 0.78022 |  0:01:55s\n",
            "epoch 59 | loss: 0.44665 | val_0_accuracy: 0.78087 |  0:01:57s\n",
            "\n",
            "Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_accuracy = 0.78541\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-02 08:13:17,795]\u001b[0m Trial 2 finished with value: 0.7854058721934369 and parameters: {'n_d': 39, 'n_a': 48, 'n_steps': 3, 'gamma': 1.201586282007976, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.0485330726501438}. Best is trial 1 with value: 0.8000863557858376.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.62      0.57      0.59       825\n",
            "           2       0.84      0.93      0.88       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.52      0.57      0.54       761\n",
            "           5       0.70      0.59      0.64       619\n",
            "\n",
            "    accuracy                           0.79      4632\n",
            "   macro avg       0.78      0.78      0.78      4632\n",
            "weighted avg       0.78      0.79      0.78      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.34386 | val_0_accuracy: 0.55656 |  0:00:03s\n",
            "epoch 1  | loss: 0.98467 | val_0_accuracy: 0.58441 |  0:00:06s\n",
            "epoch 2  | loss: 0.89326 | val_0_accuracy: 0.61313 |  0:00:09s\n",
            "epoch 3  | loss: 0.81529 | val_0_accuracy: 0.65069 |  0:00:13s\n",
            "epoch 4  | loss: 0.7816  | val_0_accuracy: 0.65522 |  0:00:16s\n",
            "epoch 5  | loss: 0.76229 | val_0_accuracy: 0.66839 |  0:00:19s\n",
            "epoch 6  | loss: 0.76349 | val_0_accuracy: 0.65717 |  0:00:23s\n",
            "epoch 7  | loss: 0.72681 | val_0_accuracy: 0.65846 |  0:00:26s\n",
            "epoch 8  | loss: 0.7141  | val_0_accuracy: 0.67358 |  0:00:29s\n",
            "epoch 9  | loss: 0.69748 | val_0_accuracy: 0.6725  |  0:00:32s\n",
            "epoch 10 | loss: 0.68789 | val_0_accuracy: 0.68545 |  0:00:36s\n",
            "epoch 11 | loss: 0.67937 | val_0_accuracy: 0.64184 |  0:00:39s\n",
            "epoch 12 | loss: 0.67233 | val_0_accuracy: 0.69279 |  0:00:42s\n",
            "epoch 13 | loss: 0.66634 | val_0_accuracy: 0.68113 |  0:00:45s\n",
            "epoch 14 | loss: 0.65986 | val_0_accuracy: 0.69775 |  0:00:49s\n",
            "epoch 15 | loss: 0.65383 | val_0_accuracy: 0.69883 |  0:00:52s\n",
            "epoch 16 | loss: 0.66242 | val_0_accuracy: 0.68459 |  0:00:55s\n",
            "epoch 17 | loss: 0.66665 | val_0_accuracy: 0.70121 |  0:00:59s\n",
            "epoch 18 | loss: 0.64858 | val_0_accuracy: 0.70617 |  0:01:02s\n",
            "epoch 19 | loss: 0.65046 | val_0_accuracy: 0.71006 |  0:01:06s\n",
            "epoch 20 | loss: 0.64161 | val_0_accuracy: 0.71524 |  0:01:09s\n",
            "epoch 21 | loss: 0.63512 | val_0_accuracy: 0.71244 |  0:01:12s\n",
            "epoch 22 | loss: 0.63674 | val_0_accuracy: 0.7092  |  0:01:16s\n",
            "epoch 23 | loss: 0.62872 | val_0_accuracy: 0.70725 |  0:01:19s\n",
            "epoch 24 | loss: 0.61861 | val_0_accuracy: 0.70142 |  0:01:22s\n",
            "epoch 25 | loss: 0.61629 | val_0_accuracy: 0.70423 |  0:01:26s\n",
            "epoch 26 | loss: 0.61424 | val_0_accuracy: 0.69819 |  0:01:29s\n",
            "epoch 27 | loss: 0.61064 | val_0_accuracy: 0.71762 |  0:01:32s\n",
            "epoch 28 | loss: 0.60034 | val_0_accuracy: 0.72172 |  0:01:36s\n",
            "epoch 29 | loss: 0.59593 | val_0_accuracy: 0.71826 |  0:01:39s\n",
            "epoch 30 | loss: 0.58508 | val_0_accuracy: 0.71697 |  0:01:42s\n",
            "epoch 31 | loss: 0.58483 | val_0_accuracy: 0.72798 |  0:01:45s\n",
            "epoch 32 | loss: 0.58384 | val_0_accuracy: 0.73079 |  0:01:49s\n",
            "epoch 33 | loss: 0.57797 | val_0_accuracy: 0.73791 |  0:01:52s\n",
            "epoch 34 | loss: 0.56743 | val_0_accuracy: 0.73856 |  0:01:56s\n",
            "epoch 35 | loss: 0.57253 | val_0_accuracy: 0.72496 |  0:01:59s\n",
            "epoch 36 | loss: 0.57486 | val_0_accuracy: 0.73618 |  0:02:02s\n",
            "epoch 37 | loss: 0.57765 | val_0_accuracy: 0.73143 |  0:02:06s\n",
            "epoch 38 | loss: 0.5653  | val_0_accuracy: 0.74547 |  0:02:09s\n",
            "epoch 39 | loss: 0.56266 | val_0_accuracy: 0.61744 |  0:02:12s\n",
            "epoch 40 | loss: 0.58501 | val_0_accuracy: 0.71934 |  0:02:16s\n",
            "epoch 41 | loss: 0.57992 | val_0_accuracy: 0.73381 |  0:02:19s\n",
            "epoch 42 | loss: 0.58089 | val_0_accuracy: 0.73554 |  0:02:22s\n",
            "epoch 43 | loss: 0.556   | val_0_accuracy: 0.74223 |  0:02:26s\n",
            "epoch 44 | loss: 0.54602 | val_0_accuracy: 0.74503 |  0:02:29s\n",
            "epoch 45 | loss: 0.54228 | val_0_accuracy: 0.7459  |  0:02:32s\n",
            "epoch 46 | loss: 0.53563 | val_0_accuracy: 0.75281 |  0:02:36s\n",
            "epoch 47 | loss: 0.53151 | val_0_accuracy: 0.75259 |  0:02:39s\n",
            "epoch 48 | loss: 0.53656 | val_0_accuracy: 0.75389 |  0:02:42s\n",
            "epoch 49 | loss: 0.52734 | val_0_accuracy: 0.75583 |  0:02:45s\n",
            "epoch 50 | loss: 0.53241 | val_0_accuracy: 0.75043 |  0:02:49s\n",
            "epoch 51 | loss: 0.52215 | val_0_accuracy: 0.75367 |  0:02:52s\n",
            "epoch 52 | loss: 0.51925 | val_0_accuracy: 0.76231 |  0:02:55s\n",
            "epoch 53 | loss: 0.51371 | val_0_accuracy: 0.75237 |  0:02:58s\n",
            "epoch 54 | loss: 0.51278 | val_0_accuracy: 0.75497 |  0:03:02s\n",
            "epoch 55 | loss: 0.51369 | val_0_accuracy: 0.75604 |  0:03:05s\n",
            "epoch 56 | loss: 0.50475 | val_0_accuracy: 0.76123 |  0:03:09s\n",
            "epoch 57 | loss: 0.5085  | val_0_accuracy: 0.76015 |  0:03:12s\n",
            "epoch 58 | loss: 0.5061  | val_0_accuracy: 0.75756 |  0:03:15s\n",
            "epoch 59 | loss: 0.50124 | val_0_accuracy: 0.76036 |  0:03:19s\n",
            "epoch 60 | loss: 0.49994 | val_0_accuracy: 0.76274 |  0:03:22s\n",
            "epoch 61 | loss: 0.50839 | val_0_accuracy: 0.75475 |  0:03:25s\n",
            "epoch 62 | loss: 0.50265 | val_0_accuracy: 0.76101 |  0:03:28s\n",
            "epoch 63 | loss: 0.48782 | val_0_accuracy: 0.76813 |  0:03:32s\n",
            "epoch 64 | loss: 0.48662 | val_0_accuracy: 0.76576 |  0:03:35s\n",
            "epoch 65 | loss: 0.48085 | val_0_accuracy: 0.77224 |  0:03:38s\n",
            "epoch 66 | loss: 0.47721 | val_0_accuracy: 0.76425 |  0:03:42s\n",
            "epoch 67 | loss: 0.48576 | val_0_accuracy: 0.77116 |  0:03:45s\n",
            "epoch 68 | loss: 0.48113 | val_0_accuracy: 0.76792 |  0:03:48s\n",
            "epoch 69 | loss: 0.46773 | val_0_accuracy: 0.76878 |  0:03:51s\n",
            "epoch 70 | loss: 0.4699  | val_0_accuracy: 0.76749 |  0:03:54s\n",
            "epoch 71 | loss: 0.47776 | val_0_accuracy: 0.77655 |  0:03:58s\n",
            "epoch 72 | loss: 0.47031 | val_0_accuracy: 0.77655 |  0:04:01s\n",
            "epoch 73 | loss: 0.46154 | val_0_accuracy: 0.77137 |  0:04:04s\n",
            "epoch 74 | loss: 0.46506 | val_0_accuracy: 0.77375 |  0:04:08s\n",
            "epoch 75 | loss: 0.4591  | val_0_accuracy: 0.77763 |  0:04:11s\n",
            "epoch 76 | loss: 0.46241 | val_0_accuracy: 0.76921 |  0:04:14s\n",
            "epoch 77 | loss: 0.45769 | val_0_accuracy: 0.78044 |  0:04:17s\n",
            "epoch 78 | loss: 0.45361 | val_0_accuracy: 0.77245 |  0:04:21s\n",
            "epoch 79 | loss: 0.44913 | val_0_accuracy: 0.77915 |  0:04:24s\n",
            "epoch 80 | loss: 0.44896 | val_0_accuracy: 0.78519 |  0:04:27s\n",
            "epoch 81 | loss: 0.44606 | val_0_accuracy: 0.78411 |  0:04:31s\n",
            "epoch 82 | loss: 0.44379 | val_0_accuracy: 0.78454 |  0:04:34s\n",
            "epoch 83 | loss: 0.45455 | val_0_accuracy: 0.77569 |  0:04:37s\n",
            "epoch 84 | loss: 0.45119 | val_0_accuracy: 0.78541 |  0:04:41s\n",
            "epoch 85 | loss: 0.44095 | val_0_accuracy: 0.77871 |  0:04:44s\n",
            "epoch 86 | loss: 0.44071 | val_0_accuracy: 0.78843 |  0:04:47s\n",
            "epoch 87 | loss: 0.43876 | val_0_accuracy: 0.78562 |  0:04:51s\n",
            "epoch 88 | loss: 0.4369  | val_0_accuracy: 0.78778 |  0:04:54s\n",
            "epoch 89 | loss: 0.43033 | val_0_accuracy: 0.78217 |  0:04:57s\n",
            "epoch 90 | loss: 0.4329  | val_0_accuracy: 0.78238 |  0:05:01s\n",
            "epoch 91 | loss: 0.4271  | val_0_accuracy: 0.78584 |  0:05:04s\n",
            "epoch 92 | loss: 0.43307 | val_0_accuracy: 0.78843 |  0:05:07s\n",
            "epoch 93 | loss: 0.42324 | val_0_accuracy: 0.78886 |  0:05:11s\n",
            "epoch 94 | loss: 0.42461 | val_0_accuracy: 0.78087 |  0:05:14s\n",
            "epoch 95 | loss: 0.42224 | val_0_accuracy: 0.79167 |  0:05:17s\n",
            "epoch 96 | loss: 0.42119 | val_0_accuracy: 0.7921  |  0:05:20s\n",
            "epoch 97 | loss: 0.41716 | val_0_accuracy: 0.79231 |  0:05:24s\n",
            "epoch 98 | loss: 0.41707 | val_0_accuracy: 0.79296 |  0:05:27s\n",
            "epoch 99 | loss: 0.4164  | val_0_accuracy: 0.79426 |  0:05:30s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_accuracy = 0.79426\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-02 08:18:50,411]\u001b[0m Trial 3 finished with value: 0.7942573402417962 and parameters: {'n_d': 27, 'n_a': 34, 'n_steps': 3, 'gamma': 1.7754003697642289, 'n_independent': 5, 'n_shared': 5, 'momentum': 0.2982423472664459}. Best is trial 1 with value: 0.8000863557858376.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.63      0.61      0.62       825\n",
            "           2       0.83      0.95      0.88       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.56      0.52      0.54       761\n",
            "           5       0.69      0.64      0.66       619\n",
            "\n",
            "    accuracy                           0.79      4632\n",
            "   macro avg       0.78      0.79      0.78      4632\n",
            "weighted avg       0.79      0.79      0.79      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.94182 | val_0_accuracy: 0.49028 |  0:00:05s\n",
            "epoch 1  | loss: 1.2434  | val_0_accuracy: 0.39551 |  0:00:11s\n",
            "epoch 2  | loss: 1.29528 | val_0_accuracy: 0.53238 |  0:00:16s\n",
            "epoch 3  | loss: 0.96127 | val_0_accuracy: 0.57254 |  0:00:22s\n",
            "epoch 4  | loss: 0.88008 | val_0_accuracy: 0.62608 |  0:00:28s\n",
            "epoch 5  | loss: 0.82943 | val_0_accuracy: 0.63709 |  0:00:33s\n",
            "epoch 6  | loss: 0.78948 | val_0_accuracy: 0.6386  |  0:00:39s\n",
            "epoch 7  | loss: 0.7801  | val_0_accuracy: 0.63493 |  0:00:44s\n",
            "epoch 8  | loss: 0.82418 | val_0_accuracy: 0.62349 |  0:00:50s\n",
            "epoch 9  | loss: 0.78902 | val_0_accuracy: 0.65242 |  0:00:55s\n",
            "epoch 10 | loss: 0.75857 | val_0_accuracy: 0.6427  |  0:01:01s\n",
            "epoch 11 | loss: 0.75736 | val_0_accuracy: 0.63709 |  0:01:07s\n",
            "epoch 12 | loss: 0.74221 | val_0_accuracy: 0.64918 |  0:01:12s\n",
            "epoch 13 | loss: 0.74036 | val_0_accuracy: 0.66084 |  0:01:18s\n",
            "epoch 14 | loss: 0.72718 | val_0_accuracy: 0.67573 |  0:01:23s\n",
            "epoch 15 | loss: 0.70804 | val_0_accuracy: 0.68351 |  0:01:29s\n",
            "epoch 16 | loss: 0.71878 | val_0_accuracy: 0.66775 |  0:01:34s\n",
            "epoch 17 | loss: 0.70081 | val_0_accuracy: 0.68221 |  0:01:40s\n",
            "epoch 18 | loss: 0.74232 | val_0_accuracy: 0.65652 |  0:01:46s\n",
            "epoch 19 | loss: 0.7264  | val_0_accuracy: 0.65522 |  0:01:51s\n",
            "epoch 20 | loss: 0.7236  | val_0_accuracy: 0.67422 |  0:01:57s\n",
            "epoch 21 | loss: 0.70545 | val_0_accuracy: 0.6725  |  0:02:02s\n",
            "epoch 22 | loss: 0.69943 | val_0_accuracy: 0.68394 |  0:02:08s\n",
            "epoch 23 | loss: 0.73817 | val_0_accuracy: 0.64594 |  0:02:13s\n",
            "epoch 24 | loss: 0.7454  | val_0_accuracy: 0.66105 |  0:02:19s\n",
            "epoch 25 | loss: 0.71343 | val_0_accuracy: 0.66429 |  0:02:25s\n",
            "epoch 26 | loss: 0.72243 | val_0_accuracy: 0.6399  |  0:02:30s\n",
            "epoch 27 | loss: 0.74401 | val_0_accuracy: 0.67055 |  0:02:36s\n",
            "epoch 28 | loss: 0.72696 | val_0_accuracy: 0.66602 |  0:02:41s\n",
            "epoch 29 | loss: 0.70748 | val_0_accuracy: 0.67595 |  0:02:47s\n",
            "epoch 30 | loss: 0.69103 | val_0_accuracy: 0.67314 |  0:02:52s\n",
            "epoch 31 | loss: 0.68013 | val_0_accuracy: 0.68523 |  0:02:58s\n",
            "epoch 32 | loss: 0.67314 | val_0_accuracy: 0.70402 |  0:03:04s\n",
            "epoch 33 | loss: 0.66347 | val_0_accuracy: 0.70445 |  0:03:09s\n",
            "epoch 34 | loss: 0.65495 | val_0_accuracy: 0.70984 |  0:03:15s\n",
            "epoch 35 | loss: 0.6575  | val_0_accuracy: 0.69905 |  0:03:20s\n",
            "epoch 36 | loss: 0.67309 | val_0_accuracy: 0.69754 |  0:03:26s\n",
            "epoch 37 | loss: 0.66374 | val_0_accuracy: 0.70358 |  0:03:31s\n",
            "epoch 38 | loss: 0.64349 | val_0_accuracy: 0.71265 |  0:03:37s\n",
            "epoch 39 | loss: 0.65679 | val_0_accuracy: 0.69128 |  0:03:42s\n",
            "epoch 40 | loss: 0.67267 | val_0_accuracy: 0.69106 |  0:03:49s\n",
            "epoch 41 | loss: 0.69705 | val_0_accuracy: 0.6753  |  0:03:54s\n",
            "epoch 42 | loss: 0.69039 | val_0_accuracy: 0.67422 |  0:04:00s\n",
            "epoch 43 | loss: 0.68877 | val_0_accuracy: 0.68631 |  0:04:05s\n",
            "epoch 44 | loss: 0.66271 | val_0_accuracy: 0.69171 |  0:04:11s\n",
            "epoch 45 | loss: 0.67181 | val_0_accuracy: 0.69646 |  0:04:16s\n",
            "epoch 46 | loss: 0.65553 | val_0_accuracy: 0.70315 |  0:04:22s\n",
            "epoch 47 | loss: 0.64022 | val_0_accuracy: 0.7174  |  0:04:28s\n",
            "epoch 48 | loss: 0.63026 | val_0_accuracy: 0.71114 |  0:04:33s\n",
            "epoch 49 | loss: 0.62072 | val_0_accuracy: 0.71373 |  0:04:39s\n",
            "epoch 50 | loss: 0.6295  | val_0_accuracy: 0.70833 |  0:04:45s\n",
            "epoch 51 | loss: 0.6305  | val_0_accuracy: 0.71114 |  0:04:50s\n",
            "epoch 52 | loss: 0.62069 | val_0_accuracy: 0.72172 |  0:04:55s\n",
            "epoch 53 | loss: 0.60784 | val_0_accuracy: 0.71891 |  0:05:01s\n",
            "epoch 54 | loss: 0.60526 | val_0_accuracy: 0.72366 |  0:05:07s\n",
            "epoch 55 | loss: 0.59582 | val_0_accuracy: 0.73273 |  0:05:12s\n",
            "epoch 56 | loss: 0.5897  | val_0_accuracy: 0.7282  |  0:05:18s\n",
            "epoch 57 | loss: 0.58284 | val_0_accuracy: 0.73964 |  0:05:23s\n",
            "epoch 58 | loss: 0.57721 | val_0_accuracy: 0.72884 |  0:05:29s\n",
            "epoch 59 | loss: 0.57813 | val_0_accuracy: 0.73791 |  0:05:34s\n",
            "epoch 60 | loss: 0.57254 | val_0_accuracy: 0.73985 |  0:05:40s\n",
            "epoch 61 | loss: 0.57047 | val_0_accuracy: 0.74827 |  0:05:46s\n",
            "epoch 62 | loss: 0.57998 | val_0_accuracy: 0.72604 |  0:05:51s\n",
            "epoch 63 | loss: 0.58192 | val_0_accuracy: 0.73813 |  0:05:57s\n",
            "epoch 64 | loss: 0.60184 | val_0_accuracy: 0.72971 |  0:06:02s\n",
            "epoch 65 | loss: 0.60491 | val_0_accuracy: 0.73381 |  0:06:08s\n",
            "epoch 66 | loss: 0.57625 | val_0_accuracy: 0.74547 |  0:06:13s\n",
            "epoch 67 | loss: 0.56625 | val_0_accuracy: 0.74827 |  0:06:19s\n",
            "epoch 68 | loss: 0.55748 | val_0_accuracy: 0.74417 |  0:06:24s\n",
            "epoch 69 | loss: 0.59513 | val_0_accuracy: 0.73424 |  0:06:30s\n",
            "epoch 70 | loss: 0.58268 | val_0_accuracy: 0.7405  |  0:06:35s\n",
            "epoch 71 | loss: 0.56279 | val_0_accuracy: 0.74914 |  0:06:41s\n",
            "epoch 72 | loss: 0.55263 | val_0_accuracy: 0.74244 |  0:06:47s\n",
            "epoch 73 | loss: 0.54956 | val_0_accuracy: 0.75216 |  0:06:52s\n",
            "epoch 74 | loss: 0.54391 | val_0_accuracy: 0.76079 |  0:06:58s\n",
            "epoch 75 | loss: 0.53553 | val_0_accuracy: 0.75389 |  0:07:03s\n",
            "epoch 76 | loss: 0.53374 | val_0_accuracy: 0.75928 |  0:07:09s\n",
            "epoch 77 | loss: 0.52891 | val_0_accuracy: 0.75518 |  0:07:14s\n",
            "epoch 78 | loss: 0.52565 | val_0_accuracy: 0.75993 |  0:07:20s\n",
            "epoch 79 | loss: 0.52124 | val_0_accuracy: 0.76231 |  0:07:25s\n",
            "epoch 80 | loss: 0.51801 | val_0_accuracy: 0.75864 |  0:07:31s\n",
            "epoch 81 | loss: 0.51626 | val_0_accuracy: 0.75583 |  0:07:36s\n",
            "epoch 82 | loss: 0.51763 | val_0_accuracy: 0.75734 |  0:07:42s\n",
            "epoch 83 | loss: 0.51638 | val_0_accuracy: 0.76166 |  0:07:47s\n",
            "epoch 84 | loss: 0.51475 | val_0_accuracy: 0.7554  |  0:07:53s\n",
            "epoch 85 | loss: 0.51197 | val_0_accuracy: 0.75799 |  0:07:58s\n",
            "epoch 86 | loss: 0.50877 | val_0_accuracy: 0.76446 |  0:08:04s\n",
            "epoch 87 | loss: 0.50576 | val_0_accuracy: 0.75777 |  0:08:10s\n",
            "epoch 88 | loss: 0.49929 | val_0_accuracy: 0.75907 |  0:08:15s\n",
            "epoch 89 | loss: 0.50012 | val_0_accuracy: 0.76706 |  0:08:21s\n",
            "epoch 90 | loss: 0.49191 | val_0_accuracy: 0.77008 |  0:08:26s\n",
            "epoch 91 | loss: 0.48837 | val_0_accuracy: 0.76727 |  0:08:32s\n",
            "epoch 92 | loss: 0.48643 | val_0_accuracy: 0.7718  |  0:08:37s\n",
            "epoch 93 | loss: 0.48551 | val_0_accuracy: 0.77224 |  0:08:43s\n",
            "epoch 94 | loss: 0.47909 | val_0_accuracy: 0.769   |  0:08:49s\n",
            "epoch 95 | loss: 0.47897 | val_0_accuracy: 0.77051 |  0:08:54s\n",
            "epoch 96 | loss: 0.4746  | val_0_accuracy: 0.77029 |  0:08:59s\n",
            "epoch 97 | loss: 0.47611 | val_0_accuracy: 0.77699 |  0:09:05s\n",
            "epoch 98 | loss: 0.46988 | val_0_accuracy: 0.77029 |  0:09:10s\n",
            "epoch 99 | loss: 0.4809  | val_0_accuracy: 0.77332 |  0:09:16s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 97 and best_val_0_accuracy = 0.77699\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-02 08:28:08,989]\u001b[0m Trial 4 finished with value: 0.7769861830742659 and parameters: {'n_d': 43, 'n_a': 55, 'n_steps': 8, 'gamma': 1.7550177663502056, 'n_independent': 5, 'n_shared': 2, 'momentum': 0.040681862609254646}. Best is trial 1 with value: 0.8000863557858376.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.62      0.55      0.58       825\n",
            "           2       0.83      0.89      0.86       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.51      0.60      0.55       761\n",
            "           5       0.69      0.57      0.62       619\n",
            "\n",
            "    accuracy                           0.78      4632\n",
            "   macro avg       0.77      0.77      0.77      4632\n",
            "weighted avg       0.78      0.78      0.78      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.19444 | val_0_accuracy: 0.59758 |  0:00:01s\n",
            "epoch 1  | loss: 0.83983 | val_0_accuracy: 0.64098 |  0:00:03s\n",
            "epoch 2  | loss: 0.76017 | val_0_accuracy: 0.65825 |  0:00:05s\n",
            "epoch 3  | loss: 0.73137 | val_0_accuracy: 0.67595 |  0:00:07s\n",
            "epoch 4  | loss: 0.70035 | val_0_accuracy: 0.68199 |  0:00:08s\n",
            "epoch 5  | loss: 0.68885 | val_0_accuracy: 0.68718 |  0:00:10s\n",
            "epoch 6  | loss: 0.6827  | val_0_accuracy: 0.69754 |  0:00:12s\n",
            "epoch 7  | loss: 0.66978 | val_0_accuracy: 0.70294 |  0:00:14s\n",
            "epoch 8  | loss: 0.65467 | val_0_accuracy: 0.70358 |  0:00:15s\n",
            "epoch 9  | loss: 0.6685  | val_0_accuracy: 0.70078 |  0:00:17s\n",
            "epoch 10 | loss: 0.65414 | val_0_accuracy: 0.70833 |  0:00:19s\n",
            "epoch 11 | loss: 0.64058 | val_0_accuracy: 0.71503 |  0:00:20s\n",
            "epoch 12 | loss: 0.62471 | val_0_accuracy: 0.70596 |  0:00:22s\n",
            "epoch 13 | loss: 0.62358 | val_0_accuracy: 0.71287 |  0:00:24s\n",
            "epoch 14 | loss: 0.61374 | val_0_accuracy: 0.71783 |  0:00:26s\n",
            "epoch 15 | loss: 0.61279 | val_0_accuracy: 0.72496 |  0:00:27s\n",
            "epoch 16 | loss: 0.6094  | val_0_accuracy: 0.72258 |  0:00:29s\n",
            "epoch 17 | loss: 0.59279 | val_0_accuracy: 0.72971 |  0:00:31s\n",
            "epoch 18 | loss: 0.59072 | val_0_accuracy: 0.72776 |  0:00:32s\n",
            "epoch 19 | loss: 0.58661 | val_0_accuracy: 0.72798 |  0:00:34s\n",
            "epoch 20 | loss: 0.59257 | val_0_accuracy: 0.72647 |  0:00:36s\n",
            "epoch 21 | loss: 0.58985 | val_0_accuracy: 0.71632 |  0:00:37s\n",
            "epoch 22 | loss: 0.60906 | val_0_accuracy: 0.71438 |  0:00:39s\n",
            "epoch 23 | loss: 0.60263 | val_0_accuracy: 0.72992 |  0:00:41s\n",
            "epoch 24 | loss: 0.58565 | val_0_accuracy: 0.73856 |  0:00:43s\n",
            "epoch 25 | loss: 0.5699  | val_0_accuracy: 0.7323  |  0:00:45s\n",
            "epoch 26 | loss: 0.56647 | val_0_accuracy: 0.73079 |  0:00:47s\n",
            "epoch 27 | loss: 0.56817 | val_0_accuracy: 0.73769 |  0:00:49s\n",
            "epoch 28 | loss: 0.57592 | val_0_accuracy: 0.73985 |  0:00:50s\n",
            "epoch 29 | loss: 0.57525 | val_0_accuracy: 0.73187 |  0:00:52s\n",
            "epoch 30 | loss: 0.5849  | val_0_accuracy: 0.73705 |  0:00:54s\n",
            "epoch 31 | loss: 0.5716  | val_0_accuracy: 0.73554 |  0:00:55s\n",
            "epoch 32 | loss: 0.56503 | val_0_accuracy: 0.74525 |  0:00:57s\n",
            "epoch 33 | loss: 0.55139 | val_0_accuracy: 0.73618 |  0:00:59s\n",
            "epoch 34 | loss: 0.54729 | val_0_accuracy: 0.74439 |  0:01:00s\n",
            "epoch 35 | loss: 0.54361 | val_0_accuracy: 0.75302 |  0:01:02s\n",
            "epoch 36 | loss: 0.54204 | val_0_accuracy: 0.74698 |  0:01:04s\n",
            "epoch 37 | loss: 0.54325 | val_0_accuracy: 0.75432 |  0:01:06s\n",
            "epoch 38 | loss: 0.53438 | val_0_accuracy: 0.74957 |  0:01:07s\n",
            "epoch 39 | loss: 0.53964 | val_0_accuracy: 0.7582  |  0:01:09s\n",
            "epoch 40 | loss: 0.5359  | val_0_accuracy: 0.75194 |  0:01:11s\n",
            "epoch 41 | loss: 0.5362  | val_0_accuracy: 0.7446  |  0:01:12s\n",
            "epoch 42 | loss: 0.53144 | val_0_accuracy: 0.75972 |  0:01:14s\n",
            "epoch 43 | loss: 0.52061 | val_0_accuracy: 0.75281 |  0:01:16s\n",
            "epoch 44 | loss: 0.51692 | val_0_accuracy: 0.76166 |  0:01:17s\n",
            "epoch 45 | loss: 0.5176  | val_0_accuracy: 0.75302 |  0:01:19s\n",
            "epoch 46 | loss: 0.52841 | val_0_accuracy: 0.73381 |  0:01:21s\n",
            "epoch 47 | loss: 0.52664 | val_0_accuracy: 0.76187 |  0:01:23s\n",
            "epoch 48 | loss: 0.51447 | val_0_accuracy: 0.75022 |  0:01:24s\n",
            "epoch 49 | loss: 0.52606 | val_0_accuracy: 0.75799 |  0:01:26s\n",
            "epoch 50 | loss: 0.53384 | val_0_accuracy: 0.74957 |  0:01:28s\n",
            "epoch 51 | loss: 0.57755 | val_0_accuracy: 0.74439 |  0:01:30s\n",
            "epoch 52 | loss: 0.54654 | val_0_accuracy: 0.73424 |  0:01:31s\n",
            "epoch 53 | loss: 0.54947 | val_0_accuracy: 0.74827 |  0:01:33s\n",
            "epoch 54 | loss: 0.55592 | val_0_accuracy: 0.75173 |  0:01:35s\n",
            "epoch 55 | loss: 0.53706 | val_0_accuracy: 0.74763 |  0:01:37s\n",
            "epoch 56 | loss: 0.52608 | val_0_accuracy: 0.75173 |  0:01:38s\n",
            "epoch 57 | loss: 0.52528 | val_0_accuracy: 0.75583 |  0:01:40s\n",
            "\n",
            "Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_accuracy = 0.76187\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-02 08:29:50,351]\u001b[0m Trial 5 finished with value: 0.761873920552677 and parameters: {'n_d': 24, 'n_a': 40, 'n_steps': 3, 'gamma': 1.2627845197908274, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.30592194844004994}. Best is trial 1 with value: 0.8000863557858376.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.57      0.57      0.57       825\n",
            "           2       0.80      0.92      0.86       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.48      0.53      0.50       761\n",
            "           5       0.71      0.48      0.57       619\n",
            "\n",
            "    accuracy                           0.76      4632\n",
            "   macro avg       0.76      0.75      0.75      4632\n",
            "weighted avg       0.76      0.76      0.76      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 2.21309 | val_0_accuracy: 0.48467 |  0:00:04s\n",
            "epoch 1  | loss: 1.42117 | val_0_accuracy: 0.47604 |  0:00:09s\n",
            "epoch 2  | loss: 1.25463 | val_0_accuracy: 0.52094 |  0:00:14s\n",
            "epoch 3  | loss: 1.06998 | val_0_accuracy: 0.5978  |  0:00:19s\n",
            "epoch 4  | loss: 0.9739  | val_0_accuracy: 0.57016 |  0:00:24s\n",
            "epoch 5  | loss: 0.90497 | val_0_accuracy: 0.60147 |  0:00:28s\n",
            "epoch 6  | loss: 0.83498 | val_0_accuracy: 0.63687 |  0:00:33s\n",
            "epoch 7  | loss: 0.8059  | val_0_accuracy: 0.62392 |  0:00:38s\n",
            "epoch 8  | loss: 0.80428 | val_0_accuracy: 0.63579 |  0:00:43s\n",
            "epoch 9  | loss: 0.78737 | val_0_accuracy: 0.6332  |  0:00:47s\n",
            "epoch 10 | loss: 0.78336 | val_0_accuracy: 0.64853 |  0:00:52s\n",
            "epoch 11 | loss: 0.7783  | val_0_accuracy: 0.64659 |  0:00:57s\n",
            "epoch 12 | loss: 0.76973 | val_0_accuracy: 0.6427  |  0:01:02s\n",
            "epoch 13 | loss: 0.75927 | val_0_accuracy: 0.65738 |  0:01:07s\n",
            "epoch 14 | loss: 0.73127 | val_0_accuracy: 0.65522 |  0:01:11s\n",
            "epoch 15 | loss: 0.72367 | val_0_accuracy: 0.66602 |  0:01:16s\n",
            "epoch 16 | loss: 0.72269 | val_0_accuracy: 0.67358 |  0:01:21s\n",
            "epoch 17 | loss: 0.72443 | val_0_accuracy: 0.67098 |  0:01:26s\n",
            "epoch 18 | loss: 0.71966 | val_0_accuracy: 0.65911 |  0:01:31s\n",
            "epoch 19 | loss: 0.72437 | val_0_accuracy: 0.6617  |  0:01:35s\n",
            "epoch 20 | loss: 0.72454 | val_0_accuracy: 0.66321 |  0:01:40s\n",
            "epoch 21 | loss: 0.71274 | val_0_accuracy: 0.66969 |  0:01:45s\n",
            "epoch 22 | loss: 0.70654 | val_0_accuracy: 0.66516 |  0:01:50s\n",
            "epoch 23 | loss: 0.70215 | val_0_accuracy: 0.67228 |  0:01:54s\n",
            "epoch 24 | loss: 0.68943 | val_0_accuracy: 0.67681 |  0:01:59s\n",
            "epoch 25 | loss: 0.6861  | val_0_accuracy: 0.67465 |  0:02:04s\n",
            "epoch 26 | loss: 0.6814  | val_0_accuracy: 0.6794  |  0:02:09s\n",
            "epoch 27 | loss: 0.6743  | val_0_accuracy: 0.68113 |  0:02:13s\n",
            "epoch 28 | loss: 0.66347 | val_0_accuracy: 0.6943  |  0:02:18s\n",
            "epoch 29 | loss: 0.65859 | val_0_accuracy: 0.68394 |  0:02:23s\n",
            "epoch 30 | loss: 0.66662 | val_0_accuracy: 0.67142 |  0:02:28s\n",
            "epoch 31 | loss: 0.66218 | val_0_accuracy: 0.68502 |  0:02:33s\n",
            "epoch 32 | loss: 0.6656  | val_0_accuracy: 0.69301 |  0:02:37s\n",
            "epoch 33 | loss: 0.65939 | val_0_accuracy: 0.68998 |  0:02:42s\n",
            "epoch 34 | loss: 0.65139 | val_0_accuracy: 0.70423 |  0:02:47s\n",
            "epoch 35 | loss: 0.64328 | val_0_accuracy: 0.6984  |  0:02:52s\n",
            "epoch 36 | loss: 0.63766 | val_0_accuracy: 0.70574 |  0:02:56s\n",
            "epoch 37 | loss: 0.63426 | val_0_accuracy: 0.70466 |  0:03:01s\n",
            "epoch 38 | loss: 0.63826 | val_0_accuracy: 0.70337 |  0:03:06s\n",
            "epoch 39 | loss: 0.62893 | val_0_accuracy: 0.71157 |  0:03:10s\n",
            "epoch 40 | loss: 0.63191 | val_0_accuracy: 0.70315 |  0:03:15s\n",
            "epoch 41 | loss: 0.62944 | val_0_accuracy: 0.70855 |  0:03:20s\n",
            "epoch 42 | loss: 0.62455 | val_0_accuracy: 0.71157 |  0:03:25s\n",
            "epoch 43 | loss: 0.6238  | val_0_accuracy: 0.71244 |  0:03:30s\n",
            "epoch 44 | loss: 0.6134  | val_0_accuracy: 0.71611 |  0:03:34s\n",
            "epoch 45 | loss: 0.60806 | val_0_accuracy: 0.70747 |  0:03:39s\n",
            "epoch 46 | loss: 0.61186 | val_0_accuracy: 0.7133  |  0:03:44s\n",
            "epoch 47 | loss: 0.60727 | val_0_accuracy: 0.71611 |  0:03:49s\n",
            "epoch 48 | loss: 0.6181  | val_0_accuracy: 0.71481 |  0:03:53s\n",
            "epoch 49 | loss: 0.60608 | val_0_accuracy: 0.71632 |  0:03:58s\n",
            "epoch 50 | loss: 0.60993 | val_0_accuracy: 0.72085 |  0:04:03s\n",
            "epoch 51 | loss: 0.60399 | val_0_accuracy: 0.72064 |  0:04:08s\n",
            "epoch 52 | loss: 0.63808 | val_0_accuracy: 0.70639 |  0:04:13s\n",
            "epoch 53 | loss: 0.62615 | val_0_accuracy: 0.71783 |  0:04:17s\n",
            "epoch 54 | loss: 0.6596  | val_0_accuracy: 0.6848  |  0:04:22s\n",
            "epoch 55 | loss: 0.72272 | val_0_accuracy: 0.6766  |  0:04:27s\n",
            "epoch 56 | loss: 0.69766 | val_0_accuracy: 0.70056 |  0:04:31s\n",
            "epoch 57 | loss: 0.64796 | val_0_accuracy: 0.70877 |  0:04:36s\n",
            "epoch 58 | loss: 0.63726 | val_0_accuracy: 0.70445 |  0:04:41s\n",
            "epoch 59 | loss: 0.62213 | val_0_accuracy: 0.71524 |  0:04:46s\n",
            "epoch 60 | loss: 0.61947 | val_0_accuracy: 0.72064 |  0:04:51s\n",
            "\n",
            "Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_accuracy = 0.72085\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-02 08:34:43,684]\u001b[0m Trial 6 finished with value: 0.7208549222797928 and parameters: {'n_d': 51, 'n_a': 26, 'n_steps': 8, 'gamma': 1.8066535072682548, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.3036044889098929}. Best is trial 1 with value: 0.8000863557858376.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.49      0.48      0.49       825\n",
            "           2       0.77      0.81      0.79       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.44      0.54      0.48       761\n",
            "           5       0.63      0.42      0.51       619\n",
            "\n",
            "    accuracy                           0.72      4632\n",
            "   macro avg       0.72      0.71      0.71      4632\n",
            "weighted avg       0.73      0.72      0.72      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.67958 | val_0_accuracy: 0.53627 |  0:00:04s\n",
            "epoch 1  | loss: 1.08618 | val_0_accuracy: 0.57189 |  0:00:08s\n",
            "epoch 2  | loss: 1.05821 | val_0_accuracy: 0.52418 |  0:00:12s\n",
            "epoch 3  | loss: 1.05616 | val_0_accuracy: 0.52461 |  0:00:16s\n",
            "epoch 4  | loss: 1.0079  | val_0_accuracy: 0.58808 |  0:00:22s\n",
            "epoch 5  | loss: 0.87317 | val_0_accuracy: 0.61939 |  0:00:26s\n",
            "epoch 6  | loss: 0.81755 | val_0_accuracy: 0.62478 |  0:00:30s\n",
            "epoch 7  | loss: 0.80562 | val_0_accuracy: 0.6345  |  0:00:34s\n",
            "epoch 8  | loss: 0.79121 | val_0_accuracy: 0.62781 |  0:00:39s\n",
            "epoch 9  | loss: 0.77661 | val_0_accuracy: 0.63752 |  0:00:43s\n",
            "epoch 10 | loss: 0.76575 | val_0_accuracy: 0.64098 |  0:00:47s\n",
            "epoch 11 | loss: 0.75182 | val_0_accuracy: 0.6481  |  0:00:51s\n",
            "epoch 12 | loss: 0.73826 | val_0_accuracy: 0.65868 |  0:00:55s\n",
            "epoch 13 | loss: 0.73844 | val_0_accuracy: 0.66408 |  0:01:00s\n",
            "epoch 14 | loss: 0.74441 | val_0_accuracy: 0.64961 |  0:01:04s\n",
            "epoch 15 | loss: 0.7349  | val_0_accuracy: 0.66775 |  0:01:08s\n",
            "epoch 16 | loss: 0.71969 | val_0_accuracy: 0.66623 |  0:01:12s\n",
            "epoch 17 | loss: 0.7169  | val_0_accuracy: 0.6766  |  0:01:17s\n",
            "epoch 18 | loss: 0.7082  | val_0_accuracy: 0.67552 |  0:01:21s\n",
            "epoch 19 | loss: 0.70281 | val_0_accuracy: 0.67854 |  0:01:25s\n",
            "epoch 20 | loss: 0.6956  | val_0_accuracy: 0.67638 |  0:01:29s\n",
            "epoch 21 | loss: 0.68605 | val_0_accuracy: 0.68847 |  0:01:33s\n",
            "epoch 22 | loss: 0.68001 | val_0_accuracy: 0.68221 |  0:01:38s\n",
            "epoch 23 | loss: 0.67252 | val_0_accuracy: 0.69689 |  0:01:42s\n",
            "epoch 24 | loss: 0.66841 | val_0_accuracy: 0.69344 |  0:01:46s\n",
            "epoch 25 | loss: 0.66158 | val_0_accuracy: 0.69905 |  0:01:50s\n",
            "epoch 26 | loss: 0.653   | val_0_accuracy: 0.71373 |  0:01:54s\n",
            "epoch 27 | loss: 0.65689 | val_0_accuracy: 0.70639 |  0:01:58s\n",
            "epoch 28 | loss: 0.64944 | val_0_accuracy: 0.70531 |  0:02:03s\n",
            "epoch 29 | loss: 0.64273 | val_0_accuracy: 0.70574 |  0:02:07s\n",
            "epoch 30 | loss: 0.63448 | val_0_accuracy: 0.71049 |  0:02:11s\n",
            "epoch 31 | loss: 0.63626 | val_0_accuracy: 0.71049 |  0:02:15s\n",
            "epoch 32 | loss: 0.62991 | val_0_accuracy: 0.71028 |  0:02:19s\n",
            "epoch 33 | loss: 0.62306 | val_0_accuracy: 0.712   |  0:02:23s\n",
            "epoch 34 | loss: 0.62438 | val_0_accuracy: 0.72107 |  0:02:28s\n",
            "epoch 35 | loss: 0.61525 | val_0_accuracy: 0.71718 |  0:02:32s\n",
            "epoch 36 | loss: 0.61364 | val_0_accuracy: 0.71611 |  0:02:36s\n",
            "epoch 37 | loss: 0.61138 | val_0_accuracy: 0.72733 |  0:02:40s\n",
            "epoch 38 | loss: 0.60965 | val_0_accuracy: 0.72453 |  0:02:45s\n",
            "epoch 39 | loss: 0.60855 | val_0_accuracy: 0.72388 |  0:02:49s\n",
            "epoch 40 | loss: 0.59796 | val_0_accuracy: 0.71308 |  0:02:53s\n",
            "epoch 41 | loss: 0.60025 | val_0_accuracy: 0.71848 |  0:02:57s\n",
            "epoch 42 | loss: 0.59644 | val_0_accuracy: 0.73597 |  0:03:01s\n",
            "epoch 43 | loss: 0.60072 | val_0_accuracy: 0.71524 |  0:03:05s\n",
            "epoch 44 | loss: 0.60071 | val_0_accuracy: 0.72647 |  0:03:10s\n",
            "epoch 45 | loss: 0.58917 | val_0_accuracy: 0.73273 |  0:03:14s\n",
            "epoch 46 | loss: 0.58221 | val_0_accuracy: 0.72841 |  0:03:18s\n",
            "epoch 47 | loss: 0.57721 | val_0_accuracy: 0.72755 |  0:03:22s\n",
            "epoch 48 | loss: 0.57983 | val_0_accuracy: 0.74115 |  0:03:27s\n",
            "epoch 49 | loss: 0.58574 | val_0_accuracy: 0.72949 |  0:03:31s\n",
            "epoch 50 | loss: 0.58708 | val_0_accuracy: 0.73165 |  0:03:35s\n",
            "epoch 51 | loss: 0.59353 | val_0_accuracy: 0.73316 |  0:03:39s\n",
            "epoch 52 | loss: 0.57946 | val_0_accuracy: 0.72863 |  0:03:44s\n",
            "epoch 53 | loss: 0.57526 | val_0_accuracy: 0.73424 |  0:03:48s\n",
            "epoch 54 | loss: 0.56985 | val_0_accuracy: 0.73338 |  0:03:52s\n",
            "epoch 55 | loss: 0.5725  | val_0_accuracy: 0.7282  |  0:03:57s\n",
            "epoch 56 | loss: 0.57231 | val_0_accuracy: 0.73467 |  0:04:01s\n",
            "epoch 57 | loss: 0.56756 | val_0_accuracy: 0.74935 |  0:04:05s\n",
            "epoch 58 | loss: 0.56208 | val_0_accuracy: 0.74158 |  0:04:09s\n",
            "epoch 59 | loss: 0.5581  | val_0_accuracy: 0.74288 |  0:04:14s\n",
            "epoch 60 | loss: 0.55333 | val_0_accuracy: 0.74309 |  0:04:18s\n",
            "epoch 61 | loss: 0.55017 | val_0_accuracy: 0.75173 |  0:04:22s\n",
            "epoch 62 | loss: 0.5438  | val_0_accuracy: 0.75065 |  0:04:27s\n",
            "epoch 63 | loss: 0.54711 | val_0_accuracy: 0.75065 |  0:04:31s\n",
            "epoch 64 | loss: 0.5417  | val_0_accuracy: 0.75043 |  0:04:35s\n",
            "epoch 65 | loss: 0.5475  | val_0_accuracy: 0.74633 |  0:04:40s\n",
            "epoch 66 | loss: 0.53693 | val_0_accuracy: 0.75561 |  0:04:44s\n",
            "epoch 67 | loss: 0.53383 | val_0_accuracy: 0.75065 |  0:04:48s\n",
            "epoch 68 | loss: 0.54673 | val_0_accuracy: 0.74763 |  0:04:53s\n",
            "epoch 69 | loss: 0.53769 | val_0_accuracy: 0.75108 |  0:04:57s\n",
            "epoch 70 | loss: 0.53227 | val_0_accuracy: 0.75173 |  0:05:01s\n",
            "epoch 71 | loss: 0.52786 | val_0_accuracy: 0.76036 |  0:05:05s\n",
            "epoch 72 | loss: 0.54431 | val_0_accuracy: 0.7582  |  0:05:09s\n",
            "epoch 73 | loss: 0.52872 | val_0_accuracy: 0.75993 |  0:05:14s\n",
            "epoch 74 | loss: 0.52795 | val_0_accuracy: 0.75151 |  0:05:18s\n",
            "epoch 75 | loss: 0.52371 | val_0_accuracy: 0.75864 |  0:05:22s\n",
            "epoch 76 | loss: 0.52063 | val_0_accuracy: 0.76231 |  0:05:26s\n",
            "epoch 77 | loss: 0.5185  | val_0_accuracy: 0.76403 |  0:05:31s\n",
            "epoch 78 | loss: 0.51331 | val_0_accuracy: 0.76317 |  0:05:35s\n",
            "epoch 79 | loss: 0.51143 | val_0_accuracy: 0.75885 |  0:05:39s\n",
            "epoch 80 | loss: 0.51332 | val_0_accuracy: 0.76576 |  0:05:43s\n",
            "epoch 81 | loss: 0.50934 | val_0_accuracy: 0.7649  |  0:05:47s\n",
            "epoch 82 | loss: 0.51284 | val_0_accuracy: 0.76015 |  0:05:52s\n",
            "epoch 83 | loss: 0.53049 | val_0_accuracy: 0.75065 |  0:05:56s\n",
            "epoch 84 | loss: 0.54032 | val_0_accuracy: 0.75928 |  0:06:00s\n",
            "epoch 85 | loss: 0.52383 | val_0_accuracy: 0.76123 |  0:06:04s\n",
            "epoch 86 | loss: 0.51717 | val_0_accuracy: 0.74439 |  0:06:08s\n",
            "epoch 87 | loss: 0.53375 | val_0_accuracy: 0.75518 |  0:06:12s\n",
            "epoch 88 | loss: 0.53389 | val_0_accuracy: 0.76036 |  0:06:16s\n",
            "epoch 89 | loss: 0.51728 | val_0_accuracy: 0.7649  |  0:06:21s\n",
            "epoch 90 | loss: 0.52759 | val_0_accuracy: 0.75345 |  0:06:25s\n",
            "\n",
            "Early stopping occurred at epoch 90 with best_epoch = 80 and best_val_0_accuracy = 0.76576\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-02 08:41:11,209]\u001b[0m Trial 7 finished with value: 0.7657599309153713 and parameters: {'n_d': 28, 'n_a': 11, 'n_steps': 7, 'gamma': 1.2565030160545585, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.0386076211533389}. Best is trial 1 with value: 0.8000863557858376.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.57      0.58      0.58       825\n",
            "           2       0.80      0.90      0.85       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.50      0.53      0.51       761\n",
            "           5       0.69      0.53      0.60       619\n",
            "\n",
            "    accuracy                           0.77      4632\n",
            "   macro avg       0.76      0.76      0.76      4632\n",
            "weighted avg       0.77      0.77      0.76      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.88536 | val_0_accuracy: 0.48208 |  0:00:06s\n",
            "epoch 1  | loss: 1.13707 | val_0_accuracy: 0.5652  |  0:00:11s\n",
            "epoch 2  | loss: 1.36285 | val_0_accuracy: 0.57729 |  0:00:17s\n",
            "epoch 3  | loss: 0.97807 | val_0_accuracy: 0.58528 |  0:00:22s\n",
            "epoch 4  | loss: 0.96789 | val_0_accuracy: 0.5842  |  0:00:28s\n",
            "epoch 5  | loss: 0.93195 | val_0_accuracy: 0.58744 |  0:00:33s\n",
            "epoch 6  | loss: 0.87548 | val_0_accuracy: 0.60039 |  0:00:38s\n",
            "epoch 7  | loss: 0.85604 | val_0_accuracy: 0.61075 |  0:00:44s\n",
            "epoch 8  | loss: 0.817   | val_0_accuracy: 0.62586 |  0:00:49s\n",
            "epoch 9  | loss: 0.80658 | val_0_accuracy: 0.62392 |  0:00:55s\n",
            "epoch 10 | loss: 0.80725 | val_0_accuracy: 0.64162 |  0:01:00s\n",
            "epoch 11 | loss: 0.78397 | val_0_accuracy: 0.64465 |  0:01:05s\n",
            "epoch 12 | loss: 0.76619 | val_0_accuracy: 0.6494  |  0:01:11s\n",
            "epoch 13 | loss: 0.78355 | val_0_accuracy: 0.64357 |  0:01:16s\n",
            "epoch 14 | loss: 0.76086 | val_0_accuracy: 0.64767 |  0:01:21s\n",
            "epoch 15 | loss: 0.76512 | val_0_accuracy: 0.64896 |  0:01:26s\n",
            "epoch 16 | loss: 0.7387  | val_0_accuracy: 0.66321 |  0:01:32s\n",
            "epoch 17 | loss: 0.72257 | val_0_accuracy: 0.66688 |  0:01:37s\n",
            "epoch 18 | loss: 0.73251 | val_0_accuracy: 0.65889 |  0:01:42s\n",
            "epoch 19 | loss: 0.73059 | val_0_accuracy: 0.66019 |  0:01:48s\n",
            "epoch 20 | loss: 0.71093 | val_0_accuracy: 0.67163 |  0:01:53s\n",
            "epoch 21 | loss: 0.70996 | val_0_accuracy: 0.66883 |  0:01:58s\n",
            "epoch 22 | loss: 0.70257 | val_0_accuracy: 0.68135 |  0:02:04s\n",
            "epoch 23 | loss: 0.68931 | val_0_accuracy: 0.69193 |  0:02:09s\n",
            "epoch 24 | loss: 0.68121 | val_0_accuracy: 0.69452 |  0:02:14s\n",
            "epoch 25 | loss: 0.68506 | val_0_accuracy: 0.6766  |  0:02:20s\n",
            "epoch 26 | loss: 0.68104 | val_0_accuracy: 0.6943  |  0:02:25s\n",
            "epoch 27 | loss: 0.66607 | val_0_accuracy: 0.6984  |  0:02:31s\n",
            "epoch 28 | loss: 0.66693 | val_0_accuracy: 0.70207 |  0:02:36s\n",
            "epoch 29 | loss: 0.6575  | val_0_accuracy: 0.69711 |  0:02:42s\n",
            "epoch 30 | loss: 0.65823 | val_0_accuracy: 0.70574 |  0:02:47s\n",
            "epoch 31 | loss: 0.64764 | val_0_accuracy: 0.69775 |  0:02:53s\n",
            "epoch 32 | loss: 0.66196 | val_0_accuracy: 0.69624 |  0:02:58s\n",
            "epoch 33 | loss: 0.65553 | val_0_accuracy: 0.70682 |  0:03:04s\n",
            "epoch 34 | loss: 0.6645  | val_0_accuracy: 0.69948 |  0:03:09s\n",
            "epoch 35 | loss: 0.65902 | val_0_accuracy: 0.69624 |  0:03:15s\n",
            "epoch 36 | loss: 0.66396 | val_0_accuracy: 0.70402 |  0:03:20s\n",
            "epoch 37 | loss: 0.66114 | val_0_accuracy: 0.70078 |  0:03:26s\n",
            "epoch 38 | loss: 0.64679 | val_0_accuracy: 0.70099 |  0:03:31s\n",
            "epoch 39 | loss: 0.64602 | val_0_accuracy: 0.70963 |  0:03:36s\n",
            "epoch 40 | loss: 0.63679 | val_0_accuracy: 0.72042 |  0:03:42s\n",
            "epoch 41 | loss: 0.63455 | val_0_accuracy: 0.7079  |  0:03:47s\n",
            "epoch 42 | loss: 0.63347 | val_0_accuracy: 0.72258 |  0:03:52s\n",
            "epoch 43 | loss: 0.62334 | val_0_accuracy: 0.72107 |  0:03:58s\n",
            "epoch 44 | loss: 0.61511 | val_0_accuracy: 0.72409 |  0:04:03s\n",
            "epoch 45 | loss: 0.61342 | val_0_accuracy: 0.71999 |  0:04:08s\n",
            "epoch 46 | loss: 0.60827 | val_0_accuracy: 0.72776 |  0:04:14s\n",
            "epoch 47 | loss: 0.60368 | val_0_accuracy: 0.7256  |  0:04:19s\n",
            "epoch 48 | loss: 0.59773 | val_0_accuracy: 0.55073 |  0:04:24s\n",
            "epoch 49 | loss: 0.59959 | val_0_accuracy: 0.72712 |  0:04:30s\n",
            "epoch 50 | loss: 0.60314 | val_0_accuracy: 0.73554 |  0:04:35s\n",
            "epoch 51 | loss: 0.59834 | val_0_accuracy: 0.72668 |  0:04:40s\n",
            "epoch 52 | loss: 0.59588 | val_0_accuracy: 0.73402 |  0:04:46s\n",
            "epoch 53 | loss: 0.58542 | val_0_accuracy: 0.73834 |  0:04:51s\n",
            "epoch 54 | loss: 0.58333 | val_0_accuracy: 0.73035 |  0:04:56s\n",
            "epoch 55 | loss: 0.59169 | val_0_accuracy: 0.73726 |  0:05:02s\n",
            "epoch 56 | loss: 0.5775  | val_0_accuracy: 0.73402 |  0:05:07s\n",
            "epoch 57 | loss: 0.5735  | val_0_accuracy: 0.74676 |  0:05:12s\n",
            "epoch 58 | loss: 0.58495 | val_0_accuracy: 0.57383 |  0:05:17s\n",
            "epoch 59 | loss: 0.60742 | val_0_accuracy: 0.70121 |  0:05:23s\n",
            "epoch 60 | loss: 0.64695 | val_0_accuracy: 0.72388 |  0:05:28s\n",
            "epoch 61 | loss: 0.62978 | val_0_accuracy: 0.71287 |  0:05:33s\n",
            "epoch 62 | loss: 0.60629 | val_0_accuracy: 0.72604 |  0:05:39s\n",
            "epoch 63 | loss: 0.61363 | val_0_accuracy: 0.70509 |  0:05:44s\n",
            "epoch 64 | loss: 0.61925 | val_0_accuracy: 0.72021 |  0:05:49s\n",
            "epoch 65 | loss: 0.60183 | val_0_accuracy: 0.72841 |  0:05:55s\n",
            "epoch 66 | loss: 0.59377 | val_0_accuracy: 0.72625 |  0:06:00s\n",
            "epoch 67 | loss: 0.58577 | val_0_accuracy: 0.72927 |  0:06:05s\n",
            "\n",
            "Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_accuracy = 0.74676\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-02 08:47:19,667]\u001b[0m Trial 8 finished with value: 0.7467616580310881 and parameters: {'n_d': 57, 'n_a': 15, 'n_steps': 9, 'gamma': 1.2637209348068037, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.08135791756194906}. Best is trial 1 with value: 0.8000863557858376.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.55      0.45      0.50       825\n",
            "           2       0.74      0.92      0.82       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.48      0.51      0.50       761\n",
            "           5       0.65      0.55      0.59       619\n",
            "\n",
            "    accuracy                           0.75      4632\n",
            "   macro avg       0.74      0.74      0.73      4632\n",
            "weighted avg       0.74      0.75      0.74      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 2.36301 | val_0_accuracy: 0.42725 |  0:00:05s\n",
            "epoch 1  | loss: 1.48216 | val_0_accuracy: 0.51749 |  0:00:09s\n",
            "epoch 2  | loss: 1.24665 | val_0_accuracy: 0.53174 |  0:00:13s\n",
            "epoch 3  | loss: 1.09866 | val_0_accuracy: 0.56822 |  0:00:17s\n",
            "epoch 4  | loss: 0.89211 | val_0_accuracy: 0.60816 |  0:00:21s\n",
            "epoch 5  | loss: 0.80741 | val_0_accuracy: 0.63277 |  0:00:26s\n",
            "epoch 6  | loss: 0.79965 | val_0_accuracy: 0.62781 |  0:00:30s\n",
            "epoch 7  | loss: 0.79341 | val_0_accuracy: 0.63752 |  0:00:34s\n",
            "epoch 8  | loss: 0.77799 | val_0_accuracy: 0.64637 |  0:00:38s\n",
            "epoch 9  | loss: 0.77663 | val_0_accuracy: 0.64292 |  0:00:43s\n",
            "epoch 10 | loss: 0.76908 | val_0_accuracy: 0.63472 |  0:00:47s\n",
            "epoch 11 | loss: 0.75048 | val_0_accuracy: 0.64918 |  0:00:51s\n",
            "epoch 12 | loss: 0.748   | val_0_accuracy: 0.64983 |  0:00:55s\n",
            "epoch 13 | loss: 0.74141 | val_0_accuracy: 0.64594 |  0:01:00s\n",
            "epoch 14 | loss: 0.73652 | val_0_accuracy: 0.66256 |  0:01:04s\n",
            "epoch 15 | loss: 0.7202  | val_0_accuracy: 0.67465 |  0:01:08s\n",
            "epoch 16 | loss: 0.70964 | val_0_accuracy: 0.67703 |  0:01:12s\n",
            "epoch 17 | loss: 0.70479 | val_0_accuracy: 0.66991 |  0:01:17s\n",
            "epoch 18 | loss: 0.70883 | val_0_accuracy: 0.6725  |  0:01:21s\n",
            "epoch 19 | loss: 0.7084  | val_0_accuracy: 0.67163 |  0:01:25s\n",
            "epoch 20 | loss: 0.70776 | val_0_accuracy: 0.67163 |  0:01:30s\n",
            "epoch 21 | loss: 0.70163 | val_0_accuracy: 0.67595 |  0:01:34s\n",
            "epoch 22 | loss: 0.69561 | val_0_accuracy: 0.68307 |  0:01:38s\n",
            "epoch 23 | loss: 0.69606 | val_0_accuracy: 0.66904 |  0:01:42s\n",
            "epoch 24 | loss: 0.68908 | val_0_accuracy: 0.67768 |  0:01:47s\n",
            "epoch 25 | loss: 0.69915 | val_0_accuracy: 0.66688 |  0:01:51s\n",
            "epoch 26 | loss: 0.70711 | val_0_accuracy: 0.66472 |  0:01:55s\n",
            "epoch 27 | loss: 0.69081 | val_0_accuracy: 0.66883 |  0:02:00s\n",
            "epoch 28 | loss: 0.68073 | val_0_accuracy: 0.6889  |  0:02:04s\n",
            "epoch 29 | loss: 0.67017 | val_0_accuracy: 0.68718 |  0:02:08s\n",
            "epoch 30 | loss: 0.67155 | val_0_accuracy: 0.69106 |  0:02:13s\n",
            "epoch 31 | loss: 0.68473 | val_0_accuracy: 0.69193 |  0:02:17s\n",
            "epoch 32 | loss: 0.68412 | val_0_accuracy: 0.68998 |  0:02:22s\n",
            "epoch 33 | loss: 0.67213 | val_0_accuracy: 0.69603 |  0:02:26s\n",
            "epoch 34 | loss: 0.68197 | val_0_accuracy: 0.6943  |  0:02:30s\n",
            "epoch 35 | loss: 0.67762 | val_0_accuracy: 0.69538 |  0:02:34s\n",
            "epoch 36 | loss: 0.66342 | val_0_accuracy: 0.7025  |  0:02:38s\n",
            "epoch 37 | loss: 0.65802 | val_0_accuracy: 0.69732 |  0:02:43s\n",
            "epoch 38 | loss: 0.65176 | val_0_accuracy: 0.69106 |  0:02:47s\n",
            "epoch 39 | loss: 0.66875 | val_0_accuracy: 0.6956  |  0:02:51s\n",
            "epoch 40 | loss: 0.68179 | val_0_accuracy: 0.69883 |  0:02:55s\n",
            "epoch 41 | loss: 0.65848 | val_0_accuracy: 0.69646 |  0:03:00s\n",
            "epoch 42 | loss: 0.68589 | val_0_accuracy: 0.69322 |  0:03:04s\n",
            "epoch 43 | loss: 0.67072 | val_0_accuracy: 0.69624 |  0:03:08s\n",
            "epoch 44 | loss: 0.66085 | val_0_accuracy: 0.69193 |  0:03:12s\n",
            "epoch 45 | loss: 0.65411 | val_0_accuracy: 0.7025  |  0:03:16s\n",
            "epoch 46 | loss: 0.65003 | val_0_accuracy: 0.69581 |  0:03:21s\n",
            "\n",
            "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_accuracy = 0.7025\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-02 08:50:42,935]\u001b[0m Trial 9 finished with value: 0.7025043177892919 and parameters: {'n_d': 27, 'n_a': 12, 'n_steps': 10, 'gamma': 1.8186441872701353, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.33889700094188235}. Best is trial 1 with value: 0.8000863557858376.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       825\n",
            "           1       0.45      0.58      0.50       825\n",
            "           2       0.78      0.67      0.72       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.44      0.34      0.38       761\n",
            "           5       0.56      0.59      0.57       619\n",
            "\n",
            "    accuracy                           0.70      4632\n",
            "   macro avg       0.70      0.70      0.70      4632\n",
            "weighted avg       0.71      0.70      0.70      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.29016 | val_0_accuracy: 0.58959 |  0:00:02s\n",
            "epoch 1  | loss: 0.86624 | val_0_accuracy: 0.63018 |  0:00:04s\n",
            "epoch 2  | loss: 0.80649 | val_0_accuracy: 0.62824 |  0:00:07s\n",
            "epoch 3  | loss: 0.78902 | val_0_accuracy: 0.63472 |  0:00:09s\n",
            "epoch 4  | loss: 0.76868 | val_0_accuracy: 0.65263 |  0:00:12s\n",
            "epoch 5  | loss: 0.74228 | val_0_accuracy: 0.65695 |  0:00:14s\n",
            "epoch 6  | loss: 0.73148 | val_0_accuracy: 0.67832 |  0:00:17s\n",
            "epoch 7  | loss: 0.71966 | val_0_accuracy: 0.67617 |  0:00:19s\n",
            "epoch 8  | loss: 0.71756 | val_0_accuracy: 0.67897 |  0:00:22s\n",
            "epoch 9  | loss: 0.69748 | val_0_accuracy: 0.67206 |  0:00:24s\n",
            "epoch 10 | loss: 0.6959  | val_0_accuracy: 0.68307 |  0:00:27s\n",
            "epoch 11 | loss: 0.6796  | val_0_accuracy: 0.69473 |  0:00:29s\n",
            "epoch 12 | loss: 0.67324 | val_0_accuracy: 0.7038  |  0:00:32s\n",
            "epoch 13 | loss: 0.66519 | val_0_accuracy: 0.70078 |  0:00:34s\n",
            "epoch 14 | loss: 0.65961 | val_0_accuracy: 0.71006 |  0:00:37s\n",
            "epoch 15 | loss: 0.65203 | val_0_accuracy: 0.70531 |  0:00:39s\n",
            "epoch 16 | loss: 0.64931 | val_0_accuracy: 0.69041 |  0:00:42s\n",
            "epoch 17 | loss: 0.65156 | val_0_accuracy: 0.70035 |  0:00:44s\n",
            "epoch 18 | loss: 0.66129 | val_0_accuracy: 0.68135 |  0:00:46s\n",
            "epoch 19 | loss: 0.64254 | val_0_accuracy: 0.70682 |  0:00:49s\n",
            "epoch 20 | loss: 0.63707 | val_0_accuracy: 0.71697 |  0:00:51s\n",
            "epoch 21 | loss: 0.63716 | val_0_accuracy: 0.70661 |  0:00:54s\n",
            "epoch 22 | loss: 0.63232 | val_0_accuracy: 0.70466 |  0:00:56s\n",
            "epoch 23 | loss: 0.63236 | val_0_accuracy: 0.7133  |  0:00:59s\n",
            "epoch 24 | loss: 0.62087 | val_0_accuracy: 0.69754 |  0:01:01s\n",
            "epoch 25 | loss: 0.61574 | val_0_accuracy: 0.70725 |  0:01:04s\n",
            "epoch 26 | loss: 0.61304 | val_0_accuracy: 0.72431 |  0:01:06s\n",
            "epoch 27 | loss: 0.60732 | val_0_accuracy: 0.71028 |  0:01:09s\n",
            "epoch 28 | loss: 0.60145 | val_0_accuracy: 0.72193 |  0:01:11s\n",
            "epoch 29 | loss: 0.59975 | val_0_accuracy: 0.71675 |  0:01:13s\n",
            "epoch 30 | loss: 0.59816 | val_0_accuracy: 0.69624 |  0:01:16s\n",
            "epoch 31 | loss: 0.60246 | val_0_accuracy: 0.71978 |  0:01:18s\n",
            "epoch 32 | loss: 0.60487 | val_0_accuracy: 0.71265 |  0:01:21s\n",
            "epoch 33 | loss: 0.59067 | val_0_accuracy: 0.70639 |  0:01:23s\n",
            "epoch 34 | loss: 0.58071 | val_0_accuracy: 0.71826 |  0:01:26s\n",
            "epoch 35 | loss: 0.5862  | val_0_accuracy: 0.71481 |  0:01:28s\n",
            "epoch 36 | loss: 0.58991 | val_0_accuracy: 0.72971 |  0:01:31s\n",
            "epoch 37 | loss: 0.57681 | val_0_accuracy: 0.7079  |  0:01:33s\n",
            "epoch 38 | loss: 0.5783  | val_0_accuracy: 0.72345 |  0:01:36s\n",
            "epoch 39 | loss: 0.57632 | val_0_accuracy: 0.71697 |  0:01:38s\n",
            "epoch 40 | loss: 0.56552 | val_0_accuracy: 0.72604 |  0:01:41s\n",
            "epoch 41 | loss: 0.56189 | val_0_accuracy: 0.71956 |  0:01:43s\n",
            "epoch 42 | loss: 0.55902 | val_0_accuracy: 0.71524 |  0:01:46s\n",
            "epoch 43 | loss: 0.5588  | val_0_accuracy: 0.72323 |  0:01:48s\n",
            "epoch 44 | loss: 0.55581 | val_0_accuracy: 0.71567 |  0:01:51s\n",
            "epoch 45 | loss: 0.55014 | val_0_accuracy: 0.71999 |  0:01:53s\n",
            "epoch 46 | loss: 0.5482  | val_0_accuracy: 0.72366 |  0:01:55s\n",
            "\n",
            "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_accuracy = 0.72971\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-02 08:52:40,115]\u001b[0m Trial 10 finished with value: 0.729706390328152 and parameters: {'n_d': 9, 'n_a': 63, 'n_steps': 5, 'gamma': 1.0016899630378995, 'n_independent': 3, 'n_shared': 1, 'momentum': 0.18310684566639013}. Best is trial 1 with value: 0.8000863557858376.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.51      0.51      0.51       825\n",
            "           2       0.78      0.83      0.81       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.44      0.50      0.47       761\n",
            "           5       0.63      0.46      0.53       619\n",
            "\n",
            "    accuracy                           0.73      4632\n",
            "   macro avg       0.73      0.72      0.72      4632\n",
            "weighted avg       0.73      0.73      0.73      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.4683  | val_0_accuracy: 0.51986 |  0:00:04s\n",
            "epoch 1  | loss: 1.09445 | val_0_accuracy: 0.54944 |  0:00:09s\n",
            "epoch 2  | loss: 1.09003 | val_0_accuracy: 0.54814 |  0:00:14s\n",
            "epoch 3  | loss: 1.05872 | val_0_accuracy: 0.56174 |  0:00:19s\n",
            "epoch 4  | loss: 0.97807 | val_0_accuracy: 0.48726 |  0:00:24s\n",
            "epoch 5  | loss: 0.8816  | val_0_accuracy: 0.61809 |  0:00:29s\n",
            "epoch 6  | loss: 0.8105  | val_0_accuracy: 0.62198 |  0:00:34s\n",
            "epoch 7  | loss: 0.78688 | val_0_accuracy: 0.63536 |  0:00:39s\n",
            "epoch 8  | loss: 0.77396 | val_0_accuracy: 0.65026 |  0:00:44s\n",
            "epoch 9  | loss: 0.7548  | val_0_accuracy: 0.64702 |  0:00:49s\n",
            "epoch 10 | loss: 0.74975 | val_0_accuracy: 0.65458 |  0:00:54s\n",
            "epoch 11 | loss: 0.73096 | val_0_accuracy: 0.64961 |  0:00:59s\n",
            "epoch 12 | loss: 0.73833 | val_0_accuracy: 0.66796 |  0:01:04s\n",
            "epoch 13 | loss: 0.71917 | val_0_accuracy: 0.66818 |  0:01:09s\n",
            "epoch 14 | loss: 0.71168 | val_0_accuracy: 0.68048 |  0:01:15s\n",
            "epoch 15 | loss: 0.70251 | val_0_accuracy: 0.66991 |  0:01:20s\n",
            "epoch 16 | loss: 0.6969  | val_0_accuracy: 0.67271 |  0:01:25s\n",
            "epoch 17 | loss: 0.69948 | val_0_accuracy: 0.68156 |  0:01:30s\n",
            "epoch 18 | loss: 0.69141 | val_0_accuracy: 0.65889 |  0:01:35s\n",
            "epoch 19 | loss: 0.6847  | val_0_accuracy: 0.68934 |  0:01:40s\n",
            "epoch 20 | loss: 0.67875 | val_0_accuracy: 0.68156 |  0:01:45s\n",
            "epoch 21 | loss: 0.67065 | val_0_accuracy: 0.69214 |  0:01:49s\n",
            "epoch 22 | loss: 0.66945 | val_0_accuracy: 0.6658  |  0:01:54s\n",
            "epoch 23 | loss: 0.66167 | val_0_accuracy: 0.69732 |  0:01:59s\n",
            "epoch 24 | loss: 0.65828 | val_0_accuracy: 0.69927 |  0:02:04s\n",
            "epoch 25 | loss: 0.65788 | val_0_accuracy: 0.6997  |  0:02:09s\n",
            "epoch 26 | loss: 0.65186 | val_0_accuracy: 0.69862 |  0:02:14s\n",
            "epoch 27 | loss: 0.64819 | val_0_accuracy: 0.70099 |  0:02:19s\n",
            "epoch 28 | loss: 0.64466 | val_0_accuracy: 0.69646 |  0:02:24s\n",
            "epoch 29 | loss: 0.63435 | val_0_accuracy: 0.69883 |  0:02:29s\n",
            "epoch 30 | loss: 0.63063 | val_0_accuracy: 0.70682 |  0:02:34s\n",
            "epoch 31 | loss: 0.62701 | val_0_accuracy: 0.70984 |  0:02:39s\n",
            "epoch 32 | loss: 0.62473 | val_0_accuracy: 0.52224 |  0:02:44s\n",
            "epoch 33 | loss: 0.62804 | val_0_accuracy: 0.71308 |  0:02:49s\n",
            "epoch 34 | loss: 0.62988 | val_0_accuracy: 0.6997  |  0:02:54s\n",
            "epoch 35 | loss: 0.62617 | val_0_accuracy: 0.71438 |  0:02:59s\n",
            "epoch 36 | loss: 0.6215  | val_0_accuracy: 0.71697 |  0:03:04s\n",
            "epoch 37 | loss: 0.60988 | val_0_accuracy: 0.6848  |  0:03:09s\n",
            "epoch 38 | loss: 0.61777 | val_0_accuracy: 0.54404 |  0:03:14s\n",
            "epoch 39 | loss: 0.60389 | val_0_accuracy: 0.7269  |  0:03:19s\n",
            "epoch 40 | loss: 0.60046 | val_0_accuracy: 0.71308 |  0:03:24s\n",
            "epoch 41 | loss: 0.5934  | val_0_accuracy: 0.72453 |  0:03:29s\n",
            "epoch 42 | loss: 0.58957 | val_0_accuracy: 0.70358 |  0:03:34s\n",
            "epoch 43 | loss: 0.59992 | val_0_accuracy: 0.7215  |  0:03:40s\n",
            "epoch 44 | loss: 0.58103 | val_0_accuracy: 0.73187 |  0:03:45s\n",
            "epoch 45 | loss: 0.59719 | val_0_accuracy: 0.70963 |  0:03:50s\n",
            "epoch 46 | loss: 0.60445 | val_0_accuracy: 0.72409 |  0:03:55s\n",
            "epoch 47 | loss: 0.59615 | val_0_accuracy: 0.55937 |  0:04:00s\n",
            "epoch 48 | loss: 0.58501 | val_0_accuracy: 0.72172 |  0:04:05s\n",
            "epoch 49 | loss: 0.57988 | val_0_accuracy: 0.73359 |  0:04:10s\n",
            "epoch 50 | loss: 0.60433 | val_0_accuracy: 0.73079 |  0:04:15s\n",
            "epoch 51 | loss: 0.58113 | val_0_accuracy: 0.56088 |  0:04:20s\n",
            "epoch 52 | loss: 0.56856 | val_0_accuracy: 0.55268 |  0:04:26s\n",
            "epoch 53 | loss: 0.56245 | val_0_accuracy: 0.56649 |  0:04:31s\n",
            "epoch 54 | loss: 0.55616 | val_0_accuracy: 0.5611  |  0:04:36s\n",
            "epoch 55 | loss: 0.56882 | val_0_accuracy: 0.56628 |  0:04:41s\n",
            "epoch 56 | loss: 0.56872 | val_0_accuracy: 0.73964 |  0:04:46s\n",
            "epoch 57 | loss: 0.55824 | val_0_accuracy: 0.75216 |  0:04:51s\n",
            "epoch 58 | loss: 0.54867 | val_0_accuracy: 0.74201 |  0:04:56s\n",
            "epoch 59 | loss: 0.54822 | val_0_accuracy: 0.56218 |  0:05:01s\n",
            "epoch 60 | loss: 0.54729 | val_0_accuracy: 0.75281 |  0:05:06s\n",
            "epoch 61 | loss: 0.54453 | val_0_accuracy: 0.75345 |  0:05:11s\n",
            "epoch 62 | loss: 0.53585 | val_0_accuracy: 0.7487  |  0:05:16s\n",
            "epoch 63 | loss: 0.54419 | val_0_accuracy: 0.54944 |  0:05:21s\n",
            "epoch 64 | loss: 0.5518  | val_0_accuracy: 0.74611 |  0:05:26s\n",
            "epoch 65 | loss: 0.53496 | val_0_accuracy: 0.61636 |  0:05:31s\n",
            "epoch 66 | loss: 0.52791 | val_0_accuracy: 0.57578 |  0:05:37s\n",
            "epoch 67 | loss: 0.52548 | val_0_accuracy: 0.75108 |  0:05:42s\n",
            "epoch 68 | loss: 0.52476 | val_0_accuracy: 0.76058 |  0:05:47s\n",
            "epoch 69 | loss: 0.51677 | val_0_accuracy: 0.61615 |  0:05:52s\n",
            "epoch 70 | loss: 0.51554 | val_0_accuracy: 0.76209 |  0:05:57s\n",
            "epoch 71 | loss: 0.5109  | val_0_accuracy: 0.58096 |  0:06:02s\n",
            "epoch 72 | loss: 0.50888 | val_0_accuracy: 0.76209 |  0:06:07s\n",
            "epoch 73 | loss: 0.5067  | val_0_accuracy: 0.76943 |  0:06:12s\n",
            "epoch 74 | loss: 0.504   | val_0_accuracy: 0.7677  |  0:06:18s\n",
            "epoch 75 | loss: 0.50251 | val_0_accuracy: 0.76425 |  0:06:23s\n",
            "epoch 76 | loss: 0.50768 | val_0_accuracy: 0.77029 |  0:06:28s\n",
            "epoch 77 | loss: 0.50707 | val_0_accuracy: 0.76878 |  0:06:33s\n",
            "epoch 78 | loss: 0.501   | val_0_accuracy: 0.77224 |  0:06:38s\n",
            "epoch 79 | loss: 0.50311 | val_0_accuracy: 0.77224 |  0:06:44s\n",
            "epoch 80 | loss: 0.50448 | val_0_accuracy: 0.77224 |  0:06:49s\n",
            "epoch 81 | loss: 0.49282 | val_0_accuracy: 0.77612 |  0:06:54s\n",
            "epoch 82 | loss: 0.48745 | val_0_accuracy: 0.7731  |  0:06:59s\n",
            "epoch 83 | loss: 0.4876  | val_0_accuracy: 0.76662 |  0:07:05s\n",
            "epoch 84 | loss: 0.49261 | val_0_accuracy: 0.77871 |  0:07:10s\n",
            "epoch 85 | loss: 0.48778 | val_0_accuracy: 0.76965 |  0:07:15s\n",
            "epoch 86 | loss: 0.48566 | val_0_accuracy: 0.78238 |  0:07:20s\n",
            "epoch 87 | loss: 0.47982 | val_0_accuracy: 0.76857 |  0:07:26s\n",
            "epoch 88 | loss: 0.47564 | val_0_accuracy: 0.76446 |  0:07:31s\n",
            "epoch 89 | loss: 0.47423 | val_0_accuracy: 0.78022 |  0:07:36s\n",
            "epoch 90 | loss: 0.47407 | val_0_accuracy: 0.78195 |  0:07:41s\n",
            "epoch 91 | loss: 0.47317 | val_0_accuracy: 0.78109 |  0:07:46s\n",
            "epoch 92 | loss: 0.47344 | val_0_accuracy: 0.78562 |  0:07:51s\n",
            "epoch 93 | loss: 0.46979 | val_0_accuracy: 0.7772  |  0:07:56s\n",
            "epoch 94 | loss: 0.46932 | val_0_accuracy: 0.78433 |  0:08:01s\n",
            "epoch 95 | loss: 0.46405 | val_0_accuracy: 0.78411 |  0:08:06s\n",
            "epoch 96 | loss: 0.46463 | val_0_accuracy: 0.78649 |  0:08:11s\n",
            "epoch 97 | loss: 0.4611  | val_0_accuracy: 0.78692 |  0:08:17s\n",
            "epoch 98 | loss: 0.46447 | val_0_accuracy: 0.77936 |  0:08:22s\n",
            "epoch 99 | loss: 0.4634  | val_0_accuracy: 0.58938 |  0:08:27s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 97 and best_val_0_accuracy = 0.78692\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-02 09:01:09,816]\u001b[0m Trial 11 finished with value: 0.7869170984455959 and parameters: {'n_d': 15, 'n_a': 32, 'n_steps': 5, 'gamma': 1.5832150903537638, 'n_independent': 5, 'n_shared': 5, 'momentum': 0.2121772705556747}. Best is trial 1 with value: 0.8000863557858376.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.61      0.62      0.62       825\n",
            "           2       0.82      0.92      0.87       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.53      0.59      0.56       761\n",
            "           5       0.75      0.53      0.62       619\n",
            "\n",
            "    accuracy                           0.79      4632\n",
            "   macro avg       0.79      0.78      0.78      4632\n",
            "weighted avg       0.79      0.79      0.79      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.49071 | val_0_accuracy: 0.51015 |  0:00:04s\n",
            "epoch 1  | loss: 1.08314 | val_0_accuracy: 0.55548 |  0:00:09s\n",
            "epoch 2  | loss: 0.95381 | val_0_accuracy: 0.5775  |  0:00:14s\n",
            "epoch 3  | loss: 0.89507 | val_0_accuracy: 0.5788  |  0:00:19s\n",
            "epoch 4  | loss: 0.85908 | val_0_accuracy: 0.60535 |  0:00:23s\n",
            "epoch 5  | loss: 0.81467 | val_0_accuracy: 0.62781 |  0:00:28s\n",
            "epoch 6  | loss: 0.79399 | val_0_accuracy: 0.64313 |  0:00:33s\n",
            "epoch 7  | loss: 0.77365 | val_0_accuracy: 0.6481  |  0:00:38s\n",
            "epoch 8  | loss: 0.7893  | val_0_accuracy: 0.63169 |  0:00:42s\n",
            "epoch 9  | loss: 0.7946  | val_0_accuracy: 0.6427  |  0:00:47s\n",
            "epoch 10 | loss: 0.76201 | val_0_accuracy: 0.64119 |  0:00:52s\n",
            "epoch 11 | loss: 0.74352 | val_0_accuracy: 0.64486 |  0:00:57s\n",
            "epoch 12 | loss: 0.77744 | val_0_accuracy: 0.63385 |  0:01:01s\n",
            "epoch 13 | loss: 0.77259 | val_0_accuracy: 0.64486 |  0:01:06s\n",
            "epoch 14 | loss: 0.75084 | val_0_accuracy: 0.66019 |  0:01:11s\n",
            "epoch 15 | loss: 0.74523 | val_0_accuracy: 0.66364 |  0:01:16s\n",
            "epoch 16 | loss: 0.71902 | val_0_accuracy: 0.66883 |  0:01:20s\n",
            "epoch 17 | loss: 0.7269  | val_0_accuracy: 0.66494 |  0:01:25s\n",
            "epoch 18 | loss: 0.72    | val_0_accuracy: 0.67358 |  0:01:30s\n",
            "epoch 19 | loss: 0.69568 | val_0_accuracy: 0.68545 |  0:01:35s\n",
            "epoch 20 | loss: 0.68919 | val_0_accuracy: 0.68502 |  0:01:40s\n",
            "epoch 21 | loss: 0.68086 | val_0_accuracy: 0.69041 |  0:01:44s\n",
            "epoch 22 | loss: 0.68245 | val_0_accuracy: 0.68545 |  0:01:49s\n",
            "epoch 23 | loss: 0.6768  | val_0_accuracy: 0.67832 |  0:01:54s\n",
            "epoch 24 | loss: 0.67898 | val_0_accuracy: 0.68243 |  0:01:59s\n",
            "epoch 25 | loss: 0.66434 | val_0_accuracy: 0.7038  |  0:02:03s\n",
            "epoch 26 | loss: 0.6606  | val_0_accuracy: 0.70877 |  0:02:08s\n",
            "epoch 27 | loss: 0.65131 | val_0_accuracy: 0.70639 |  0:02:13s\n",
            "epoch 28 | loss: 0.63761 | val_0_accuracy: 0.70963 |  0:02:18s\n",
            "epoch 29 | loss: 0.63439 | val_0_accuracy: 0.71287 |  0:02:22s\n",
            "epoch 30 | loss: 0.63078 | val_0_accuracy: 0.70488 |  0:02:27s\n",
            "epoch 31 | loss: 0.62671 | val_0_accuracy: 0.712   |  0:02:32s\n",
            "epoch 32 | loss: 0.62162 | val_0_accuracy: 0.71481 |  0:02:37s\n",
            "epoch 33 | loss: 0.62034 | val_0_accuracy: 0.71675 |  0:02:41s\n",
            "epoch 34 | loss: 0.65089 | val_0_accuracy: 0.70121 |  0:02:46s\n",
            "epoch 35 | loss: 0.62383 | val_0_accuracy: 0.71287 |  0:02:51s\n",
            "epoch 36 | loss: 0.61326 | val_0_accuracy: 0.72841 |  0:02:56s\n",
            "epoch 37 | loss: 0.62947 | val_0_accuracy: 0.70574 |  0:03:01s\n",
            "epoch 38 | loss: 0.62423 | val_0_accuracy: 0.72064 |  0:03:05s\n",
            "epoch 39 | loss: 0.61085 | val_0_accuracy: 0.72042 |  0:03:10s\n",
            "epoch 40 | loss: 0.6213  | val_0_accuracy: 0.72021 |  0:03:15s\n",
            "epoch 41 | loss: 0.60734 | val_0_accuracy: 0.71438 |  0:03:20s\n",
            "epoch 42 | loss: 0.62244 | val_0_accuracy: 0.72129 |  0:03:25s\n",
            "epoch 43 | loss: 0.60122 | val_0_accuracy: 0.71826 |  0:03:29s\n",
            "epoch 44 | loss: 0.59463 | val_0_accuracy: 0.73489 |  0:03:34s\n",
            "epoch 45 | loss: 0.58949 | val_0_accuracy: 0.73208 |  0:03:39s\n",
            "epoch 46 | loss: 0.585   | val_0_accuracy: 0.7351  |  0:03:44s\n",
            "epoch 47 | loss: 0.5815  | val_0_accuracy: 0.73208 |  0:03:48s\n",
            "epoch 48 | loss: 0.58627 | val_0_accuracy: 0.72172 |  0:03:53s\n",
            "epoch 49 | loss: 0.58821 | val_0_accuracy: 0.73057 |  0:03:58s\n",
            "epoch 50 | loss: 0.57785 | val_0_accuracy: 0.73661 |  0:04:03s\n",
            "epoch 51 | loss: 0.57476 | val_0_accuracy: 0.73575 |  0:04:07s\n",
            "epoch 52 | loss: 0.56927 | val_0_accuracy: 0.72604 |  0:04:12s\n",
            "epoch 53 | loss: 0.56545 | val_0_accuracy: 0.73597 |  0:04:17s\n",
            "epoch 54 | loss: 0.56857 | val_0_accuracy: 0.73381 |  0:04:21s\n",
            "epoch 55 | loss: 0.56259 | val_0_accuracy: 0.73899 |  0:04:26s\n",
            "epoch 56 | loss: 0.5576  | val_0_accuracy: 0.73359 |  0:04:31s\n",
            "epoch 57 | loss: 0.57167 | val_0_accuracy: 0.73122 |  0:04:35s\n",
            "epoch 58 | loss: 0.56107 | val_0_accuracy: 0.73899 |  0:04:40s\n",
            "epoch 59 | loss: 0.5549  | val_0_accuracy: 0.73942 |  0:04:45s\n",
            "epoch 60 | loss: 0.55386 | val_0_accuracy: 0.74503 |  0:04:50s\n",
            "epoch 61 | loss: 0.55616 | val_0_accuracy: 0.7405  |  0:04:55s\n",
            "epoch 62 | loss: 0.54507 | val_0_accuracy: 0.74784 |  0:05:00s\n",
            "epoch 63 | loss: 0.54687 | val_0_accuracy: 0.73381 |  0:05:05s\n",
            "epoch 64 | loss: 0.54596 | val_0_accuracy: 0.75194 |  0:05:09s\n",
            "epoch 65 | loss: 0.54552 | val_0_accuracy: 0.73942 |  0:05:14s\n",
            "epoch 66 | loss: 0.53709 | val_0_accuracy: 0.74482 |  0:05:19s\n",
            "epoch 67 | loss: 0.53692 | val_0_accuracy: 0.74266 |  0:05:24s\n",
            "epoch 68 | loss: 0.53609 | val_0_accuracy: 0.74525 |  0:05:28s\n",
            "epoch 69 | loss: 0.58756 | val_0_accuracy: 0.74417 |  0:05:33s\n",
            "epoch 70 | loss: 0.55213 | val_0_accuracy: 0.7513  |  0:05:38s\n",
            "epoch 71 | loss: 0.53691 | val_0_accuracy: 0.75043 |  0:05:43s\n",
            "epoch 72 | loss: 0.52796 | val_0_accuracy: 0.74763 |  0:05:48s\n",
            "epoch 73 | loss: 0.51576 | val_0_accuracy: 0.76123 |  0:05:52s\n",
            "epoch 74 | loss: 0.52602 | val_0_accuracy: 0.75453 |  0:05:57s\n",
            "epoch 75 | loss: 0.51725 | val_0_accuracy: 0.75691 |  0:06:02s\n",
            "epoch 76 | loss: 0.5153  | val_0_accuracy: 0.75907 |  0:06:07s\n",
            "epoch 77 | loss: 0.51087 | val_0_accuracy: 0.76058 |  0:06:12s\n",
            "epoch 78 | loss: 0.5065  | val_0_accuracy: 0.7595  |  0:06:17s\n",
            "epoch 79 | loss: 0.50197 | val_0_accuracy: 0.76317 |  0:06:21s\n",
            "epoch 80 | loss: 0.50242 | val_0_accuracy: 0.76554 |  0:06:26s\n",
            "epoch 81 | loss: 0.50012 | val_0_accuracy: 0.76878 |  0:06:31s\n",
            "epoch 82 | loss: 0.50306 | val_0_accuracy: 0.77116 |  0:06:35s\n",
            "epoch 83 | loss: 0.49822 | val_0_accuracy: 0.76662 |  0:06:40s\n",
            "epoch 84 | loss: 0.51188 | val_0_accuracy: 0.74028 |  0:06:44s\n",
            "epoch 85 | loss: 0.52397 | val_0_accuracy: 0.76015 |  0:06:49s\n",
            "epoch 86 | loss: 0.50124 | val_0_accuracy: 0.76554 |  0:06:54s\n",
            "epoch 87 | loss: 0.4914  | val_0_accuracy: 0.76835 |  0:06:58s\n",
            "epoch 88 | loss: 0.50005 | val_0_accuracy: 0.769   |  0:07:03s\n",
            "epoch 89 | loss: 0.49221 | val_0_accuracy: 0.76317 |  0:07:08s\n",
            "epoch 90 | loss: 0.48929 | val_0_accuracy: 0.76792 |  0:07:12s\n",
            "epoch 91 | loss: 0.4874  | val_0_accuracy: 0.76511 |  0:07:17s\n",
            "epoch 92 | loss: 0.48595 | val_0_accuracy: 0.77073 |  0:07:21s\n",
            "\n",
            "Early stopping occurred at epoch 92 with best_epoch = 82 and best_val_0_accuracy = 0.77116\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-02 09:08:33,890]\u001b[0m Trial 12 finished with value: 0.7711571675302246 and parameters: {'n_d': 49, 'n_a': 42, 'n_steps': 5, 'gamma': 1.9795783775481637, 'n_independent': 4, 'n_shared': 5, 'momentum': 0.219172559178882}. Best is trial 1 with value: 0.8000863557858376.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.59      0.55      0.57       825\n",
            "           2       0.81      0.90      0.85       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.49      0.60      0.54       761\n",
            "           5       0.75      0.52      0.61       619\n",
            "\n",
            "    accuracy                           0.77      4632\n",
            "   macro avg       0.77      0.76      0.76      4632\n",
            "weighted avg       0.78      0.77      0.77      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.34099 | val_0_accuracy: 0.54879 |  0:00:03s\n",
            "epoch 1  | loss: 0.94335 | val_0_accuracy: 0.5652  |  0:00:06s\n",
            "epoch 2  | loss: 0.89654 | val_0_accuracy: 0.61507 |  0:00:09s\n",
            "epoch 3  | loss: 0.83246 | val_0_accuracy: 0.63342 |  0:00:12s\n",
            "epoch 4  | loss: 0.82799 | val_0_accuracy: 0.62889 |  0:00:15s\n",
            "epoch 5  | loss: 0.79278 | val_0_accuracy: 0.64162 |  0:00:19s\n",
            "epoch 6  | loss: 0.76946 | val_0_accuracy: 0.6468  |  0:00:22s\n",
            "epoch 7  | loss: 0.75779 | val_0_accuracy: 0.6522  |  0:00:25s\n",
            "epoch 8  | loss: 0.7835  | val_0_accuracy: 0.6291  |  0:00:28s\n",
            "epoch 9  | loss: 0.77247 | val_0_accuracy: 0.65803 |  0:00:31s\n",
            "epoch 10 | loss: 0.73676 | val_0_accuracy: 0.66753 |  0:00:34s\n",
            "epoch 11 | loss: 0.71931 | val_0_accuracy: 0.67206 |  0:00:38s\n",
            "epoch 12 | loss: 0.70635 | val_0_accuracy: 0.67465 |  0:00:41s\n",
            "epoch 13 | loss: 0.69517 | val_0_accuracy: 0.67444 |  0:00:44s\n",
            "epoch 14 | loss: 0.68712 | val_0_accuracy: 0.67725 |  0:00:47s\n",
            "epoch 15 | loss: 0.67841 | val_0_accuracy: 0.68653 |  0:00:50s\n",
            "epoch 16 | loss: 0.67664 | val_0_accuracy: 0.67962 |  0:00:54s\n",
            "epoch 17 | loss: 0.69999 | val_0_accuracy: 0.68178 |  0:00:57s\n",
            "epoch 18 | loss: 0.69628 | val_0_accuracy: 0.67379 |  0:01:00s\n",
            "epoch 19 | loss: 0.69284 | val_0_accuracy: 0.68545 |  0:01:03s\n",
            "epoch 20 | loss: 0.69088 | val_0_accuracy: 0.67789 |  0:01:06s\n",
            "epoch 21 | loss: 0.68516 | val_0_accuracy: 0.66256 |  0:01:09s\n",
            "epoch 22 | loss: 0.67456 | val_0_accuracy: 0.69279 |  0:01:13s\n",
            "epoch 23 | loss: 0.66626 | val_0_accuracy: 0.68955 |  0:01:16s\n",
            "epoch 24 | loss: 0.65677 | val_0_accuracy: 0.69927 |  0:01:19s\n",
            "epoch 25 | loss: 0.65008 | val_0_accuracy: 0.69754 |  0:01:22s\n",
            "epoch 26 | loss: 0.64556 | val_0_accuracy: 0.69646 |  0:01:25s\n",
            "epoch 27 | loss: 0.65305 | val_0_accuracy: 0.6984  |  0:01:28s\n",
            "epoch 28 | loss: 0.63927 | val_0_accuracy: 0.71114 |  0:01:32s\n",
            "epoch 29 | loss: 0.63023 | val_0_accuracy: 0.71006 |  0:01:35s\n",
            "epoch 30 | loss: 0.62774 | val_0_accuracy: 0.70877 |  0:01:38s\n",
            "epoch 31 | loss: 0.63323 | val_0_accuracy: 0.70812 |  0:01:41s\n",
            "epoch 32 | loss: 0.63953 | val_0_accuracy: 0.71222 |  0:01:44s\n",
            "epoch 33 | loss: 0.63205 | val_0_accuracy: 0.70337 |  0:01:47s\n",
            "epoch 34 | loss: 0.65772 | val_0_accuracy: 0.6889  |  0:01:51s\n",
            "epoch 35 | loss: 0.64531 | val_0_accuracy: 0.7025  |  0:01:54s\n",
            "epoch 36 | loss: 0.64376 | val_0_accuracy: 0.69991 |  0:01:57s\n",
            "epoch 37 | loss: 0.64123 | val_0_accuracy: 0.70769 |  0:02:00s\n",
            "epoch 38 | loss: 0.63414 | val_0_accuracy: 0.6997  |  0:02:03s\n",
            "epoch 39 | loss: 0.62683 | val_0_accuracy: 0.71632 |  0:02:06s\n",
            "epoch 40 | loss: 0.61201 | val_0_accuracy: 0.71848 |  0:02:09s\n",
            "epoch 41 | loss: 0.6087  | val_0_accuracy: 0.71913 |  0:02:12s\n",
            "epoch 42 | loss: 0.61997 | val_0_accuracy: 0.71848 |  0:02:16s\n",
            "epoch 43 | loss: 0.60543 | val_0_accuracy: 0.72237 |  0:02:19s\n",
            "epoch 44 | loss: 0.60328 | val_0_accuracy: 0.72496 |  0:02:22s\n",
            "epoch 45 | loss: 0.60588 | val_0_accuracy: 0.72129 |  0:02:25s\n",
            "epoch 46 | loss: 0.59349 | val_0_accuracy: 0.73316 |  0:02:28s\n",
            "epoch 47 | loss: 0.59538 | val_0_accuracy: 0.7323  |  0:02:31s\n",
            "epoch 48 | loss: 0.58812 | val_0_accuracy: 0.71826 |  0:02:34s\n",
            "epoch 49 | loss: 0.64455 | val_0_accuracy: 0.71308 |  0:02:38s\n",
            "epoch 50 | loss: 0.62078 | val_0_accuracy: 0.7256  |  0:02:41s\n",
            "epoch 51 | loss: 0.63023 | val_0_accuracy: 0.72258 |  0:02:44s\n",
            "epoch 52 | loss: 0.61545 | val_0_accuracy: 0.72237 |  0:02:47s\n",
            "epoch 53 | loss: 0.60807 | val_0_accuracy: 0.72237 |  0:02:50s\n",
            "epoch 54 | loss: 0.59839 | val_0_accuracy: 0.72949 |  0:02:54s\n",
            "epoch 55 | loss: 0.59263 | val_0_accuracy: 0.72539 |  0:02:57s\n",
            "epoch 56 | loss: 0.60481 | val_0_accuracy: 0.72712 |  0:03:00s\n",
            "\n",
            "Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_accuracy = 0.73316\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-02 09:11:35,709]\u001b[0m Trial 13 finished with value: 0.7331606217616581 and parameters: {'n_d': 32, 'n_a': 28, 'n_steps': 4, 'gamma': 1.5040840300774818, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.12852369033736816}. Best is trial 1 with value: 0.8000863557858376.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       825\n",
            "           1       0.50      0.56      0.53       825\n",
            "           2       0.78      0.84      0.81       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.48      0.37      0.42       761\n",
            "           5       0.56      0.58      0.57       619\n",
            "\n",
            "    accuracy                           0.73      4632\n",
            "   macro avg       0.72      0.72      0.72      4632\n",
            "weighted avg       0.73      0.73      0.73      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.38891 | val_0_accuracy: 0.55009 |  0:00:03s\n",
            "epoch 1  | loss: 0.91682 | val_0_accuracy: 0.61226 |  0:00:06s\n",
            "epoch 2  | loss: 0.84495 | val_0_accuracy: 0.64292 |  0:00:09s\n",
            "epoch 3  | loss: 0.78569 | val_0_accuracy: 0.65112 |  0:00:12s\n",
            "epoch 4  | loss: 0.74737 | val_0_accuracy: 0.66278 |  0:00:15s\n",
            "epoch 5  | loss: 0.72677 | val_0_accuracy: 0.67703 |  0:00:18s\n",
            "epoch 6  | loss: 0.70847 | val_0_accuracy: 0.6725  |  0:00:21s\n",
            "epoch 7  | loss: 0.70214 | val_0_accuracy: 0.68005 |  0:00:25s\n",
            "epoch 8  | loss: 0.69005 | val_0_accuracy: 0.6807  |  0:00:28s\n",
            "epoch 9  | loss: 0.67608 | val_0_accuracy: 0.68718 |  0:00:31s\n",
            "epoch 10 | loss: 0.67772 | val_0_accuracy: 0.69775 |  0:00:34s\n",
            "epoch 11 | loss: 0.66898 | val_0_accuracy: 0.69819 |  0:00:37s\n",
            "epoch 12 | loss: 0.66411 | val_0_accuracy: 0.69473 |  0:00:41s\n",
            "epoch 13 | loss: 0.65403 | val_0_accuracy: 0.68912 |  0:00:44s\n",
            "epoch 14 | loss: 0.65071 | val_0_accuracy: 0.71114 |  0:00:48s\n",
            "epoch 15 | loss: 0.64146 | val_0_accuracy: 0.71157 |  0:00:51s\n",
            "epoch 16 | loss: 0.63836 | val_0_accuracy: 0.71136 |  0:00:54s\n",
            "epoch 17 | loss: 0.6344  | val_0_accuracy: 0.71395 |  0:00:57s\n",
            "epoch 18 | loss: 0.6274  | val_0_accuracy: 0.70855 |  0:01:00s\n",
            "epoch 19 | loss: 0.62434 | val_0_accuracy: 0.7133  |  0:01:03s\n",
            "epoch 20 | loss: 0.62112 | val_0_accuracy: 0.72107 |  0:01:06s\n",
            "epoch 21 | loss: 0.61598 | val_0_accuracy: 0.71006 |  0:01:10s\n",
            "epoch 22 | loss: 0.61352 | val_0_accuracy: 0.71611 |  0:01:13s\n",
            "epoch 23 | loss: 0.60763 | val_0_accuracy: 0.71632 |  0:01:16s\n",
            "epoch 24 | loss: 0.60112 | val_0_accuracy: 0.7256  |  0:01:19s\n",
            "epoch 25 | loss: 0.60303 | val_0_accuracy: 0.71157 |  0:01:22s\n",
            "epoch 26 | loss: 0.60455 | val_0_accuracy: 0.72107 |  0:01:26s\n",
            "epoch 27 | loss: 0.59776 | val_0_accuracy: 0.72409 |  0:01:29s\n",
            "epoch 28 | loss: 0.60252 | val_0_accuracy: 0.72755 |  0:01:32s\n",
            "epoch 29 | loss: 0.59215 | val_0_accuracy: 0.72971 |  0:01:35s\n",
            "epoch 30 | loss: 0.59403 | val_0_accuracy: 0.72042 |  0:01:38s\n",
            "epoch 31 | loss: 0.61399 | val_0_accuracy: 0.72776 |  0:01:41s\n",
            "epoch 32 | loss: 0.59068 | val_0_accuracy: 0.73079 |  0:01:45s\n",
            "epoch 33 | loss: 0.58332 | val_0_accuracy: 0.7228  |  0:01:48s\n",
            "epoch 34 | loss: 0.57789 | val_0_accuracy: 0.72906 |  0:01:51s\n",
            "epoch 35 | loss: 0.57269 | val_0_accuracy: 0.74244 |  0:01:54s\n",
            "epoch 36 | loss: 0.56657 | val_0_accuracy: 0.74223 |  0:01:57s\n",
            "epoch 37 | loss: 0.56278 | val_0_accuracy: 0.72474 |  0:02:00s\n",
            "epoch 38 | loss: 0.55934 | val_0_accuracy: 0.74482 |  0:02:03s\n",
            "epoch 39 | loss: 0.55647 | val_0_accuracy: 0.74417 |  0:02:06s\n",
            "epoch 40 | loss: 0.55332 | val_0_accuracy: 0.74806 |  0:02:10s\n",
            "epoch 41 | loss: 0.54867 | val_0_accuracy: 0.75626 |  0:02:13s\n",
            "epoch 42 | loss: 0.54615 | val_0_accuracy: 0.74223 |  0:02:16s\n",
            "epoch 43 | loss: 0.5385  | val_0_accuracy: 0.75108 |  0:02:19s\n",
            "epoch 44 | loss: 0.53379 | val_0_accuracy: 0.75237 |  0:02:23s\n",
            "epoch 45 | loss: 0.52951 | val_0_accuracy: 0.75993 |  0:02:26s\n",
            "epoch 46 | loss: 0.52602 | val_0_accuracy: 0.75281 |  0:02:29s\n",
            "epoch 47 | loss: 0.52736 | val_0_accuracy: 0.7677  |  0:02:32s\n",
            "epoch 48 | loss: 0.52195 | val_0_accuracy: 0.7554  |  0:02:36s\n",
            "epoch 49 | loss: 0.5204  | val_0_accuracy: 0.76576 |  0:02:39s\n",
            "epoch 50 | loss: 0.51471 | val_0_accuracy: 0.75626 |  0:02:42s\n",
            "epoch 51 | loss: 0.51943 | val_0_accuracy: 0.76144 |  0:02:45s\n",
            "epoch 52 | loss: 0.52512 | val_0_accuracy: 0.77051 |  0:02:49s\n",
            "epoch 53 | loss: 0.50751 | val_0_accuracy: 0.77029 |  0:02:52s\n",
            "epoch 54 | loss: 0.50045 | val_0_accuracy: 0.77807 |  0:02:55s\n",
            "epoch 55 | loss: 0.50024 | val_0_accuracy: 0.77159 |  0:02:58s\n",
            "epoch 56 | loss: 0.49364 | val_0_accuracy: 0.76641 |  0:03:02s\n",
            "epoch 57 | loss: 0.49429 | val_0_accuracy: 0.7718  |  0:03:05s\n",
            "epoch 58 | loss: 0.49548 | val_0_accuracy: 0.77159 |  0:03:08s\n",
            "epoch 59 | loss: 0.48719 | val_0_accuracy: 0.77267 |  0:03:11s\n",
            "epoch 60 | loss: 0.48776 | val_0_accuracy: 0.77353 |  0:03:14s\n",
            "epoch 61 | loss: 0.48233 | val_0_accuracy: 0.76986 |  0:03:17s\n",
            "epoch 62 | loss: 0.49112 | val_0_accuracy: 0.7731  |  0:03:20s\n",
            "epoch 63 | loss: 0.48219 | val_0_accuracy: 0.77288 |  0:03:24s\n",
            "epoch 64 | loss: 0.48306 | val_0_accuracy: 0.77267 |  0:03:27s\n",
            "\n",
            "Early stopping occurred at epoch 64 with best_epoch = 54 and best_val_0_accuracy = 0.77807\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-02 09:15:04,320]\u001b[0m Trial 14 finished with value: 0.7780656303972366 and parameters: {'n_d': 20, 'n_a': 51, 'n_steps': 3, 'gamma': 1.6242948207253791, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.2702754488171034}. Best is trial 1 with value: 0.8000863557858376.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.59      0.60      0.59       825\n",
            "           2       0.83      0.89      0.86       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.53      0.51      0.52       761\n",
            "           5       0.67      0.62      0.64       619\n",
            "\n",
            "    accuracy                           0.78      4632\n",
            "   macro avg       0.77      0.77      0.77      4632\n",
            "weighted avg       0.78      0.78      0.78      4632\n",
            "\n",
            " Best params for fold : [3/10]\n",
            "{'n_d': 43, 'n_a': 53, 'n_steps': 3, 'gamma': 1.473431800730167, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.19414592575862027}\n",
            "Saved best_params at : outputs/pytorch_tabnet/best_params/fold_3_best_params.txt\n",
            "Device used : cuda\n",
            "No early stopping will be performed, last training weights will be used.\n",
            "epoch 0  | loss: 1.16468 |  0:00:01s\n",
            "epoch 1  | loss: 0.79328 |  0:00:02s\n",
            "epoch 2  | loss: 0.75559 |  0:00:04s\n",
            "epoch 3  | loss: 0.71965 |  0:00:05s\n",
            "epoch 4  | loss: 0.69697 |  0:00:07s\n",
            "epoch 5  | loss: 0.68107 |  0:00:08s\n",
            "epoch 6  | loss: 0.67339 |  0:00:09s\n",
            "epoch 7  | loss: 0.65818 |  0:00:11s\n",
            "epoch 8  | loss: 0.64758 |  0:00:12s\n",
            "epoch 9  | loss: 0.64183 |  0:00:13s\n",
            "epoch 10 | loss: 0.63774 |  0:00:15s\n",
            "epoch 11 | loss: 0.62501 |  0:00:16s\n",
            "epoch 12 | loss: 0.61116 |  0:00:18s\n",
            "epoch 13 | loss: 0.60789 |  0:00:19s\n",
            "epoch 14 | loss: 0.60717 |  0:00:20s\n",
            "epoch 15 | loss: 0.60255 |  0:00:22s\n",
            "epoch 16 | loss: 0.60203 |  0:00:23s\n",
            "epoch 17 | loss: 0.58945 |  0:00:25s\n",
            "epoch 18 | loss: 0.58242 |  0:00:26s\n",
            "epoch 19 | loss: 0.58192 |  0:00:27s\n",
            "epoch 20 | loss: 0.57229 |  0:00:29s\n",
            "epoch 21 | loss: 0.57884 |  0:00:30s\n",
            "epoch 22 | loss: 0.57941 |  0:00:31s\n",
            "epoch 23 | loss: 0.56795 |  0:00:33s\n",
            "epoch 24 | loss: 0.5541  |  0:00:34s\n",
            "epoch 25 | loss: 0.54825 |  0:00:36s\n",
            "epoch 26 | loss: 0.54601 |  0:00:37s\n",
            "epoch 27 | loss: 0.53986 |  0:00:38s\n",
            "epoch 28 | loss: 0.53707 |  0:00:40s\n",
            "epoch 29 | loss: 0.53031 |  0:00:41s\n",
            "epoch 30 | loss: 0.5315  |  0:00:43s\n",
            "epoch 31 | loss: 0.53105 |  0:00:44s\n",
            "epoch 32 | loss: 0.52552 |  0:00:45s\n",
            "epoch 33 | loss: 0.52369 |  0:00:47s\n",
            "epoch 34 | loss: 0.52795 |  0:00:48s\n",
            "epoch 35 | loss: 0.51131 |  0:00:49s\n",
            "epoch 36 | loss: 0.50639 |  0:00:51s\n",
            "epoch 37 | loss: 0.50281 |  0:00:52s\n",
            "epoch 38 | loss: 0.50079 |  0:00:54s\n",
            "epoch 39 | loss: 0.49863 |  0:00:55s\n",
            "epoch 40 | loss: 0.49562 |  0:00:56s\n",
            "epoch 41 | loss: 0.48787 |  0:00:58s\n",
            "epoch 42 | loss: 0.48673 |  0:00:59s\n",
            "epoch 43 | loss: 0.4786  |  0:01:01s\n",
            "epoch 44 | loss: 0.4826  |  0:01:02s\n",
            "epoch 45 | loss: 0.48566 |  0:01:03s\n",
            "epoch 46 | loss: 0.48107 |  0:01:05s\n",
            "epoch 47 | loss: 0.47075 |  0:01:06s\n",
            "epoch 48 | loss: 0.46923 |  0:01:07s\n",
            "epoch 49 | loss: 0.46709 |  0:01:09s\n",
            "epoch 50 | loss: 0.46443 |  0:01:10s\n",
            "epoch 51 | loss: 0.47128 |  0:01:12s\n",
            "epoch 52 | loss: 0.49363 |  0:01:13s\n",
            "epoch 53 | loss: 0.47412 |  0:01:14s\n",
            "epoch 54 | loss: 0.46464 |  0:01:16s\n",
            "epoch 55 | loss: 0.46118 |  0:01:17s\n",
            "epoch 56 | loss: 0.45507 |  0:01:18s\n",
            "epoch 57 | loss: 0.45093 |  0:01:20s\n",
            "epoch 58 | loss: 0.44627 |  0:01:21s\n",
            "epoch 59 | loss: 0.44499 |  0:01:23s\n",
            "epoch 60 | loss: 0.44341 |  0:01:24s\n",
            "epoch 61 | loss: 0.43917 |  0:01:25s\n",
            "epoch 62 | loss: 0.44145 |  0:01:27s\n",
            "epoch 63 | loss: 0.43573 |  0:01:28s\n",
            "epoch 64 | loss: 0.43333 |  0:01:30s\n",
            "epoch 65 | loss: 0.43138 |  0:01:31s\n",
            "epoch 66 | loss: 0.43459 |  0:01:32s\n",
            "epoch 67 | loss: 0.43491 |  0:01:34s\n",
            "epoch 68 | loss: 0.43454 |  0:01:35s\n",
            "epoch 69 | loss: 0.42784 |  0:01:36s\n",
            "epoch 70 | loss: 0.45122 |  0:01:38s\n",
            "epoch 71 | loss: 0.4499  |  0:01:39s\n",
            "epoch 72 | loss: 0.43713 |  0:01:41s\n",
            "epoch 73 | loss: 0.42708 |  0:01:42s\n",
            "epoch 74 | loss: 0.42215 |  0:01:43s\n",
            "epoch 75 | loss: 0.42221 |  0:01:45s\n",
            "epoch 76 | loss: 0.41053 |  0:01:46s\n",
            "epoch 77 | loss: 0.41737 |  0:01:47s\n",
            "epoch 78 | loss: 0.41665 |  0:01:49s\n",
            "epoch 79 | loss: 0.41174 |  0:01:50s\n",
            "epoch 80 | loss: 0.40892 |  0:01:52s\n",
            "epoch 81 | loss: 0.40718 |  0:01:53s\n",
            "epoch 82 | loss: 0.40781 |  0:01:54s\n",
            "epoch 83 | loss: 0.40291 |  0:01:56s\n",
            "epoch 84 | loss: 0.40505 |  0:01:57s\n",
            "epoch 85 | loss: 0.40112 |  0:01:59s\n",
            "epoch 86 | loss: 0.40367 |  0:02:00s\n",
            "epoch 87 | loss: 0.40636 |  0:02:01s\n",
            "epoch 88 | loss: 0.40359 |  0:02:03s\n",
            "epoch 89 | loss: 0.39933 |  0:02:04s\n",
            "epoch 90 | loss: 0.39809 |  0:02:06s\n",
            "epoch 91 | loss: 0.40233 |  0:02:07s\n",
            "epoch 92 | loss: 0.39326 |  0:02:08s\n",
            "epoch 93 | loss: 0.39031 |  0:02:10s\n",
            "epoch 94 | loss: 0.39029 |  0:02:11s\n",
            "epoch 95 | loss: 0.38497 |  0:02:12s\n",
            "epoch 96 | loss: 0.41401 |  0:02:14s\n",
            "epoch 97 | loss: 0.39912 |  0:02:15s\n",
            "epoch 98 | loss: 0.38779 |  0:02:17s\n",
            "epoch 99 | loss: 0.39315 |  0:02:18s\n",
            "[++] Saving the model and parameters in corresponding directories\n",
            "[++] Ended the training process for fold 3\n"
          ]
        }
      ],
      "source": [
        "train(fold_dict = fold_dict,\n",
        "      fold = fold,\n",
        "      model_name=model_name,\n",
        "      sc_df=use_df,\n",
        "      tar_col=tar_col,\n",
        "      optim=optimizer,\n",
        "      optim_trial = 15)\n",
        "print(f\"[++] Ended the training process for fold {fold}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja5dUXmqsCFF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afu4nJyHu-sp"
      },
      "source": [
        "Fold 0 has started running on 20-05-22 \n",
        "\n",
        "\n",
        "Fold 0 has completed sucessfully on 17:00 20-05-22\n",
        "\n",
        "Fold 1 has started running at 15:15 21-05-22\n",
        "\n",
        "Fold 2 has started running at 09:45 22-05-22\n",
        "\n",
        "Fold 2 has completed sucessfully on 10:58 22-05-22\n",
        "\n",
        "Fold 3 has started running at 18:40 22-05-22\n",
        "\n",
        "Fold 3 has completed sucessfully on 22-05-22\n",
        "\n",
        "Fold 4 completed sucessfully on 21:04 on 22-05-22\n",
        "\n",
        "Fold 5 started at 18:21 on 23-05-22\n",
        "\n",
        "Fold 5 completed sucessfully on 19:44 on 23-05-22\n",
        "\n",
        "Fold 6 started at 12:53 on 24-05-22\n",
        "\n",
        "Fold 6 has completed at 14:14 on 24-05-22\n",
        "\n",
        "Fold 7 started at 14:18 on 24-05-22\n",
        "\n",
        "Fold 7 execution failed due to colab gpu time limit\n",
        "\n",
        "Fold 7 trial 1 started at 11:00 on 25-05-22\n",
        "\n",
        "Fold 7 has completed sucessfully at 12:14 on 25-05-22 \n",
        "\n",
        "Fold 8 has started at 9:38 on 26-05-22\n",
        "\n",
        "Fold 8 filed due to interrupted internet connection\n",
        "\n",
        "Fold 8 trial 1 started at 13:38 on 26-05-22\n",
        "\n",
        "Fold 8 has successfully executed at 15:33 on 26-05-22\n",
        "\n",
        "Fold 9 has started at 13:35 on 27-05-22\n",
        "\n",
        "Fold 9 has completed at 14:55 on 27-05-22"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me85YLlzpUM8"
      },
      "source": [
        "Editing with rectified dataset witout duplicacy because of space values\n",
        "\n",
        "Fold 0 started at 13:21 on 28-05-22\n",
        "\n",
        "Fold 0 completed sucessfully at 14:46 on 28-05-22\n",
        "\n",
        "Fold 1 Failed to run due to some index error\n",
        "\n",
        "_____ Restarting the training process again due to data distribution failure____\n",
        "\n",
        "\n",
        "\n",
        "Fold 0 started at 10:47 on 30-05-22\n",
        "\n",
        "Fold 0 completed successfully at 12:30 on 30-05-22\n",
        "\n",
        "Fold 1 started at 8:27 on 31-05-22\n",
        "\n",
        "Fold 1 execution failed due to runtime disconnection\n",
        "\n",
        "Fold 1 started again at 9:38 on 31-05-22\n",
        "\n",
        "Fold 1 execution failed due to gpu disconnect \n",
        "\n",
        "Fold 1 started again at 8:36 on 1-06-22\n",
        "\n",
        "Fold 1 execution failed due to network disconnection\n",
        "\n",
        "Fold 1 started again at 13:11 on 01-06-22\n",
        "\n",
        "Fold 1 has succesfully executed at 14:25 on 01-06-22\n",
        "\n",
        "Fold 2 started at 14:29 on 01-06-22\n",
        "\n",
        "Fold 2 completed succesfully at 16:00 on 01-06-22\n",
        "\n",
        "Fold 3 started at 09:43 on 02-06-22\n",
        "\n",
        "Fold 3 execution failed due to gpu server disconnection \n",
        "\n",
        "Fold 3 started again at 13:34 on 02-06-22\n",
        "\n",
        "Fold 3 ran successfully at 14:47 on 02-06-22"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zICGdYlFNr13"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "train_tabnet_fold_div.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}