{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5-jiYKypEVY",
        "outputId": "ee0b16a2-5515-4e8b-9072-5b6b82919209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun  3 08:21:11 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0tPZaeupLWn",
        "outputId": "a0c50d71-dea4-4cad-ffe2-b1d9c4e55eaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-3.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.4.1)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.11.0+cu113)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.0.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.21.6)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (4.64.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.8.0-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 67.1 MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 10.4 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.4)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 9.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.9 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 71.1 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 64.5 MB/s \n",
            "\u001b[?25hCollecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=5492a291352efe578a0e28f062a099fe45935e9f5eb6cd155800934258535b86\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, pytorch-tabnet, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.8.0 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.0 pbr-5.9.0 pyperclip-1.8.2 pytorch-tabnet-3.1.1 stevedore-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-tabnet optuna "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vRmDYdsCpMT-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "import optuna as opt\n",
        "import torch\n",
        "import os\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L4HljGyopQs_"
      },
      "outputs": [],
      "source": [
        "def make_save_cv_model(i,model_name,model,best_params,optim,output_path=\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/cross_validated_models\"):\n",
        "\n",
        "    ''' This function saves cross validation model in the corresponding directory ( if the path does not exist it creates the path for it'''\n",
        "\n",
        "\n",
        "    if os.path.exists(os.path.join(output_path,f\"{i}_{model_name}_{optim}\")):\n",
        "        joblib.dump(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n",
        "        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/model_params.txt\"),\"w+\") as file:\n",
        "            file.write(str(best_params))\n",
        "    else:\n",
        "        os.mkdir(os.path.join(output_path,f\"{i}_{model_name}_{optim}\"))\n",
        "        joblib.dump(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n",
        "        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/model_params.txt\"),\"w+\") as file:\n",
        "            file.write(str(best_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z_M5FI9PpVA_"
      },
      "outputs": [],
      "source": [
        "def train(fold_dict,fold,model_name,sc_df,tar_col,optim,optim_trial,k_folds=10,tar_cols=\"\",verbose=1):\n",
        "\n",
        "    ''' this function is used to train the model with parameters optimization using optuna and cross validation using stratified k_folds'''\n",
        "\n",
        "    y = sc_df[tar_col]\n",
        "    x = sc_df.drop([tar_col],axis=1)\n",
        "    model_name = model_name \n",
        "    def objective(trial):\n",
        "      train_index = fold_dict[fold][\"train\"]\n",
        "      test_index = fold_dict[fold][\"test\"]\n",
        "      clf = TabNetClassifier(n_d=trial.suggest_int(\"n_d\", 8, 64),\n",
        "                              n_a =trial.suggest_int(\"n_a\", 8, 64),\n",
        "                              n_steps = trial.suggest_int(\"n_steps\",3,10),\n",
        "                              gamma =trial.suggest_float(\"gamma\", 1.0, 2.0),\n",
        "                              n_independent = trial.suggest_int(\"n_independent\",1,5),\n",
        "                              n_shared = trial.suggest_int(\"n_shared\",1,5),\n",
        "                              momentum = trial.suggest_float(\"momentum\", 0.01, 0.4),\n",
        "                              optimizer_fn = torch.optim.Adam,\n",
        "                              # scheduler_fn = torch.optim.lr_scheduler,\n",
        "                              # scheduler_params = {\"gamma\" :trial.suggest_float(\"sch-gamma\", 0.5, 0.95), \"step_size\": trial.suggest_int(\"sch_step_size\", 10, 20, 2)},\n",
        "                              verbose = verbose,\n",
        "                              device_name = \"auto\"\n",
        "                              )\n",
        "      # print(f\" train_index :: {train_index}\")\n",
        "      # print(f\" test_index :: {test_index}\")\n",
        "      X_train,X_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
        "      # print(X_train.shape, X_test.shape)\n",
        "      X_train, X_test = X_train.to_numpy(dtype=np.float64), X_test.to_numpy(dtype=np.float64)\n",
        "      Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "      Y_train, Y_test = Y_train.to_numpy(dtype=np.float64), Y_test.to_numpy(dtype=np.float64)\n",
        "      print(Y_train.shape, Y_test.shape)\n",
        "      clf.fit(X_train, Y_train,\n",
        "              eval_set=[(X_test, Y_test)],\n",
        "              eval_metric=['accuracy'])\n",
        "      Y_pred = clf.predict(X_test)\n",
        "      print(classification_report(Y_test, Y_pred, labels=[x for x in range(6)]))\n",
        "      acc = accuracy_score(Y_pred, Y_test)\n",
        "      return acc\n",
        "\n",
        "    print(f\"Starting optimization for fold : [{fold}/{k_folds}]\")\n",
        "    study = opt.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=optim_trial)\n",
        "    best_params = study.best_params\n",
        "    print(f\" Best params for fold : [{fold}/{k_folds}]\")\n",
        "    print(best_params)\n",
        "    joblib.dump(best_params,f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/best_params/comp/fold_{fold}_best_params.z\")\n",
        "    with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/best_params/fold_{fold}_best_params.txt\", \"w+\") as file:file.write(str(best_params))\n",
        "    print(f\"Saved best_params at : outputs/{model_name}/best_params/fold_{fold}_best_params.txt\")\n",
        "    train_index = fold_dict[fold][\"train\"]\n",
        "    test_index = fold_dict[fold][\"test\"]\n",
        "    X_train,X_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
        "    # print(X_train.shape, X_test.shape)\n",
        "    X_train, X_test = X_train.to_numpy(dtype=np.float64), X_test.to_numpy(dtype=np.float64)\n",
        "    Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    Y_train, Y_test = Y_train.to_numpy(dtype=np.float64), Y_test.to_numpy(dtype=np.float64)\n",
        "    clf_model = TabNetClassifier(**study.best_params)\n",
        "    clf_model.fit(X_train,Y_train)\n",
        "    Y_pred = clf_model.predict(X_test)\n",
        "    clf_report = classification_report(Y_test, Y_pred, labels=[x for x in range(6)])\n",
        "    with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/classification_report/{model_name}_{fold}_classification_report.txt\",\"w+\") as file:file.write(str(clf_report))\n",
        "    accuracy = accuracy_score(Y_pred, Y_test)\n",
        "    with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/{model_name}_{fold}_accuracy_score.txt\",\"w+\") as file:file.write(f\" accuracy :: {str(accuracy)}\")\n",
        "    try:\n",
        "        print(\"[++] Saving the model and parameters in corresponding directories\")\n",
        "        make_save_cv_model(fold,model_name,clf_model,best_params,optim=optim)\n",
        "    except:\n",
        "        print(\"[-] Failed to save the model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xNlu9Ktsq6VG"
      },
      "outputs": [],
      "source": [
        "use_df = pd.read_csv(\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/data/trainable_scaled_balanced.csv\")\n",
        "tar_col = \"PCE_categorical\"\n",
        "model_name = \"pytorch_tabnet\"\n",
        "optimizer = \"Adam\"\n",
        "fold_dict = joblib.load(\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/inputs/fold_vals/fold_data.z\")\n",
        "fold = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ9h3wayrIp_",
        "outputId": "d53d58ca-2a36-4824-8a18-f9ace1cb1aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 08:21:33,236]\u001b[0m A new study created in memory with name: no-name-6e95cbc4-ebda-48f4-8b63-cf71dfbce2b8\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting optimization for fold : [5/10]\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.1681  | val_0_accuracy: 0.62522 |  0:00:02s\n",
            "epoch 1  | loss: 0.82519 | val_0_accuracy: 0.62457 |  0:00:05s\n",
            "epoch 2  | loss: 0.75707 | val_0_accuracy: 0.66041 |  0:00:07s\n",
            "epoch 3  | loss: 0.72432 | val_0_accuracy: 0.65868 |  0:00:09s\n",
            "epoch 4  | loss: 0.70752 | val_0_accuracy: 0.67552 |  0:00:12s\n",
            "epoch 5  | loss: 0.68283 | val_0_accuracy: 0.6848  |  0:00:15s\n",
            "epoch 6  | loss: 0.66955 | val_0_accuracy: 0.6943  |  0:00:17s\n",
            "epoch 7  | loss: 0.66118 | val_0_accuracy: 0.68696 |  0:00:19s\n",
            "epoch 8  | loss: 0.6519  | val_0_accuracy: 0.6997  |  0:00:22s\n",
            "epoch 9  | loss: 0.65193 | val_0_accuracy: 0.70099 |  0:00:24s\n",
            "epoch 10 | loss: 0.64958 | val_0_accuracy: 0.70877 |  0:00:26s\n",
            "epoch 11 | loss: 0.64269 | val_0_accuracy: 0.70898 |  0:00:29s\n",
            "epoch 12 | loss: 0.63373 | val_0_accuracy: 0.70531 |  0:00:31s\n",
            "epoch 13 | loss: 0.64128 | val_0_accuracy: 0.70984 |  0:00:33s\n",
            "epoch 14 | loss: 0.61919 | val_0_accuracy: 0.71611 |  0:00:36s\n",
            "epoch 15 | loss: 0.62414 | val_0_accuracy: 0.71503 |  0:00:38s\n",
            "epoch 16 | loss: 0.61444 | val_0_accuracy: 0.71654 |  0:00:40s\n",
            "epoch 17 | loss: 0.61106 | val_0_accuracy: 0.71222 |  0:00:43s\n",
            "epoch 18 | loss: 0.60388 | val_0_accuracy: 0.72453 |  0:00:45s\n",
            "epoch 19 | loss: 0.60067 | val_0_accuracy: 0.72712 |  0:00:47s\n",
            "epoch 20 | loss: 0.5931  | val_0_accuracy: 0.72971 |  0:00:49s\n",
            "epoch 21 | loss: 0.58788 | val_0_accuracy: 0.72172 |  0:00:51s\n",
            "epoch 22 | loss: 0.581   | val_0_accuracy: 0.72884 |  0:00:54s\n",
            "epoch 23 | loss: 0.57633 | val_0_accuracy: 0.72604 |  0:00:56s\n",
            "epoch 24 | loss: 0.60333 | val_0_accuracy: 0.71567 |  0:00:58s\n",
            "epoch 25 | loss: 0.58499 | val_0_accuracy: 0.72647 |  0:01:00s\n",
            "epoch 26 | loss: 0.58138 | val_0_accuracy: 0.73597 |  0:01:03s\n",
            "epoch 27 | loss: 0.56973 | val_0_accuracy: 0.73813 |  0:01:05s\n",
            "epoch 28 | loss: 0.56541 | val_0_accuracy: 0.74482 |  0:01:07s\n",
            "epoch 29 | loss: 0.55967 | val_0_accuracy: 0.73942 |  0:01:09s\n",
            "epoch 30 | loss: 0.59947 | val_0_accuracy: 0.72172 |  0:01:12s\n",
            "epoch 31 | loss: 0.60072 | val_0_accuracy: 0.71632 |  0:01:14s\n",
            "epoch 32 | loss: 0.58487 | val_0_accuracy: 0.72841 |  0:01:16s\n",
            "epoch 33 | loss: 0.57375 | val_0_accuracy: 0.73813 |  0:01:18s\n",
            "epoch 34 | loss: 0.57227 | val_0_accuracy: 0.73381 |  0:01:21s\n",
            "epoch 35 | loss: 0.56952 | val_0_accuracy: 0.73597 |  0:01:23s\n",
            "epoch 36 | loss: 0.5843  | val_0_accuracy: 0.74331 |  0:01:25s\n",
            "epoch 37 | loss: 0.56005 | val_0_accuracy: 0.73791 |  0:01:27s\n",
            "epoch 38 | loss: 0.55799 | val_0_accuracy: 0.74655 |  0:01:29s\n",
            "epoch 39 | loss: 0.55346 | val_0_accuracy: 0.75194 |  0:01:32s\n",
            "epoch 40 | loss: 0.54316 | val_0_accuracy: 0.73964 |  0:01:34s\n",
            "epoch 41 | loss: 0.53968 | val_0_accuracy: 0.74093 |  0:01:36s\n",
            "epoch 42 | loss: 0.53747 | val_0_accuracy: 0.74957 |  0:01:38s\n",
            "epoch 43 | loss: 0.55258 | val_0_accuracy: 0.74698 |  0:01:40s\n",
            "epoch 44 | loss: 0.53654 | val_0_accuracy: 0.75561 |  0:01:43s\n",
            "epoch 45 | loss: 0.52945 | val_0_accuracy: 0.75777 |  0:01:45s\n",
            "epoch 46 | loss: 0.51838 | val_0_accuracy: 0.75669 |  0:01:47s\n",
            "epoch 47 | loss: 0.517   | val_0_accuracy: 0.76446 |  0:01:50s\n",
            "epoch 48 | loss: 0.52643 | val_0_accuracy: 0.76317 |  0:01:52s\n",
            "epoch 49 | loss: 0.52365 | val_0_accuracy: 0.75345 |  0:01:54s\n",
            "epoch 50 | loss: 0.5202  | val_0_accuracy: 0.7582  |  0:01:56s\n",
            "epoch 51 | loss: 0.50709 | val_0_accuracy: 0.76446 |  0:01:58s\n",
            "epoch 52 | loss: 0.50149 | val_0_accuracy: 0.76079 |  0:02:01s\n",
            "epoch 53 | loss: 0.51569 | val_0_accuracy: 0.76835 |  0:02:03s\n",
            "epoch 54 | loss: 0.50717 | val_0_accuracy: 0.76317 |  0:02:05s\n",
            "epoch 55 | loss: 0.49226 | val_0_accuracy: 0.76662 |  0:02:07s\n",
            "epoch 56 | loss: 0.49099 | val_0_accuracy: 0.76727 |  0:02:09s\n",
            "epoch 57 | loss: 0.48153 | val_0_accuracy: 0.76554 |  0:02:12s\n",
            "epoch 58 | loss: 0.47762 | val_0_accuracy: 0.77224 |  0:02:15s\n",
            "epoch 59 | loss: 0.48444 | val_0_accuracy: 0.769   |  0:02:17s\n",
            "epoch 60 | loss: 0.48548 | val_0_accuracy: 0.76813 |  0:02:19s\n",
            "epoch 61 | loss: 0.49374 | val_0_accuracy: 0.77332 |  0:02:21s\n",
            "epoch 62 | loss: 0.49819 | val_0_accuracy: 0.7677  |  0:02:23s\n",
            "epoch 63 | loss: 0.4844  | val_0_accuracy: 0.77202 |  0:02:26s\n",
            "epoch 64 | loss: 0.49243 | val_0_accuracy: 0.76511 |  0:02:28s\n",
            "epoch 65 | loss: 0.49114 | val_0_accuracy: 0.76813 |  0:02:30s\n",
            "epoch 66 | loss: 0.46825 | val_0_accuracy: 0.77547 |  0:02:32s\n",
            "epoch 67 | loss: 0.4841  | val_0_accuracy: 0.77073 |  0:02:34s\n",
            "epoch 68 | loss: 0.47266 | val_0_accuracy: 0.77742 |  0:02:37s\n",
            "epoch 69 | loss: 0.49884 | val_0_accuracy: 0.7718  |  0:02:39s\n",
            "epoch 70 | loss: 0.47861 | val_0_accuracy: 0.77612 |  0:02:41s\n",
            "epoch 71 | loss: 0.4708  | val_0_accuracy: 0.77893 |  0:02:43s\n",
            "epoch 72 | loss: 0.45593 | val_0_accuracy: 0.77893 |  0:02:45s\n",
            "epoch 73 | loss: 0.45173 | val_0_accuracy: 0.78217 |  0:02:48s\n",
            "epoch 74 | loss: 0.45157 | val_0_accuracy: 0.78411 |  0:02:50s\n",
            "epoch 75 | loss: 0.45409 | val_0_accuracy: 0.77483 |  0:02:52s\n",
            "epoch 76 | loss: 0.46063 | val_0_accuracy: 0.77353 |  0:02:54s\n",
            "epoch 77 | loss: 0.46257 | val_0_accuracy: 0.77051 |  0:02:56s\n",
            "epoch 78 | loss: 0.44534 | val_0_accuracy: 0.78238 |  0:02:59s\n",
            "epoch 79 | loss: 0.43796 | val_0_accuracy: 0.77936 |  0:03:01s\n",
            "epoch 80 | loss: 0.4345  | val_0_accuracy: 0.77893 |  0:03:03s\n",
            "epoch 81 | loss: 0.45732 | val_0_accuracy: 0.76339 |  0:03:05s\n",
            "epoch 82 | loss: 0.50016 | val_0_accuracy: 0.75885 |  0:03:07s\n",
            "epoch 83 | loss: 0.47407 | val_0_accuracy: 0.77742 |  0:03:10s\n",
            "epoch 84 | loss: 0.45469 | val_0_accuracy: 0.77332 |  0:03:12s\n",
            "\n",
            "Early stopping occurred at epoch 84 with best_epoch = 74 and best_val_0_accuracy = 0.78411\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 08:25:03,507]\u001b[0m Trial 0 finished with value: 0.7841105354058722 and parameters: {'n_d': 55, 'n_a': 54, 'n_steps': 4, 'gamma': 1.18524595355649, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.20621816805984905}. Best is trial 0 with value: 0.7841105354058722.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       826\n",
            "           1       0.62      0.61      0.61       825\n",
            "           2       0.80      0.91      0.85       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.57      0.54      0.55       761\n",
            "           5       0.68      0.59      0.63       619\n",
            "\n",
            "    accuracy                           0.78      4632\n",
            "   macro avg       0.77      0.77      0.77      4632\n",
            "weighted avg       0.78      0.78      0.78      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.95834 | val_0_accuracy: 0.55721 |  0:00:03s\n",
            "epoch 1  | loss: 1.08431 | val_0_accuracy: 0.56779 |  0:00:07s\n",
            "epoch 2  | loss: 0.99385 | val_0_accuracy: 0.58679 |  0:00:10s\n",
            "epoch 3  | loss: 1.01784 | val_0_accuracy: 0.61248 |  0:00:14s\n",
            "epoch 4  | loss: 0.87192 | val_0_accuracy: 0.60643 |  0:00:17s\n",
            "epoch 5  | loss: 0.83007 | val_0_accuracy: 0.63752 |  0:00:21s\n",
            "epoch 6  | loss: 0.79552 | val_0_accuracy: 0.64443 |  0:00:24s\n",
            "epoch 7  | loss: 0.77536 | val_0_accuracy: 0.65069 |  0:00:28s\n",
            "epoch 8  | loss: 0.75949 | val_0_accuracy: 0.65587 |  0:00:32s\n",
            "epoch 9  | loss: 0.74749 | val_0_accuracy: 0.65155 |  0:00:35s\n",
            "epoch 10 | loss: 0.74301 | val_0_accuracy: 0.65458 |  0:00:39s\n",
            "epoch 11 | loss: 0.72453 | val_0_accuracy: 0.66494 |  0:00:42s\n",
            "epoch 12 | loss: 0.7056  | val_0_accuracy: 0.67465 |  0:00:46s\n",
            "epoch 13 | loss: 0.69742 | val_0_accuracy: 0.67703 |  0:00:50s\n",
            "epoch 14 | loss: 0.68494 | val_0_accuracy: 0.68394 |  0:00:53s\n",
            "epoch 15 | loss: 0.68145 | val_0_accuracy: 0.66105 |  0:00:57s\n",
            "epoch 16 | loss: 0.6856  | val_0_accuracy: 0.68696 |  0:01:00s\n",
            "epoch 17 | loss: 0.67995 | val_0_accuracy: 0.6902  |  0:01:04s\n",
            "epoch 18 | loss: 0.67305 | val_0_accuracy: 0.69085 |  0:01:08s\n",
            "epoch 19 | loss: 0.65549 | val_0_accuracy: 0.69732 |  0:01:11s\n",
            "epoch 20 | loss: 0.65138 | val_0_accuracy: 0.70877 |  0:01:15s\n",
            "epoch 21 | loss: 0.6448  | val_0_accuracy: 0.70358 |  0:01:18s\n",
            "epoch 22 | loss: 0.63772 | val_0_accuracy: 0.71028 |  0:01:22s\n",
            "epoch 23 | loss: 0.63398 | val_0_accuracy: 0.70877 |  0:01:26s\n",
            "epoch 24 | loss: 0.63361 | val_0_accuracy: 0.70229 |  0:01:29s\n",
            "epoch 25 | loss: 0.66435 | val_0_accuracy: 0.70337 |  0:01:33s\n",
            "epoch 26 | loss: 0.66248 | val_0_accuracy: 0.67509 |  0:01:36s\n",
            "epoch 27 | loss: 0.68739 | val_0_accuracy: 0.70315 |  0:01:40s\n",
            "epoch 28 | loss: 0.66479 | val_0_accuracy: 0.70509 |  0:01:44s\n",
            "epoch 29 | loss: 0.63885 | val_0_accuracy: 0.70553 |  0:01:47s\n",
            "epoch 30 | loss: 0.62517 | val_0_accuracy: 0.70617 |  0:01:51s\n",
            "epoch 31 | loss: 0.62222 | val_0_accuracy: 0.71611 |  0:01:54s\n",
            "epoch 32 | loss: 0.61595 | val_0_accuracy: 0.71675 |  0:01:58s\n",
            "epoch 33 | loss: 0.61457 | val_0_accuracy: 0.70898 |  0:02:01s\n",
            "epoch 34 | loss: 0.62181 | val_0_accuracy: 0.71891 |  0:02:05s\n",
            "epoch 35 | loss: 0.62337 | val_0_accuracy: 0.72064 |  0:02:08s\n",
            "epoch 36 | loss: 0.61169 | val_0_accuracy: 0.71611 |  0:02:12s\n",
            "epoch 37 | loss: 0.6071  | val_0_accuracy: 0.71179 |  0:02:15s\n",
            "epoch 38 | loss: 0.6031  | val_0_accuracy: 0.72107 |  0:02:19s\n",
            "epoch 39 | loss: 0.59174 | val_0_accuracy: 0.72301 |  0:02:22s\n",
            "epoch 40 | loss: 0.58966 | val_0_accuracy: 0.72949 |  0:02:26s\n",
            "epoch 41 | loss: 0.59082 | val_0_accuracy: 0.71589 |  0:02:30s\n",
            "epoch 42 | loss: 0.60164 | val_0_accuracy: 0.72453 |  0:02:34s\n",
            "epoch 43 | loss: 0.59551 | val_0_accuracy: 0.72539 |  0:02:37s\n",
            "epoch 44 | loss: 0.58406 | val_0_accuracy: 0.73251 |  0:02:41s\n",
            "epoch 45 | loss: 0.57681 | val_0_accuracy: 0.72776 |  0:02:45s\n",
            "epoch 46 | loss: 0.57577 | val_0_accuracy: 0.72992 |  0:02:48s\n",
            "epoch 47 | loss: 0.58297 | val_0_accuracy: 0.71718 |  0:02:52s\n",
            "epoch 48 | loss: 0.59447 | val_0_accuracy: 0.72345 |  0:02:55s\n",
            "epoch 49 | loss: 0.58723 | val_0_accuracy: 0.73402 |  0:02:59s\n",
            "epoch 50 | loss: 0.57929 | val_0_accuracy: 0.73554 |  0:03:02s\n",
            "epoch 51 | loss: 0.57041 | val_0_accuracy: 0.72733 |  0:03:06s\n",
            "epoch 52 | loss: 0.5669  | val_0_accuracy: 0.73122 |  0:03:10s\n",
            "epoch 53 | loss: 0.56666 | val_0_accuracy: 0.73597 |  0:03:13s\n",
            "epoch 54 | loss: 0.56468 | val_0_accuracy: 0.7323  |  0:03:17s\n",
            "epoch 55 | loss: 0.56221 | val_0_accuracy: 0.7364  |  0:03:20s\n",
            "epoch 56 | loss: 0.56073 | val_0_accuracy: 0.73575 |  0:03:24s\n",
            "epoch 57 | loss: 0.56244 | val_0_accuracy: 0.73575 |  0:03:27s\n",
            "epoch 58 | loss: 0.55657 | val_0_accuracy: 0.7405  |  0:03:31s\n",
            "epoch 59 | loss: 0.54786 | val_0_accuracy: 0.74417 |  0:03:35s\n",
            "epoch 60 | loss: 0.55741 | val_0_accuracy: 0.73877 |  0:03:38s\n",
            "epoch 61 | loss: 0.54782 | val_0_accuracy: 0.73942 |  0:03:42s\n",
            "epoch 62 | loss: 0.54621 | val_0_accuracy: 0.74503 |  0:03:45s\n",
            "epoch 63 | loss: 0.54326 | val_0_accuracy: 0.74115 |  0:03:49s\n",
            "epoch 64 | loss: 0.54498 | val_0_accuracy: 0.74482 |  0:03:53s\n",
            "epoch 65 | loss: 0.54404 | val_0_accuracy: 0.74309 |  0:03:56s\n",
            "epoch 66 | loss: 0.53644 | val_0_accuracy: 0.74525 |  0:04:00s\n",
            "epoch 67 | loss: 0.53531 | val_0_accuracy: 0.74892 |  0:04:03s\n",
            "epoch 68 | loss: 0.54953 | val_0_accuracy: 0.73791 |  0:04:07s\n",
            "epoch 69 | loss: 0.53274 | val_0_accuracy: 0.74633 |  0:04:11s\n",
            "epoch 70 | loss: 0.53233 | val_0_accuracy: 0.74547 |  0:04:14s\n",
            "epoch 71 | loss: 0.53631 | val_0_accuracy: 0.74309 |  0:04:18s\n",
            "epoch 72 | loss: 0.52059 | val_0_accuracy: 0.75518 |  0:04:21s\n",
            "epoch 73 | loss: 0.53928 | val_0_accuracy: 0.75173 |  0:04:25s\n",
            "epoch 74 | loss: 0.53505 | val_0_accuracy: 0.73899 |  0:04:28s\n",
            "epoch 75 | loss: 0.53253 | val_0_accuracy: 0.74503 |  0:04:32s\n",
            "epoch 76 | loss: 0.52852 | val_0_accuracy: 0.75022 |  0:04:35s\n",
            "epoch 77 | loss: 0.52438 | val_0_accuracy: 0.73726 |  0:04:39s\n",
            "epoch 78 | loss: 0.53013 | val_0_accuracy: 0.75453 |  0:04:42s\n",
            "epoch 79 | loss: 0.52006 | val_0_accuracy: 0.76252 |  0:04:46s\n",
            "epoch 80 | loss: 0.5142  | val_0_accuracy: 0.76878 |  0:04:49s\n",
            "epoch 81 | loss: 0.50188 | val_0_accuracy: 0.76317 |  0:04:53s\n",
            "epoch 82 | loss: 0.50492 | val_0_accuracy: 0.76662 |  0:04:56s\n",
            "epoch 83 | loss: 0.49802 | val_0_accuracy: 0.76295 |  0:05:00s\n",
            "epoch 84 | loss: 0.50065 | val_0_accuracy: 0.76857 |  0:05:03s\n",
            "epoch 85 | loss: 0.49265 | val_0_accuracy: 0.75864 |  0:05:07s\n",
            "epoch 86 | loss: 0.48722 | val_0_accuracy: 0.76749 |  0:05:10s\n",
            "epoch 87 | loss: 0.48765 | val_0_accuracy: 0.77634 |  0:05:14s\n",
            "epoch 88 | loss: 0.48865 | val_0_accuracy: 0.76576 |  0:05:17s\n",
            "epoch 89 | loss: 0.49116 | val_0_accuracy: 0.77591 |  0:05:21s\n",
            "epoch 90 | loss: 0.48362 | val_0_accuracy: 0.76533 |  0:05:25s\n",
            "epoch 91 | loss: 0.48162 | val_0_accuracy: 0.77202 |  0:05:28s\n",
            "epoch 92 | loss: 0.48175 | val_0_accuracy: 0.77094 |  0:05:32s\n",
            "epoch 93 | loss: 0.47699 | val_0_accuracy: 0.7772  |  0:05:35s\n",
            "epoch 94 | loss: 0.47511 | val_0_accuracy: 0.78152 |  0:05:39s\n",
            "epoch 95 | loss: 0.46666 | val_0_accuracy: 0.77526 |  0:05:42s\n",
            "epoch 96 | loss: 0.46937 | val_0_accuracy: 0.7744  |  0:05:46s\n",
            "epoch 97 | loss: 0.467   | val_0_accuracy: 0.77871 |  0:05:49s\n",
            "epoch 98 | loss: 0.48051 | val_0_accuracy: 0.78195 |  0:05:53s\n",
            "epoch 99 | loss: 0.47115 | val_0_accuracy: 0.78001 |  0:05:56s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 98 and best_val_0_accuracy = 0.78195\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 08:31:01,967]\u001b[0m Trial 1 finished with value: 0.781951640759931 and parameters: {'n_d': 54, 'n_a': 14, 'n_steps': 9, 'gamma': 1.5510957863801187, 'n_independent': 2, 'n_shared': 1, 'momentum': 0.04310287994244824}. Best is trial 0 with value: 0.7841105354058722.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       826\n",
            "           1       0.63      0.57      0.60       825\n",
            "           2       0.78      0.94      0.85       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.54      0.59      0.56       761\n",
            "           5       0.73      0.52      0.61       619\n",
            "\n",
            "    accuracy                           0.78      4632\n",
            "   macro avg       0.78      0.77      0.77      4632\n",
            "weighted avg       0.78      0.78      0.78      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.58986 | val_0_accuracy: 0.52461 |  0:00:03s\n",
            "epoch 1  | loss: 1.14503 | val_0_accuracy: 0.5788  |  0:00:08s\n",
            "epoch 2  | loss: 0.94452 | val_0_accuracy: 0.61917 |  0:00:12s\n",
            "epoch 3  | loss: 0.83099 | val_0_accuracy: 0.62522 |  0:00:16s\n",
            "epoch 4  | loss: 0.78823 | val_0_accuracy: 0.6386  |  0:00:20s\n",
            "epoch 5  | loss: 0.76294 | val_0_accuracy: 0.65566 |  0:00:24s\n",
            "epoch 6  | loss: 0.73172 | val_0_accuracy: 0.67228 |  0:00:28s\n",
            "epoch 7  | loss: 0.70728 | val_0_accuracy: 0.67444 |  0:00:32s\n",
            "epoch 8  | loss: 0.69347 | val_0_accuracy: 0.68761 |  0:00:36s\n",
            "epoch 9  | loss: 0.68523 | val_0_accuracy: 0.68545 |  0:00:40s\n",
            "epoch 10 | loss: 0.67726 | val_0_accuracy: 0.69495 |  0:00:44s\n",
            "epoch 11 | loss: 0.66499 | val_0_accuracy: 0.70445 |  0:00:48s\n",
            "epoch 12 | loss: 0.65765 | val_0_accuracy: 0.70186 |  0:00:52s\n",
            "epoch 13 | loss: 0.65972 | val_0_accuracy: 0.70661 |  0:00:56s\n",
            "epoch 14 | loss: 0.66267 | val_0_accuracy: 0.70337 |  0:01:00s\n",
            "epoch 15 | loss: 0.64611 | val_0_accuracy: 0.69754 |  0:01:04s\n",
            "epoch 16 | loss: 0.63278 | val_0_accuracy: 0.70769 |  0:01:08s\n",
            "epoch 17 | loss: 0.63555 | val_0_accuracy: 0.70035 |  0:01:13s\n",
            "epoch 18 | loss: 0.62719 | val_0_accuracy: 0.71783 |  0:01:17s\n",
            "epoch 19 | loss: 0.61754 | val_0_accuracy: 0.712   |  0:01:21s\n",
            "epoch 20 | loss: 0.61833 | val_0_accuracy: 0.71373 |  0:01:25s\n",
            "epoch 21 | loss: 0.61207 | val_0_accuracy: 0.7092  |  0:01:29s\n",
            "epoch 22 | loss: 0.6072  | val_0_accuracy: 0.72129 |  0:01:33s\n",
            "epoch 23 | loss: 0.60256 | val_0_accuracy: 0.71848 |  0:01:37s\n",
            "epoch 24 | loss: 0.58932 | val_0_accuracy: 0.72539 |  0:01:41s\n",
            "epoch 25 | loss: 0.58722 | val_0_accuracy: 0.7282  |  0:01:45s\n",
            "epoch 26 | loss: 0.58506 | val_0_accuracy: 0.72107 |  0:01:49s\n",
            "epoch 27 | loss: 0.57345 | val_0_accuracy: 0.73187 |  0:01:53s\n",
            "epoch 28 | loss: 0.57154 | val_0_accuracy: 0.73359 |  0:01:57s\n",
            "epoch 29 | loss: 0.57273 | val_0_accuracy: 0.74417 |  0:02:02s\n",
            "epoch 30 | loss: 0.57152 | val_0_accuracy: 0.73338 |  0:02:06s\n",
            "epoch 31 | loss: 0.56272 | val_0_accuracy: 0.7513  |  0:02:10s\n",
            "epoch 32 | loss: 0.56173 | val_0_accuracy: 0.74331 |  0:02:15s\n",
            "epoch 33 | loss: 0.55329 | val_0_accuracy: 0.75151 |  0:02:19s\n",
            "epoch 34 | loss: 0.5445  | val_0_accuracy: 0.74352 |  0:02:23s\n",
            "epoch 35 | loss: 0.5435  | val_0_accuracy: 0.74892 |  0:02:27s\n",
            "epoch 36 | loss: 0.54228 | val_0_accuracy: 0.75194 |  0:02:31s\n",
            "epoch 37 | loss: 0.53333 | val_0_accuracy: 0.74849 |  0:02:35s\n",
            "epoch 38 | loss: 0.53157 | val_0_accuracy: 0.75151 |  0:02:39s\n",
            "epoch 39 | loss: 0.53009 | val_0_accuracy: 0.75367 |  0:02:43s\n",
            "epoch 40 | loss: 0.52878 | val_0_accuracy: 0.75216 |  0:02:47s\n",
            "epoch 41 | loss: 0.51972 | val_0_accuracy: 0.75712 |  0:02:51s\n",
            "epoch 42 | loss: 0.51927 | val_0_accuracy: 0.75108 |  0:02:55s\n",
            "epoch 43 | loss: 0.51221 | val_0_accuracy: 0.74978 |  0:02:59s\n",
            "epoch 44 | loss: 0.50906 | val_0_accuracy: 0.76274 |  0:03:03s\n",
            "epoch 45 | loss: 0.50424 | val_0_accuracy: 0.75799 |  0:03:07s\n",
            "epoch 46 | loss: 0.4997  | val_0_accuracy: 0.76058 |  0:03:11s\n",
            "epoch 47 | loss: 0.51905 | val_0_accuracy: 0.74978 |  0:03:15s\n",
            "epoch 48 | loss: 0.51879 | val_0_accuracy: 0.76166 |  0:03:19s\n",
            "epoch 49 | loss: 0.49896 | val_0_accuracy: 0.75928 |  0:03:23s\n",
            "epoch 50 | loss: 0.49584 | val_0_accuracy: 0.76123 |  0:03:28s\n",
            "epoch 51 | loss: 0.4936  | val_0_accuracy: 0.76079 |  0:03:32s\n",
            "epoch 52 | loss: 0.49158 | val_0_accuracy: 0.76878 |  0:03:36s\n",
            "epoch 53 | loss: 0.48431 | val_0_accuracy: 0.76446 |  0:03:40s\n",
            "epoch 54 | loss: 0.48691 | val_0_accuracy: 0.76166 |  0:03:44s\n",
            "epoch 55 | loss: 0.4823  | val_0_accuracy: 0.77008 |  0:03:48s\n",
            "epoch 56 | loss: 0.47235 | val_0_accuracy: 0.76598 |  0:03:52s\n",
            "epoch 57 | loss: 0.46427 | val_0_accuracy: 0.76339 |  0:03:56s\n",
            "epoch 58 | loss: 0.46919 | val_0_accuracy: 0.7772  |  0:04:00s\n",
            "epoch 59 | loss: 0.45983 | val_0_accuracy: 0.77504 |  0:04:04s\n",
            "epoch 60 | loss: 0.46497 | val_0_accuracy: 0.77634 |  0:04:08s\n",
            "epoch 61 | loss: 0.46057 | val_0_accuracy: 0.7772  |  0:04:12s\n",
            "epoch 62 | loss: 0.46086 | val_0_accuracy: 0.77893 |  0:04:16s\n",
            "epoch 63 | loss: 0.45948 | val_0_accuracy: 0.77871 |  0:04:20s\n",
            "epoch 64 | loss: 0.4552  | val_0_accuracy: 0.77267 |  0:04:24s\n",
            "epoch 65 | loss: 0.45163 | val_0_accuracy: 0.78044 |  0:04:28s\n",
            "epoch 66 | loss: 0.44398 | val_0_accuracy: 0.7826  |  0:04:33s\n",
            "epoch 67 | loss: 0.4411  | val_0_accuracy: 0.78238 |  0:04:37s\n",
            "epoch 68 | loss: 0.43454 | val_0_accuracy: 0.78562 |  0:04:41s\n",
            "epoch 69 | loss: 0.43292 | val_0_accuracy: 0.77828 |  0:04:45s\n",
            "epoch 70 | loss: 0.43559 | val_0_accuracy: 0.78562 |  0:04:49s\n",
            "epoch 71 | loss: 0.43273 | val_0_accuracy: 0.78692 |  0:04:53s\n",
            "epoch 72 | loss: 0.44547 | val_0_accuracy: 0.7785  |  0:04:57s\n",
            "epoch 73 | loss: 0.45995 | val_0_accuracy: 0.76857 |  0:05:01s\n",
            "epoch 74 | loss: 0.47864 | val_0_accuracy: 0.76166 |  0:05:05s\n",
            "epoch 75 | loss: 0.47998 | val_0_accuracy: 0.77828 |  0:05:09s\n",
            "epoch 76 | loss: 0.44749 | val_0_accuracy: 0.78195 |  0:05:13s\n",
            "epoch 77 | loss: 0.45043 | val_0_accuracy: 0.7867  |  0:05:17s\n",
            "epoch 78 | loss: 0.43726 | val_0_accuracy: 0.78066 |  0:05:21s\n",
            "epoch 79 | loss: 0.42635 | val_0_accuracy: 0.78519 |  0:05:25s\n",
            "epoch 80 | loss: 0.42202 | val_0_accuracy: 0.788   |  0:05:29s\n",
            "epoch 81 | loss: 0.41493 | val_0_accuracy: 0.78584 |  0:05:34s\n",
            "epoch 82 | loss: 0.42172 | val_0_accuracy: 0.78649 |  0:05:38s\n",
            "epoch 83 | loss: 0.42503 | val_0_accuracy: 0.78368 |  0:05:42s\n",
            "epoch 84 | loss: 0.41651 | val_0_accuracy: 0.80095 |  0:05:46s\n",
            "epoch 85 | loss: 0.41095 | val_0_accuracy: 0.79706 |  0:05:50s\n",
            "epoch 86 | loss: 0.41516 | val_0_accuracy: 0.78886 |  0:05:54s\n",
            "epoch 87 | loss: 0.41024 | val_0_accuracy: 0.79447 |  0:05:58s\n",
            "epoch 88 | loss: 0.40294 | val_0_accuracy: 0.80009 |  0:06:02s\n",
            "epoch 89 | loss: 0.39554 | val_0_accuracy: 0.79577 |  0:06:06s\n",
            "epoch 90 | loss: 0.40137 | val_0_accuracy: 0.79663 |  0:06:10s\n",
            "epoch 91 | loss: 0.39821 | val_0_accuracy: 0.78864 |  0:06:14s\n",
            "epoch 92 | loss: 0.40093 | val_0_accuracy: 0.79534 |  0:06:18s\n",
            "epoch 93 | loss: 0.3953  | val_0_accuracy: 0.79253 |  0:06:22s\n",
            "epoch 94 | loss: 0.39794 | val_0_accuracy: 0.79123 |  0:06:26s\n",
            "\n",
            "Early stopping occurred at epoch 94 with best_epoch = 84 and best_val_0_accuracy = 0.80095\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 08:37:30,730]\u001b[0m Trial 2 finished with value: 0.8009499136442142 and parameters: {'n_d': 42, 'n_a': 60, 'n_steps': 6, 'gamma': 1.575059266508576, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.20431519971315895}. Best is trial 2 with value: 0.8009499136442142.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       826\n",
            "           1       0.64      0.69      0.67       825\n",
            "           2       0.84      0.93      0.88       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.58      0.52      0.55       761\n",
            "           5       0.69      0.62      0.65       619\n",
            "\n",
            "    accuracy                           0.80      4632\n",
            "   macro avg       0.79      0.79      0.79      4632\n",
            "weighted avg       0.80      0.80      0.80      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.95191 | val_0_accuracy: 0.46978 |  0:00:04s\n",
            "epoch 1  | loss: 1.40504 | val_0_accuracy: 0.36809 |  0:00:08s\n",
            "epoch 2  | loss: 1.30235 | val_0_accuracy: 0.56714 |  0:00:12s\n",
            "epoch 3  | loss: 0.95797 | val_0_accuracy: 0.6168  |  0:00:17s\n",
            "epoch 4  | loss: 0.85625 | val_0_accuracy: 0.62953 |  0:00:21s\n",
            "epoch 5  | loss: 0.81284 | val_0_accuracy: 0.63687 |  0:00:25s\n",
            "epoch 6  | loss: 0.77487 | val_0_accuracy: 0.63558 |  0:00:30s\n",
            "epoch 7  | loss: 0.76024 | val_0_accuracy: 0.65609 |  0:00:34s\n",
            "epoch 8  | loss: 0.73485 | val_0_accuracy: 0.67077 |  0:00:38s\n",
            "epoch 9  | loss: 0.73367 | val_0_accuracy: 0.66731 |  0:00:43s\n",
            "epoch 10 | loss: 0.72136 | val_0_accuracy: 0.66688 |  0:00:47s\n",
            "epoch 11 | loss: 0.71786 | val_0_accuracy: 0.6658  |  0:00:51s\n",
            "epoch 12 | loss: 0.70783 | val_0_accuracy: 0.66667 |  0:00:56s\n",
            "epoch 13 | loss: 0.71041 | val_0_accuracy: 0.67185 |  0:01:00s\n",
            "epoch 14 | loss: 0.71022 | val_0_accuracy: 0.64421 |  0:01:04s\n",
            "epoch 15 | loss: 0.70773 | val_0_accuracy: 0.6794  |  0:01:10s\n",
            "epoch 16 | loss: 0.69616 | val_0_accuracy: 0.67358 |  0:01:14s\n",
            "epoch 17 | loss: 0.69579 | val_0_accuracy: 0.67573 |  0:01:18s\n",
            "epoch 18 | loss: 0.70165 | val_0_accuracy: 0.67725 |  0:01:22s\n",
            "epoch 19 | loss: 0.6949  | val_0_accuracy: 0.68523 |  0:01:27s\n",
            "epoch 20 | loss: 0.67718 | val_0_accuracy: 0.68437 |  0:01:31s\n",
            "epoch 21 | loss: 0.67483 | val_0_accuracy: 0.69106 |  0:01:35s\n",
            "epoch 22 | loss: 0.67682 | val_0_accuracy: 0.69257 |  0:01:40s\n",
            "epoch 23 | loss: 0.67167 | val_0_accuracy: 0.6807  |  0:01:44s\n",
            "epoch 24 | loss: 0.67907 | val_0_accuracy: 0.66926 |  0:01:48s\n",
            "epoch 25 | loss: 0.67664 | val_0_accuracy: 0.70207 |  0:01:52s\n",
            "epoch 26 | loss: 0.66392 | val_0_accuracy: 0.6943  |  0:01:57s\n",
            "epoch 27 | loss: 0.66388 | val_0_accuracy: 0.69732 |  0:02:01s\n",
            "epoch 28 | loss: 0.6521  | val_0_accuracy: 0.7038  |  0:02:05s\n",
            "epoch 29 | loss: 0.6453  | val_0_accuracy: 0.69452 |  0:02:10s\n",
            "epoch 30 | loss: 0.6453  | val_0_accuracy: 0.70445 |  0:02:14s\n",
            "epoch 31 | loss: 0.65028 | val_0_accuracy: 0.70488 |  0:02:18s\n",
            "epoch 32 | loss: 0.67524 | val_0_accuracy: 0.67379 |  0:02:22s\n",
            "epoch 33 | loss: 0.69738 | val_0_accuracy: 0.67163 |  0:02:27s\n",
            "epoch 34 | loss: 0.67059 | val_0_accuracy: 0.68696 |  0:02:31s\n",
            "epoch 35 | loss: 0.65722 | val_0_accuracy: 0.70488 |  0:02:35s\n",
            "epoch 36 | loss: 0.65579 | val_0_accuracy: 0.68631 |  0:02:40s\n",
            "epoch 37 | loss: 0.66304 | val_0_accuracy: 0.68631 |  0:02:44s\n",
            "epoch 38 | loss: 0.69751 | val_0_accuracy: 0.66364 |  0:02:48s\n",
            "epoch 39 | loss: 0.68243 | val_0_accuracy: 0.67552 |  0:02:52s\n",
            "epoch 40 | loss: 0.68752 | val_0_accuracy: 0.67509 |  0:02:57s\n",
            "epoch 41 | loss: 0.7013  | val_0_accuracy: 0.68156 |  0:03:01s\n",
            "\n",
            "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_accuracy = 0.70488\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 08:40:34,297]\u001b[0m Trial 3 finished with value: 0.7048791018998273 and parameters: {'n_d': 37, 'n_a': 18, 'n_steps': 9, 'gamma': 1.958867275886594, 'n_independent': 3, 'n_shared': 1, 'momentum': 0.19639512040802348}. Best is trial 2 with value: 0.8009499136442142.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       826\n",
            "           1       0.44      0.61      0.51       825\n",
            "           2       0.76      0.74      0.75       822\n",
            "           3       1.00      0.99      1.00       779\n",
            "           4       0.47      0.40      0.43       761\n",
            "           5       0.57      0.40      0.47       619\n",
            "\n",
            "    accuracy                           0.70      4632\n",
            "   macro avg       0.70      0.69      0.69      4632\n",
            "weighted avg       0.71      0.70      0.70      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.48497 | val_0_accuracy: 0.55332 |  0:00:05s\n",
            "epoch 1  | loss: 1.00001 | val_0_accuracy: 0.58463 |  0:00:10s\n",
            "epoch 2  | loss: 0.97361 | val_0_accuracy: 0.57448 |  0:00:15s\n",
            "epoch 3  | loss: 1.05548 | val_0_accuracy: 0.57923 |  0:00:20s\n",
            "epoch 4  | loss: 0.89149 | val_0_accuracy: 0.60579 |  0:00:25s\n",
            "epoch 5  | loss: 0.88595 | val_0_accuracy: 0.60147 |  0:00:31s\n",
            "epoch 6  | loss: 0.85773 | val_0_accuracy: 0.61421 |  0:00:36s\n",
            "epoch 7  | loss: 0.83487 | val_0_accuracy: 0.62025 |  0:00:41s\n",
            "epoch 8  | loss: 0.80997 | val_0_accuracy: 0.63191 |  0:00:46s\n",
            "epoch 9  | loss: 0.78677 | val_0_accuracy: 0.64206 |  0:00:52s\n",
            "epoch 10 | loss: 0.76916 | val_0_accuracy: 0.64335 |  0:00:57s\n",
            "epoch 11 | loss: 0.75771 | val_0_accuracy: 0.64853 |  0:01:02s\n",
            "epoch 12 | loss: 0.74781 | val_0_accuracy: 0.6576  |  0:01:07s\n",
            "epoch 13 | loss: 0.73902 | val_0_accuracy: 0.66149 |  0:01:13s\n",
            "epoch 14 | loss: 0.73247 | val_0_accuracy: 0.66839 |  0:01:18s\n",
            "epoch 15 | loss: 0.74205 | val_0_accuracy: 0.65954 |  0:01:23s\n",
            "epoch 16 | loss: 0.73382 | val_0_accuracy: 0.66926 |  0:01:28s\n",
            "epoch 17 | loss: 0.72435 | val_0_accuracy: 0.67077 |  0:01:33s\n",
            "epoch 18 | loss: 0.75743 | val_0_accuracy: 0.64745 |  0:01:39s\n",
            "epoch 19 | loss: 0.76502 | val_0_accuracy: 0.6576  |  0:01:44s\n",
            "epoch 20 | loss: 0.72855 | val_0_accuracy: 0.66602 |  0:01:49s\n",
            "epoch 21 | loss: 0.7055  | val_0_accuracy: 0.67703 |  0:01:54s\n",
            "epoch 22 | loss: 0.70106 | val_0_accuracy: 0.67422 |  0:01:59s\n",
            "epoch 23 | loss: 0.71271 | val_0_accuracy: 0.67012 |  0:02:05s\n",
            "epoch 24 | loss: 0.70179 | val_0_accuracy: 0.68459 |  0:02:10s\n",
            "epoch 25 | loss: 0.68364 | val_0_accuracy: 0.68221 |  0:02:15s\n",
            "epoch 26 | loss: 0.67181 | val_0_accuracy: 0.69408 |  0:02:20s\n",
            "epoch 27 | loss: 0.66812 | val_0_accuracy: 0.69322 |  0:02:25s\n",
            "epoch 28 | loss: 0.66258 | val_0_accuracy: 0.70056 |  0:02:31s\n",
            "epoch 29 | loss: 0.66002 | val_0_accuracy: 0.69128 |  0:02:36s\n",
            "epoch 30 | loss: 0.6559  | val_0_accuracy: 0.70337 |  0:02:41s\n",
            "epoch 31 | loss: 0.6448  | val_0_accuracy: 0.69991 |  0:02:46s\n",
            "epoch 32 | loss: 0.64668 | val_0_accuracy: 0.70574 |  0:02:51s\n",
            "epoch 33 | loss: 0.64054 | val_0_accuracy: 0.71136 |  0:02:57s\n",
            "epoch 34 | loss: 0.63379 | val_0_accuracy: 0.72129 |  0:03:02s\n",
            "epoch 35 | loss: 0.62788 | val_0_accuracy: 0.72107 |  0:03:07s\n",
            "epoch 36 | loss: 0.62016 | val_0_accuracy: 0.71524 |  0:03:12s\n",
            "epoch 37 | loss: 0.62245 | val_0_accuracy: 0.71028 |  0:03:18s\n",
            "epoch 38 | loss: 0.6139  | val_0_accuracy: 0.7215  |  0:03:23s\n",
            "epoch 39 | loss: 0.60934 | val_0_accuracy: 0.72388 |  0:03:28s\n",
            "epoch 40 | loss: 0.61254 | val_0_accuracy: 0.71805 |  0:03:33s\n",
            "epoch 41 | loss: 0.61076 | val_0_accuracy: 0.72258 |  0:03:39s\n",
            "epoch 42 | loss: 0.60362 | val_0_accuracy: 0.73316 |  0:03:45s\n",
            "epoch 43 | loss: 0.60302 | val_0_accuracy: 0.72388 |  0:03:50s\n",
            "epoch 44 | loss: 0.60376 | val_0_accuracy: 0.72863 |  0:03:55s\n",
            "epoch 45 | loss: 0.60356 | val_0_accuracy: 0.72388 |  0:04:00s\n",
            "epoch 46 | loss: 0.59692 | val_0_accuracy: 0.72927 |  0:04:05s\n",
            "epoch 47 | loss: 0.59095 | val_0_accuracy: 0.7282  |  0:04:11s\n",
            "epoch 48 | loss: 0.5882  | val_0_accuracy: 0.7405  |  0:04:16s\n",
            "epoch 49 | loss: 0.58702 | val_0_accuracy: 0.73618 |  0:04:21s\n",
            "epoch 50 | loss: 0.59044 | val_0_accuracy: 0.7228  |  0:04:26s\n",
            "epoch 51 | loss: 0.58096 | val_0_accuracy: 0.73726 |  0:04:31s\n",
            "epoch 52 | loss: 0.57158 | val_0_accuracy: 0.74244 |  0:04:37s\n",
            "epoch 53 | loss: 0.56947 | val_0_accuracy: 0.74655 |  0:04:42s\n",
            "epoch 54 | loss: 0.58242 | val_0_accuracy: 0.7269  |  0:04:47s\n",
            "epoch 55 | loss: 0.57297 | val_0_accuracy: 0.7364  |  0:04:52s\n",
            "epoch 56 | loss: 0.568   | val_0_accuracy: 0.74482 |  0:04:57s\n",
            "epoch 57 | loss: 0.55851 | val_0_accuracy: 0.74331 |  0:05:02s\n",
            "epoch 58 | loss: 0.55329 | val_0_accuracy: 0.75043 |  0:05:08s\n",
            "epoch 59 | loss: 0.54827 | val_0_accuracy: 0.75259 |  0:05:13s\n",
            "epoch 60 | loss: 0.54823 | val_0_accuracy: 0.75194 |  0:05:18s\n",
            "epoch 61 | loss: 0.53961 | val_0_accuracy: 0.75065 |  0:05:23s\n",
            "epoch 62 | loss: 0.546   | val_0_accuracy: 0.7446  |  0:05:28s\n",
            "epoch 63 | loss: 0.53998 | val_0_accuracy: 0.75389 |  0:05:34s\n",
            "epoch 64 | loss: 0.53196 | val_0_accuracy: 0.75626 |  0:05:39s\n",
            "epoch 65 | loss: 0.53107 | val_0_accuracy: 0.75993 |  0:05:44s\n",
            "epoch 66 | loss: 0.52731 | val_0_accuracy: 0.75389 |  0:05:49s\n",
            "epoch 67 | loss: 0.51937 | val_0_accuracy: 0.76446 |  0:05:55s\n",
            "epoch 68 | loss: 0.51565 | val_0_accuracy: 0.77224 |  0:06:00s\n",
            "epoch 69 | loss: 0.51615 | val_0_accuracy: 0.76339 |  0:06:05s\n",
            "epoch 70 | loss: 0.52717 | val_0_accuracy: 0.76727 |  0:06:10s\n",
            "epoch 71 | loss: 0.51443 | val_0_accuracy: 0.76921 |  0:06:15s\n",
            "epoch 72 | loss: 0.51056 | val_0_accuracy: 0.77807 |  0:06:21s\n",
            "epoch 73 | loss: 0.50351 | val_0_accuracy: 0.7744  |  0:06:26s\n",
            "epoch 74 | loss: 0.4994  | val_0_accuracy: 0.77353 |  0:06:31s\n",
            "epoch 75 | loss: 0.49904 | val_0_accuracy: 0.77202 |  0:06:36s\n",
            "epoch 76 | loss: 0.50112 | val_0_accuracy: 0.77202 |  0:06:41s\n",
            "epoch 77 | loss: 0.49287 | val_0_accuracy: 0.76943 |  0:06:46s\n",
            "epoch 78 | loss: 0.49576 | val_0_accuracy: 0.77591 |  0:06:52s\n",
            "epoch 79 | loss: 0.48738 | val_0_accuracy: 0.77807 |  0:06:57s\n",
            "epoch 80 | loss: 0.48068 | val_0_accuracy: 0.77634 |  0:07:02s\n",
            "epoch 81 | loss: 0.47971 | val_0_accuracy: 0.76706 |  0:07:07s\n",
            "epoch 82 | loss: 0.47639 | val_0_accuracy: 0.77591 |  0:07:12s\n",
            "\n",
            "Early stopping occurred at epoch 82 with best_epoch = 72 and best_val_0_accuracy = 0.77807\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 08:47:49,647]\u001b[0m Trial 4 finished with value: 0.7780656303972366 and parameters: {'n_d': 47, 'n_a': 24, 'n_steps': 7, 'gamma': 1.1557307904883856, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.17943138819895943}. Best is trial 2 with value: 0.8009499136442142.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       826\n",
            "           1       0.60      0.59      0.60       825\n",
            "           2       0.77      0.91      0.84       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.56      0.60      0.58       761\n",
            "           5       0.74      0.49      0.59       619\n",
            "\n",
            "    accuracy                           0.78      4632\n",
            "   macro avg       0.78      0.77      0.77      4632\n",
            "weighted avg       0.78      0.78      0.77      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.31021 | val_0_accuracy: 0.57837 |  0:00:02s\n",
            "epoch 1  | loss: 0.88222 | val_0_accuracy: 0.61399 |  0:00:04s\n",
            "epoch 2  | loss: 0.80888 | val_0_accuracy: 0.62845 |  0:00:07s\n",
            "epoch 3  | loss: 0.77296 | val_0_accuracy: 0.64551 |  0:00:09s\n",
            "epoch 4  | loss: 0.73344 | val_0_accuracy: 0.66408 |  0:00:12s\n",
            "epoch 5  | loss: 0.70757 | val_0_accuracy: 0.66688 |  0:00:14s\n",
            "epoch 6  | loss: 0.70131 | val_0_accuracy: 0.67962 |  0:00:16s\n",
            "epoch 7  | loss: 0.69671 | val_0_accuracy: 0.6861  |  0:00:19s\n",
            "epoch 8  | loss: 0.67864 | val_0_accuracy: 0.69365 |  0:00:21s\n",
            "epoch 9  | loss: 0.66867 | val_0_accuracy: 0.69041 |  0:00:23s\n",
            "epoch 10 | loss: 0.65904 | val_0_accuracy: 0.70142 |  0:00:26s\n",
            "epoch 11 | loss: 0.65486 | val_0_accuracy: 0.69538 |  0:00:28s\n",
            "epoch 12 | loss: 0.64715 | val_0_accuracy: 0.70099 |  0:00:31s\n",
            "epoch 13 | loss: 0.63769 | val_0_accuracy: 0.70941 |  0:00:33s\n",
            "epoch 14 | loss: 0.63036 | val_0_accuracy: 0.71179 |  0:00:35s\n",
            "epoch 15 | loss: 0.62299 | val_0_accuracy: 0.71956 |  0:00:38s\n",
            "epoch 16 | loss: 0.62374 | val_0_accuracy: 0.70596 |  0:00:40s\n",
            "epoch 17 | loss: 0.61726 | val_0_accuracy: 0.7174  |  0:00:43s\n",
            "epoch 18 | loss: 0.61177 | val_0_accuracy: 0.72021 |  0:00:45s\n",
            "epoch 19 | loss: 0.60778 | val_0_accuracy: 0.7282  |  0:00:47s\n",
            "epoch 20 | loss: 0.60352 | val_0_accuracy: 0.72366 |  0:00:50s\n",
            "epoch 21 | loss: 0.60705 | val_0_accuracy: 0.73381 |  0:00:52s\n",
            "epoch 22 | loss: 0.60472 | val_0_accuracy: 0.70984 |  0:00:55s\n",
            "epoch 23 | loss: 0.60886 | val_0_accuracy: 0.71611 |  0:00:57s\n",
            "epoch 24 | loss: 0.60051 | val_0_accuracy: 0.73143 |  0:00:59s\n",
            "epoch 25 | loss: 0.59152 | val_0_accuracy: 0.73316 |  0:01:02s\n",
            "epoch 26 | loss: 0.57998 | val_0_accuracy: 0.74028 |  0:01:04s\n",
            "epoch 27 | loss: 0.58047 | val_0_accuracy: 0.73489 |  0:01:07s\n",
            "epoch 28 | loss: 0.57592 | val_0_accuracy: 0.74352 |  0:01:09s\n",
            "epoch 29 | loss: 0.57335 | val_0_accuracy: 0.73381 |  0:01:11s\n",
            "epoch 30 | loss: 0.5701  | val_0_accuracy: 0.74093 |  0:01:14s\n",
            "epoch 31 | loss: 0.56367 | val_0_accuracy: 0.73877 |  0:01:16s\n",
            "epoch 32 | loss: 0.57029 | val_0_accuracy: 0.73273 |  0:01:18s\n",
            "epoch 33 | loss: 0.57216 | val_0_accuracy: 0.74525 |  0:01:21s\n",
            "epoch 34 | loss: 0.56024 | val_0_accuracy: 0.72517 |  0:01:23s\n",
            "epoch 35 | loss: 0.56115 | val_0_accuracy: 0.74331 |  0:01:26s\n",
            "epoch 36 | loss: 0.5513  | val_0_accuracy: 0.74914 |  0:01:28s\n",
            "epoch 37 | loss: 0.55017 | val_0_accuracy: 0.7418  |  0:01:30s\n",
            "epoch 38 | loss: 0.54851 | val_0_accuracy: 0.74331 |  0:01:33s\n",
            "epoch 39 | loss: 0.5454  | val_0_accuracy: 0.74439 |  0:01:35s\n",
            "epoch 40 | loss: 0.54293 | val_0_accuracy: 0.75022 |  0:01:37s\n",
            "epoch 41 | loss: 0.53529 | val_0_accuracy: 0.74827 |  0:01:40s\n",
            "epoch 42 | loss: 0.53241 | val_0_accuracy: 0.75756 |  0:01:42s\n",
            "epoch 43 | loss: 0.53248 | val_0_accuracy: 0.74417 |  0:01:45s\n",
            "epoch 44 | loss: 0.53076 | val_0_accuracy: 0.75756 |  0:01:47s\n",
            "epoch 45 | loss: 0.52653 | val_0_accuracy: 0.75475 |  0:01:50s\n",
            "epoch 46 | loss: 0.52176 | val_0_accuracy: 0.75151 |  0:01:53s\n",
            "epoch 47 | loss: 0.52338 | val_0_accuracy: 0.75259 |  0:01:55s\n",
            "epoch 48 | loss: 0.52158 | val_0_accuracy: 0.75518 |  0:01:58s\n",
            "epoch 49 | loss: 0.51678 | val_0_accuracy: 0.75648 |  0:02:00s\n",
            "epoch 50 | loss: 0.51668 | val_0_accuracy: 0.76187 |  0:02:02s\n",
            "epoch 51 | loss: 0.51002 | val_0_accuracy: 0.76231 |  0:02:05s\n",
            "epoch 52 | loss: 0.50828 | val_0_accuracy: 0.7649  |  0:02:07s\n",
            "epoch 53 | loss: 0.50822 | val_0_accuracy: 0.75799 |  0:02:10s\n",
            "epoch 54 | loss: 0.50883 | val_0_accuracy: 0.76986 |  0:02:12s\n",
            "epoch 55 | loss: 0.50423 | val_0_accuracy: 0.76209 |  0:02:14s\n",
            "epoch 56 | loss: 0.49758 | val_0_accuracy: 0.77008 |  0:02:17s\n",
            "epoch 57 | loss: 0.5005  | val_0_accuracy: 0.76749 |  0:02:19s\n",
            "epoch 58 | loss: 0.49427 | val_0_accuracy: 0.76662 |  0:02:21s\n",
            "epoch 59 | loss: 0.49989 | val_0_accuracy: 0.75885 |  0:02:24s\n",
            "epoch 60 | loss: 0.50739 | val_0_accuracy: 0.76878 |  0:02:26s\n",
            "epoch 61 | loss: 0.51128 | val_0_accuracy: 0.76144 |  0:02:29s\n",
            "epoch 62 | loss: 0.50557 | val_0_accuracy: 0.76641 |  0:02:31s\n",
            "epoch 63 | loss: 0.49125 | val_0_accuracy: 0.76857 |  0:02:33s\n",
            "epoch 64 | loss: 0.49156 | val_0_accuracy: 0.77332 |  0:02:36s\n",
            "epoch 65 | loss: 0.48287 | val_0_accuracy: 0.77051 |  0:02:38s\n",
            "epoch 66 | loss: 0.48542 | val_0_accuracy: 0.77051 |  0:02:41s\n",
            "epoch 67 | loss: 0.48103 | val_0_accuracy: 0.77396 |  0:02:43s\n",
            "epoch 68 | loss: 0.49108 | val_0_accuracy: 0.76187 |  0:02:45s\n",
            "epoch 69 | loss: 0.48298 | val_0_accuracy: 0.76921 |  0:02:48s\n",
            "epoch 70 | loss: 0.47869 | val_0_accuracy: 0.77699 |  0:02:50s\n",
            "epoch 71 | loss: 0.4736  | val_0_accuracy: 0.76727 |  0:02:53s\n",
            "epoch 72 | loss: 0.47426 | val_0_accuracy: 0.77547 |  0:02:55s\n",
            "epoch 73 | loss: 0.46992 | val_0_accuracy: 0.77612 |  0:02:57s\n",
            "epoch 74 | loss: 0.46436 | val_0_accuracy: 0.7785  |  0:03:00s\n",
            "epoch 75 | loss: 0.46479 | val_0_accuracy: 0.77677 |  0:03:02s\n",
            "epoch 76 | loss: 0.46887 | val_0_accuracy: 0.7772  |  0:03:04s\n",
            "epoch 77 | loss: 0.46407 | val_0_accuracy: 0.77915 |  0:03:07s\n",
            "epoch 78 | loss: 0.46143 | val_0_accuracy: 0.77979 |  0:03:09s\n",
            "epoch 79 | loss: 0.456   | val_0_accuracy: 0.78411 |  0:03:12s\n",
            "epoch 80 | loss: 0.46139 | val_0_accuracy: 0.77094 |  0:03:14s\n",
            "epoch 81 | loss: 0.46889 | val_0_accuracy: 0.77677 |  0:03:16s\n",
            "epoch 82 | loss: 0.45831 | val_0_accuracy: 0.77547 |  0:03:19s\n",
            "epoch 83 | loss: 0.45591 | val_0_accuracy: 0.78303 |  0:03:21s\n",
            "epoch 84 | loss: 0.45461 | val_0_accuracy: 0.77807 |  0:03:23s\n",
            "epoch 85 | loss: 0.45139 | val_0_accuracy: 0.7813  |  0:03:26s\n",
            "epoch 86 | loss: 0.4516  | val_0_accuracy: 0.78562 |  0:03:28s\n",
            "epoch 87 | loss: 0.44419 | val_0_accuracy: 0.78152 |  0:03:31s\n",
            "epoch 88 | loss: 0.44683 | val_0_accuracy: 0.77936 |  0:03:33s\n",
            "epoch 89 | loss: 0.44824 | val_0_accuracy: 0.77612 |  0:03:35s\n",
            "epoch 90 | loss: 0.45164 | val_0_accuracy: 0.77936 |  0:03:38s\n",
            "epoch 91 | loss: 0.46062 | val_0_accuracy: 0.76835 |  0:03:40s\n",
            "epoch 92 | loss: 0.45348 | val_0_accuracy: 0.77655 |  0:03:43s\n",
            "epoch 93 | loss: 0.46345 | val_0_accuracy: 0.76986 |  0:03:45s\n",
            "epoch 94 | loss: 0.44984 | val_0_accuracy: 0.78217 |  0:03:47s\n",
            "epoch 95 | loss: 0.44273 | val_0_accuracy: 0.77785 |  0:03:50s\n",
            "epoch 96 | loss: 0.43943 | val_0_accuracy: 0.78735 |  0:03:52s\n",
            "epoch 97 | loss: 0.43772 | val_0_accuracy: 0.78433 |  0:03:55s\n",
            "epoch 98 | loss: 0.43415 | val_0_accuracy: 0.78584 |  0:03:57s\n",
            "epoch 99 | loss: 0.43881 | val_0_accuracy: 0.77979 |  0:03:59s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 96 and best_val_0_accuracy = 0.78735\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 08:51:50,807]\u001b[0m Trial 5 finished with value: 0.7873488773747841 and parameters: {'n_d': 12, 'n_a': 33, 'n_steps': 3, 'gamma': 1.0599053948107544, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.27648200182524596}. Best is trial 2 with value: 0.8009499136442142.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       826\n",
            "           1       0.62      0.61      0.62       825\n",
            "           2       0.80      0.92      0.86       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.55      0.59      0.57       761\n",
            "           5       0.73      0.54      0.62       619\n",
            "\n",
            "    accuracy                           0.79      4632\n",
            "   macro avg       0.78      0.78      0.78      4632\n",
            "weighted avg       0.79      0.79      0.78      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.64259 | val_0_accuracy: 0.48921 |  0:00:05s\n",
            "epoch 1  | loss: 1.20812 | val_0_accuracy: 0.36054 |  0:00:10s\n",
            "epoch 2  | loss: 1.22755 | val_0_accuracy: 0.37284 |  0:00:15s\n",
            "epoch 3  | loss: 1.0655  | val_0_accuracy: 0.53217 |  0:00:20s\n",
            "epoch 4  | loss: 0.89991 | val_0_accuracy: 0.61183 |  0:00:26s\n",
            "epoch 5  | loss: 0.82348 | val_0_accuracy: 0.63968 |  0:00:31s\n",
            "epoch 6  | loss: 0.77762 | val_0_accuracy: 0.65436 |  0:00:36s\n",
            "epoch 7  | loss: 0.74317 | val_0_accuracy: 0.65177 |  0:00:41s\n",
            "epoch 8  | loss: 0.73709 | val_0_accuracy: 0.66256 |  0:00:46s\n",
            "epoch 9  | loss: 0.73007 | val_0_accuracy: 0.67012 |  0:00:52s\n",
            "epoch 10 | loss: 0.72918 | val_0_accuracy: 0.65544 |  0:00:57s\n",
            "epoch 11 | loss: 0.73286 | val_0_accuracy: 0.65177 |  0:01:02s\n",
            "epoch 12 | loss: 0.73567 | val_0_accuracy: 0.67358 |  0:01:07s\n",
            "epoch 13 | loss: 0.71179 | val_0_accuracy: 0.66861 |  0:01:13s\n",
            "epoch 14 | loss: 0.70877 | val_0_accuracy: 0.67271 |  0:01:18s\n",
            "epoch 15 | loss: 0.69618 | val_0_accuracy: 0.68739 |  0:01:23s\n",
            "epoch 16 | loss: 0.69778 | val_0_accuracy: 0.6617  |  0:01:28s\n",
            "epoch 17 | loss: 0.70745 | val_0_accuracy: 0.67876 |  0:01:33s\n",
            "epoch 18 | loss: 0.68831 | val_0_accuracy: 0.68459 |  0:01:39s\n",
            "epoch 19 | loss: 0.6857  | val_0_accuracy: 0.67703 |  0:01:44s\n",
            "epoch 20 | loss: 0.67188 | val_0_accuracy: 0.6848  |  0:01:49s\n",
            "epoch 21 | loss: 0.65759 | val_0_accuracy: 0.70294 |  0:01:54s\n",
            "epoch 22 | loss: 0.65037 | val_0_accuracy: 0.69711 |  0:01:59s\n",
            "epoch 23 | loss: 0.65355 | val_0_accuracy: 0.70617 |  0:02:05s\n",
            "epoch 24 | loss: 0.6555  | val_0_accuracy: 0.68804 |  0:02:10s\n",
            "epoch 25 | loss: 0.64278 | val_0_accuracy: 0.70121 |  0:02:15s\n",
            "epoch 26 | loss: 0.63568 | val_0_accuracy: 0.71718 |  0:02:20s\n",
            "epoch 27 | loss: 0.65121 | val_0_accuracy: 0.69948 |  0:02:26s\n",
            "epoch 28 | loss: 0.63    | val_0_accuracy: 0.71373 |  0:02:31s\n",
            "epoch 29 | loss: 0.62434 | val_0_accuracy: 0.71222 |  0:02:36s\n",
            "epoch 30 | loss: 0.61824 | val_0_accuracy: 0.70833 |  0:02:41s\n",
            "epoch 31 | loss: 0.61545 | val_0_accuracy: 0.70121 |  0:02:46s\n",
            "epoch 32 | loss: 0.6078  | val_0_accuracy: 0.72237 |  0:02:52s\n",
            "epoch 33 | loss: 0.60719 | val_0_accuracy: 0.72085 |  0:02:57s\n",
            "epoch 34 | loss: 0.60244 | val_0_accuracy: 0.72604 |  0:03:02s\n",
            "epoch 35 | loss: 0.59862 | val_0_accuracy: 0.71762 |  0:03:07s\n",
            "epoch 36 | loss: 0.60088 | val_0_accuracy: 0.72927 |  0:03:13s\n",
            "epoch 37 | loss: 0.59028 | val_0_accuracy: 0.72172 |  0:03:19s\n",
            "epoch 38 | loss: 0.58966 | val_0_accuracy: 0.71848 |  0:03:24s\n",
            "epoch 39 | loss: 0.587   | val_0_accuracy: 0.73273 |  0:03:29s\n",
            "epoch 40 | loss: 0.58023 | val_0_accuracy: 0.72906 |  0:03:34s\n",
            "epoch 41 | loss: 0.57423 | val_0_accuracy: 0.72431 |  0:03:39s\n",
            "epoch 42 | loss: 0.57217 | val_0_accuracy: 0.72949 |  0:03:45s\n",
            "epoch 43 | loss: 0.57372 | val_0_accuracy: 0.73813 |  0:03:50s\n",
            "epoch 44 | loss: 0.57297 | val_0_accuracy: 0.7282  |  0:03:55s\n",
            "epoch 45 | loss: 0.56569 | val_0_accuracy: 0.73165 |  0:04:00s\n",
            "epoch 46 | loss: 0.56194 | val_0_accuracy: 0.73877 |  0:04:05s\n",
            "epoch 47 | loss: 0.55974 | val_0_accuracy: 0.73964 |  0:04:10s\n",
            "epoch 48 | loss: 0.55495 | val_0_accuracy: 0.74072 |  0:04:16s\n",
            "epoch 49 | loss: 0.55141 | val_0_accuracy: 0.74288 |  0:04:21s\n",
            "epoch 50 | loss: 0.54836 | val_0_accuracy: 0.74482 |  0:04:26s\n",
            "epoch 51 | loss: 0.54828 | val_0_accuracy: 0.74266 |  0:04:31s\n",
            "epoch 52 | loss: 0.54453 | val_0_accuracy: 0.74935 |  0:04:36s\n",
            "epoch 53 | loss: 0.54002 | val_0_accuracy: 0.7459  |  0:04:42s\n",
            "epoch 54 | loss: 0.5361  | val_0_accuracy: 0.74331 |  0:04:47s\n",
            "epoch 55 | loss: 0.53672 | val_0_accuracy: 0.75065 |  0:04:52s\n",
            "epoch 56 | loss: 0.53343 | val_0_accuracy: 0.7541  |  0:04:57s\n",
            "epoch 57 | loss: 0.53172 | val_0_accuracy: 0.75302 |  0:05:02s\n",
            "epoch 58 | loss: 0.52939 | val_0_accuracy: 0.75281 |  0:05:08s\n",
            "epoch 59 | loss: 0.52423 | val_0_accuracy: 0.75302 |  0:05:13s\n",
            "epoch 60 | loss: 0.52177 | val_0_accuracy: 0.75345 |  0:05:18s\n",
            "epoch 61 | loss: 0.52301 | val_0_accuracy: 0.75518 |  0:05:23s\n",
            "epoch 62 | loss: 0.51467 | val_0_accuracy: 0.75518 |  0:05:28s\n",
            "epoch 63 | loss: 0.51158 | val_0_accuracy: 0.75756 |  0:05:34s\n",
            "epoch 64 | loss: 0.51086 | val_0_accuracy: 0.76166 |  0:05:39s\n",
            "epoch 65 | loss: 0.51175 | val_0_accuracy: 0.75691 |  0:05:44s\n",
            "epoch 66 | loss: 0.50391 | val_0_accuracy: 0.76015 |  0:05:49s\n",
            "epoch 67 | loss: 0.5046  | val_0_accuracy: 0.76598 |  0:05:54s\n",
            "epoch 68 | loss: 0.50694 | val_0_accuracy: 0.75691 |  0:06:00s\n",
            "epoch 69 | loss: 0.50098 | val_0_accuracy: 0.77828 |  0:06:05s\n",
            "epoch 70 | loss: 0.49402 | val_0_accuracy: 0.76576 |  0:06:10s\n",
            "epoch 71 | loss: 0.49227 | val_0_accuracy: 0.76943 |  0:06:15s\n",
            "epoch 72 | loss: 0.48962 | val_0_accuracy: 0.75993 |  0:06:21s\n",
            "epoch 73 | loss: 0.49036 | val_0_accuracy: 0.77137 |  0:06:26s\n",
            "epoch 74 | loss: 0.49252 | val_0_accuracy: 0.77224 |  0:06:31s\n",
            "epoch 75 | loss: 0.4834  | val_0_accuracy: 0.77137 |  0:06:36s\n",
            "epoch 76 | loss: 0.48295 | val_0_accuracy: 0.76576 |  0:06:41s\n",
            "epoch 77 | loss: 0.48079 | val_0_accuracy: 0.76123 |  0:06:46s\n",
            "epoch 78 | loss: 0.4797  | val_0_accuracy: 0.77029 |  0:06:52s\n",
            "epoch 79 | loss: 0.47773 | val_0_accuracy: 0.77504 |  0:06:57s\n",
            "\n",
            "Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_accuracy = 0.77828\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 08:58:50,644]\u001b[0m Trial 6 finished with value: 0.7782815198618307 and parameters: {'n_d': 43, 'n_a': 38, 'n_steps': 7, 'gamma': 1.7477952807645485, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.2645248074310637}. Best is trial 2 with value: 0.8009499136442142.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       826\n",
            "           1       0.61      0.59      0.60       825\n",
            "           2       0.81      0.91      0.86       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.53      0.57      0.55       761\n",
            "           5       0.70      0.53      0.61       619\n",
            "\n",
            "    accuracy                           0.78      4632\n",
            "   macro avg       0.77      0.77      0.77      4632\n",
            "weighted avg       0.78      0.78      0.78      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.48327 | val_0_accuracy: 0.54814 |  0:00:03s\n",
            "epoch 1  | loss: 1.1128  | val_0_accuracy: 0.53087 |  0:00:07s\n",
            "epoch 2  | loss: 1.00961 | val_0_accuracy: 0.55721 |  0:00:10s\n",
            "epoch 3  | loss: 0.95109 | val_0_accuracy: 0.59672 |  0:00:14s\n",
            "epoch 4  | loss: 0.86816 | val_0_accuracy: 0.62047 |  0:00:17s\n",
            "epoch 5  | loss: 0.79766 | val_0_accuracy: 0.64832 |  0:00:21s\n",
            "epoch 6  | loss: 0.77244 | val_0_accuracy: 0.64788 |  0:00:24s\n",
            "epoch 7  | loss: 0.7477  | val_0_accuracy: 0.65112 |  0:00:28s\n",
            "epoch 8  | loss: 0.74048 | val_0_accuracy: 0.66947 |  0:00:31s\n",
            "epoch 9  | loss: 0.71051 | val_0_accuracy: 0.6725  |  0:00:35s\n",
            "epoch 10 | loss: 0.71991 | val_0_accuracy: 0.67595 |  0:00:38s\n",
            "epoch 11 | loss: 0.69523 | val_0_accuracy: 0.67638 |  0:00:42s\n",
            "epoch 12 | loss: 0.70118 | val_0_accuracy: 0.66451 |  0:00:46s\n",
            "epoch 13 | loss: 0.68682 | val_0_accuracy: 0.66818 |  0:00:49s\n",
            "epoch 14 | loss: 0.6761  | val_0_accuracy: 0.64292 |  0:00:52s\n",
            "epoch 15 | loss: 0.67726 | val_0_accuracy: 0.65155 |  0:00:56s\n",
            "epoch 16 | loss: 0.6673  | val_0_accuracy: 0.66494 |  0:00:59s\n",
            "epoch 17 | loss: 0.66006 | val_0_accuracy: 0.6576  |  0:01:03s\n",
            "epoch 18 | loss: 0.67121 | val_0_accuracy: 0.64724 |  0:01:07s\n",
            "epoch 19 | loss: 0.65645 | val_0_accuracy: 0.64918 |  0:01:10s\n",
            "epoch 20 | loss: 0.65105 | val_0_accuracy: 0.64983 |  0:01:14s\n",
            "epoch 21 | loss: 0.65088 | val_0_accuracy: 0.63104 |  0:01:17s\n",
            "\n",
            "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_accuracy = 0.67638\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 09:00:09,931]\u001b[0m Trial 7 finished with value: 0.6763816925734024 and parameters: {'n_d': 60, 'n_a': 29, 'n_steps': 6, 'gamma': 1.3200248034372848, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.09827065820533537}. Best is trial 2 with value: 0.8009499136442142.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       826\n",
            "           1       0.42      0.34      0.38       825\n",
            "           2       0.56      0.88      0.68       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.49      0.22      0.31       761\n",
            "           5       0.51      0.58      0.54       619\n",
            "\n",
            "    accuracy                           0.68      4632\n",
            "   macro avg       0.66      0.67      0.65      4632\n",
            "weighted avg       0.67      0.68      0.66      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.74411 | val_0_accuracy: 0.51921 |  0:00:05s\n",
            "epoch 1  | loss: 1.11795 | val_0_accuracy: 0.55203 |  0:00:10s\n",
            "epoch 2  | loss: 1.03097 | val_0_accuracy: 0.52245 |  0:00:16s\n",
            "epoch 3  | loss: 1.01947 | val_0_accuracy: 0.53195 |  0:00:22s\n",
            "epoch 4  | loss: 0.96201 | val_0_accuracy: 0.58441 |  0:00:28s\n",
            "epoch 5  | loss: 0.89097 | val_0_accuracy: 0.60751 |  0:00:33s\n",
            "epoch 6  | loss: 0.83508 | val_0_accuracy: 0.62263 |  0:00:39s\n",
            "epoch 7  | loss: 0.81892 | val_0_accuracy: 0.6209  |  0:00:44s\n",
            "epoch 8  | loss: 0.81269 | val_0_accuracy: 0.62608 |  0:00:50s\n",
            "epoch 9  | loss: 0.80491 | val_0_accuracy: 0.60687 |  0:00:55s\n",
            "epoch 10 | loss: 0.79926 | val_0_accuracy: 0.62781 |  0:01:01s\n",
            "epoch 11 | loss: 0.80789 | val_0_accuracy: 0.63256 |  0:01:06s\n",
            "epoch 12 | loss: 0.78794 | val_0_accuracy: 0.61226 |  0:01:12s\n",
            "epoch 13 | loss: 0.79214 | val_0_accuracy: 0.62781 |  0:01:17s\n",
            "epoch 14 | loss: 0.8008  | val_0_accuracy: 0.62111 |  0:01:23s\n",
            "epoch 15 | loss: 0.76223 | val_0_accuracy: 0.606   |  0:01:28s\n",
            "epoch 16 | loss: 0.74064 | val_0_accuracy: 0.63364 |  0:01:34s\n",
            "epoch 17 | loss: 0.76737 | val_0_accuracy: 0.65134 |  0:01:39s\n",
            "epoch 18 | loss: 0.74256 | val_0_accuracy: 0.66861 |  0:01:45s\n",
            "epoch 19 | loss: 0.72419 | val_0_accuracy: 0.66753 |  0:01:50s\n",
            "epoch 20 | loss: 0.7195  | val_0_accuracy: 0.62975 |  0:01:56s\n",
            "epoch 21 | loss: 0.71276 | val_0_accuracy: 0.64745 |  0:02:01s\n",
            "epoch 22 | loss: 0.70221 | val_0_accuracy: 0.61464 |  0:02:07s\n",
            "epoch 23 | loss: 0.68949 | val_0_accuracy: 0.65307 |  0:02:12s\n",
            "epoch 24 | loss: 0.67704 | val_0_accuracy: 0.67422 |  0:02:17s\n",
            "epoch 25 | loss: 0.6716  | val_0_accuracy: 0.65004 |  0:02:23s\n",
            "epoch 26 | loss: 0.66358 | val_0_accuracy: 0.65091 |  0:02:28s\n",
            "epoch 27 | loss: 0.65883 | val_0_accuracy: 0.67465 |  0:02:34s\n",
            "epoch 28 | loss: 0.65579 | val_0_accuracy: 0.66149 |  0:02:39s\n",
            "epoch 29 | loss: 0.64939 | val_0_accuracy: 0.67768 |  0:02:45s\n",
            "epoch 30 | loss: 0.64382 | val_0_accuracy: 0.65954 |  0:02:50s\n",
            "epoch 31 | loss: 0.6396  | val_0_accuracy: 0.70164 |  0:02:56s\n",
            "epoch 32 | loss: 0.63123 | val_0_accuracy: 0.70272 |  0:03:01s\n",
            "epoch 33 | loss: 0.62985 | val_0_accuracy: 0.68545 |  0:03:07s\n",
            "epoch 34 | loss: 0.62077 | val_0_accuracy: 0.71308 |  0:03:12s\n",
            "epoch 35 | loss: 0.61558 | val_0_accuracy: 0.69322 |  0:03:18s\n",
            "epoch 36 | loss: 0.60978 | val_0_accuracy: 0.70531 |  0:03:23s\n",
            "epoch 37 | loss: 0.61038 | val_0_accuracy: 0.68782 |  0:03:29s\n",
            "epoch 38 | loss: 0.60254 | val_0_accuracy: 0.68869 |  0:03:34s\n",
            "epoch 39 | loss: 0.60428 | val_0_accuracy: 0.69495 |  0:03:40s\n",
            "epoch 40 | loss: 0.60357 | val_0_accuracy: 0.69063 |  0:03:45s\n",
            "epoch 41 | loss: 0.59794 | val_0_accuracy: 0.70402 |  0:03:50s\n",
            "epoch 42 | loss: 0.59444 | val_0_accuracy: 0.70596 |  0:03:56s\n",
            "epoch 43 | loss: 0.59177 | val_0_accuracy: 0.63083 |  0:04:01s\n",
            "epoch 44 | loss: 0.59195 | val_0_accuracy: 0.69516 |  0:04:07s\n",
            "\n",
            "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_accuracy = 0.71308\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 09:04:19,669]\u001b[0m Trial 8 finished with value: 0.7130829015544041 and parameters: {'n_d': 26, 'n_a': 18, 'n_steps': 6, 'gamma': 1.1470869788163012, 'n_independent': 4, 'n_shared': 5, 'momentum': 0.03256852661518873}. Best is trial 2 with value: 0.8009499136442142.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       826\n",
            "           1       0.49      0.47      0.48       825\n",
            "           2       0.78      0.74      0.76       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.44      0.54      0.48       761\n",
            "           5       0.58      0.47      0.52       619\n",
            "\n",
            "    accuracy                           0.71      4632\n",
            "   macro avg       0.71      0.70      0.71      4632\n",
            "weighted avg       0.72      0.71      0.71      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.23214 | val_0_accuracy: 0.57923 |  0:00:02s\n",
            "epoch 1  | loss: 0.90123 | val_0_accuracy: 0.62068 |  0:00:05s\n",
            "epoch 2  | loss: 0.8284  | val_0_accuracy: 0.62781 |  0:00:08s\n",
            "epoch 3  | loss: 0.7812  | val_0_accuracy: 0.64119 |  0:00:10s\n",
            "epoch 4  | loss: 0.7548  | val_0_accuracy: 0.65263 |  0:00:13s\n",
            "epoch 5  | loss: 0.73489 | val_0_accuracy: 0.66839 |  0:00:16s\n",
            "epoch 6  | loss: 0.72156 | val_0_accuracy: 0.66256 |  0:00:18s\n",
            "epoch 7  | loss: 0.70457 | val_0_accuracy: 0.68221 |  0:00:21s\n",
            "epoch 8  | loss: 0.68873 | val_0_accuracy: 0.67142 |  0:00:24s\n",
            "epoch 9  | loss: 0.68041 | val_0_accuracy: 0.68437 |  0:00:26s\n",
            "epoch 10 | loss: 0.67717 | val_0_accuracy: 0.68739 |  0:00:29s\n",
            "epoch 11 | loss: 0.66978 | val_0_accuracy: 0.69063 |  0:00:32s\n",
            "epoch 12 | loss: 0.65959 | val_0_accuracy: 0.6984  |  0:00:34s\n",
            "epoch 13 | loss: 0.66233 | val_0_accuracy: 0.70272 |  0:00:37s\n",
            "epoch 14 | loss: 0.66694 | val_0_accuracy: 0.69193 |  0:00:40s\n",
            "epoch 15 | loss: 0.66289 | val_0_accuracy: 0.68113 |  0:00:43s\n",
            "epoch 16 | loss: 0.64896 | val_0_accuracy: 0.69862 |  0:00:45s\n",
            "epoch 17 | loss: 0.64273 | val_0_accuracy: 0.69408 |  0:00:48s\n",
            "epoch 18 | loss: 0.63841 | val_0_accuracy: 0.71136 |  0:00:51s\n",
            "epoch 19 | loss: 0.62963 | val_0_accuracy: 0.70725 |  0:00:53s\n",
            "epoch 20 | loss: 0.62583 | val_0_accuracy: 0.71308 |  0:00:56s\n",
            "epoch 21 | loss: 0.61635 | val_0_accuracy: 0.72172 |  0:00:59s\n",
            "epoch 22 | loss: 0.61808 | val_0_accuracy: 0.72647 |  0:01:01s\n",
            "epoch 23 | loss: 0.60674 | val_0_accuracy: 0.72776 |  0:01:04s\n",
            "epoch 24 | loss: 0.60455 | val_0_accuracy: 0.72366 |  0:01:07s\n",
            "epoch 25 | loss: 0.60002 | val_0_accuracy: 0.73035 |  0:01:09s\n",
            "epoch 26 | loss: 0.59722 | val_0_accuracy: 0.72668 |  0:01:12s\n",
            "epoch 27 | loss: 0.60425 | val_0_accuracy: 0.72409 |  0:01:15s\n",
            "epoch 28 | loss: 0.58867 | val_0_accuracy: 0.72927 |  0:01:17s\n",
            "epoch 29 | loss: 0.58624 | val_0_accuracy: 0.73014 |  0:01:20s\n",
            "epoch 30 | loss: 0.57942 | val_0_accuracy: 0.73057 |  0:01:23s\n",
            "epoch 31 | loss: 0.58103 | val_0_accuracy: 0.72798 |  0:01:25s\n",
            "epoch 32 | loss: 0.57898 | val_0_accuracy: 0.7364  |  0:01:28s\n",
            "epoch 33 | loss: 0.57317 | val_0_accuracy: 0.73791 |  0:01:31s\n",
            "epoch 34 | loss: 0.57237 | val_0_accuracy: 0.73748 |  0:01:33s\n",
            "epoch 35 | loss: 0.57006 | val_0_accuracy: 0.73273 |  0:01:37s\n",
            "epoch 36 | loss: 0.5648  | val_0_accuracy: 0.73921 |  0:01:40s\n",
            "epoch 37 | loss: 0.561   | val_0_accuracy: 0.74158 |  0:01:42s\n",
            "epoch 38 | loss: 0.57025 | val_0_accuracy: 0.7364  |  0:01:45s\n",
            "epoch 39 | loss: 0.6167  | val_0_accuracy: 0.73035 |  0:01:48s\n",
            "epoch 40 | loss: 0.59226 | val_0_accuracy: 0.72992 |  0:01:50s\n",
            "epoch 41 | loss: 0.57975 | val_0_accuracy: 0.73489 |  0:01:53s\n",
            "epoch 42 | loss: 0.592   | val_0_accuracy: 0.73165 |  0:01:56s\n",
            "epoch 43 | loss: 0.57186 | val_0_accuracy: 0.73813 |  0:01:58s\n",
            "epoch 44 | loss: 0.57039 | val_0_accuracy: 0.73338 |  0:02:01s\n",
            "epoch 45 | loss: 0.55994 | val_0_accuracy: 0.75389 |  0:02:03s\n",
            "epoch 46 | loss: 0.55033 | val_0_accuracy: 0.74784 |  0:02:06s\n",
            "epoch 47 | loss: 0.54597 | val_0_accuracy: 0.74978 |  0:02:09s\n",
            "epoch 48 | loss: 0.54356 | val_0_accuracy: 0.75043 |  0:02:11s\n",
            "epoch 49 | loss: 0.53864 | val_0_accuracy: 0.74676 |  0:02:14s\n",
            "epoch 50 | loss: 0.55849 | val_0_accuracy: 0.74396 |  0:02:17s\n",
            "epoch 51 | loss: 0.55071 | val_0_accuracy: 0.7446  |  0:02:19s\n",
            "epoch 52 | loss: 0.54953 | val_0_accuracy: 0.75173 |  0:02:22s\n",
            "epoch 53 | loss: 0.54036 | val_0_accuracy: 0.74827 |  0:02:25s\n",
            "epoch 54 | loss: 0.53815 | val_0_accuracy: 0.75259 |  0:02:27s\n",
            "epoch 55 | loss: 0.52835 | val_0_accuracy: 0.75756 |  0:02:30s\n",
            "epoch 56 | loss: 0.52933 | val_0_accuracy: 0.75756 |  0:02:33s\n",
            "epoch 57 | loss: 0.52769 | val_0_accuracy: 0.76425 |  0:02:35s\n",
            "epoch 58 | loss: 0.52248 | val_0_accuracy: 0.7582  |  0:02:38s\n",
            "epoch 59 | loss: 0.52059 | val_0_accuracy: 0.75885 |  0:02:41s\n",
            "epoch 60 | loss: 0.51979 | val_0_accuracy: 0.76274 |  0:02:43s\n",
            "epoch 61 | loss: 0.51328 | val_0_accuracy: 0.76187 |  0:02:46s\n",
            "epoch 62 | loss: 0.50868 | val_0_accuracy: 0.76835 |  0:02:49s\n",
            "epoch 63 | loss: 0.50401 | val_0_accuracy: 0.7582  |  0:02:51s\n",
            "epoch 64 | loss: 0.50189 | val_0_accuracy: 0.76986 |  0:02:54s\n",
            "epoch 65 | loss: 0.50208 | val_0_accuracy: 0.76295 |  0:02:57s\n",
            "epoch 66 | loss: 0.51029 | val_0_accuracy: 0.76036 |  0:02:59s\n",
            "epoch 67 | loss: 0.50662 | val_0_accuracy: 0.76123 |  0:03:02s\n",
            "epoch 68 | loss: 0.50493 | val_0_accuracy: 0.75972 |  0:03:05s\n",
            "epoch 69 | loss: 0.50724 | val_0_accuracy: 0.76598 |  0:03:07s\n",
            "epoch 70 | loss: 0.50106 | val_0_accuracy: 0.76662 |  0:03:10s\n",
            "epoch 71 | loss: 0.49825 | val_0_accuracy: 0.76857 |  0:03:12s\n",
            "epoch 72 | loss: 0.50161 | val_0_accuracy: 0.76706 |  0:03:15s\n",
            "epoch 73 | loss: 0.50935 | val_0_accuracy: 0.74136 |  0:03:18s\n",
            "epoch 74 | loss: 0.51206 | val_0_accuracy: 0.76662 |  0:03:20s\n",
            "\n",
            "Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_accuracy = 0.76986\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 09:07:41,943]\u001b[0m Trial 9 finished with value: 0.7698618307426598 and parameters: {'n_d': 30, 'n_a': 20, 'n_steps': 3, 'gamma': 1.6157899544227163, 'n_independent': 5, 'n_shared': 2, 'momentum': 0.34326731337411176}. Best is trial 2 with value: 0.8009499136442142.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       826\n",
            "           1       0.61      0.58      0.60       825\n",
            "           2       0.78      0.91      0.84       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.51      0.60      0.55       761\n",
            "           5       0.73      0.45      0.55       619\n",
            "\n",
            "    accuracy                           0.77      4632\n",
            "   macro avg       0.77      0.76      0.76      4632\n",
            "weighted avg       0.77      0.77      0.77      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.45663 | val_0_accuracy: 0.53951 |  0:00:03s\n",
            "epoch 1  | loss: 1.0247  | val_0_accuracy: 0.54188 |  0:00:07s\n",
            "epoch 2  | loss: 0.9762  | val_0_accuracy: 0.58787 |  0:00:11s\n",
            "epoch 3  | loss: 0.91149 | val_0_accuracy: 0.60492 |  0:00:15s\n",
            "epoch 4  | loss: 0.8495  | val_0_accuracy: 0.62327 |  0:00:19s\n",
            "epoch 5  | loss: 0.78769 | val_0_accuracy: 0.64745 |  0:00:23s\n",
            "epoch 6  | loss: 0.74419 | val_0_accuracy: 0.6617  |  0:00:27s\n",
            "epoch 7  | loss: 0.72392 | val_0_accuracy: 0.6617  |  0:00:31s\n",
            "epoch 8  | loss: 0.71475 | val_0_accuracy: 0.65868 |  0:00:35s\n",
            "epoch 9  | loss: 0.69919 | val_0_accuracy: 0.6861  |  0:00:38s\n",
            "epoch 10 | loss: 0.69213 | val_0_accuracy: 0.67746 |  0:00:42s\n",
            "epoch 11 | loss: 0.68753 | val_0_accuracy: 0.6766  |  0:00:46s\n",
            "epoch 12 | loss: 0.69041 | val_0_accuracy: 0.68243 |  0:00:50s\n",
            "epoch 13 | loss: 0.6803  | val_0_accuracy: 0.68566 |  0:00:54s\n",
            "epoch 14 | loss: 0.68028 | val_0_accuracy: 0.6807  |  0:00:58s\n",
            "epoch 15 | loss: 0.66636 | val_0_accuracy: 0.69236 |  0:01:02s\n",
            "epoch 16 | loss: 0.65941 | val_0_accuracy: 0.69603 |  0:01:06s\n",
            "epoch 17 | loss: 0.65473 | val_0_accuracy: 0.69495 |  0:01:10s\n",
            "epoch 18 | loss: 0.65302 | val_0_accuracy: 0.70013 |  0:01:13s\n",
            "epoch 19 | loss: 0.65515 | val_0_accuracy: 0.7025  |  0:01:17s\n",
            "epoch 20 | loss: 0.65062 | val_0_accuracy: 0.69775 |  0:01:21s\n",
            "epoch 21 | loss: 0.63978 | val_0_accuracy: 0.70207 |  0:01:25s\n",
            "epoch 22 | loss: 0.639   | val_0_accuracy: 0.70078 |  0:01:29s\n",
            "epoch 23 | loss: 0.63159 | val_0_accuracy: 0.70769 |  0:01:33s\n",
            "epoch 24 | loss: 0.62563 | val_0_accuracy: 0.71006 |  0:01:37s\n",
            "epoch 25 | loss: 0.62317 | val_0_accuracy: 0.71826 |  0:01:41s\n",
            "epoch 26 | loss: 0.62328 | val_0_accuracy: 0.71783 |  0:01:45s\n",
            "epoch 27 | loss: 0.64659 | val_0_accuracy: 0.70164 |  0:01:48s\n",
            "epoch 28 | loss: 0.64235 | val_0_accuracy: 0.70617 |  0:01:52s\n",
            "epoch 29 | loss: 0.63048 | val_0_accuracy: 0.70682 |  0:01:56s\n",
            "epoch 30 | loss: 0.63252 | val_0_accuracy: 0.71395 |  0:02:00s\n",
            "epoch 31 | loss: 0.63118 | val_0_accuracy: 0.71481 |  0:02:04s\n",
            "epoch 32 | loss: 0.61985 | val_0_accuracy: 0.72021 |  0:02:08s\n",
            "epoch 33 | loss: 0.61327 | val_0_accuracy: 0.72582 |  0:02:12s\n",
            "epoch 34 | loss: 0.60394 | val_0_accuracy: 0.71697 |  0:02:16s\n",
            "epoch 35 | loss: 0.59906 | val_0_accuracy: 0.73143 |  0:02:19s\n",
            "epoch 36 | loss: 0.59325 | val_0_accuracy: 0.72388 |  0:02:23s\n",
            "epoch 37 | loss: 0.58854 | val_0_accuracy: 0.7256  |  0:02:27s\n",
            "epoch 38 | loss: 0.59204 | val_0_accuracy: 0.71805 |  0:02:31s\n",
            "epoch 39 | loss: 0.58309 | val_0_accuracy: 0.7228  |  0:02:35s\n",
            "epoch 40 | loss: 0.57351 | val_0_accuracy: 0.73143 |  0:02:39s\n",
            "epoch 41 | loss: 0.57364 | val_0_accuracy: 0.73402 |  0:02:43s\n",
            "epoch 42 | loss: 0.57053 | val_0_accuracy: 0.72647 |  0:02:46s\n",
            "epoch 43 | loss: 0.56491 | val_0_accuracy: 0.72647 |  0:02:50s\n",
            "epoch 44 | loss: 0.56425 | val_0_accuracy: 0.72863 |  0:02:54s\n",
            "epoch 45 | loss: 0.55961 | val_0_accuracy: 0.74072 |  0:02:58s\n",
            "epoch 46 | loss: 0.55196 | val_0_accuracy: 0.73985 |  0:03:02s\n",
            "epoch 47 | loss: 0.55122 | val_0_accuracy: 0.7446  |  0:03:06s\n",
            "epoch 48 | loss: 0.54636 | val_0_accuracy: 0.73381 |  0:03:10s\n",
            "epoch 49 | loss: 0.54367 | val_0_accuracy: 0.72992 |  0:03:14s\n",
            "epoch 50 | loss: 0.53882 | val_0_accuracy: 0.7418  |  0:03:18s\n",
            "epoch 51 | loss: 0.5379  | val_0_accuracy: 0.74827 |  0:03:21s\n",
            "epoch 52 | loss: 0.53286 | val_0_accuracy: 0.74396 |  0:03:25s\n",
            "epoch 53 | loss: 0.53751 | val_0_accuracy: 0.75648 |  0:03:29s\n",
            "epoch 54 | loss: 0.5292  | val_0_accuracy: 0.75151 |  0:03:34s\n",
            "epoch 55 | loss: 0.52557 | val_0_accuracy: 0.75    |  0:03:38s\n",
            "epoch 56 | loss: 0.52289 | val_0_accuracy: 0.75518 |  0:03:42s\n",
            "epoch 57 | loss: 0.5345  | val_0_accuracy: 0.75345 |  0:03:46s\n",
            "epoch 58 | loss: 0.52908 | val_0_accuracy: 0.75669 |  0:03:50s\n",
            "epoch 59 | loss: 0.52274 | val_0_accuracy: 0.73985 |  0:03:54s\n",
            "epoch 60 | loss: 0.51836 | val_0_accuracy: 0.7541  |  0:03:58s\n",
            "epoch 61 | loss: 0.50918 | val_0_accuracy: 0.76058 |  0:04:02s\n",
            "epoch 62 | loss: 0.50948 | val_0_accuracy: 0.76144 |  0:04:06s\n",
            "epoch 63 | loss: 0.51147 | val_0_accuracy: 0.7595  |  0:04:10s\n",
            "epoch 64 | loss: 0.50435 | val_0_accuracy: 0.75777 |  0:04:14s\n",
            "epoch 65 | loss: 0.50605 | val_0_accuracy: 0.76036 |  0:04:18s\n",
            "epoch 66 | loss: 0.50147 | val_0_accuracy: 0.76749 |  0:04:22s\n",
            "epoch 67 | loss: 0.49385 | val_0_accuracy: 0.77375 |  0:04:26s\n",
            "epoch 68 | loss: 0.49664 | val_0_accuracy: 0.76058 |  0:04:30s\n",
            "epoch 69 | loss: 0.53175 | val_0_accuracy: 0.73985 |  0:04:33s\n",
            "epoch 70 | loss: 0.53405 | val_0_accuracy: 0.74978 |  0:04:37s\n",
            "epoch 71 | loss: 0.5099  | val_0_accuracy: 0.76533 |  0:04:41s\n",
            "epoch 72 | loss: 0.51432 | val_0_accuracy: 0.76015 |  0:04:45s\n",
            "epoch 73 | loss: 0.49374 | val_0_accuracy: 0.76641 |  0:04:49s\n",
            "epoch 74 | loss: 0.48656 | val_0_accuracy: 0.76187 |  0:04:53s\n",
            "epoch 75 | loss: 0.48603 | val_0_accuracy: 0.76576 |  0:04:57s\n",
            "epoch 76 | loss: 0.49537 | val_0_accuracy: 0.75604 |  0:05:01s\n",
            "epoch 77 | loss: 0.4885  | val_0_accuracy: 0.77418 |  0:05:05s\n",
            "epoch 78 | loss: 0.47385 | val_0_accuracy: 0.77807 |  0:05:09s\n",
            "epoch 79 | loss: 0.47174 | val_0_accuracy: 0.77375 |  0:05:12s\n",
            "epoch 80 | loss: 0.47019 | val_0_accuracy: 0.78109 |  0:05:16s\n",
            "epoch 81 | loss: 0.47064 | val_0_accuracy: 0.77288 |  0:05:20s\n",
            "epoch 82 | loss: 0.46213 | val_0_accuracy: 0.78282 |  0:05:24s\n",
            "epoch 83 | loss: 0.45742 | val_0_accuracy: 0.78325 |  0:05:28s\n",
            "epoch 84 | loss: 0.49183 | val_0_accuracy: 0.74439 |  0:05:32s\n",
            "epoch 85 | loss: 0.50551 | val_0_accuracy: 0.7731  |  0:05:36s\n",
            "epoch 86 | loss: 0.47754 | val_0_accuracy: 0.77828 |  0:05:40s\n",
            "epoch 87 | loss: 0.46133 | val_0_accuracy: 0.77547 |  0:05:44s\n",
            "epoch 88 | loss: 0.45832 | val_0_accuracy: 0.78109 |  0:05:48s\n",
            "epoch 89 | loss: 0.48912 | val_0_accuracy: 0.77094 |  0:05:51s\n",
            "epoch 90 | loss: 0.47472 | val_0_accuracy: 0.7867  |  0:05:55s\n",
            "epoch 91 | loss: 0.46623 | val_0_accuracy: 0.78217 |  0:05:59s\n",
            "epoch 92 | loss: 0.45634 | val_0_accuracy: 0.78476 |  0:06:03s\n",
            "epoch 93 | loss: 0.44988 | val_0_accuracy: 0.77979 |  0:06:07s\n",
            "epoch 94 | loss: 0.44837 | val_0_accuracy: 0.78282 |  0:06:11s\n",
            "epoch 95 | loss: 0.44152 | val_0_accuracy: 0.78627 |  0:06:15s\n",
            "epoch 96 | loss: 0.43792 | val_0_accuracy: 0.78497 |  0:06:18s\n",
            "epoch 97 | loss: 0.43795 | val_0_accuracy: 0.78735 |  0:06:22s\n",
            "epoch 98 | loss: 0.43199 | val_0_accuracy: 0.78756 |  0:06:26s\n",
            "epoch 99 | loss: 0.43033 | val_0_accuracy: 0.78929 |  0:06:30s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_accuracy = 0.78929\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 09:14:14,469]\u001b[0m Trial 10 finished with value: 0.7892918825561313 and parameters: {'n_d': 16, 'n_a': 62, 'n_steps': 5, 'gamma': 1.4163179381422513, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.35644075532362185}. Best is trial 2 with value: 0.8009499136442142.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       826\n",
            "           1       0.63      0.68      0.65       825\n",
            "           2       0.80      0.93      0.86       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.54      0.61      0.58       761\n",
            "           5       0.84      0.42      0.56       619\n",
            "\n",
            "    accuracy                           0.79      4632\n",
            "   macro avg       0.80      0.77      0.77      4632\n",
            "weighted avg       0.80      0.79      0.78      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.48641 | val_0_accuracy: 0.54383 |  0:00:03s\n",
            "epoch 1  | loss: 1.13558 | val_0_accuracy: 0.52785 |  0:00:07s\n",
            "epoch 2  | loss: 1.06352 | val_0_accuracy: 0.58528 |  0:00:11s\n",
            "epoch 3  | loss: 1.03402 | val_0_accuracy: 0.50518 |  0:00:15s\n",
            "epoch 4  | loss: 0.91491 | val_0_accuracy: 0.60212 |  0:00:19s\n",
            "epoch 5  | loss: 0.8225  | val_0_accuracy: 0.56498 |  0:00:23s\n",
            "epoch 6  | loss: 0.81845 | val_0_accuracy: 0.62802 |  0:00:27s\n",
            "epoch 7  | loss: 0.7976  | val_0_accuracy: 0.58398 |  0:00:31s\n",
            "epoch 8  | loss: 0.78493 | val_0_accuracy: 0.62025 |  0:00:35s\n",
            "epoch 9  | loss: 0.77635 | val_0_accuracy: 0.62975 |  0:00:39s\n",
            "epoch 10 | loss: 0.7525  | val_0_accuracy: 0.62953 |  0:00:43s\n",
            "epoch 11 | loss: 0.7463  | val_0_accuracy: 0.61399 |  0:00:46s\n",
            "epoch 12 | loss: 0.74523 | val_0_accuracy: 0.57966 |  0:00:50s\n",
            "epoch 13 | loss: 0.75884 | val_0_accuracy: 0.62694 |  0:00:54s\n",
            "epoch 14 | loss: 0.732   | val_0_accuracy: 0.64745 |  0:00:58s\n",
            "epoch 15 | loss: 0.72849 | val_0_accuracy: 0.63795 |  0:01:02s\n",
            "epoch 16 | loss: 0.71708 | val_0_accuracy: 0.65307 |  0:01:06s\n",
            "epoch 17 | loss: 0.70834 | val_0_accuracy: 0.61507 |  0:01:10s\n",
            "epoch 18 | loss: 0.71514 | val_0_accuracy: 0.64551 |  0:01:13s\n",
            "epoch 19 | loss: 0.69571 | val_0_accuracy: 0.68156 |  0:01:17s\n",
            "epoch 20 | loss: 0.68779 | val_0_accuracy: 0.67228 |  0:01:21s\n",
            "epoch 21 | loss: 0.67839 | val_0_accuracy: 0.68523 |  0:01:25s\n",
            "epoch 22 | loss: 0.66942 | val_0_accuracy: 0.6753  |  0:01:29s\n",
            "epoch 23 | loss: 0.66248 | val_0_accuracy: 0.67897 |  0:01:33s\n",
            "epoch 24 | loss: 0.65893 | val_0_accuracy: 0.67832 |  0:01:37s\n",
            "epoch 25 | loss: 0.65324 | val_0_accuracy: 0.6848  |  0:01:41s\n",
            "epoch 26 | loss: 0.65041 | val_0_accuracy: 0.67746 |  0:01:45s\n",
            "epoch 27 | loss: 0.64319 | val_0_accuracy: 0.67876 |  0:01:49s\n",
            "epoch 28 | loss: 0.63903 | val_0_accuracy: 0.67444 |  0:01:52s\n",
            "epoch 29 | loss: 0.63424 | val_0_accuracy: 0.6861  |  0:01:56s\n",
            "epoch 30 | loss: 0.63577 | val_0_accuracy: 0.66472 |  0:02:00s\n",
            "epoch 31 | loss: 0.62605 | val_0_accuracy: 0.71265 |  0:02:04s\n",
            "epoch 32 | loss: 0.62144 | val_0_accuracy: 0.68199 |  0:02:08s\n",
            "epoch 33 | loss: 0.61358 | val_0_accuracy: 0.63061 |  0:02:12s\n",
            "epoch 34 | loss: 0.6112  | val_0_accuracy: 0.68502 |  0:02:16s\n",
            "epoch 35 | loss: 0.60312 | val_0_accuracy: 0.69948 |  0:02:20s\n",
            "epoch 36 | loss: 0.61998 | val_0_accuracy: 0.68048 |  0:02:24s\n",
            "epoch 37 | loss: 0.60264 | val_0_accuracy: 0.69862 |  0:02:29s\n",
            "epoch 38 | loss: 0.59187 | val_0_accuracy: 0.71481 |  0:02:33s\n",
            "epoch 39 | loss: 0.58523 | val_0_accuracy: 0.71244 |  0:02:36s\n",
            "epoch 40 | loss: 0.59624 | val_0_accuracy: 0.7092  |  0:02:40s\n",
            "epoch 41 | loss: 0.62029 | val_0_accuracy: 0.70466 |  0:02:44s\n",
            "epoch 42 | loss: 0.59272 | val_0_accuracy: 0.70596 |  0:02:48s\n",
            "epoch 43 | loss: 0.57914 | val_0_accuracy: 0.71308 |  0:02:52s\n",
            "epoch 44 | loss: 0.57297 | val_0_accuracy: 0.71848 |  0:02:56s\n",
            "epoch 45 | loss: 0.56842 | val_0_accuracy: 0.71114 |  0:03:00s\n",
            "epoch 46 | loss: 0.55968 | val_0_accuracy: 0.70553 |  0:03:04s\n",
            "epoch 47 | loss: 0.56349 | val_0_accuracy: 0.69603 |  0:03:08s\n",
            "epoch 48 | loss: 0.56466 | val_0_accuracy: 0.66818 |  0:03:12s\n",
            "epoch 49 | loss: 0.58905 | val_0_accuracy: 0.70725 |  0:03:16s\n",
            "epoch 50 | loss: 0.57604 | val_0_accuracy: 0.72517 |  0:03:20s\n",
            "epoch 51 | loss: 0.56041 | val_0_accuracy: 0.72323 |  0:03:24s\n",
            "epoch 52 | loss: 0.56233 | val_0_accuracy: 0.6807  |  0:03:28s\n",
            "epoch 53 | loss: 0.57064 | val_0_accuracy: 0.71244 |  0:03:32s\n",
            "epoch 54 | loss: 0.55726 | val_0_accuracy: 0.71114 |  0:03:36s\n",
            "epoch 55 | loss: 0.56376 | val_0_accuracy: 0.72906 |  0:03:40s\n",
            "epoch 56 | loss: 0.5495  | val_0_accuracy: 0.72949 |  0:03:44s\n",
            "epoch 57 | loss: 0.54593 | val_0_accuracy: 0.70963 |  0:03:48s\n",
            "epoch 58 | loss: 0.53207 | val_0_accuracy: 0.7459  |  0:03:52s\n",
            "epoch 59 | loss: 0.53609 | val_0_accuracy: 0.73705 |  0:03:56s\n",
            "epoch 60 | loss: 0.53746 | val_0_accuracy: 0.73748 |  0:04:00s\n",
            "epoch 61 | loss: 0.54295 | val_0_accuracy: 0.72647 |  0:04:04s\n",
            "epoch 62 | loss: 0.52748 | val_0_accuracy: 0.73294 |  0:04:08s\n",
            "epoch 63 | loss: 0.521   | val_0_accuracy: 0.71049 |  0:04:11s\n",
            "epoch 64 | loss: 0.51819 | val_0_accuracy: 0.74698 |  0:04:15s\n",
            "epoch 65 | loss: 0.51482 | val_0_accuracy: 0.75475 |  0:04:20s\n",
            "epoch 66 | loss: 0.50853 | val_0_accuracy: 0.74352 |  0:04:23s\n",
            "epoch 67 | loss: 0.50965 | val_0_accuracy: 0.74352 |  0:04:27s\n",
            "epoch 68 | loss: 0.50132 | val_0_accuracy: 0.73748 |  0:04:31s\n",
            "epoch 69 | loss: 0.49805 | val_0_accuracy: 0.7446  |  0:04:35s\n",
            "epoch 70 | loss: 0.49389 | val_0_accuracy: 0.75561 |  0:04:39s\n",
            "epoch 71 | loss: 0.50804 | val_0_accuracy: 0.74633 |  0:04:43s\n",
            "epoch 72 | loss: 0.50022 | val_0_accuracy: 0.74568 |  0:04:47s\n",
            "epoch 73 | loss: 0.48976 | val_0_accuracy: 0.75972 |  0:04:51s\n",
            "epoch 74 | loss: 0.48245 | val_0_accuracy: 0.75345 |  0:04:55s\n",
            "epoch 75 | loss: 0.48031 | val_0_accuracy: 0.77807 |  0:04:59s\n",
            "epoch 76 | loss: 0.47925 | val_0_accuracy: 0.76209 |  0:05:03s\n",
            "epoch 77 | loss: 0.4721  | val_0_accuracy: 0.75842 |  0:05:07s\n",
            "epoch 78 | loss: 0.47139 | val_0_accuracy: 0.7405  |  0:05:11s\n",
            "epoch 79 | loss: 0.47128 | val_0_accuracy: 0.77116 |  0:05:15s\n",
            "epoch 80 | loss: 0.46763 | val_0_accuracy: 0.76317 |  0:05:19s\n",
            "epoch 81 | loss: 0.46949 | val_0_accuracy: 0.7677  |  0:05:23s\n",
            "epoch 82 | loss: 0.46762 | val_0_accuracy: 0.76662 |  0:05:27s\n",
            "epoch 83 | loss: 0.48132 | val_0_accuracy: 0.76425 |  0:05:31s\n",
            "epoch 84 | loss: 0.48799 | val_0_accuracy: 0.75345 |  0:05:35s\n",
            "epoch 85 | loss: 0.46828 | val_0_accuracy: 0.75151 |  0:05:39s\n",
            "\n",
            "Early stopping occurred at epoch 85 with best_epoch = 75 and best_val_0_accuracy = 0.77807\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 09:19:55,597]\u001b[0m Trial 11 finished with value: 0.7780656303972366 and parameters: {'n_d': 11, 'n_a': 63, 'n_steps': 5, 'gamma': 1.3877049314074026, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.3889100229700468}. Best is trial 2 with value: 0.8009499136442142.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       826\n",
            "           1       0.62      0.59      0.60       825\n",
            "           2       0.78      0.92      0.84       822\n",
            "           3       0.99      1.00      0.99       779\n",
            "           4       0.56      0.51      0.53       761\n",
            "           5       0.66      0.60      0.63       619\n",
            "\n",
            "    accuracy                           0.78      4632\n",
            "   macro avg       0.77      0.77      0.77      4632\n",
            "weighted avg       0.77      0.78      0.77      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.47127 | val_0_accuracy: 0.54534 |  0:00:03s\n",
            "epoch 1  | loss: 1.07714 | val_0_accuracy: 0.54102 |  0:00:07s\n",
            "epoch 2  | loss: 1.00607 | val_0_accuracy: 0.59434 |  0:00:10s\n",
            "epoch 3  | loss: 0.98215 | val_0_accuracy: 0.58139 |  0:00:14s\n",
            "epoch 4  | loss: 0.87591 | val_0_accuracy: 0.55095 |  0:00:17s\n",
            "epoch 5  | loss: 0.8224  | val_0_accuracy: 0.53627 |  0:00:21s\n",
            "epoch 6  | loss: 0.79324 | val_0_accuracy: 0.63752 |  0:00:24s\n",
            "epoch 7  | loss: 0.77088 | val_0_accuracy: 0.64443 |  0:00:28s\n",
            "epoch 8  | loss: 0.76568 | val_0_accuracy: 0.63687 |  0:00:31s\n",
            "epoch 9  | loss: 0.74433 | val_0_accuracy: 0.63083 |  0:00:35s\n",
            "epoch 10 | loss: 0.7595  | val_0_accuracy: 0.6345  |  0:00:38s\n",
            "epoch 11 | loss: 0.73493 | val_0_accuracy: 0.59218 |  0:00:41s\n",
            "epoch 12 | loss: 0.74223 | val_0_accuracy: 0.61269 |  0:00:45s\n",
            "epoch 13 | loss: 0.76506 | val_0_accuracy: 0.61615 |  0:00:48s\n",
            "epoch 14 | loss: 0.75039 | val_0_accuracy: 0.6468  |  0:00:52s\n",
            "epoch 15 | loss: 0.72598 | val_0_accuracy: 0.65587 |  0:00:55s\n",
            "epoch 16 | loss: 0.73158 | val_0_accuracy: 0.66688 |  0:00:59s\n",
            "epoch 17 | loss: 0.7196  | val_0_accuracy: 0.65091 |  0:01:02s\n",
            "epoch 18 | loss: 0.70225 | val_0_accuracy: 0.66019 |  0:01:06s\n",
            "epoch 19 | loss: 0.69214 | val_0_accuracy: 0.65522 |  0:01:09s\n",
            "epoch 20 | loss: 0.68175 | val_0_accuracy: 0.65004 |  0:01:13s\n",
            "epoch 21 | loss: 0.67662 | val_0_accuracy: 0.64292 |  0:01:16s\n",
            "epoch 22 | loss: 0.67789 | val_0_accuracy: 0.6712  |  0:01:19s\n",
            "epoch 23 | loss: 0.67294 | val_0_accuracy: 0.62414 |  0:01:23s\n",
            "epoch 24 | loss: 0.70189 | val_0_accuracy: 0.61852 |  0:01:26s\n",
            "epoch 25 | loss: 0.70715 | val_0_accuracy: 0.65371 |  0:01:30s\n",
            "epoch 26 | loss: 0.68011 | val_0_accuracy: 0.66926 |  0:01:33s\n",
            "epoch 27 | loss: 0.67166 | val_0_accuracy: 0.67832 |  0:01:37s\n",
            "epoch 28 | loss: 0.66035 | val_0_accuracy: 0.68631 |  0:01:40s\n",
            "epoch 29 | loss: 0.65456 | val_0_accuracy: 0.68459 |  0:01:44s\n",
            "epoch 30 | loss: 0.65904 | val_0_accuracy: 0.68307 |  0:01:47s\n",
            "epoch 31 | loss: 0.6539  | val_0_accuracy: 0.6889  |  0:01:51s\n",
            "epoch 32 | loss: 0.64961 | val_0_accuracy: 0.6861  |  0:01:54s\n",
            "epoch 33 | loss: 0.67631 | val_0_accuracy: 0.65415 |  0:01:58s\n",
            "epoch 34 | loss: 0.65834 | val_0_accuracy: 0.69214 |  0:02:01s\n",
            "epoch 35 | loss: 0.63822 | val_0_accuracy: 0.65436 |  0:02:05s\n",
            "epoch 36 | loss: 0.63059 | val_0_accuracy: 0.70682 |  0:02:09s\n",
            "epoch 37 | loss: 0.63512 | val_0_accuracy: 0.69927 |  0:02:13s\n",
            "epoch 38 | loss: 0.62427 | val_0_accuracy: 0.69883 |  0:02:16s\n",
            "epoch 39 | loss: 0.62234 | val_0_accuracy: 0.7038  |  0:02:19s\n",
            "epoch 40 | loss: 0.61234 | val_0_accuracy: 0.7092  |  0:02:23s\n",
            "epoch 41 | loss: 0.62339 | val_0_accuracy: 0.65285 |  0:02:26s\n",
            "epoch 42 | loss: 0.62966 | val_0_accuracy: 0.72042 |  0:02:30s\n",
            "epoch 43 | loss: 0.61424 | val_0_accuracy: 0.71459 |  0:02:33s\n",
            "epoch 44 | loss: 0.61108 | val_0_accuracy: 0.71287 |  0:02:37s\n",
            "epoch 45 | loss: 0.59782 | val_0_accuracy: 0.70272 |  0:02:40s\n",
            "epoch 46 | loss: 0.59522 | val_0_accuracy: 0.71481 |  0:02:44s\n",
            "epoch 47 | loss: 0.59139 | val_0_accuracy: 0.70747 |  0:02:47s\n",
            "epoch 48 | loss: 0.58313 | val_0_accuracy: 0.70747 |  0:02:51s\n",
            "epoch 49 | loss: 0.58732 | val_0_accuracy: 0.70812 |  0:02:54s\n",
            "epoch 50 | loss: 0.58136 | val_0_accuracy: 0.72949 |  0:02:58s\n",
            "epoch 51 | loss: 0.57486 | val_0_accuracy: 0.71373 |  0:03:01s\n",
            "epoch 52 | loss: 0.56966 | val_0_accuracy: 0.72453 |  0:03:05s\n",
            "epoch 53 | loss: 0.56678 | val_0_accuracy: 0.68998 |  0:03:08s\n",
            "epoch 54 | loss: 0.56519 | val_0_accuracy: 0.71654 |  0:03:12s\n",
            "epoch 55 | loss: 0.56313 | val_0_accuracy: 0.7282  |  0:03:15s\n",
            "epoch 56 | loss: 0.55397 | val_0_accuracy: 0.69948 |  0:03:18s\n",
            "epoch 57 | loss: 0.55198 | val_0_accuracy: 0.70855 |  0:03:22s\n",
            "epoch 58 | loss: 0.54823 | val_0_accuracy: 0.74763 |  0:03:25s\n",
            "epoch 59 | loss: 0.5498  | val_0_accuracy: 0.71395 |  0:03:29s\n",
            "epoch 60 | loss: 0.5456  | val_0_accuracy: 0.68696 |  0:03:32s\n",
            "epoch 61 | loss: 0.54055 | val_0_accuracy: 0.71438 |  0:03:36s\n",
            "epoch 62 | loss: 0.53765 | val_0_accuracy: 0.69797 |  0:03:39s\n",
            "epoch 63 | loss: 0.53466 | val_0_accuracy: 0.73316 |  0:03:43s\n",
            "epoch 64 | loss: 0.53088 | val_0_accuracy: 0.72841 |  0:03:46s\n",
            "epoch 65 | loss: 0.54749 | val_0_accuracy: 0.70898 |  0:03:50s\n",
            "epoch 66 | loss: 0.54382 | val_0_accuracy: 0.70877 |  0:03:53s\n",
            "epoch 67 | loss: 0.55266 | val_0_accuracy: 0.69106 |  0:03:57s\n",
            "epoch 68 | loss: 0.5511  | val_0_accuracy: 0.73208 |  0:04:00s\n",
            "\n",
            "Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_accuracy = 0.74763\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 09:23:58,019]\u001b[0m Trial 12 finished with value: 0.7476252158894646 and parameters: {'n_d': 19, 'n_a': 48, 'n_steps': 5, 'gamma': 1.6701658940926012, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.28536970291783736}. Best is trial 2 with value: 0.8009499136442142.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       826\n",
            "           1       0.57      0.47      0.51       825\n",
            "           2       0.71      0.91      0.80       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.52      0.49      0.50       761\n",
            "           5       0.62      0.57      0.59       619\n",
            "\n",
            "    accuracy                           0.75      4632\n",
            "   macro avg       0.73      0.74      0.73      4632\n",
            "weighted avg       0.74      0.75      0.74      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.64958 | val_0_accuracy: 0.50432 |  0:00:05s\n",
            "epoch 1  | loss: 1.12246 | val_0_accuracy: 0.5408  |  0:00:10s\n",
            "epoch 2  | loss: 0.98394 | val_0_accuracy: 0.56671 |  0:00:15s\n",
            "epoch 3  | loss: 1.06621 | val_0_accuracy: 0.56261 |  0:00:20s\n",
            "epoch 4  | loss: 0.93177 | val_0_accuracy: 0.5747  |  0:00:25s\n",
            "epoch 5  | loss: 0.90773 | val_0_accuracy: 0.59218 |  0:00:31s\n",
            "epoch 6  | loss: 0.87899 | val_0_accuracy: 0.61118 |  0:00:36s\n",
            "epoch 7  | loss: 0.83768 | val_0_accuracy: 0.61356 |  0:00:41s\n",
            "epoch 8  | loss: 0.84294 | val_0_accuracy: 0.60384 |  0:00:47s\n",
            "epoch 9  | loss: 0.84593 | val_0_accuracy: 0.60147 |  0:00:52s\n",
            "epoch 10 | loss: 0.80718 | val_0_accuracy: 0.62651 |  0:00:57s\n",
            "epoch 11 | loss: 0.7658  | val_0_accuracy: 0.58117 |  0:01:03s\n",
            "epoch 12 | loss: 0.78023 | val_0_accuracy: 0.6304  |  0:01:08s\n",
            "epoch 13 | loss: 0.76321 | val_0_accuracy: 0.63882 |  0:01:13s\n",
            "epoch 14 | loss: 0.75313 | val_0_accuracy: 0.64249 |  0:01:19s\n",
            "epoch 15 | loss: 0.74754 | val_0_accuracy: 0.64896 |  0:01:24s\n",
            "epoch 16 | loss: 0.77774 | val_0_accuracy: 0.64853 |  0:01:30s\n",
            "epoch 17 | loss: 0.74328 | val_0_accuracy: 0.64033 |  0:01:35s\n",
            "epoch 18 | loss: 0.71963 | val_0_accuracy: 0.65177 |  0:01:40s\n",
            "epoch 19 | loss: 0.72372 | val_0_accuracy: 0.6345  |  0:01:45s\n",
            "epoch 20 | loss: 0.73134 | val_0_accuracy: 0.66235 |  0:01:50s\n",
            "epoch 21 | loss: 0.70359 | val_0_accuracy: 0.5978  |  0:01:56s\n",
            "epoch 22 | loss: 0.69494 | val_0_accuracy: 0.58398 |  0:02:01s\n",
            "epoch 23 | loss: 0.69266 | val_0_accuracy: 0.59175 |  0:02:06s\n",
            "epoch 24 | loss: 0.69683 | val_0_accuracy: 0.46978 |  0:02:11s\n",
            "epoch 25 | loss: 0.6958  | val_0_accuracy: 0.52029 |  0:02:16s\n",
            "epoch 26 | loss: 0.6944  | val_0_accuracy: 0.4756  |  0:02:23s\n",
            "epoch 27 | loss: 0.68735 | val_0_accuracy: 0.62889 |  0:02:28s\n",
            "epoch 28 | loss: 0.68013 | val_0_accuracy: 0.48143 |  0:02:33s\n",
            "epoch 29 | loss: 0.68275 | val_0_accuracy: 0.60147 |  0:02:39s\n",
            "epoch 30 | loss: 0.70113 | val_0_accuracy: 0.46265 |  0:02:44s\n",
            "\n",
            "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_accuracy = 0.66235\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 09:26:45,580]\u001b[0m Trial 13 finished with value: 0.6623488773747841 and parameters: {'n_d': 33, 'n_a': 64, 'n_steps': 8, 'gamma': 1.4497866791446188, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.13500092359188443}. Best is trial 2 with value: 0.8009499136442142.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       826\n",
            "           1       0.40      0.32      0.36       825\n",
            "           2       0.56      0.79      0.66       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.42      0.53      0.47       761\n",
            "           5       0.61      0.25      0.36       619\n",
            "\n",
            "    accuracy                           0.66      4632\n",
            "   macro avg       0.66      0.65      0.64      4632\n",
            "weighted avg       0.67      0.66      0.65      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.49582 | val_0_accuracy: 0.56455 |  0:00:03s\n",
            "epoch 1  | loss: 1.0224  | val_0_accuracy: 0.58225 |  0:00:06s\n",
            "epoch 2  | loss: 0.86979 | val_0_accuracy: 0.61485 |  0:00:09s\n",
            "epoch 3  | loss: 0.79153 | val_0_accuracy: 0.65371 |  0:00:12s\n",
            "epoch 4  | loss: 0.74889 | val_0_accuracy: 0.67055 |  0:00:15s\n",
            "epoch 5  | loss: 0.72788 | val_0_accuracy: 0.6617  |  0:00:19s\n",
            "epoch 6  | loss: 0.7077  | val_0_accuracy: 0.67336 |  0:00:22s\n",
            "epoch 7  | loss: 0.68974 | val_0_accuracy: 0.68588 |  0:00:25s\n",
            "epoch 8  | loss: 0.68021 | val_0_accuracy: 0.67336 |  0:00:28s\n",
            "epoch 9  | loss: 0.67895 | val_0_accuracy: 0.69085 |  0:00:31s\n",
            "epoch 10 | loss: 0.69177 | val_0_accuracy: 0.68566 |  0:00:34s\n",
            "epoch 11 | loss: 0.66506 | val_0_accuracy: 0.69948 |  0:00:37s\n",
            "epoch 12 | loss: 0.65209 | val_0_accuracy: 0.69991 |  0:00:41s\n",
            "epoch 13 | loss: 0.64097 | val_0_accuracy: 0.69646 |  0:00:44s\n",
            "epoch 14 | loss: 0.63067 | val_0_accuracy: 0.69344 |  0:00:47s\n",
            "epoch 15 | loss: 0.62554 | val_0_accuracy: 0.70704 |  0:00:50s\n",
            "epoch 16 | loss: 0.62488 | val_0_accuracy: 0.69581 |  0:00:53s\n",
            "epoch 17 | loss: 0.61358 | val_0_accuracy: 0.71718 |  0:00:56s\n",
            "epoch 18 | loss: 0.60624 | val_0_accuracy: 0.71092 |  0:00:59s\n",
            "epoch 19 | loss: 0.60163 | val_0_accuracy: 0.69344 |  0:01:02s\n",
            "epoch 20 | loss: 0.61067 | val_0_accuracy: 0.72474 |  0:01:05s\n",
            "epoch 21 | loss: 0.59118 | val_0_accuracy: 0.73381 |  0:01:08s\n",
            "epoch 22 | loss: 0.5851  | val_0_accuracy: 0.71913 |  0:01:12s\n",
            "epoch 23 | loss: 0.59259 | val_0_accuracy: 0.7174  |  0:01:15s\n",
            "epoch 24 | loss: 0.59054 | val_0_accuracy: 0.71805 |  0:01:18s\n",
            "epoch 25 | loss: 0.57977 | val_0_accuracy: 0.7228  |  0:01:21s\n",
            "epoch 26 | loss: 0.57575 | val_0_accuracy: 0.71999 |  0:01:24s\n",
            "epoch 27 | loss: 0.56924 | val_0_accuracy: 0.73446 |  0:01:27s\n",
            "epoch 28 | loss: 0.56505 | val_0_accuracy: 0.73359 |  0:01:30s\n",
            "epoch 29 | loss: 0.57243 | val_0_accuracy: 0.73554 |  0:01:33s\n",
            "epoch 30 | loss: 0.57499 | val_0_accuracy: 0.72539 |  0:01:37s\n",
            "epoch 31 | loss: 0.55842 | val_0_accuracy: 0.72129 |  0:01:40s\n",
            "epoch 32 | loss: 0.54938 | val_0_accuracy: 0.73705 |  0:01:43s\n",
            "epoch 33 | loss: 0.54689 | val_0_accuracy: 0.73597 |  0:01:46s\n",
            "epoch 34 | loss: 0.54039 | val_0_accuracy: 0.72798 |  0:01:49s\n",
            "epoch 35 | loss: 0.53676 | val_0_accuracy: 0.72776 |  0:01:52s\n",
            "epoch 36 | loss: 0.53635 | val_0_accuracy: 0.74827 |  0:01:55s\n",
            "epoch 37 | loss: 0.52836 | val_0_accuracy: 0.73705 |  0:01:58s\n",
            "epoch 38 | loss: 0.52527 | val_0_accuracy: 0.74676 |  0:02:02s\n",
            "epoch 39 | loss: 0.52591 | val_0_accuracy: 0.75173 |  0:02:05s\n",
            "epoch 40 | loss: 0.52415 | val_0_accuracy: 0.75065 |  0:02:08s\n",
            "epoch 41 | loss: 0.51513 | val_0_accuracy: 0.7582  |  0:02:11s\n",
            "epoch 42 | loss: 0.51679 | val_0_accuracy: 0.75734 |  0:02:14s\n",
            "epoch 43 | loss: 0.51052 | val_0_accuracy: 0.75583 |  0:02:17s\n",
            "epoch 44 | loss: 0.50953 | val_0_accuracy: 0.7541  |  0:02:20s\n",
            "epoch 45 | loss: 0.50106 | val_0_accuracy: 0.76878 |  0:02:23s\n",
            "epoch 46 | loss: 0.49459 | val_0_accuracy: 0.76317 |  0:02:26s\n",
            "epoch 47 | loss: 0.51854 | val_0_accuracy: 0.74439 |  0:02:29s\n",
            "epoch 48 | loss: 0.51572 | val_0_accuracy: 0.75907 |  0:02:33s\n",
            "epoch 49 | loss: 0.49832 | val_0_accuracy: 0.75799 |  0:02:36s\n",
            "epoch 50 | loss: 0.49717 | val_0_accuracy: 0.76144 |  0:02:39s\n",
            "epoch 51 | loss: 0.48598 | val_0_accuracy: 0.76511 |  0:02:42s\n",
            "epoch 52 | loss: 0.48609 | val_0_accuracy: 0.76684 |  0:02:45s\n",
            "epoch 53 | loss: 0.48052 | val_0_accuracy: 0.76727 |  0:02:48s\n",
            "epoch 54 | loss: 0.47373 | val_0_accuracy: 0.76274 |  0:02:51s\n",
            "epoch 55 | loss: 0.47401 | val_0_accuracy: 0.76446 |  0:02:54s\n",
            "\n",
            "Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_accuracy = 0.76878\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-03 09:29:41,848]\u001b[0m Trial 14 finished with value: 0.7687823834196891 and parameters: {'n_d': 24, 'n_a': 52, 'n_steps': 5, 'gamma': 1.8178616071133977, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.33934668644101934}. Best is trial 2 with value: 0.8009499136442142.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       826\n",
            "           1       0.57      0.62      0.59       825\n",
            "           2       0.79      0.91      0.84       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.53      0.50      0.51       761\n",
            "           5       0.69      0.52      0.59       619\n",
            "\n",
            "    accuracy                           0.77      4632\n",
            "   macro avg       0.76      0.76      0.76      4632\n",
            "weighted avg       0.77      0.77      0.77      4632\n",
            "\n",
            " Best params for fold : [5/10]\n",
            "{'n_d': 42, 'n_a': 60, 'n_steps': 6, 'gamma': 1.575059266508576, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.20431519971315895}\n",
            "Saved best_params at : outputs/pytorch_tabnet/best_params/fold_5_best_params.txt\n",
            "Device used : cuda\n",
            "No early stopping will be performed, last training weights will be used.\n",
            "epoch 0  | loss: 1.58986 |  0:00:04s\n",
            "epoch 1  | loss: 1.0617  |  0:00:07s\n",
            "epoch 2  | loss: 0.93178 |  0:00:11s\n",
            "epoch 3  | loss: 0.83513 |  0:00:15s\n",
            "epoch 4  | loss: 0.79425 |  0:00:19s\n",
            "epoch 5  | loss: 0.76775 |  0:00:23s\n",
            "epoch 6  | loss: 0.76954 |  0:00:27s\n",
            "epoch 7  | loss: 0.7402  |  0:00:35s\n",
            "epoch 8  | loss: 0.72844 |  0:00:39s\n",
            "epoch 9  | loss: 0.71534 |  0:00:43s\n",
            "epoch 10 | loss: 0.69666 |  0:00:47s\n",
            "epoch 11 | loss: 0.68422 |  0:00:51s\n",
            "epoch 12 | loss: 0.68794 |  0:00:55s\n",
            "epoch 13 | loss: 0.69521 |  0:00:59s\n",
            "epoch 14 | loss: 0.68804 |  0:01:03s\n",
            "epoch 15 | loss: 0.66713 |  0:01:07s\n",
            "epoch 16 | loss: 0.65573 |  0:01:10s\n",
            "epoch 17 | loss: 0.65991 |  0:01:14s\n",
            "epoch 18 | loss: 0.64906 |  0:01:18s\n",
            "epoch 19 | loss: 0.63466 |  0:01:22s\n",
            "epoch 20 | loss: 0.62981 |  0:01:26s\n",
            "epoch 21 | loss: 0.62243 |  0:01:30s\n",
            "epoch 22 | loss: 0.61172 |  0:01:34s\n",
            "epoch 23 | loss: 0.60756 |  0:01:38s\n",
            "epoch 24 | loss: 0.59841 |  0:01:42s\n",
            "epoch 25 | loss: 0.59878 |  0:01:46s\n",
            "epoch 26 | loss: 0.59429 |  0:01:50s\n",
            "epoch 27 | loss: 0.59266 |  0:01:53s\n",
            "epoch 28 | loss: 0.5817  |  0:01:57s\n",
            "epoch 29 | loss: 0.57617 |  0:02:01s\n",
            "epoch 30 | loss: 0.57372 |  0:02:05s\n",
            "epoch 31 | loss: 0.57452 |  0:02:09s\n",
            "epoch 32 | loss: 0.60333 |  0:02:13s\n",
            "epoch 33 | loss: 0.60717 |  0:02:17s\n",
            "epoch 34 | loss: 0.5784  |  0:02:20s\n",
            "epoch 35 | loss: 0.56362 |  0:02:24s\n",
            "epoch 36 | loss: 0.55576 |  0:02:28s\n",
            "epoch 37 | loss: 0.55276 |  0:02:32s\n",
            "epoch 38 | loss: 0.54823 |  0:02:36s\n",
            "epoch 39 | loss: 0.54444 |  0:02:39s\n",
            "epoch 40 | loss: 0.53519 |  0:02:43s\n",
            "epoch 41 | loss: 0.53571 |  0:02:47s\n",
            "epoch 42 | loss: 0.5475  |  0:02:51s\n",
            "epoch 43 | loss: 0.58447 |  0:02:55s\n",
            "epoch 44 | loss: 0.55209 |  0:02:59s\n",
            "epoch 45 | loss: 0.54963 |  0:03:03s\n",
            "epoch 46 | loss: 0.57369 |  0:03:06s\n",
            "epoch 47 | loss: 0.54231 |  0:03:10s\n",
            "epoch 48 | loss: 0.52768 |  0:03:14s\n",
            "epoch 49 | loss: 0.51969 |  0:03:19s\n",
            "epoch 50 | loss: 0.51626 |  0:03:23s\n",
            "epoch 51 | loss: 0.51282 |  0:03:27s\n",
            "epoch 52 | loss: 0.50345 |  0:03:31s\n",
            "epoch 53 | loss: 0.50029 |  0:03:34s\n",
            "epoch 54 | loss: 0.49656 |  0:03:38s\n",
            "epoch 55 | loss: 0.49521 |  0:03:42s\n",
            "epoch 56 | loss: 0.49159 |  0:03:46s\n",
            "epoch 57 | loss: 0.4946  |  0:03:50s\n",
            "epoch 58 | loss: 0.48955 |  0:03:54s\n",
            "epoch 59 | loss: 0.47943 |  0:03:58s\n",
            "epoch 60 | loss: 0.48089 |  0:04:01s\n",
            "epoch 61 | loss: 0.47581 |  0:04:05s\n",
            "epoch 62 | loss: 0.47253 |  0:04:09s\n",
            "epoch 63 | loss: 0.489   |  0:04:13s\n",
            "epoch 64 | loss: 0.47114 |  0:04:17s\n",
            "epoch 65 | loss: 0.46734 |  0:04:21s\n",
            "epoch 66 | loss: 0.46096 |  0:04:25s\n",
            "epoch 67 | loss: 0.46018 |  0:04:28s\n",
            "epoch 68 | loss: 0.45598 |  0:04:32s\n",
            "epoch 69 | loss: 0.45706 |  0:04:36s\n",
            "epoch 70 | loss: 0.45147 |  0:04:40s\n",
            "epoch 71 | loss: 0.44732 |  0:04:44s\n",
            "epoch 72 | loss: 0.46355 |  0:04:47s\n",
            "epoch 73 | loss: 0.47986 |  0:04:51s\n",
            "epoch 74 | loss: 0.45877 |  0:04:55s\n",
            "epoch 75 | loss: 0.45748 |  0:04:59s\n",
            "epoch 76 | loss: 0.44644 |  0:05:03s\n",
            "epoch 77 | loss: 0.44374 |  0:05:07s\n",
            "epoch 78 | loss: 0.43949 |  0:05:10s\n",
            "epoch 79 | loss: 0.43275 |  0:05:14s\n",
            "epoch 80 | loss: 0.45294 |  0:05:18s\n",
            "epoch 81 | loss: 0.44033 |  0:05:22s\n",
            "epoch 82 | loss: 0.43313 |  0:05:26s\n",
            "epoch 83 | loss: 0.42651 |  0:05:30s\n",
            "epoch 84 | loss: 0.42512 |  0:05:34s\n",
            "epoch 85 | loss: 0.42035 |  0:05:38s\n",
            "epoch 86 | loss: 0.41944 |  0:05:41s\n",
            "epoch 87 | loss: 0.43677 |  0:05:45s\n",
            "epoch 88 | loss: 0.44336 |  0:05:49s\n",
            "epoch 89 | loss: 0.42715 |  0:05:53s\n",
            "epoch 90 | loss: 0.4157  |  0:05:57s\n",
            "epoch 91 | loss: 0.41199 |  0:06:01s\n",
            "epoch 92 | loss: 0.41267 |  0:06:05s\n",
            "epoch 93 | loss: 0.41001 |  0:06:09s\n",
            "epoch 94 | loss: 0.40166 |  0:06:13s\n",
            "epoch 95 | loss: 0.40682 |  0:06:16s\n",
            "epoch 96 | loss: 0.432   |  0:06:20s\n",
            "epoch 97 | loss: 0.43302 |  0:06:24s\n",
            "epoch 98 | loss: 0.40723 |  0:06:28s\n",
            "epoch 99 | loss: 0.41577 |  0:06:32s\n",
            "[++] Saving the model and parameters in corresponding directories\n",
            "[++] Ended the training process for fold 5\n"
          ]
        }
      ],
      "source": [
        "train(fold_dict = fold_dict,\n",
        "      fold = fold,\n",
        "      model_name=model_name,\n",
        "      sc_df=use_df,\n",
        "      tar_col=tar_col,\n",
        "      optim=optimizer,\n",
        "      optim_trial = 15)\n",
        "print(f\"[++] Ended the training process for fold {fold}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja5dUXmqsCFF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afu4nJyHu-sp"
      },
      "source": [
        "Fold 0 has started running on 20-05-22 \n",
        "\n",
        "\n",
        "Fold 0 has completed sucessfully on 17:00 20-05-22\n",
        "\n",
        "Fold 1 has started running at 15:15 21-05-22\n",
        "\n",
        "Fold 2 has started running at 09:45 22-05-22\n",
        "\n",
        "Fold 2 has completed sucessfully on 10:58 22-05-22\n",
        "\n",
        "Fold 3 has started running at 18:40 22-05-22\n",
        "\n",
        "Fold 3 has completed sucessfully on 22-05-22\n",
        "\n",
        "Fold 4 completed sucessfully on 21:04 on 22-05-22\n",
        "\n",
        "Fold 5 started at 18:21 on 23-05-22\n",
        "\n",
        "Fold 5 completed sucessfully on 19:44 on 23-05-22\n",
        "\n",
        "Fold 6 started at 12:53 on 24-05-22\n",
        "\n",
        "Fold 6 has completed at 14:14 on 24-05-22\n",
        "\n",
        "Fold 7 started at 14:18 on 24-05-22\n",
        "\n",
        "Fold 7 execution failed due to colab gpu time limit\n",
        "\n",
        "Fold 7 trial 1 started at 11:00 on 25-05-22\n",
        "\n",
        "Fold 7 has completed sucessfully at 12:14 on 25-05-22 \n",
        "\n",
        "Fold 8 has started at 9:38 on 26-05-22\n",
        "\n",
        "Fold 8 filed due to interrupted internet connection\n",
        "\n",
        "Fold 8 trial 1 started at 13:38 on 26-05-22\n",
        "\n",
        "Fold 8 has successfully executed at 15:33 on 26-05-22\n",
        "\n",
        "Fold 9 has started at 13:35 on 27-05-22\n",
        "\n",
        "Fold 9 has completed at 14:55 on 27-05-22"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me85YLlzpUM8"
      },
      "source": [
        "Editing with rectified dataset witout duplicacy because of space values\n",
        "\n",
        "Fold 0 started at 13:21 on 28-05-22\n",
        "\n",
        "Fold 0 completed sucessfully at 14:46 on 28-05-22\n",
        "\n",
        "Fold 1 Failed to run due to some index error\n",
        "\n",
        "_____ Restarting the training process again due to data distribution failure____\n",
        "\n",
        "\n",
        "\n",
        "Fold 0 started at 10:47 on 30-05-22\n",
        "\n",
        "Fold 0 completed successfully at 12:30 on 30-05-22\n",
        "\n",
        "Fold 1 started at 8:27 on 31-05-22\n",
        "\n",
        "Fold 1 execution failed due to runtime disconnection\n",
        "\n",
        "Fold 1 started again at 9:38 on 31-05-22\n",
        "\n",
        "Fold 1 execution failed due to gpu disconnect \n",
        "\n",
        "Fold 1 started again at 8:36 on 1-06-22\n",
        "\n",
        "Fold 1 execution failed due to network disconnection\n",
        "\n",
        "Fold 1 started again at 13:11 on 01-06-22\n",
        "\n",
        "Fold 1 has succesfully executed at 14:25 on 01-06-22\n",
        "\n",
        "Fold 2 started at 14:29 on 01-06-22\n",
        "\n",
        "Fold 2 completed succesfully at 16:00 on 01-06-22\n",
        "\n",
        "Fold 3 started at 09:43 on 02-06-22\n",
        "\n",
        "Fold 3 execution failed due to gpu server disconnection \n",
        "\n",
        "Fold 3 started again at 13:34 on 02-06-22\n",
        "\n",
        "Fold 3 ran successfully at 14:47 on 02-06-22\n",
        "\n",
        "Fold 4 started at 14:48 on 02-06-22\n",
        "\n",
        "Fold 4 ran successfully at 04:01 on 02-06-22\n",
        "\n",
        "Fold 5 started at 13:51 on 03-06-22"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zICGdYlFNr13"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "train_tabnet_fold_div.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}