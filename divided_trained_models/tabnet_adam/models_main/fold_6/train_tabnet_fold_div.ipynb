{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5-jiYKypEVY",
        "outputId": "2addcbd6-5996-4774-e250-3e2e7129b799"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun  4 08:09:40 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0tPZaeupLWn",
        "outputId": "54623981-cb6f-4c2d-8525-0df5a5940329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-3.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (4.64.0)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.4.1)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.11.0+cu113)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.0.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.2.0)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 10.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.8.0-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 58.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.4)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.4 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 64.8 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 71.9 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=ea49c6021bb2c1353a6a7dd839947936feda825bc0c22d1f2867d05d30dbcbb8\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, pytorch-tabnet, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.8.0 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.0 pbr-5.9.0 pyperclip-1.8.2 pytorch-tabnet-3.1.1 stevedore-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-tabnet optuna "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vRmDYdsCpMT-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "import optuna as opt\n",
        "import torch\n",
        "import os\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L4HljGyopQs_"
      },
      "outputs": [],
      "source": [
        "def make_save_cv_model(i,model_name,model,best_params,optim,output_path=\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/cross_validated_models\"):\n",
        "\n",
        "    ''' This function saves cross validation model in the corresponding directory ( if the path does not exist it creates the path for it'''\n",
        "\n",
        "\n",
        "    if os.path.exists(os.path.join(output_path,f\"{i}_{model_name}_{optim}\")):\n",
        "        joblib.dump(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n",
        "        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/model_params.txt\"),\"w+\") as file:\n",
        "            file.write(str(best_params))\n",
        "    else:\n",
        "        os.mkdir(os.path.join(output_path,f\"{i}_{model_name}_{optim}\"))\n",
        "        joblib.dump(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n",
        "        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/model_params.txt\"),\"w+\") as file:\n",
        "            file.write(str(best_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z_M5FI9PpVA_"
      },
      "outputs": [],
      "source": [
        "def train(fold_dict,fold,model_name,sc_df,tar_col,optim,optim_trial,k_folds=10,tar_cols=\"\",verbose=1):\n",
        "\n",
        "    ''' this function is used to train the model with parameters optimization using optuna and cross validation using stratified k_folds'''\n",
        "\n",
        "    y = sc_df[tar_col]\n",
        "    x = sc_df.drop([tar_col],axis=1)\n",
        "    model_name = model_name \n",
        "    def objective(trial):\n",
        "      train_index = fold_dict[fold][\"train\"]\n",
        "      test_index = fold_dict[fold][\"test\"]\n",
        "      clf = TabNetClassifier(n_d=trial.suggest_int(\"n_d\", 8, 64),\n",
        "                              n_a =trial.suggest_int(\"n_a\", 8, 64),\n",
        "                              n_steps = trial.suggest_int(\"n_steps\",3,10),\n",
        "                              gamma =trial.suggest_float(\"gamma\", 1.0, 2.0),\n",
        "                              n_independent = trial.suggest_int(\"n_independent\",1,5),\n",
        "                              n_shared = trial.suggest_int(\"n_shared\",1,5),\n",
        "                              momentum = trial.suggest_float(\"momentum\", 0.01, 0.4),\n",
        "                              optimizer_fn = torch.optim.Adam,\n",
        "                              # scheduler_fn = torch.optim.lr_scheduler,\n",
        "                              # scheduler_params = {\"gamma\" :trial.suggest_float(\"sch-gamma\", 0.5, 0.95), \"step_size\": trial.suggest_int(\"sch_step_size\", 10, 20, 2)},\n",
        "                              verbose = verbose,\n",
        "                              device_name = \"auto\"\n",
        "                              )\n",
        "      # print(f\" train_index :: {train_index}\")\n",
        "      # print(f\" test_index :: {test_index}\")\n",
        "      X_train,X_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
        "      # print(X_train.shape, X_test.shape)\n",
        "      X_train, X_test = X_train.to_numpy(dtype=np.float64), X_test.to_numpy(dtype=np.float64)\n",
        "      Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "      Y_train, Y_test = Y_train.to_numpy(dtype=np.float64), Y_test.to_numpy(dtype=np.float64)\n",
        "      print(Y_train.shape, Y_test.shape)\n",
        "      clf.fit(X_train, Y_train,\n",
        "              eval_set=[(X_test, Y_test)],\n",
        "              eval_metric=['accuracy'])\n",
        "      Y_pred = clf.predict(X_test)\n",
        "      print(classification_report(Y_test, Y_pred, labels=[x for x in range(6)]))\n",
        "      acc = accuracy_score(Y_pred, Y_test)\n",
        "      return acc\n",
        "\n",
        "    print(f\"Starting optimization for fold : [{fold}/{k_folds}]\")\n",
        "    study = opt.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=optim_trial)\n",
        "    best_params = study.best_params\n",
        "    print(f\" Best params for fold : [{fold}/{k_folds}]\")\n",
        "    print(best_params)\n",
        "    joblib.dump(best_params,f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/best_params/comp/fold_{fold}_best_params.z\")\n",
        "    with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/best_params/fold_{fold}_best_params.txt\", \"w+\") as file:file.write(str(best_params))\n",
        "    print(f\"Saved best_params at : outputs/{model_name}/best_params/fold_{fold}_best_params.txt\")\n",
        "    train_index = fold_dict[fold][\"train\"]\n",
        "    test_index = fold_dict[fold][\"test\"]\n",
        "    X_train,X_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
        "    # print(X_train.shape, X_test.shape)\n",
        "    X_train, X_test = X_train.to_numpy(dtype=np.float64), X_test.to_numpy(dtype=np.float64)\n",
        "    Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    Y_train, Y_test = Y_train.to_numpy(dtype=np.float64), Y_test.to_numpy(dtype=np.float64)\n",
        "    clf_model = TabNetClassifier(**study.best_params)\n",
        "    clf_model.fit(X_train,Y_train)\n",
        "    Y_pred = clf_model.predict(X_test)\n",
        "    clf_report = classification_report(Y_test, Y_pred, labels=[x for x in range(6)])\n",
        "    with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/classification_report/{model_name}_{fold}_classification_report.txt\",\"w+\") as file:file.write(str(clf_report))\n",
        "    accuracy = accuracy_score(Y_pred, Y_test)\n",
        "    with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/{model_name}_{fold}_accuracy_score.txt\",\"w+\") as file:file.write(f\" accuracy :: {str(accuracy)}\")\n",
        "    try:\n",
        "        print(\"[++] Saving the model and parameters in corresponding directories\")\n",
        "        make_save_cv_model(fold,model_name,clf_model,best_params,optim=optim)\n",
        "    except:\n",
        "        print(\"[-] Failed to save the model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xNlu9Ktsq6VG"
      },
      "outputs": [],
      "source": [
        "use_df = pd.read_csv(\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/data/trainable_scaled_balanced.csv\")\n",
        "tar_col = \"PCE_categorical\"\n",
        "model_name = \"pytorch_tabnet\"\n",
        "optimizer = \"Adam\"\n",
        "fold_dict = joblib.load(\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/inputs/fold_vals/fold_data.z\")\n",
        "fold = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ9h3wayrIp_",
        "outputId": "252be418-3061-41cc-f3f4-7b2136efeb61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-04 08:10:14,798]\u001b[0m A new study created in memory with name: no-name-4deb1fd2-5d1e-4e8d-bad9-c193d492b269\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting optimization for fold : [6/10]\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.62146 | val_0_accuracy: 0.51943 |  0:00:04s\n",
            "epoch 1  | loss: 1.12912 | val_0_accuracy: 0.49784 |  0:00:08s\n",
            "epoch 2  | loss: 1.1043  | val_0_accuracy: 0.56844 |  0:00:12s\n",
            "epoch 3  | loss: 1.08207 | val_0_accuracy: 0.55181 |  0:00:17s\n",
            "epoch 4  | loss: 1.11669 | val_0_accuracy: 0.56693 |  0:00:21s\n",
            "epoch 5  | loss: 1.03224 | val_0_accuracy: 0.57275 |  0:00:25s\n",
            "epoch 6  | loss: 0.96315 | val_0_accuracy: 0.60168 |  0:00:30s\n",
            "epoch 7  | loss: 0.89346 | val_0_accuracy: 0.61118 |  0:00:34s\n",
            "epoch 8  | loss: 0.82764 | val_0_accuracy: 0.62414 |  0:00:38s\n",
            "epoch 9  | loss: 0.82639 | val_0_accuracy: 0.62953 |  0:00:43s\n",
            "epoch 10 | loss: 0.79471 | val_0_accuracy: 0.64033 |  0:00:47s\n",
            "epoch 11 | loss: 0.7704  | val_0_accuracy: 0.64465 |  0:00:51s\n",
            "epoch 12 | loss: 0.77282 | val_0_accuracy: 0.65609 |  0:00:56s\n",
            "epoch 13 | loss: 0.76677 | val_0_accuracy: 0.64767 |  0:01:00s\n",
            "epoch 14 | loss: 0.7741  | val_0_accuracy: 0.63839 |  0:01:05s\n",
            "epoch 15 | loss: 0.76148 | val_0_accuracy: 0.64465 |  0:01:14s\n",
            "epoch 16 | loss: 0.74851 | val_0_accuracy: 0.65415 |  0:01:18s\n",
            "epoch 17 | loss: 0.73334 | val_0_accuracy: 0.65782 |  0:01:22s\n",
            "epoch 18 | loss: 0.72316 | val_0_accuracy: 0.66278 |  0:01:26s\n",
            "epoch 19 | loss: 0.73085 | val_0_accuracy: 0.64076 |  0:01:31s\n",
            "epoch 20 | loss: 0.77277 | val_0_accuracy: 0.65047 |  0:01:35s\n",
            "epoch 21 | loss: 0.74501 | val_0_accuracy: 0.64551 |  0:01:39s\n",
            "epoch 22 | loss: 0.7723  | val_0_accuracy: 0.63407 |  0:01:43s\n",
            "epoch 23 | loss: 0.80357 | val_0_accuracy: 0.64853 |  0:01:48s\n",
            "epoch 24 | loss: 0.77972 | val_0_accuracy: 0.64918 |  0:01:52s\n",
            "epoch 25 | loss: 0.7596  | val_0_accuracy: 0.65307 |  0:01:56s\n",
            "epoch 26 | loss: 0.75655 | val_0_accuracy: 0.64875 |  0:02:00s\n",
            "epoch 27 | loss: 0.75112 | val_0_accuracy: 0.65436 |  0:02:05s\n",
            "epoch 28 | loss: 0.74337 | val_0_accuracy: 0.65501 |  0:02:10s\n",
            "\n",
            "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_accuracy = 0.66278\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-04 08:12:37,970]\u001b[0m Trial 0 finished with value: 0.6627806563039723 and parameters: {'n_d': 13, 'n_a': 56, 'n_steps': 8, 'gamma': 1.3568037572727158, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.17395658802813507}. Best is trial 0 with value: 0.6627806563039723.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       826\n",
            "           1       0.39      0.40      0.40       825\n",
            "           2       0.63      0.72      0.67       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.40      0.24      0.30       761\n",
            "           5       0.47      0.59      0.52       619\n",
            "\n",
            "    accuracy                           0.66      4632\n",
            "   macro avg       0.64      0.66      0.65      4632\n",
            "weighted avg       0.65      0.66      0.65      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 3.52453 | val_0_accuracy: 0.40263 |  0:00:05s\n",
            "epoch 1  | loss: 1.61691 | val_0_accuracy: 0.49007 |  0:00:11s\n",
            "epoch 2  | loss: 1.2589  | val_0_accuracy: 0.47064 |  0:00:18s\n",
            "epoch 3  | loss: 1.35691 | val_0_accuracy: 0.59737 |  0:00:24s\n",
            "epoch 4  | loss: 0.90008 | val_0_accuracy: 0.63277 |  0:00:30s\n",
            "epoch 5  | loss: 0.82197 | val_0_accuracy: 0.62478 |  0:00:36s\n",
            "epoch 6  | loss: 0.77977 | val_0_accuracy: 0.64486 |  0:00:42s\n",
            "epoch 7  | loss: 0.75075 | val_0_accuracy: 0.65393 |  0:00:48s\n",
            "epoch 8  | loss: 0.72668 | val_0_accuracy: 0.66472 |  0:00:55s\n",
            "epoch 9  | loss: 0.71532 | val_0_accuracy: 0.67401 |  0:01:01s\n",
            "epoch 10 | loss: 0.70845 | val_0_accuracy: 0.64594 |  0:01:07s\n",
            "epoch 11 | loss: 0.69998 | val_0_accuracy: 0.68869 |  0:01:14s\n",
            "epoch 12 | loss: 0.68493 | val_0_accuracy: 0.69775 |  0:01:20s\n",
            "epoch 13 | loss: 0.67185 | val_0_accuracy: 0.69171 |  0:01:26s\n",
            "epoch 14 | loss: 0.66262 | val_0_accuracy: 0.70337 |  0:01:32s\n",
            "epoch 15 | loss: 0.65141 | val_0_accuracy: 0.69063 |  0:01:38s\n",
            "epoch 16 | loss: 0.65501 | val_0_accuracy: 0.6984  |  0:01:44s\n",
            "epoch 17 | loss: 0.64091 | val_0_accuracy: 0.70358 |  0:01:50s\n",
            "epoch 18 | loss: 0.6406  | val_0_accuracy: 0.68588 |  0:01:56s\n",
            "epoch 19 | loss: 0.64026 | val_0_accuracy: 0.69279 |  0:02:02s\n",
            "epoch 20 | loss: 0.63175 | val_0_accuracy: 0.61075 |  0:02:08s\n",
            "epoch 21 | loss: 0.62897 | val_0_accuracy: 0.71611 |  0:02:14s\n",
            "epoch 22 | loss: 0.61526 | val_0_accuracy: 0.71179 |  0:02:21s\n",
            "epoch 23 | loss: 0.61367 | val_0_accuracy: 0.71351 |  0:02:27s\n",
            "epoch 24 | loss: 0.6059  | val_0_accuracy: 0.72517 |  0:02:33s\n",
            "epoch 25 | loss: 0.6036  | val_0_accuracy: 0.72582 |  0:02:40s\n",
            "epoch 26 | loss: 0.60274 | val_0_accuracy: 0.73014 |  0:02:46s\n",
            "epoch 27 | loss: 0.59594 | val_0_accuracy: 0.71956 |  0:02:52s\n",
            "epoch 28 | loss: 0.60547 | val_0_accuracy: 0.71244 |  0:02:58s\n",
            "epoch 29 | loss: 0.60807 | val_0_accuracy: 0.7323  |  0:03:04s\n",
            "epoch 30 | loss: 0.60754 | val_0_accuracy: 0.73251 |  0:03:10s\n",
            "epoch 31 | loss: 0.59255 | val_0_accuracy: 0.73402 |  0:03:16s\n",
            "epoch 32 | loss: 0.58539 | val_0_accuracy: 0.72733 |  0:03:23s\n",
            "epoch 33 | loss: 0.59326 | val_0_accuracy: 0.73208 |  0:03:29s\n",
            "epoch 34 | loss: 0.58915 | val_0_accuracy: 0.73661 |  0:03:35s\n",
            "epoch 35 | loss: 0.57297 | val_0_accuracy: 0.75    |  0:03:41s\n",
            "epoch 36 | loss: 0.57141 | val_0_accuracy: 0.74547 |  0:03:47s\n",
            "epoch 37 | loss: 0.5642  | val_0_accuracy: 0.74914 |  0:03:53s\n",
            "epoch 38 | loss: 0.56219 | val_0_accuracy: 0.74374 |  0:03:59s\n",
            "epoch 39 | loss: 0.55122 | val_0_accuracy: 0.75302 |  0:04:05s\n",
            "epoch 40 | loss: 0.55366 | val_0_accuracy: 0.76209 |  0:04:11s\n",
            "epoch 41 | loss: 0.54323 | val_0_accuracy: 0.75669 |  0:04:17s\n",
            "epoch 42 | loss: 0.54025 | val_0_accuracy: 0.74266 |  0:04:24s\n",
            "epoch 43 | loss: 0.53766 | val_0_accuracy: 0.76317 |  0:04:30s\n",
            "epoch 44 | loss: 0.5381  | val_0_accuracy: 0.76036 |  0:04:36s\n",
            "epoch 45 | loss: 0.53028 | val_0_accuracy: 0.76123 |  0:04:42s\n",
            "epoch 46 | loss: 0.52481 | val_0_accuracy: 0.76015 |  0:04:48s\n",
            "epoch 47 | loss: 0.51942 | val_0_accuracy: 0.76511 |  0:04:54s\n",
            "epoch 48 | loss: 0.51928 | val_0_accuracy: 0.76468 |  0:05:01s\n",
            "epoch 49 | loss: 0.51491 | val_0_accuracy: 0.76813 |  0:05:07s\n",
            "epoch 50 | loss: 0.51656 | val_0_accuracy: 0.76144 |  0:05:13s\n",
            "epoch 51 | loss: 0.50803 | val_0_accuracy: 0.76511 |  0:05:19s\n",
            "epoch 52 | loss: 0.50733 | val_0_accuracy: 0.76166 |  0:05:25s\n",
            "epoch 53 | loss: 0.50233 | val_0_accuracy: 0.76554 |  0:05:31s\n",
            "epoch 54 | loss: 0.50054 | val_0_accuracy: 0.77094 |  0:05:37s\n",
            "epoch 55 | loss: 0.49388 | val_0_accuracy: 0.77893 |  0:05:43s\n",
            "epoch 56 | loss: 0.49842 | val_0_accuracy: 0.76857 |  0:05:49s\n",
            "epoch 57 | loss: 0.50156 | val_0_accuracy: 0.75389 |  0:05:55s\n",
            "epoch 58 | loss: 0.53652 | val_0_accuracy: 0.75734 |  0:06:01s\n",
            "epoch 59 | loss: 0.5236  | val_0_accuracy: 0.73381 |  0:06:07s\n",
            "epoch 60 | loss: 0.64522 | val_0_accuracy: 0.70142 |  0:06:13s\n",
            "epoch 61 | loss: 0.66448 | val_0_accuracy: 0.69711 |  0:06:20s\n",
            "epoch 62 | loss: 0.63838 | val_0_accuracy: 0.72107 |  0:06:26s\n",
            "epoch 63 | loss: 0.59775 | val_0_accuracy: 0.70078 |  0:06:32s\n",
            "epoch 64 | loss: 0.63197 | val_0_accuracy: 0.68696 |  0:06:38s\n",
            "epoch 65 | loss: 0.63378 | val_0_accuracy: 0.71028 |  0:06:44s\n",
            "\n",
            "Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_0_accuracy = 0.77893\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-04 08:19:25,567]\u001b[0m Trial 1 finished with value: 0.7789291882556131 and parameters: {'n_d': 55, 'n_a': 63, 'n_steps': 10, 'gamma': 1.471764426245155, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.03428445332631497}. Best is trial 1 with value: 0.7789291882556131.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       826\n",
            "           1       0.60      0.58      0.59       825\n",
            "           2       0.80      0.94      0.86       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.52      0.50      0.51       761\n",
            "           5       0.70      0.60      0.64       619\n",
            "\n",
            "    accuracy                           0.78      4632\n",
            "   macro avg       0.77      0.77      0.77      4632\n",
            "weighted avg       0.77      0.78      0.77      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.7281  | val_0_accuracy: 0.56002 |  0:00:05s\n",
            "epoch 1  | loss: 0.94243 | val_0_accuracy: 0.61161 |  0:00:10s\n",
            "epoch 2  | loss: 0.90972 | val_0_accuracy: 0.59672 |  0:00:15s\n",
            "epoch 3  | loss: 0.94656 | val_0_accuracy: 0.58096 |  0:00:20s\n",
            "epoch 4  | loss: 0.90326 | val_0_accuracy: 0.60773 |  0:00:25s\n",
            "epoch 5  | loss: 0.80734 | val_0_accuracy: 0.64443 |  0:00:30s\n",
            "epoch 6  | loss: 0.77498 | val_0_accuracy: 0.64724 |  0:00:35s\n",
            "epoch 7  | loss: 0.76412 | val_0_accuracy: 0.64637 |  0:00:40s\n",
            "epoch 8  | loss: 0.75273 | val_0_accuracy: 0.65199 |  0:00:44s\n",
            "epoch 9  | loss: 0.73572 | val_0_accuracy: 0.65997 |  0:00:49s\n",
            "epoch 10 | loss: 0.73371 | val_0_accuracy: 0.66818 |  0:00:54s\n",
            "epoch 11 | loss: 0.72352 | val_0_accuracy: 0.65004 |  0:00:59s\n",
            "epoch 12 | loss: 0.7169  | val_0_accuracy: 0.66386 |  0:01:04s\n",
            "epoch 13 | loss: 0.70225 | val_0_accuracy: 0.65501 |  0:01:09s\n",
            "epoch 14 | loss: 0.6914  | val_0_accuracy: 0.68437 |  0:01:14s\n",
            "epoch 15 | loss: 0.68687 | val_0_accuracy: 0.6807  |  0:01:19s\n",
            "epoch 16 | loss: 0.68128 | val_0_accuracy: 0.6807  |  0:01:24s\n",
            "epoch 17 | loss: 0.67655 | val_0_accuracy: 0.68264 |  0:01:29s\n",
            "epoch 18 | loss: 0.68596 | val_0_accuracy: 0.68545 |  0:01:34s\n",
            "epoch 19 | loss: 0.67578 | val_0_accuracy: 0.68674 |  0:01:38s\n",
            "epoch 20 | loss: 0.67245 | val_0_accuracy: 0.68048 |  0:01:44s\n",
            "epoch 21 | loss: 0.67778 | val_0_accuracy: 0.68826 |  0:01:48s\n",
            "epoch 22 | loss: 0.6618  | val_0_accuracy: 0.69905 |  0:01:53s\n",
            "epoch 23 | loss: 0.65973 | val_0_accuracy: 0.70488 |  0:01:59s\n",
            "epoch 24 | loss: 0.66952 | val_0_accuracy: 0.69041 |  0:02:04s\n",
            "epoch 25 | loss: 0.68365 | val_0_accuracy: 0.68912 |  0:02:09s\n",
            "epoch 26 | loss: 0.71185 | val_0_accuracy: 0.67703 |  0:02:14s\n",
            "epoch 27 | loss: 0.70721 | val_0_accuracy: 0.66105 |  0:02:19s\n",
            "epoch 28 | loss: 0.71609 | val_0_accuracy: 0.65134 |  0:02:24s\n",
            "epoch 29 | loss: 0.70437 | val_0_accuracy: 0.68394 |  0:02:29s\n",
            "epoch 30 | loss: 0.67929 | val_0_accuracy: 0.68545 |  0:02:34s\n",
            "epoch 31 | loss: 0.66691 | val_0_accuracy: 0.67358 |  0:02:39s\n",
            "epoch 32 | loss: 0.67605 | val_0_accuracy: 0.69171 |  0:02:44s\n",
            "epoch 33 | loss: 0.65993 | val_0_accuracy: 0.6956  |  0:02:49s\n",
            "\n",
            "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_accuracy = 0.70488\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-04 08:22:17,593]\u001b[0m Trial 2 finished with value: 0.7048791018998273 and parameters: {'n_d': 24, 'n_a': 24, 'n_steps': 7, 'gamma': 1.0807506865107057, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.2819731803504611}. Best is trial 1 with value: 0.7789291882556131.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       826\n",
            "           1       0.47      0.44      0.45       825\n",
            "           2       0.70      0.84      0.76       822\n",
            "           3       1.00      0.99      1.00       779\n",
            "           4       0.45      0.35      0.40       761\n",
            "           5       0.52      0.56      0.54       619\n",
            "\n",
            "    accuracy                           0.70      4632\n",
            "   macro avg       0.69      0.70      0.69      4632\n",
            "weighted avg       0.69      0.70      0.70      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 2.17828 | val_0_accuracy: 0.44279 |  0:00:05s\n",
            "epoch 1  | loss: 1.2908  | val_0_accuracy: 0.46718 |  0:00:10s\n",
            "epoch 2  | loss: 1.17501 | val_0_accuracy: 0.51295 |  0:00:16s\n",
            "epoch 3  | loss: 1.17865 | val_0_accuracy: 0.52029 |  0:00:21s\n",
            "epoch 4  | loss: 1.12922 | val_0_accuracy: 0.48208 |  0:00:27s\n",
            "epoch 5  | loss: 1.03899 | val_0_accuracy: 0.55397 |  0:00:32s\n",
            "epoch 6  | loss: 0.92054 | val_0_accuracy: 0.58636 |  0:00:37s\n",
            "epoch 7  | loss: 0.86488 | val_0_accuracy: 0.62694 |  0:00:44s\n",
            "epoch 8  | loss: 0.82414 | val_0_accuracy: 0.6332  |  0:00:49s\n",
            "epoch 9  | loss: 0.8091  | val_0_accuracy: 0.64594 |  0:00:55s\n",
            "epoch 10 | loss: 0.78827 | val_0_accuracy: 0.64421 |  0:01:00s\n",
            "epoch 11 | loss: 0.79421 | val_0_accuracy: 0.63731 |  0:01:06s\n",
            "epoch 12 | loss: 0.80056 | val_0_accuracy: 0.64162 |  0:01:11s\n",
            "epoch 13 | loss: 0.76725 | val_0_accuracy: 0.65307 |  0:01:16s\n",
            "epoch 14 | loss: 0.76246 | val_0_accuracy: 0.65155 |  0:01:22s\n",
            "epoch 15 | loss: 0.77967 | val_0_accuracy: 0.65933 |  0:01:27s\n",
            "epoch 16 | loss: 0.79303 | val_0_accuracy: 0.64098 |  0:01:33s\n",
            "epoch 17 | loss: 0.77711 | val_0_accuracy: 0.64745 |  0:01:38s\n",
            "epoch 18 | loss: 0.76258 | val_0_accuracy: 0.64659 |  0:01:43s\n",
            "epoch 19 | loss: 0.75538 | val_0_accuracy: 0.64918 |  0:01:49s\n",
            "epoch 20 | loss: 0.75098 | val_0_accuracy: 0.65199 |  0:01:54s\n",
            "epoch 21 | loss: 0.75895 | val_0_accuracy: 0.64076 |  0:01:59s\n",
            "epoch 22 | loss: 0.74978 | val_0_accuracy: 0.65328 |  0:02:05s\n",
            "epoch 23 | loss: 0.73769 | val_0_accuracy: 0.65954 |  0:02:10s\n",
            "epoch 24 | loss: 0.73377 | val_0_accuracy: 0.65566 |  0:02:16s\n",
            "epoch 25 | loss: 0.73792 | val_0_accuracy: 0.65738 |  0:02:21s\n",
            "epoch 26 | loss: 0.72538 | val_0_accuracy: 0.66019 |  0:02:26s\n",
            "epoch 27 | loss: 0.71839 | val_0_accuracy: 0.66386 |  0:02:32s\n",
            "epoch 28 | loss: 0.71264 | val_0_accuracy: 0.66494 |  0:02:37s\n",
            "epoch 29 | loss: 0.70926 | val_0_accuracy: 0.66645 |  0:02:42s\n",
            "epoch 30 | loss: 0.71797 | val_0_accuracy: 0.67314 |  0:02:48s\n",
            "epoch 31 | loss: 0.70799 | val_0_accuracy: 0.66775 |  0:02:53s\n",
            "epoch 32 | loss: 0.69994 | val_0_accuracy: 0.66731 |  0:02:59s\n",
            "epoch 33 | loss: 0.68944 | val_0_accuracy: 0.67617 |  0:03:04s\n",
            "epoch 34 | loss: 0.68448 | val_0_accuracy: 0.67789 |  0:03:09s\n",
            "epoch 35 | loss: 0.67976 | val_0_accuracy: 0.67919 |  0:03:15s\n",
            "epoch 36 | loss: 0.67884 | val_0_accuracy: 0.68912 |  0:03:20s\n",
            "epoch 37 | loss: 0.67519 | val_0_accuracy: 0.6848  |  0:03:26s\n",
            "epoch 38 | loss: 0.66629 | val_0_accuracy: 0.69452 |  0:03:31s\n",
            "epoch 39 | loss: 0.65782 | val_0_accuracy: 0.69171 |  0:03:37s\n",
            "epoch 40 | loss: 0.67002 | val_0_accuracy: 0.69387 |  0:03:42s\n",
            "epoch 41 | loss: 0.65599 | val_0_accuracy: 0.69085 |  0:03:47s\n",
            "epoch 42 | loss: 0.65117 | val_0_accuracy: 0.6889  |  0:03:53s\n",
            "epoch 43 | loss: 0.64653 | val_0_accuracy: 0.69797 |  0:03:58s\n",
            "epoch 44 | loss: 0.64194 | val_0_accuracy: 0.70488 |  0:04:03s\n",
            "epoch 45 | loss: 0.64781 | val_0_accuracy: 0.71006 |  0:04:10s\n",
            "epoch 46 | loss: 0.6452  | val_0_accuracy: 0.69754 |  0:04:15s\n",
            "epoch 47 | loss: 0.64188 | val_0_accuracy: 0.71028 |  0:04:21s\n",
            "epoch 48 | loss: 0.63469 | val_0_accuracy: 0.69883 |  0:04:26s\n",
            "epoch 49 | loss: 0.62673 | val_0_accuracy: 0.7187  |  0:04:32s\n",
            "epoch 50 | loss: 0.62286 | val_0_accuracy: 0.71136 |  0:04:37s\n",
            "epoch 51 | loss: 0.61898 | val_0_accuracy: 0.70984 |  0:04:42s\n",
            "epoch 52 | loss: 0.61407 | val_0_accuracy: 0.71611 |  0:04:48s\n",
            "epoch 53 | loss: 0.61727 | val_0_accuracy: 0.71805 |  0:04:53s\n",
            "epoch 54 | loss: 0.61299 | val_0_accuracy: 0.71589 |  0:04:59s\n",
            "epoch 55 | loss: 0.61098 | val_0_accuracy: 0.72301 |  0:05:04s\n",
            "epoch 56 | loss: 0.6057  | val_0_accuracy: 0.72971 |  0:05:09s\n",
            "epoch 57 | loss: 0.60455 | val_0_accuracy: 0.71978 |  0:05:15s\n",
            "epoch 58 | loss: 0.60433 | val_0_accuracy: 0.73079 |  0:05:20s\n",
            "epoch 59 | loss: 0.59716 | val_0_accuracy: 0.72453 |  0:05:26s\n",
            "epoch 60 | loss: 0.59496 | val_0_accuracy: 0.72971 |  0:05:31s\n",
            "epoch 61 | loss: 0.59486 | val_0_accuracy: 0.73273 |  0:05:36s\n",
            "epoch 62 | loss: 0.5897  | val_0_accuracy: 0.72388 |  0:05:42s\n",
            "epoch 63 | loss: 0.5875  | val_0_accuracy: 0.73618 |  0:05:47s\n",
            "epoch 64 | loss: 0.58408 | val_0_accuracy: 0.73597 |  0:05:52s\n",
            "epoch 65 | loss: 0.58376 | val_0_accuracy: 0.73705 |  0:05:58s\n",
            "epoch 66 | loss: 0.58257 | val_0_accuracy: 0.72258 |  0:06:03s\n",
            "epoch 67 | loss: 0.59551 | val_0_accuracy: 0.73079 |  0:06:09s\n",
            "epoch 68 | loss: 0.58219 | val_0_accuracy: 0.74201 |  0:06:14s\n",
            "epoch 69 | loss: 0.57756 | val_0_accuracy: 0.74136 |  0:06:19s\n",
            "epoch 70 | loss: 0.57157 | val_0_accuracy: 0.74417 |  0:06:25s\n",
            "epoch 71 | loss: 0.57293 | val_0_accuracy: 0.74309 |  0:06:30s\n",
            "epoch 72 | loss: 0.57255 | val_0_accuracy: 0.74072 |  0:06:36s\n",
            "epoch 73 | loss: 0.5712  | val_0_accuracy: 0.73402 |  0:06:41s\n",
            "epoch 74 | loss: 0.57722 | val_0_accuracy: 0.73381 |  0:06:46s\n",
            "epoch 75 | loss: 0.56499 | val_0_accuracy: 0.74352 |  0:06:52s\n",
            "epoch 76 | loss: 0.55908 | val_0_accuracy: 0.75    |  0:06:57s\n",
            "epoch 77 | loss: 0.55803 | val_0_accuracy: 0.74806 |  0:07:02s\n",
            "epoch 78 | loss: 0.56129 | val_0_accuracy: 0.74784 |  0:07:08s\n",
            "epoch 79 | loss: 0.56326 | val_0_accuracy: 0.73942 |  0:07:13s\n",
            "epoch 80 | loss: 0.56078 | val_0_accuracy: 0.75259 |  0:07:18s\n",
            "epoch 81 | loss: 0.55269 | val_0_accuracy: 0.73964 |  0:07:24s\n",
            "epoch 82 | loss: 0.54767 | val_0_accuracy: 0.75173 |  0:07:29s\n",
            "epoch 83 | loss: 0.54009 | val_0_accuracy: 0.75907 |  0:07:34s\n",
            "epoch 84 | loss: 0.53772 | val_0_accuracy: 0.75734 |  0:07:40s\n",
            "epoch 85 | loss: 0.53813 | val_0_accuracy: 0.76058 |  0:07:46s\n",
            "epoch 86 | loss: 0.53559 | val_0_accuracy: 0.76123 |  0:07:52s\n",
            "epoch 87 | loss: 0.5353  | val_0_accuracy: 0.76943 |  0:07:57s\n",
            "epoch 88 | loss: 0.54242 | val_0_accuracy: 0.7595  |  0:08:02s\n",
            "epoch 89 | loss: 0.53613 | val_0_accuracy: 0.74849 |  0:08:08s\n",
            "epoch 90 | loss: 0.55509 | val_0_accuracy: 0.76425 |  0:08:13s\n",
            "epoch 91 | loss: 0.54141 | val_0_accuracy: 0.75604 |  0:08:19s\n",
            "epoch 92 | loss: 0.53539 | val_0_accuracy: 0.75885 |  0:08:24s\n",
            "epoch 93 | loss: 0.52688 | val_0_accuracy: 0.76339 |  0:08:29s\n",
            "epoch 94 | loss: 0.52324 | val_0_accuracy: 0.76792 |  0:08:35s\n",
            "epoch 95 | loss: 0.52727 | val_0_accuracy: 0.74957 |  0:08:40s\n",
            "epoch 96 | loss: 0.53324 | val_0_accuracy: 0.76706 |  0:08:45s\n",
            "epoch 97 | loss: 0.52056 | val_0_accuracy: 0.7718  |  0:08:51s\n",
            "epoch 98 | loss: 0.51742 | val_0_accuracy: 0.76123 |  0:08:56s\n",
            "epoch 99 | loss: 0.51338 | val_0_accuracy: 0.77871 |  0:09:02s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_accuracy = 0.77871\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-04 08:31:22,210]\u001b[0m Trial 3 finished with value: 0.778713298791019 and parameters: {'n_d': 13, 'n_a': 37, 'n_steps': 9, 'gamma': 1.4448731845774843, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.04549165037662816}. Best is trial 1 with value: 0.7789291882556131.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       826\n",
            "           1       0.61      0.56      0.59       825\n",
            "           2       0.83      0.93      0.88       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.50      0.65      0.56       761\n",
            "           5       0.81      0.45      0.58       619\n",
            "\n",
            "    accuracy                           0.78      4632\n",
            "   macro avg       0.79      0.77      0.77      4632\n",
            "weighted avg       0.79      0.78      0.78      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 2.15483 | val_0_accuracy: 0.29491 |  0:00:06s\n",
            "epoch 1  | loss: 1.32016 | val_0_accuracy: 0.49374 |  0:00:12s\n",
            "epoch 2  | loss: 1.16067 | val_0_accuracy: 0.4959  |  0:00:18s\n",
            "epoch 3  | loss: 1.25021 | val_0_accuracy: 0.43437 |  0:00:24s\n",
            "epoch 4  | loss: 1.2244  | val_0_accuracy: 0.50734 |  0:00:30s\n",
            "epoch 5  | loss: 1.09814 | val_0_accuracy: 0.52202 |  0:00:36s\n",
            "epoch 6  | loss: 0.94426 | val_0_accuracy: 0.57837 |  0:00:42s\n",
            "epoch 7  | loss: 0.86165 | val_0_accuracy: 0.60039 |  0:00:49s\n",
            "epoch 8  | loss: 0.82449 | val_0_accuracy: 0.63126 |  0:00:55s\n",
            "epoch 9  | loss: 0.78916 | val_0_accuracy: 0.63277 |  0:01:01s\n",
            "epoch 10 | loss: 0.77195 | val_0_accuracy: 0.64832 |  0:01:07s\n",
            "epoch 11 | loss: 0.76396 | val_0_accuracy: 0.64702 |  0:01:13s\n",
            "epoch 12 | loss: 0.75825 | val_0_accuracy: 0.65026 |  0:01:19s\n",
            "epoch 13 | loss: 0.74568 | val_0_accuracy: 0.64227 |  0:01:25s\n",
            "epoch 14 | loss: 0.75334 | val_0_accuracy: 0.65242 |  0:01:32s\n",
            "epoch 15 | loss: 0.7475  | val_0_accuracy: 0.65047 |  0:01:38s\n",
            "epoch 16 | loss: 0.76173 | val_0_accuracy: 0.64832 |  0:01:44s\n",
            "epoch 17 | loss: 0.75953 | val_0_accuracy: 0.63903 |  0:01:50s\n",
            "epoch 18 | loss: 0.7418  | val_0_accuracy: 0.65609 |  0:01:56s\n",
            "epoch 19 | loss: 0.72777 | val_0_accuracy: 0.65544 |  0:02:02s\n",
            "epoch 20 | loss: 0.71643 | val_0_accuracy: 0.65501 |  0:02:08s\n",
            "epoch 21 | loss: 0.71063 | val_0_accuracy: 0.66839 |  0:02:15s\n",
            "epoch 22 | loss: 0.70472 | val_0_accuracy: 0.66947 |  0:02:21s\n",
            "epoch 23 | loss: 0.69859 | val_0_accuracy: 0.6753  |  0:02:28s\n",
            "epoch 24 | loss: 0.69423 | val_0_accuracy: 0.66926 |  0:02:34s\n",
            "epoch 25 | loss: 0.68659 | val_0_accuracy: 0.6807  |  0:02:40s\n",
            "epoch 26 | loss: 0.67897 | val_0_accuracy: 0.6807  |  0:02:46s\n",
            "epoch 27 | loss: 0.67716 | val_0_accuracy: 0.68502 |  0:02:52s\n",
            "epoch 28 | loss: 0.6706  | val_0_accuracy: 0.68394 |  0:02:58s\n",
            "epoch 29 | loss: 0.67311 | val_0_accuracy: 0.68847 |  0:03:04s\n",
            "epoch 30 | loss: 0.66911 | val_0_accuracy: 0.68782 |  0:03:10s\n",
            "epoch 31 | loss: 0.66008 | val_0_accuracy: 0.68718 |  0:03:16s\n",
            "epoch 32 | loss: 0.65691 | val_0_accuracy: 0.6943  |  0:03:23s\n",
            "epoch 33 | loss: 0.64889 | val_0_accuracy: 0.69301 |  0:03:29s\n",
            "epoch 34 | loss: 0.64911 | val_0_accuracy: 0.68804 |  0:03:35s\n",
            "epoch 35 | loss: 0.6468  | val_0_accuracy: 0.69603 |  0:03:41s\n",
            "epoch 36 | loss: 0.64462 | val_0_accuracy: 0.69603 |  0:03:47s\n",
            "epoch 37 | loss: 0.64056 | val_0_accuracy: 0.70142 |  0:03:53s\n",
            "epoch 38 | loss: 0.66003 | val_0_accuracy: 0.68934 |  0:03:59s\n",
            "epoch 39 | loss: 0.67305 | val_0_accuracy: 0.69516 |  0:04:05s\n",
            "epoch 40 | loss: 0.66184 | val_0_accuracy: 0.70294 |  0:04:11s\n",
            "epoch 41 | loss: 0.64754 | val_0_accuracy: 0.68156 |  0:04:17s\n",
            "epoch 42 | loss: 0.64329 | val_0_accuracy: 0.70855 |  0:04:24s\n",
            "epoch 43 | loss: 0.63226 | val_0_accuracy: 0.70574 |  0:04:30s\n",
            "epoch 44 | loss: 0.62613 | val_0_accuracy: 0.71416 |  0:04:36s\n",
            "epoch 45 | loss: 0.62289 | val_0_accuracy: 0.71049 |  0:04:42s\n",
            "epoch 46 | loss: 0.61836 | val_0_accuracy: 0.71826 |  0:04:48s\n",
            "epoch 47 | loss: 0.61661 | val_0_accuracy: 0.7133  |  0:04:54s\n",
            "epoch 48 | loss: 0.61329 | val_0_accuracy: 0.69085 |  0:05:00s\n",
            "epoch 49 | loss: 0.63634 | val_0_accuracy: 0.70984 |  0:05:06s\n",
            "epoch 50 | loss: 0.62247 | val_0_accuracy: 0.72172 |  0:05:12s\n",
            "epoch 51 | loss: 0.63982 | val_0_accuracy: 0.70229 |  0:05:19s\n",
            "epoch 52 | loss: 0.63293 | val_0_accuracy: 0.71459 |  0:05:25s\n",
            "epoch 53 | loss: 0.6213  | val_0_accuracy: 0.71351 |  0:05:31s\n",
            "epoch 54 | loss: 0.65909 | val_0_accuracy: 0.67142 |  0:05:37s\n",
            "epoch 55 | loss: 0.71689 | val_0_accuracy: 0.67142 |  0:05:43s\n",
            "epoch 56 | loss: 0.71255 | val_0_accuracy: 0.66688 |  0:05:50s\n",
            "epoch 57 | loss: 0.69784 | val_0_accuracy: 0.67055 |  0:05:56s\n",
            "epoch 58 | loss: 0.69901 | val_0_accuracy: 0.67811 |  0:06:02s\n",
            "epoch 59 | loss: 0.66763 | val_0_accuracy: 0.69193 |  0:06:08s\n",
            "epoch 60 | loss: 0.65649 | val_0_accuracy: 0.68696 |  0:06:14s\n",
            "\n",
            "Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_accuracy = 0.72172\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-04 08:37:39,693]\u001b[0m Trial 4 finished with value: 0.7217184801381693 and parameters: {'n_d': 8, 'n_a': 27, 'n_steps': 9, 'gamma': 1.4990287251838699, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.29926000402627745}. Best is trial 1 with value: 0.7789291882556131.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       826\n",
            "           1       0.50      0.54      0.52       825\n",
            "           2       0.78      0.85      0.81       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.45      0.31      0.37       761\n",
            "           5       0.52      0.57      0.54       619\n",
            "\n",
            "    accuracy                           0.72      4632\n",
            "   macro avg       0.70      0.71      0.71      4632\n",
            "weighted avg       0.71      0.72      0.71      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.47144 | val_0_accuracy: 0.5775  |  0:00:01s\n",
            "epoch 1  | loss: 0.97722 | val_0_accuracy: 0.59823 |  0:00:03s\n",
            "epoch 2  | loss: 0.93137 | val_0_accuracy: 0.60298 |  0:00:05s\n",
            "epoch 3  | loss: 0.81889 | val_0_accuracy: 0.62478 |  0:00:07s\n",
            "epoch 4  | loss: 0.77653 | val_0_accuracy: 0.65026 |  0:00:09s\n",
            "epoch 5  | loss: 0.72921 | val_0_accuracy: 0.65436 |  0:00:11s\n",
            "epoch 6  | loss: 0.71304 | val_0_accuracy: 0.68264 |  0:00:13s\n",
            "epoch 7  | loss: 0.69522 | val_0_accuracy: 0.66969 |  0:00:15s\n",
            "epoch 8  | loss: 0.68648 | val_0_accuracy: 0.68545 |  0:00:17s\n",
            "epoch 9  | loss: 0.67983 | val_0_accuracy: 0.68437 |  0:00:19s\n",
            "epoch 10 | loss: 0.68869 | val_0_accuracy: 0.6889  |  0:00:21s\n",
            "epoch 11 | loss: 0.66449 | val_0_accuracy: 0.68869 |  0:00:23s\n",
            "epoch 12 | loss: 0.66066 | val_0_accuracy: 0.70488 |  0:00:25s\n",
            "epoch 13 | loss: 0.64571 | val_0_accuracy: 0.70747 |  0:00:27s\n",
            "epoch 14 | loss: 0.63969 | val_0_accuracy: 0.70725 |  0:00:29s\n",
            "epoch 15 | loss: 0.63351 | val_0_accuracy: 0.70855 |  0:00:31s\n",
            "epoch 16 | loss: 0.62792 | val_0_accuracy: 0.70553 |  0:00:33s\n",
            "epoch 17 | loss: 0.62887 | val_0_accuracy: 0.70121 |  0:00:34s\n",
            "epoch 18 | loss: 0.6264  | val_0_accuracy: 0.71762 |  0:00:36s\n",
            "epoch 19 | loss: 0.61291 | val_0_accuracy: 0.72237 |  0:00:38s\n",
            "epoch 20 | loss: 0.61169 | val_0_accuracy: 0.72409 |  0:00:40s\n",
            "epoch 21 | loss: 0.60466 | val_0_accuracy: 0.72906 |  0:00:42s\n",
            "epoch 22 | loss: 0.59908 | val_0_accuracy: 0.73359 |  0:00:44s\n",
            "epoch 23 | loss: 0.60078 | val_0_accuracy: 0.73532 |  0:00:46s\n",
            "epoch 24 | loss: 0.59237 | val_0_accuracy: 0.73057 |  0:00:48s\n",
            "epoch 25 | loss: 0.5909  | val_0_accuracy: 0.73402 |  0:00:50s\n",
            "epoch 26 | loss: 0.58559 | val_0_accuracy: 0.74331 |  0:00:52s\n",
            "epoch 27 | loss: 0.57699 | val_0_accuracy: 0.75151 |  0:00:54s\n",
            "epoch 28 | loss: 0.57672 | val_0_accuracy: 0.74396 |  0:00:56s\n",
            "epoch 29 | loss: 0.57649 | val_0_accuracy: 0.74806 |  0:00:59s\n",
            "epoch 30 | loss: 0.56783 | val_0_accuracy: 0.74935 |  0:01:01s\n",
            "epoch 31 | loss: 0.5655  | val_0_accuracy: 0.75022 |  0:01:03s\n",
            "epoch 32 | loss: 0.55494 | val_0_accuracy: 0.75324 |  0:01:05s\n",
            "epoch 33 | loss: 0.55293 | val_0_accuracy: 0.75345 |  0:01:07s\n",
            "epoch 34 | loss: 0.55341 | val_0_accuracy: 0.75669 |  0:01:09s\n",
            "epoch 35 | loss: 0.54602 | val_0_accuracy: 0.7541  |  0:01:11s\n",
            "epoch 36 | loss: 0.54403 | val_0_accuracy: 0.75389 |  0:01:13s\n",
            "epoch 37 | loss: 0.5422  | val_0_accuracy: 0.75756 |  0:01:15s\n",
            "epoch 38 | loss: 0.53447 | val_0_accuracy: 0.76295 |  0:01:17s\n",
            "epoch 39 | loss: 0.5314  | val_0_accuracy: 0.76015 |  0:01:19s\n",
            "epoch 40 | loss: 0.53298 | val_0_accuracy: 0.75216 |  0:01:21s\n",
            "epoch 41 | loss: 0.52943 | val_0_accuracy: 0.769   |  0:01:24s\n",
            "epoch 42 | loss: 0.52897 | val_0_accuracy: 0.75972 |  0:01:26s\n",
            "epoch 43 | loss: 0.51962 | val_0_accuracy: 0.76403 |  0:01:28s\n",
            "epoch 44 | loss: 0.51627 | val_0_accuracy: 0.77029 |  0:01:30s\n",
            "epoch 45 | loss: 0.51487 | val_0_accuracy: 0.76274 |  0:01:32s\n",
            "epoch 46 | loss: 0.51416 | val_0_accuracy: 0.76943 |  0:01:34s\n",
            "epoch 47 | loss: 0.51319 | val_0_accuracy: 0.75302 |  0:01:36s\n",
            "epoch 48 | loss: 0.51248 | val_0_accuracy: 0.76554 |  0:01:38s\n",
            "epoch 49 | loss: 0.5166  | val_0_accuracy: 0.76339 |  0:01:40s\n",
            "epoch 50 | loss: 0.50873 | val_0_accuracy: 0.77332 |  0:01:42s\n",
            "epoch 51 | loss: 0.54081 | val_0_accuracy: 0.74158 |  0:01:44s\n",
            "epoch 52 | loss: 0.55208 | val_0_accuracy: 0.76058 |  0:01:46s\n",
            "epoch 53 | loss: 0.53078 | val_0_accuracy: 0.76339 |  0:01:48s\n",
            "epoch 54 | loss: 0.51639 | val_0_accuracy: 0.76619 |  0:01:50s\n",
            "epoch 55 | loss: 0.51304 | val_0_accuracy: 0.76792 |  0:01:52s\n",
            "epoch 56 | loss: 0.51738 | val_0_accuracy: 0.76921 |  0:01:54s\n",
            "epoch 57 | loss: 0.51825 | val_0_accuracy: 0.76533 |  0:01:56s\n",
            "epoch 58 | loss: 0.50724 | val_0_accuracy: 0.76878 |  0:01:58s\n",
            "epoch 59 | loss: 0.49957 | val_0_accuracy: 0.76749 |  0:02:00s\n",
            "epoch 60 | loss: 0.49477 | val_0_accuracy: 0.77008 |  0:02:02s\n",
            "\n",
            "Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_accuracy = 0.77332\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-04 08:39:42,866]\u001b[0m Trial 5 finished with value: 0.7733160621761658 and parameters: {'n_d': 55, 'n_a': 45, 'n_steps': 6, 'gamma': 1.7247042081341464, 'n_independent': 1, 'n_shared': 1, 'momentum': 0.10463354022743417}. Best is trial 1 with value: 0.7789291882556131.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       826\n",
            "           1       0.59      0.59      0.59       825\n",
            "           2       0.84      0.87      0.86       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.51      0.52      0.51       761\n",
            "           5       0.66      0.61      0.63       619\n",
            "\n",
            "    accuracy                           0.77      4632\n",
            "   macro avg       0.77      0.77      0.77      4632\n",
            "weighted avg       0.77      0.77      0.77      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.61919 | val_0_accuracy: 0.54447 |  0:00:05s\n",
            "epoch 1  | loss: 0.98384 | val_0_accuracy: 0.5924  |  0:00:11s\n",
            "epoch 2  | loss: 0.92313 | val_0_accuracy: 0.61766 |  0:00:16s\n",
            "epoch 3  | loss: 0.88959 | val_0_accuracy: 0.62608 |  0:00:22s\n",
            "epoch 4  | loss: 0.89927 | val_0_accuracy: 0.57081 |  0:00:28s\n",
            "epoch 5  | loss: 0.87949 | val_0_accuracy: 0.61766 |  0:00:33s\n",
            "epoch 6  | loss: 0.83    | val_0_accuracy: 0.63104 |  0:00:39s\n",
            "epoch 7  | loss: 0.79735 | val_0_accuracy: 0.64529 |  0:00:44s\n",
            "epoch 8  | loss: 0.78521 | val_0_accuracy: 0.64594 |  0:00:50s\n",
            "epoch 9  | loss: 0.7781  | val_0_accuracy: 0.64724 |  0:00:56s\n",
            "epoch 10 | loss: 0.77407 | val_0_accuracy: 0.64335 |  0:01:02s\n",
            "epoch 11 | loss: 0.79045 | val_0_accuracy: 0.6345  |  0:01:08s\n",
            "epoch 12 | loss: 0.78153 | val_0_accuracy: 0.64465 |  0:01:13s\n",
            "epoch 13 | loss: 0.77983 | val_0_accuracy: 0.64486 |  0:01:19s\n",
            "epoch 14 | loss: 0.76605 | val_0_accuracy: 0.65004 |  0:01:25s\n",
            "epoch 15 | loss: 0.75516 | val_0_accuracy: 0.65177 |  0:01:30s\n",
            "epoch 16 | loss: 0.75541 | val_0_accuracy: 0.65026 |  0:01:36s\n",
            "epoch 17 | loss: 0.74814 | val_0_accuracy: 0.65026 |  0:01:41s\n",
            "epoch 18 | loss: 0.74184 | val_0_accuracy: 0.6522  |  0:01:47s\n",
            "epoch 19 | loss: 0.73072 | val_0_accuracy: 0.65393 |  0:01:52s\n",
            "epoch 20 | loss: 0.73613 | val_0_accuracy: 0.65501 |  0:01:58s\n",
            "epoch 21 | loss: 0.73622 | val_0_accuracy: 0.6386  |  0:02:04s\n",
            "epoch 22 | loss: 0.73713 | val_0_accuracy: 0.64292 |  0:02:09s\n",
            "epoch 23 | loss: 0.7344  | val_0_accuracy: 0.63104 |  0:02:15s\n",
            "epoch 24 | loss: 0.72963 | val_0_accuracy: 0.66386 |  0:02:20s\n",
            "epoch 25 | loss: 0.71715 | val_0_accuracy: 0.65458 |  0:02:26s\n",
            "epoch 26 | loss: 0.72184 | val_0_accuracy: 0.64421 |  0:02:31s\n",
            "epoch 27 | loss: 0.72465 | val_0_accuracy: 0.6522  |  0:02:37s\n",
            "epoch 28 | loss: 0.71335 | val_0_accuracy: 0.65609 |  0:02:42s\n",
            "epoch 29 | loss: 0.71199 | val_0_accuracy: 0.663   |  0:02:48s\n",
            "epoch 30 | loss: 0.70858 | val_0_accuracy: 0.66602 |  0:02:53s\n",
            "epoch 31 | loss: 0.70632 | val_0_accuracy: 0.66775 |  0:02:59s\n",
            "epoch 32 | loss: 0.7064  | val_0_accuracy: 0.65976 |  0:03:05s\n",
            "epoch 33 | loss: 0.70823 | val_0_accuracy: 0.64378 |  0:03:10s\n",
            "epoch 34 | loss: 0.70343 | val_0_accuracy: 0.66516 |  0:03:16s\n",
            "epoch 35 | loss: 0.69726 | val_0_accuracy: 0.66408 |  0:03:21s\n",
            "epoch 36 | loss: 0.70021 | val_0_accuracy: 0.66796 |  0:03:27s\n",
            "epoch 37 | loss: 0.69918 | val_0_accuracy: 0.6725  |  0:03:33s\n",
            "epoch 38 | loss: 0.68981 | val_0_accuracy: 0.67832 |  0:03:38s\n",
            "epoch 39 | loss: 0.68962 | val_0_accuracy: 0.67617 |  0:03:44s\n",
            "epoch 40 | loss: 0.68593 | val_0_accuracy: 0.67034 |  0:03:49s\n",
            "epoch 41 | loss: 0.68339 | val_0_accuracy: 0.52051 |  0:03:55s\n",
            "epoch 42 | loss: 0.69092 | val_0_accuracy: 0.68156 |  0:04:00s\n",
            "epoch 43 | loss: 0.6854  | val_0_accuracy: 0.538   |  0:04:06s\n",
            "epoch 44 | loss: 0.67901 | val_0_accuracy: 0.54771 |  0:04:12s\n",
            "epoch 45 | loss: 0.67974 | val_0_accuracy: 0.54188 |  0:04:17s\n",
            "epoch 46 | loss: 0.67408 | val_0_accuracy: 0.68156 |  0:04:23s\n",
            "epoch 47 | loss: 0.67329 | val_0_accuracy: 0.54944 |  0:04:28s\n",
            "epoch 48 | loss: 0.66752 | val_0_accuracy: 0.70056 |  0:04:34s\n",
            "epoch 49 | loss: 0.67069 | val_0_accuracy: 0.68243 |  0:04:40s\n",
            "epoch 50 | loss: 0.66435 | val_0_accuracy: 0.69581 |  0:04:46s\n",
            "epoch 51 | loss: 0.67202 | val_0_accuracy: 0.67228 |  0:04:51s\n",
            "epoch 52 | loss: 0.67179 | val_0_accuracy: 0.68977 |  0:04:57s\n",
            "epoch 53 | loss: 0.66652 | val_0_accuracy: 0.68113 |  0:05:03s\n",
            "epoch 54 | loss: 0.69648 | val_0_accuracy: 0.66753 |  0:05:08s\n",
            "epoch 55 | loss: 0.71167 | val_0_accuracy: 0.52634 |  0:05:14s\n",
            "epoch 56 | loss: 0.68419 | val_0_accuracy: 0.68178 |  0:05:19s\n",
            "epoch 57 | loss: 0.66827 | val_0_accuracy: 0.67854 |  0:05:25s\n",
            "epoch 58 | loss: 0.66753 | val_0_accuracy: 0.66516 |  0:05:30s\n",
            "\n",
            "Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_accuracy = 0.70056\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-04 08:45:16,287]\u001b[0m Trial 6 finished with value: 0.7005613126079447 and parameters: {'n_d': 33, 'n_a': 43, 'n_steps': 8, 'gamma': 1.0841794035165062, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.025979194015075473}. Best is trial 1 with value: 0.7789291882556131.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98       826\n",
            "           1       0.47      0.43      0.45       825\n",
            "           2       0.67      0.82      0.74       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.47      0.40      0.43       761\n",
            "           5       0.53      0.50      0.52       619\n",
            "\n",
            "    accuracy                           0.70      4632\n",
            "   macro avg       0.68      0.69      0.68      4632\n",
            "weighted avg       0.69      0.70      0.69      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.54353 | val_0_accuracy: 0.48338 |  0:00:04s\n",
            "epoch 1  | loss: 1.23162 | val_0_accuracy: 0.50194 |  0:00:09s\n",
            "epoch 2  | loss: 1.14715 | val_0_accuracy: 0.49957 |  0:00:14s\n",
            "epoch 3  | loss: 1.06862 | val_0_accuracy: 0.57016 |  0:00:18s\n",
            "epoch 4  | loss: 1.12446 | val_0_accuracy: 0.56282 |  0:00:23s\n",
            "epoch 5  | loss: 0.93964 | val_0_accuracy: 0.59909 |  0:00:28s\n",
            "epoch 6  | loss: 0.86884 | val_0_accuracy: 0.55894 |  0:00:33s\n",
            "epoch 7  | loss: 0.84856 | val_0_accuracy: 0.59003 |  0:00:37s\n",
            "epoch 8  | loss: 0.84282 | val_0_accuracy: 0.56973 |  0:00:42s\n",
            "epoch 9  | loss: 0.82399 | val_0_accuracy: 0.56757 |  0:00:47s\n",
            "epoch 10 | loss: 0.81787 | val_0_accuracy: 0.56563 |  0:00:52s\n",
            "epoch 11 | loss: 0.80997 | val_0_accuracy: 0.59607 |  0:00:56s\n",
            "epoch 12 | loss: 0.82647 | val_0_accuracy: 0.57707 |  0:01:01s\n",
            "epoch 13 | loss: 0.81436 | val_0_accuracy: 0.60406 |  0:01:06s\n",
            "epoch 14 | loss: 0.8203  | val_0_accuracy: 0.5775  |  0:01:10s\n",
            "epoch 15 | loss: 0.81446 | val_0_accuracy: 0.60017 |  0:01:15s\n",
            "epoch 16 | loss: 0.8178  | val_0_accuracy: 0.59715 |  0:01:20s\n",
            "epoch 17 | loss: 0.81408 | val_0_accuracy: 0.59175 |  0:01:25s\n",
            "epoch 18 | loss: 0.80105 | val_0_accuracy: 0.59089 |  0:01:29s\n",
            "epoch 19 | loss: 0.79225 | val_0_accuracy: 0.58873 |  0:01:34s\n",
            "epoch 20 | loss: 0.795   | val_0_accuracy: 0.61421 |  0:01:39s\n",
            "epoch 21 | loss: 0.78966 | val_0_accuracy: 0.57642 |  0:01:43s\n",
            "epoch 22 | loss: 0.80441 | val_0_accuracy: 0.58333 |  0:01:48s\n",
            "epoch 23 | loss: 0.78976 | val_0_accuracy: 0.58182 |  0:01:53s\n",
            "epoch 24 | loss: 0.79117 | val_0_accuracy: 0.54167 |  0:01:58s\n",
            "epoch 25 | loss: 0.77609 | val_0_accuracy: 0.57081 |  0:02:02s\n",
            "epoch 26 | loss: 0.78264 | val_0_accuracy: 0.62867 |  0:02:07s\n",
            "epoch 27 | loss: 0.79733 | val_0_accuracy: 0.60687 |  0:02:12s\n",
            "epoch 28 | loss: 0.78791 | val_0_accuracy: 0.6114  |  0:02:17s\n",
            "epoch 29 | loss: 0.78263 | val_0_accuracy: 0.59801 |  0:02:22s\n",
            "epoch 30 | loss: 0.76452 | val_0_accuracy: 0.60838 |  0:02:26s\n",
            "epoch 31 | loss: 0.75724 | val_0_accuracy: 0.63342 |  0:02:31s\n",
            "epoch 32 | loss: 0.7487  | val_0_accuracy: 0.56865 |  0:02:37s\n",
            "epoch 33 | loss: 0.75253 | val_0_accuracy: 0.62694 |  0:02:42s\n",
            "epoch 34 | loss: 0.76487 | val_0_accuracy: 0.44128 |  0:02:46s\n",
            "epoch 35 | loss: 0.7416  | val_0_accuracy: 0.60924 |  0:02:51s\n",
            "epoch 36 | loss: 0.73848 | val_0_accuracy: 0.63299 |  0:02:56s\n",
            "epoch 37 | loss: 0.73366 | val_0_accuracy: 0.61939 |  0:03:01s\n",
            "epoch 38 | loss: 0.72625 | val_0_accuracy: 0.60924 |  0:03:06s\n",
            "epoch 39 | loss: 0.715   | val_0_accuracy: 0.61744 |  0:03:11s\n",
            "epoch 40 | loss: 0.71912 | val_0_accuracy: 0.62047 |  0:03:16s\n",
            "epoch 41 | loss: 0.72349 | val_0_accuracy: 0.61917 |  0:03:20s\n",
            "\n",
            "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_accuracy = 0.63342\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-04 08:48:39,328]\u001b[0m Trial 7 finished with value: 0.633419689119171 and parameters: {'n_d': 16, 'n_a': 13, 'n_steps': 5, 'gamma': 1.71175064770821, 'n_independent': 5, 'n_shared': 5, 'momentum': 0.04581295877423421}. Best is trial 1 with value: 0.7789291882556131.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       826\n",
            "           1       0.37      0.55      0.44       825\n",
            "           2       0.65      0.46      0.54       822\n",
            "           3       0.99      1.00      0.99       779\n",
            "           4       0.35      0.29      0.31       761\n",
            "           5       0.50      0.45      0.47       619\n",
            "\n",
            "    accuracy                           0.63      4632\n",
            "   macro avg       0.64      0.62      0.63      4632\n",
            "weighted avg       0.64      0.63      0.63      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.55606 | val_0_accuracy: 0.5421  |  0:00:02s\n",
            "epoch 1  | loss: 1.01927 | val_0_accuracy: 0.56585 |  0:00:05s\n",
            "epoch 2  | loss: 0.95859 | val_0_accuracy: 0.61982 |  0:00:08s\n",
            "epoch 3  | loss: 0.819   | val_0_accuracy: 0.64875 |  0:00:11s\n",
            "epoch 4  | loss: 0.76037 | val_0_accuracy: 0.66213 |  0:00:14s\n",
            "epoch 5  | loss: 0.73428 | val_0_accuracy: 0.663   |  0:00:17s\n",
            "epoch 6  | loss: 0.71426 | val_0_accuracy: 0.67077 |  0:00:20s\n",
            "epoch 7  | loss: 0.69824 | val_0_accuracy: 0.66386 |  0:00:24s\n",
            "epoch 8  | loss: 0.70276 | val_0_accuracy: 0.66926 |  0:00:27s\n",
            "epoch 9  | loss: 0.68818 | val_0_accuracy: 0.67509 |  0:00:29s\n",
            "epoch 10 | loss: 0.6806  | val_0_accuracy: 0.68199 |  0:00:32s\n",
            "epoch 11 | loss: 0.67739 | val_0_accuracy: 0.67984 |  0:00:35s\n",
            "epoch 12 | loss: 0.6789  | val_0_accuracy: 0.67617 |  0:00:38s\n",
            "epoch 13 | loss: 0.66976 | val_0_accuracy: 0.69344 |  0:00:41s\n",
            "epoch 14 | loss: 0.67087 | val_0_accuracy: 0.67509 |  0:00:44s\n",
            "epoch 15 | loss: 0.65779 | val_0_accuracy: 0.68502 |  0:00:47s\n",
            "epoch 16 | loss: 0.64695 | val_0_accuracy: 0.69473 |  0:00:50s\n",
            "epoch 17 | loss: 0.63754 | val_0_accuracy: 0.69948 |  0:00:53s\n",
            "epoch 18 | loss: 0.63516 | val_0_accuracy: 0.70142 |  0:00:56s\n",
            "epoch 19 | loss: 0.63131 | val_0_accuracy: 0.70294 |  0:00:59s\n",
            "epoch 20 | loss: 0.63084 | val_0_accuracy: 0.70164 |  0:01:02s\n",
            "epoch 21 | loss: 0.62201 | val_0_accuracy: 0.70941 |  0:01:05s\n",
            "epoch 22 | loss: 0.62014 | val_0_accuracy: 0.71136 |  0:01:08s\n",
            "epoch 23 | loss: 0.62599 | val_0_accuracy: 0.712   |  0:01:11s\n",
            "epoch 24 | loss: 0.61695 | val_0_accuracy: 0.7079  |  0:01:14s\n",
            "epoch 25 | loss: 0.60631 | val_0_accuracy: 0.71783 |  0:01:17s\n",
            "epoch 26 | loss: 0.60503 | val_0_accuracy: 0.72474 |  0:01:20s\n",
            "epoch 27 | loss: 0.59858 | val_0_accuracy: 0.72712 |  0:01:23s\n",
            "epoch 28 | loss: 0.59724 | val_0_accuracy: 0.72301 |  0:01:27s\n",
            "epoch 29 | loss: 0.59331 | val_0_accuracy: 0.72064 |  0:01:30s\n",
            "epoch 30 | loss: 0.58854 | val_0_accuracy: 0.72064 |  0:01:33s\n",
            "epoch 31 | loss: 0.58742 | val_0_accuracy: 0.72625 |  0:01:35s\n",
            "epoch 32 | loss: 0.57858 | val_0_accuracy: 0.73014 |  0:01:38s\n",
            "epoch 33 | loss: 0.57624 | val_0_accuracy: 0.72949 |  0:01:41s\n",
            "epoch 34 | loss: 0.57409 | val_0_accuracy: 0.73597 |  0:01:44s\n",
            "epoch 35 | loss: 0.5757  | val_0_accuracy: 0.73424 |  0:01:47s\n",
            "epoch 36 | loss: 0.56842 | val_0_accuracy: 0.72971 |  0:01:50s\n",
            "epoch 37 | loss: 0.56433 | val_0_accuracy: 0.74158 |  0:01:53s\n",
            "epoch 38 | loss: 0.64469 | val_0_accuracy: 0.70553 |  0:01:56s\n",
            "epoch 39 | loss: 0.65403 | val_0_accuracy: 0.68221 |  0:01:59s\n",
            "epoch 40 | loss: 0.64555 | val_0_accuracy: 0.7092  |  0:02:02s\n",
            "epoch 41 | loss: 0.63408 | val_0_accuracy: 0.67897 |  0:02:05s\n",
            "epoch 42 | loss: 0.77788 | val_0_accuracy: 0.64832 |  0:02:08s\n",
            "epoch 43 | loss: 0.72022 | val_0_accuracy: 0.68372 |  0:02:11s\n",
            "epoch 44 | loss: 0.66767 | val_0_accuracy: 0.70142 |  0:02:14s\n",
            "epoch 45 | loss: 0.65051 | val_0_accuracy: 0.6889  |  0:02:17s\n",
            "epoch 46 | loss: 0.65791 | val_0_accuracy: 0.70164 |  0:02:20s\n",
            "epoch 47 | loss: 0.63159 | val_0_accuracy: 0.71308 |  0:02:23s\n",
            "\n",
            "Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_accuracy = 0.74158\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-04 08:51:04,531]\u001b[0m Trial 8 finished with value: 0.741580310880829 and parameters: {'n_d': 19, 'n_a': 37, 'n_steps': 5, 'gamma': 1.6423317059221954, 'n_independent': 4, 'n_shared': 1, 'momentum': 0.2653438380380938}. Best is trial 1 with value: 0.7789291882556131.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       826\n",
            "           1       0.52      0.51      0.51       825\n",
            "           2       0.76      0.89      0.82       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.48      0.44      0.46       761\n",
            "           5       0.62      0.56      0.59       619\n",
            "\n",
            "    accuracy                           0.74      4632\n",
            "   macro avg       0.73      0.73      0.73      4632\n",
            "weighted avg       0.73      0.74      0.74      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 2.29351 | val_0_accuracy: 0.38277 |  0:00:05s\n",
            "epoch 1  | loss: 1.44078 | val_0_accuracy: 0.53389 |  0:00:11s\n",
            "epoch 2  | loss: 1.1795  | val_0_accuracy: 0.57686 |  0:00:17s\n",
            "epoch 3  | loss: 0.91089 | val_0_accuracy: 0.60406 |  0:00:23s\n",
            "epoch 4  | loss: 0.84727 | val_0_accuracy: 0.6019  |  0:00:28s\n",
            "epoch 5  | loss: 0.83793 | val_0_accuracy: 0.61507 |  0:00:34s\n",
            "epoch 6  | loss: 0.78921 | val_0_accuracy: 0.63126 |  0:00:39s\n",
            "epoch 7  | loss: 0.77963 | val_0_accuracy: 0.63277 |  0:00:45s\n",
            "epoch 8  | loss: 0.76767 | val_0_accuracy: 0.64551 |  0:00:50s\n",
            "epoch 9  | loss: 0.75855 | val_0_accuracy: 0.63968 |  0:00:56s\n",
            "epoch 10 | loss: 0.75272 | val_0_accuracy: 0.64443 |  0:01:01s\n",
            "epoch 11 | loss: 0.73801 | val_0_accuracy: 0.65091 |  0:01:06s\n",
            "epoch 12 | loss: 0.73418 | val_0_accuracy: 0.65199 |  0:01:12s\n",
            "epoch 13 | loss: 0.72587 | val_0_accuracy: 0.64983 |  0:01:17s\n",
            "epoch 14 | loss: 0.71365 | val_0_accuracy: 0.64983 |  0:01:22s\n",
            "epoch 15 | loss: 0.72753 | val_0_accuracy: 0.66537 |  0:01:28s\n",
            "epoch 16 | loss: 0.71895 | val_0_accuracy: 0.65587 |  0:01:33s\n",
            "epoch 17 | loss: 0.71509 | val_0_accuracy: 0.66278 |  0:01:38s\n",
            "epoch 18 | loss: 0.70289 | val_0_accuracy: 0.6535  |  0:01:44s\n",
            "epoch 19 | loss: 0.70166 | val_0_accuracy: 0.67142 |  0:01:49s\n",
            "epoch 20 | loss: 0.6905  | val_0_accuracy: 0.63126 |  0:01:54s\n",
            "epoch 21 | loss: 0.68398 | val_0_accuracy: 0.67228 |  0:02:00s\n",
            "epoch 22 | loss: 0.67602 | val_0_accuracy: 0.67789 |  0:02:05s\n",
            "epoch 23 | loss: 0.66755 | val_0_accuracy: 0.67897 |  0:02:11s\n",
            "epoch 24 | loss: 0.65987 | val_0_accuracy: 0.69171 |  0:02:16s\n",
            "epoch 25 | loss: 0.66427 | val_0_accuracy: 0.69473 |  0:02:21s\n",
            "epoch 26 | loss: 0.65539 | val_0_accuracy: 0.69948 |  0:02:27s\n",
            "epoch 27 | loss: 0.65053 | val_0_accuracy: 0.67379 |  0:02:32s\n",
            "epoch 28 | loss: 0.65385 | val_0_accuracy: 0.6997  |  0:02:37s\n",
            "epoch 29 | loss: 0.63865 | val_0_accuracy: 0.59823 |  0:02:43s\n",
            "epoch 30 | loss: 0.6377  | val_0_accuracy: 0.67444 |  0:02:48s\n",
            "epoch 31 | loss: 0.6288  | val_0_accuracy: 0.69279 |  0:02:53s\n",
            "epoch 32 | loss: 0.62588 | val_0_accuracy: 0.71718 |  0:02:59s\n",
            "epoch 33 | loss: 0.62153 | val_0_accuracy: 0.71848 |  0:03:04s\n",
            "epoch 34 | loss: 0.62555 | val_0_accuracy: 0.68092 |  0:03:09s\n",
            "epoch 35 | loss: 0.62026 | val_0_accuracy: 0.65652 |  0:03:15s\n",
            "epoch 36 | loss: 0.6543  | val_0_accuracy: 0.72323 |  0:03:20s\n",
            "epoch 37 | loss: 0.62527 | val_0_accuracy: 0.71611 |  0:03:25s\n",
            "epoch 38 | loss: 0.62227 | val_0_accuracy: 0.71503 |  0:03:30s\n",
            "epoch 39 | loss: 0.61918 | val_0_accuracy: 0.57707 |  0:03:36s\n",
            "epoch 40 | loss: 0.6245  | val_0_accuracy: 0.72215 |  0:03:41s\n",
            "epoch 41 | loss: 0.67164 | val_0_accuracy: 0.70639 |  0:03:46s\n",
            "epoch 42 | loss: 0.6372  | val_0_accuracy: 0.72064 |  0:03:52s\n",
            "epoch 43 | loss: 0.6153  | val_0_accuracy: 0.73467 |  0:03:58s\n",
            "epoch 44 | loss: 0.60719 | val_0_accuracy: 0.72733 |  0:04:03s\n",
            "epoch 45 | loss: 0.59599 | val_0_accuracy: 0.73402 |  0:04:08s\n",
            "epoch 46 | loss: 0.58569 | val_0_accuracy: 0.74503 |  0:04:14s\n",
            "epoch 47 | loss: 0.61191 | val_0_accuracy: 0.70747 |  0:04:19s\n",
            "epoch 48 | loss: 0.61856 | val_0_accuracy: 0.73251 |  0:04:24s\n",
            "epoch 49 | loss: 0.59362 | val_0_accuracy: 0.73705 |  0:04:30s\n",
            "epoch 50 | loss: 0.5809  | val_0_accuracy: 0.74028 |  0:04:35s\n",
            "epoch 51 | loss: 0.57622 | val_0_accuracy: 0.73705 |  0:04:40s\n",
            "epoch 52 | loss: 0.56678 | val_0_accuracy: 0.74374 |  0:04:45s\n",
            "epoch 53 | loss: 0.58647 | val_0_accuracy: 0.74482 |  0:04:51s\n",
            "epoch 54 | loss: 0.57094 | val_0_accuracy: 0.74849 |  0:04:56s\n",
            "epoch 55 | loss: 0.56778 | val_0_accuracy: 0.73877 |  0:05:01s\n",
            "epoch 56 | loss: 0.57515 | val_0_accuracy: 0.75173 |  0:05:06s\n",
            "epoch 57 | loss: 0.56419 | val_0_accuracy: 0.75259 |  0:05:12s\n",
            "epoch 58 | loss: 0.55984 | val_0_accuracy: 0.75043 |  0:05:17s\n",
            "epoch 59 | loss: 0.55376 | val_0_accuracy: 0.76166 |  0:05:22s\n",
            "epoch 60 | loss: 0.55988 | val_0_accuracy: 0.7582  |  0:05:28s\n",
            "epoch 61 | loss: 0.55838 | val_0_accuracy: 0.74547 |  0:05:33s\n",
            "epoch 62 | loss: 0.5497  | val_0_accuracy: 0.75604 |  0:05:38s\n",
            "epoch 63 | loss: 0.54561 | val_0_accuracy: 0.76317 |  0:05:44s\n",
            "epoch 64 | loss: 0.54004 | val_0_accuracy: 0.75885 |  0:05:49s\n",
            "epoch 65 | loss: 0.53667 | val_0_accuracy: 0.76231 |  0:05:54s\n",
            "epoch 66 | loss: 0.53969 | val_0_accuracy: 0.75712 |  0:05:59s\n",
            "epoch 67 | loss: 0.53192 | val_0_accuracy: 0.77008 |  0:06:05s\n",
            "epoch 68 | loss: 0.52333 | val_0_accuracy: 0.75907 |  0:06:10s\n",
            "epoch 69 | loss: 0.52136 | val_0_accuracy: 0.76144 |  0:06:15s\n",
            "epoch 70 | loss: 0.52347 | val_0_accuracy: 0.769   |  0:06:20s\n",
            "epoch 71 | loss: 0.53139 | val_0_accuracy: 0.75065 |  0:06:26s\n",
            "epoch 72 | loss: 0.53403 | val_0_accuracy: 0.77116 |  0:06:31s\n",
            "epoch 73 | loss: 0.53263 | val_0_accuracy: 0.75864 |  0:06:36s\n",
            "epoch 74 | loss: 0.52147 | val_0_accuracy: 0.76619 |  0:06:42s\n",
            "epoch 75 | loss: 0.52718 | val_0_accuracy: 0.76684 |  0:06:47s\n",
            "epoch 76 | loss: 0.51432 | val_0_accuracy: 0.76641 |  0:06:52s\n",
            "epoch 77 | loss: 0.50682 | val_0_accuracy: 0.77332 |  0:06:57s\n",
            "epoch 78 | loss: 0.50775 | val_0_accuracy: 0.7785  |  0:07:03s\n",
            "epoch 79 | loss: 0.51082 | val_0_accuracy: 0.77461 |  0:07:08s\n",
            "epoch 80 | loss: 0.50394 | val_0_accuracy: 0.78411 |  0:07:13s\n",
            "epoch 81 | loss: 0.4975  | val_0_accuracy: 0.77245 |  0:07:20s\n",
            "epoch 82 | loss: 0.4908  | val_0_accuracy: 0.77547 |  0:07:25s\n",
            "epoch 83 | loss: 0.48817 | val_0_accuracy: 0.77547 |  0:07:30s\n",
            "epoch 84 | loss: 0.48731 | val_0_accuracy: 0.77267 |  0:07:36s\n",
            "epoch 85 | loss: 0.49585 | val_0_accuracy: 0.77915 |  0:07:41s\n",
            "epoch 86 | loss: 0.48626 | val_0_accuracy: 0.78454 |  0:07:46s\n",
            "epoch 87 | loss: 0.48275 | val_0_accuracy: 0.77763 |  0:07:51s\n",
            "epoch 88 | loss: 0.47433 | val_0_accuracy: 0.78649 |  0:07:57s\n",
            "epoch 89 | loss: 0.47134 | val_0_accuracy: 0.77418 |  0:08:02s\n",
            "epoch 90 | loss: 0.46948 | val_0_accuracy: 0.78778 |  0:08:08s\n",
            "epoch 91 | loss: 0.4718  | val_0_accuracy: 0.78541 |  0:08:13s\n",
            "epoch 92 | loss: 0.46794 | val_0_accuracy: 0.78497 |  0:08:18s\n",
            "epoch 93 | loss: 0.46194 | val_0_accuracy: 0.78584 |  0:08:23s\n",
            "epoch 94 | loss: 0.46714 | val_0_accuracy: 0.77461 |  0:08:29s\n",
            "epoch 95 | loss: 0.47074 | val_0_accuracy: 0.77936 |  0:08:34s\n",
            "epoch 96 | loss: 0.46194 | val_0_accuracy: 0.78325 |  0:08:39s\n",
            "epoch 97 | loss: 0.46812 | val_0_accuracy: 0.77763 |  0:08:44s\n",
            "epoch 98 | loss: 0.47899 | val_0_accuracy: 0.78195 |  0:08:49s\n",
            "epoch 99 | loss: 0.46774 | val_0_accuracy: 0.78454 |  0:08:55s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 90 and best_val_0_accuracy = 0.78778\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-04 09:00:02,184]\u001b[0m Trial 9 finished with value: 0.7877806563039723 and parameters: {'n_d': 27, 'n_a': 57, 'n_steps': 10, 'gamma': 1.872241759366836, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.1466592585848076}. Best is trial 9 with value: 0.7877806563039723.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       826\n",
            "           1       0.63      0.58      0.60       825\n",
            "           2       0.83      0.92      0.87       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.53      0.66      0.59       761\n",
            "           5       0.77      0.51      0.61       619\n",
            "\n",
            "    accuracy                           0.79      4632\n",
            "   macro avg       0.79      0.78      0.78      4632\n",
            "weighted avg       0.79      0.79      0.79      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.25473 | val_0_accuracy: 0.58247 |  0:00:02s\n",
            "epoch 1  | loss: 0.95719 | val_0_accuracy: 0.58787 |  0:00:04s\n",
            "epoch 2  | loss: 0.87985 | val_0_accuracy: 0.62068 |  0:00:06s\n",
            "epoch 3  | loss: 0.80687 | val_0_accuracy: 0.63903 |  0:00:08s\n",
            "epoch 4  | loss: 0.7676  | val_0_accuracy: 0.63687 |  0:00:10s\n",
            "epoch 5  | loss: 0.7498  | val_0_accuracy: 0.66278 |  0:00:12s\n",
            "epoch 6  | loss: 0.71328 | val_0_accuracy: 0.66041 |  0:00:15s\n",
            "epoch 7  | loss: 0.70114 | val_0_accuracy: 0.66861 |  0:00:17s\n",
            "epoch 8  | loss: 0.68906 | val_0_accuracy: 0.67832 |  0:00:19s\n",
            "epoch 9  | loss: 0.68079 | val_0_accuracy: 0.68739 |  0:00:21s\n",
            "epoch 10 | loss: 0.6745  | val_0_accuracy: 0.68005 |  0:00:23s\n",
            "epoch 11 | loss: 0.67646 | val_0_accuracy: 0.68804 |  0:00:25s\n",
            "epoch 12 | loss: 0.66943 | val_0_accuracy: 0.68415 |  0:00:27s\n",
            "epoch 13 | loss: 0.66062 | val_0_accuracy: 0.69819 |  0:00:30s\n",
            "epoch 14 | loss: 0.64338 | val_0_accuracy: 0.71373 |  0:00:32s\n",
            "epoch 15 | loss: 0.62873 | val_0_accuracy: 0.7038  |  0:00:34s\n",
            "epoch 16 | loss: 0.62572 | val_0_accuracy: 0.70402 |  0:00:36s\n",
            "epoch 17 | loss: 0.62148 | val_0_accuracy: 0.71222 |  0:00:38s\n",
            "epoch 18 | loss: 0.62825 | val_0_accuracy: 0.71762 |  0:00:40s\n",
            "epoch 19 | loss: 0.62073 | val_0_accuracy: 0.70553 |  0:00:43s\n",
            "epoch 20 | loss: 0.62953 | val_0_accuracy: 0.70984 |  0:00:45s\n",
            "epoch 21 | loss: 0.61278 | val_0_accuracy: 0.72733 |  0:00:47s\n",
            "epoch 22 | loss: 0.60821 | val_0_accuracy: 0.71934 |  0:00:49s\n",
            "epoch 23 | loss: 0.61049 | val_0_accuracy: 0.72453 |  0:00:51s\n",
            "epoch 24 | loss: 0.60351 | val_0_accuracy: 0.73057 |  0:00:53s\n",
            "epoch 25 | loss: 0.60411 | val_0_accuracy: 0.72345 |  0:00:55s\n",
            "epoch 26 | loss: 0.59229 | val_0_accuracy: 0.72345 |  0:00:57s\n",
            "epoch 27 | loss: 0.60269 | val_0_accuracy: 0.72042 |  0:01:00s\n",
            "epoch 28 | loss: 0.59508 | val_0_accuracy: 0.73424 |  0:01:02s\n",
            "epoch 29 | loss: 0.5858  | val_0_accuracy: 0.71718 |  0:01:04s\n",
            "epoch 30 | loss: 0.6025  | val_0_accuracy: 0.73489 |  0:01:06s\n",
            "epoch 31 | loss: 0.57889 | val_0_accuracy: 0.73813 |  0:01:08s\n",
            "epoch 32 | loss: 0.57093 | val_0_accuracy: 0.75    |  0:01:10s\n",
            "epoch 33 | loss: 0.56396 | val_0_accuracy: 0.74244 |  0:01:13s\n",
            "epoch 34 | loss: 0.57618 | val_0_accuracy: 0.74136 |  0:01:15s\n",
            "epoch 35 | loss: 0.56088 | val_0_accuracy: 0.74827 |  0:01:17s\n",
            "epoch 36 | loss: 0.56726 | val_0_accuracy: 0.7513  |  0:01:19s\n",
            "epoch 37 | loss: 0.56637 | val_0_accuracy: 0.74503 |  0:01:21s\n",
            "epoch 38 | loss: 0.55332 | val_0_accuracy: 0.75453 |  0:01:23s\n",
            "epoch 39 | loss: 0.54982 | val_0_accuracy: 0.74309 |  0:01:25s\n",
            "epoch 40 | loss: 0.54476 | val_0_accuracy: 0.75216 |  0:01:27s\n",
            "epoch 41 | loss: 0.53938 | val_0_accuracy: 0.75864 |  0:01:30s\n",
            "epoch 42 | loss: 0.53213 | val_0_accuracy: 0.7582  |  0:01:32s\n",
            "epoch 43 | loss: 0.52486 | val_0_accuracy: 0.7582  |  0:01:34s\n",
            "epoch 44 | loss: 0.54181 | val_0_accuracy: 0.75518 |  0:01:36s\n",
            "epoch 45 | loss: 0.5291  | val_0_accuracy: 0.75669 |  0:01:38s\n",
            "epoch 46 | loss: 0.52494 | val_0_accuracy: 0.769   |  0:01:40s\n",
            "epoch 47 | loss: 0.51577 | val_0_accuracy: 0.76921 |  0:01:42s\n",
            "epoch 48 | loss: 0.51101 | val_0_accuracy: 0.75086 |  0:01:45s\n",
            "epoch 49 | loss: 0.50822 | val_0_accuracy: 0.77094 |  0:01:47s\n",
            "epoch 50 | loss: 0.50717 | val_0_accuracy: 0.76684 |  0:01:49s\n",
            "epoch 51 | loss: 0.50596 | val_0_accuracy: 0.75151 |  0:01:51s\n",
            "epoch 52 | loss: 0.50326 | val_0_accuracy: 0.7744  |  0:01:53s\n",
            "epoch 53 | loss: 0.4979  | val_0_accuracy: 0.77699 |  0:01:55s\n",
            "epoch 54 | loss: 0.50147 | val_0_accuracy: 0.76835 |  0:01:58s\n",
            "epoch 55 | loss: 0.50247 | val_0_accuracy: 0.77029 |  0:02:01s\n",
            "epoch 56 | loss: 0.49055 | val_0_accuracy: 0.77828 |  0:02:03s\n",
            "epoch 57 | loss: 0.48812 | val_0_accuracy: 0.77591 |  0:02:05s\n",
            "epoch 58 | loss: 0.48513 | val_0_accuracy: 0.78238 |  0:02:07s\n",
            "epoch 59 | loss: 0.48379 | val_0_accuracy: 0.78217 |  0:02:09s\n",
            "epoch 60 | loss: 0.47632 | val_0_accuracy: 0.77936 |  0:02:11s\n",
            "epoch 61 | loss: 0.47888 | val_0_accuracy: 0.77094 |  0:02:13s\n",
            "epoch 62 | loss: 0.47331 | val_0_accuracy: 0.77677 |  0:02:15s\n",
            "epoch 63 | loss: 0.47779 | val_0_accuracy: 0.77979 |  0:02:18s\n",
            "epoch 64 | loss: 0.46853 | val_0_accuracy: 0.78368 |  0:02:20s\n",
            "epoch 65 | loss: 0.46927 | val_0_accuracy: 0.77893 |  0:02:22s\n",
            "epoch 66 | loss: 0.46497 | val_0_accuracy: 0.78195 |  0:02:24s\n",
            "epoch 67 | loss: 0.46145 | val_0_accuracy: 0.78001 |  0:02:26s\n",
            "epoch 68 | loss: 0.4661  | val_0_accuracy: 0.78368 |  0:02:28s\n",
            "epoch 69 | loss: 0.45974 | val_0_accuracy: 0.78433 |  0:02:30s\n",
            "epoch 70 | loss: 0.4586  | val_0_accuracy: 0.78195 |  0:02:32s\n",
            "epoch 71 | loss: 0.4573  | val_0_accuracy: 0.77915 |  0:02:34s\n",
            "epoch 72 | loss: 0.45523 | val_0_accuracy: 0.78519 |  0:02:37s\n",
            "epoch 73 | loss: 0.44646 | val_0_accuracy: 0.78325 |  0:02:39s\n",
            "epoch 74 | loss: 0.44598 | val_0_accuracy: 0.7921  |  0:02:41s\n",
            "epoch 75 | loss: 0.44601 | val_0_accuracy: 0.78584 |  0:02:43s\n",
            "epoch 76 | loss: 0.44403 | val_0_accuracy: 0.78994 |  0:02:45s\n",
            "epoch 77 | loss: 0.44881 | val_0_accuracy: 0.78541 |  0:02:47s\n",
            "epoch 78 | loss: 0.44237 | val_0_accuracy: 0.788   |  0:02:49s\n",
            "epoch 79 | loss: 0.44858 | val_0_accuracy: 0.78929 |  0:02:51s\n",
            "epoch 80 | loss: 0.44511 | val_0_accuracy: 0.79188 |  0:02:54s\n",
            "epoch 81 | loss: 0.43396 | val_0_accuracy: 0.78864 |  0:02:56s\n",
            "epoch 82 | loss: 0.43687 | val_0_accuracy: 0.78908 |  0:02:58s\n",
            "epoch 83 | loss: 0.44207 | val_0_accuracy: 0.78994 |  0:03:00s\n",
            "epoch 84 | loss: 0.43085 | val_0_accuracy: 0.78821 |  0:03:02s\n",
            "\n",
            "Early stopping occurred at epoch 84 with best_epoch = 74 and best_val_0_accuracy = 0.7921\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-04 09:03:05,967]\u001b[0m Trial 10 finished with value: 0.792098445595855 and parameters: {'n_d': 42, 'n_a': 55, 'n_steps': 4, 'gamma': 1.9682800912993588, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.1803100114434414}. Best is trial 10 with value: 0.792098445595855.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       826\n",
            "           1       0.64      0.60      0.62       825\n",
            "           2       0.84      0.91      0.88       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.53      0.61      0.57       761\n",
            "           5       0.73      0.57      0.64       619\n",
            "\n",
            "    accuracy                           0.79      4632\n",
            "   macro avg       0.79      0.78      0.78      4632\n",
            "weighted avg       0.79      0.79      0.79      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.12951 | val_0_accuracy: 0.61205 |  0:00:01s\n",
            "epoch 1  | loss: 0.83717 | val_0_accuracy: 0.62845 |  0:00:03s\n",
            "epoch 2  | loss: 0.77534 | val_0_accuracy: 0.66149 |  0:00:05s\n",
            "epoch 3  | loss: 0.74468 | val_0_accuracy: 0.65242 |  0:00:07s\n",
            "epoch 4  | loss: 0.72294 | val_0_accuracy: 0.67509 |  0:00:08s\n",
            "epoch 5  | loss: 0.69809 | val_0_accuracy: 0.68739 |  0:00:10s\n",
            "epoch 6  | loss: 0.67985 | val_0_accuracy: 0.6889  |  0:00:12s\n",
            "epoch 7  | loss: 0.67028 | val_0_accuracy: 0.70315 |  0:00:14s\n",
            "epoch 8  | loss: 0.65661 | val_0_accuracy: 0.69408 |  0:00:15s\n",
            "epoch 9  | loss: 0.65113 | val_0_accuracy: 0.70553 |  0:00:17s\n",
            "epoch 10 | loss: 0.6443  | val_0_accuracy: 0.70639 |  0:00:19s\n",
            "epoch 11 | loss: 0.63983 | val_0_accuracy: 0.70358 |  0:00:21s\n",
            "epoch 12 | loss: 0.63011 | val_0_accuracy: 0.71071 |  0:00:22s\n",
            "epoch 13 | loss: 0.62531 | val_0_accuracy: 0.71373 |  0:00:24s\n",
            "epoch 14 | loss: 0.61081 | val_0_accuracy: 0.70725 |  0:00:26s\n",
            "epoch 15 | loss: 0.60467 | val_0_accuracy: 0.71546 |  0:00:28s\n",
            "epoch 16 | loss: 0.60012 | val_0_accuracy: 0.731   |  0:00:29s\n",
            "epoch 17 | loss: 0.60587 | val_0_accuracy: 0.71978 |  0:00:31s\n",
            "epoch 18 | loss: 0.59452 | val_0_accuracy: 0.72776 |  0:00:33s\n",
            "epoch 19 | loss: 0.59123 | val_0_accuracy: 0.73726 |  0:00:35s\n",
            "epoch 20 | loss: 0.58399 | val_0_accuracy: 0.73057 |  0:00:37s\n",
            "epoch 21 | loss: 0.57421 | val_0_accuracy: 0.73726 |  0:00:38s\n",
            "epoch 22 | loss: 0.56741 | val_0_accuracy: 0.73769 |  0:00:40s\n",
            "epoch 23 | loss: 0.56816 | val_0_accuracy: 0.74266 |  0:00:42s\n",
            "epoch 24 | loss: 0.55485 | val_0_accuracy: 0.74223 |  0:00:43s\n",
            "epoch 25 | loss: 0.55794 | val_0_accuracy: 0.73921 |  0:00:45s\n",
            "epoch 26 | loss: 0.55188 | val_0_accuracy: 0.74914 |  0:00:47s\n",
            "epoch 27 | loss: 0.54287 | val_0_accuracy: 0.74935 |  0:00:49s\n",
            "epoch 28 | loss: 0.5401  | val_0_accuracy: 0.75086 |  0:00:50s\n",
            "epoch 29 | loss: 0.54139 | val_0_accuracy: 0.75022 |  0:00:52s\n",
            "epoch 30 | loss: 0.53652 | val_0_accuracy: 0.75864 |  0:00:54s\n",
            "epoch 31 | loss: 0.52732 | val_0_accuracy: 0.75648 |  0:00:56s\n",
            "epoch 32 | loss: 0.52542 | val_0_accuracy: 0.7595  |  0:00:57s\n",
            "epoch 33 | loss: 0.51907 | val_0_accuracy: 0.75756 |  0:00:59s\n",
            "epoch 34 | loss: 0.51424 | val_0_accuracy: 0.7595  |  0:01:01s\n",
            "epoch 35 | loss: 0.51599 | val_0_accuracy: 0.75302 |  0:01:03s\n",
            "epoch 36 | loss: 0.50833 | val_0_accuracy: 0.76857 |  0:01:04s\n",
            "epoch 37 | loss: 0.50346 | val_0_accuracy: 0.76123 |  0:01:06s\n",
            "epoch 38 | loss: 0.50417 | val_0_accuracy: 0.76576 |  0:01:08s\n",
            "epoch 39 | loss: 0.49918 | val_0_accuracy: 0.76727 |  0:01:10s\n",
            "epoch 40 | loss: 0.4917  | val_0_accuracy: 0.77137 |  0:01:11s\n",
            "epoch 41 | loss: 0.48806 | val_0_accuracy: 0.7677  |  0:01:13s\n",
            "epoch 42 | loss: 0.48814 | val_0_accuracy: 0.77396 |  0:01:15s\n",
            "epoch 43 | loss: 0.48219 | val_0_accuracy: 0.77245 |  0:01:17s\n",
            "epoch 44 | loss: 0.47789 | val_0_accuracy: 0.77677 |  0:01:18s\n",
            "epoch 45 | loss: 0.48463 | val_0_accuracy: 0.76425 |  0:01:20s\n",
            "epoch 46 | loss: 0.48021 | val_0_accuracy: 0.77396 |  0:01:22s\n",
            "epoch 47 | loss: 0.47191 | val_0_accuracy: 0.78044 |  0:01:24s\n",
            "epoch 48 | loss: 0.4662  | val_0_accuracy: 0.78087 |  0:01:25s\n",
            "epoch 49 | loss: 0.46788 | val_0_accuracy: 0.78195 |  0:01:27s\n",
            "epoch 50 | loss: 0.46715 | val_0_accuracy: 0.77418 |  0:01:29s\n",
            "epoch 51 | loss: 0.46586 | val_0_accuracy: 0.77871 |  0:01:31s\n",
            "epoch 52 | loss: 0.45664 | val_0_accuracy: 0.78001 |  0:01:33s\n",
            "epoch 53 | loss: 0.45886 | val_0_accuracy: 0.78692 |  0:01:34s\n",
            "epoch 54 | loss: 0.45118 | val_0_accuracy: 0.78022 |  0:01:36s\n",
            "epoch 55 | loss: 0.45143 | val_0_accuracy: 0.78433 |  0:01:38s\n",
            "epoch 56 | loss: 0.44876 | val_0_accuracy: 0.78584 |  0:01:40s\n",
            "epoch 57 | loss: 0.44767 | val_0_accuracy: 0.78282 |  0:01:41s\n",
            "epoch 58 | loss: 0.43703 | val_0_accuracy: 0.79016 |  0:01:43s\n",
            "epoch 59 | loss: 0.44392 | val_0_accuracy: 0.78152 |  0:01:45s\n",
            "epoch 60 | loss: 0.43747 | val_0_accuracy: 0.78649 |  0:01:47s\n",
            "epoch 61 | loss: 0.44144 | val_0_accuracy: 0.78951 |  0:01:48s\n",
            "epoch 62 | loss: 0.43659 | val_0_accuracy: 0.79102 |  0:01:50s\n",
            "epoch 63 | loss: 0.4335  | val_0_accuracy: 0.78821 |  0:01:52s\n",
            "epoch 64 | loss: 0.44378 | val_0_accuracy: 0.78735 |  0:01:53s\n",
            "epoch 65 | loss: 0.43272 | val_0_accuracy: 0.79059 |  0:01:55s\n",
            "epoch 66 | loss: 0.42533 | val_0_accuracy: 0.79253 |  0:01:57s\n",
            "epoch 67 | loss: 0.42903 | val_0_accuracy: 0.78605 |  0:01:59s\n",
            "epoch 68 | loss: 0.43555 | val_0_accuracy: 0.7813  |  0:02:00s\n",
            "epoch 69 | loss: 0.42656 | val_0_accuracy: 0.79469 |  0:02:02s\n",
            "epoch 70 | loss: 0.41824 | val_0_accuracy: 0.7921  |  0:02:04s\n",
            "epoch 71 | loss: 0.423   | val_0_accuracy: 0.788   |  0:02:06s\n",
            "epoch 72 | loss: 0.42288 | val_0_accuracy: 0.7921  |  0:02:08s\n",
            "epoch 73 | loss: 0.41414 | val_0_accuracy: 0.79663 |  0:02:09s\n",
            "epoch 74 | loss: 0.41556 | val_0_accuracy: 0.79016 |  0:02:11s\n",
            "epoch 75 | loss: 0.41058 | val_0_accuracy: 0.79275 |  0:02:13s\n",
            "epoch 76 | loss: 0.40719 | val_0_accuracy: 0.79339 |  0:02:15s\n",
            "epoch 77 | loss: 0.40295 | val_0_accuracy: 0.79706 |  0:02:16s\n",
            "epoch 78 | loss: 0.402   | val_0_accuracy: 0.79965 |  0:02:18s\n",
            "epoch 79 | loss: 0.40434 | val_0_accuracy: 0.80181 |  0:02:20s\n",
            "epoch 80 | loss: 0.39866 | val_0_accuracy: 0.79901 |  0:02:22s\n",
            "epoch 81 | loss: 0.39838 | val_0_accuracy: 0.79771 |  0:02:23s\n",
            "epoch 82 | loss: 0.39601 | val_0_accuracy: 0.79275 |  0:02:25s\n",
            "epoch 83 | loss: 0.39745 | val_0_accuracy: 0.79706 |  0:02:28s\n",
            "epoch 84 | loss: 0.39431 | val_0_accuracy: 0.79879 |  0:02:29s\n",
            "epoch 85 | loss: 0.3982  | val_0_accuracy: 0.79361 |  0:02:31s\n",
            "epoch 86 | loss: 0.39072 | val_0_accuracy: 0.79685 |  0:02:33s\n",
            "epoch 87 | loss: 0.38979 | val_0_accuracy: 0.79922 |  0:02:35s\n",
            "epoch 88 | loss: 0.39019 | val_0_accuracy: 0.79685 |  0:02:37s\n",
            "epoch 89 | loss: 0.39258 | val_0_accuracy: 0.79879 |  0:02:38s\n",
            "\n",
            "Early stopping occurred at epoch 89 with best_epoch = 79 and best_val_0_accuracy = 0.80181\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-04 09:05:45,653]\u001b[0m Trial 11 finished with value: 0.8018134715025906 and parameters: {'n_d': 42, 'n_a': 53, 'n_steps': 3, 'gamma': 1.991212418400103, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.1743157179441465}. Best is trial 11 with value: 0.8018134715025906.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       826\n",
            "           1       0.67      0.61      0.64       825\n",
            "           2       0.83      0.94      0.88       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.57      0.55      0.56       761\n",
            "           5       0.69      0.66      0.67       619\n",
            "\n",
            "    accuracy                           0.80      4632\n",
            "   macro avg       0.79      0.79      0.79      4632\n",
            "weighted avg       0.80      0.80      0.80      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.15244 | val_0_accuracy: 0.59499 |  0:00:01s\n",
            "epoch 1  | loss: 0.83324 | val_0_accuracy: 0.64162 |  0:00:03s\n",
            "epoch 2  | loss: 0.75438 | val_0_accuracy: 0.64486 |  0:00:05s\n",
            "epoch 3  | loss: 0.7191  | val_0_accuracy: 0.68372 |  0:00:07s\n",
            "epoch 4  | loss: 0.69332 | val_0_accuracy: 0.69387 |  0:00:08s\n",
            "epoch 5  | loss: 0.67523 | val_0_accuracy: 0.70078 |  0:00:10s\n",
            "epoch 6  | loss: 0.66103 | val_0_accuracy: 0.69862 |  0:00:12s\n",
            "epoch 7  | loss: 0.65618 | val_0_accuracy: 0.70121 |  0:00:14s\n",
            "epoch 8  | loss: 0.64183 | val_0_accuracy: 0.70941 |  0:00:15s\n",
            "epoch 9  | loss: 0.63559 | val_0_accuracy: 0.712   |  0:00:17s\n",
            "epoch 10 | loss: 0.62138 | val_0_accuracy: 0.71718 |  0:00:19s\n",
            "epoch 11 | loss: 0.62344 | val_0_accuracy: 0.72085 |  0:00:21s\n",
            "epoch 12 | loss: 0.61675 | val_0_accuracy: 0.72237 |  0:00:23s\n",
            "epoch 13 | loss: 0.60704 | val_0_accuracy: 0.73834 |  0:00:24s\n",
            "epoch 14 | loss: 0.60095 | val_0_accuracy: 0.73942 |  0:00:26s\n",
            "epoch 15 | loss: 0.5913  | val_0_accuracy: 0.73187 |  0:00:28s\n",
            "epoch 16 | loss: 0.58647 | val_0_accuracy: 0.7323  |  0:00:30s\n",
            "epoch 17 | loss: 0.58424 | val_0_accuracy: 0.73618 |  0:00:31s\n",
            "epoch 18 | loss: 0.58335 | val_0_accuracy: 0.73575 |  0:00:33s\n",
            "epoch 19 | loss: 0.59519 | val_0_accuracy: 0.74007 |  0:00:35s\n",
            "epoch 20 | loss: 0.57864 | val_0_accuracy: 0.74288 |  0:00:37s\n",
            "epoch 21 | loss: 0.57371 | val_0_accuracy: 0.7487  |  0:00:38s\n",
            "epoch 22 | loss: 0.56823 | val_0_accuracy: 0.75216 |  0:00:40s\n",
            "epoch 23 | loss: 0.56399 | val_0_accuracy: 0.75086 |  0:00:42s\n",
            "epoch 24 | loss: 0.55415 | val_0_accuracy: 0.7554  |  0:00:44s\n",
            "epoch 25 | loss: 0.54758 | val_0_accuracy: 0.75173 |  0:00:45s\n",
            "epoch 26 | loss: 0.5427  | val_0_accuracy: 0.7513  |  0:00:47s\n",
            "epoch 27 | loss: 0.53976 | val_0_accuracy: 0.7582  |  0:00:49s\n",
            "epoch 28 | loss: 0.53261 | val_0_accuracy: 0.76295 |  0:00:51s\n",
            "epoch 29 | loss: 0.52864 | val_0_accuracy: 0.75583 |  0:00:52s\n",
            "epoch 30 | loss: 0.52503 | val_0_accuracy: 0.76209 |  0:00:54s\n",
            "epoch 31 | loss: 0.52186 | val_0_accuracy: 0.77396 |  0:00:56s\n",
            "epoch 32 | loss: 0.51747 | val_0_accuracy: 0.76813 |  0:00:58s\n",
            "epoch 33 | loss: 0.51413 | val_0_accuracy: 0.76403 |  0:00:59s\n",
            "epoch 34 | loss: 0.51441 | val_0_accuracy: 0.76231 |  0:01:01s\n",
            "epoch 35 | loss: 0.50623 | val_0_accuracy: 0.77224 |  0:01:03s\n",
            "epoch 36 | loss: 0.50752 | val_0_accuracy: 0.77202 |  0:01:05s\n",
            "epoch 37 | loss: 0.49785 | val_0_accuracy: 0.76921 |  0:01:06s\n",
            "epoch 38 | loss: 0.48935 | val_0_accuracy: 0.76706 |  0:01:08s\n",
            "epoch 39 | loss: 0.49122 | val_0_accuracy: 0.78087 |  0:01:10s\n",
            "epoch 40 | loss: 0.4865  | val_0_accuracy: 0.77742 |  0:01:12s\n",
            "epoch 41 | loss: 0.48184 | val_0_accuracy: 0.77893 |  0:01:13s\n",
            "epoch 42 | loss: 0.4785  | val_0_accuracy: 0.7772  |  0:01:15s\n",
            "epoch 43 | loss: 0.47817 | val_0_accuracy: 0.78368 |  0:01:17s\n",
            "epoch 44 | loss: 0.47136 | val_0_accuracy: 0.78303 |  0:01:19s\n",
            "epoch 45 | loss: 0.46739 | val_0_accuracy: 0.78497 |  0:01:20s\n",
            "epoch 46 | loss: 0.46467 | val_0_accuracy: 0.78303 |  0:01:22s\n",
            "epoch 47 | loss: 0.46148 | val_0_accuracy: 0.78627 |  0:01:24s\n",
            "epoch 48 | loss: 0.46014 | val_0_accuracy: 0.78411 |  0:01:25s\n",
            "epoch 49 | loss: 0.45349 | val_0_accuracy: 0.78562 |  0:01:27s\n",
            "epoch 50 | loss: 0.45099 | val_0_accuracy: 0.78368 |  0:01:29s\n",
            "epoch 51 | loss: 0.45876 | val_0_accuracy: 0.77785 |  0:01:31s\n",
            "epoch 52 | loss: 0.45157 | val_0_accuracy: 0.78433 |  0:01:32s\n",
            "epoch 53 | loss: 0.44637 | val_0_accuracy: 0.78497 |  0:01:34s\n",
            "epoch 54 | loss: 0.44926 | val_0_accuracy: 0.78735 |  0:01:36s\n",
            "epoch 55 | loss: 0.4439  | val_0_accuracy: 0.79037 |  0:01:38s\n",
            "epoch 56 | loss: 0.44147 | val_0_accuracy: 0.78541 |  0:01:39s\n",
            "epoch 57 | loss: 0.45274 | val_0_accuracy: 0.7908  |  0:01:41s\n",
            "epoch 58 | loss: 0.44366 | val_0_accuracy: 0.78152 |  0:01:43s\n",
            "epoch 59 | loss: 0.44567 | val_0_accuracy: 0.79231 |  0:01:44s\n",
            "epoch 60 | loss: 0.43348 | val_0_accuracy: 0.79491 |  0:01:46s\n",
            "epoch 61 | loss: 0.43083 | val_0_accuracy: 0.7908  |  0:01:48s\n",
            "epoch 62 | loss: 0.43443 | val_0_accuracy: 0.79491 |  0:01:50s\n",
            "epoch 63 | loss: 0.42835 | val_0_accuracy: 0.7908  |  0:01:51s\n",
            "epoch 64 | loss: 0.42068 | val_0_accuracy: 0.78843 |  0:01:53s\n",
            "epoch 65 | loss: 0.42156 | val_0_accuracy: 0.79598 |  0:01:55s\n",
            "epoch 66 | loss: 0.42217 | val_0_accuracy: 0.79383 |  0:01:56s\n",
            "epoch 67 | loss: 0.41327 | val_0_accuracy: 0.7908  |  0:01:58s\n",
            "epoch 68 | loss: 0.41282 | val_0_accuracy: 0.79253 |  0:02:00s\n",
            "epoch 69 | loss: 0.41337 | val_0_accuracy: 0.79663 |  0:02:02s\n",
            "epoch 70 | loss: 0.40667 | val_0_accuracy: 0.79404 |  0:02:04s\n",
            "epoch 71 | loss: 0.40799 | val_0_accuracy: 0.79534 |  0:02:05s\n",
            "epoch 72 | loss: 0.40767 | val_0_accuracy: 0.80009 |  0:02:07s\n",
            "epoch 73 | loss: 0.40186 | val_0_accuracy: 0.79231 |  0:02:09s\n",
            "epoch 74 | loss: 0.40025 | val_0_accuracy: 0.79491 |  0:02:11s\n",
            "epoch 75 | loss: 0.40427 | val_0_accuracy: 0.79793 |  0:02:12s\n",
            "epoch 76 | loss: 0.39905 | val_0_accuracy: 0.79836 |  0:02:14s\n",
            "epoch 77 | loss: 0.40854 | val_0_accuracy: 0.79944 |  0:02:16s\n",
            "epoch 78 | loss: 0.40421 | val_0_accuracy: 0.79555 |  0:02:18s\n",
            "epoch 79 | loss: 0.40017 | val_0_accuracy: 0.80332 |  0:02:20s\n",
            "epoch 80 | loss: 0.39573 | val_0_accuracy: 0.80073 |  0:02:22s\n",
            "epoch 81 | loss: 0.39153 | val_0_accuracy: 0.80246 |  0:02:23s\n",
            "epoch 82 | loss: 0.3933  | val_0_accuracy: 0.7962  |  0:02:25s\n",
            "epoch 83 | loss: 0.39083 | val_0_accuracy: 0.79879 |  0:02:27s\n",
            "epoch 84 | loss: 0.38413 | val_0_accuracy: 0.7975  |  0:02:29s\n",
            "epoch 85 | loss: 0.38783 | val_0_accuracy: 0.79642 |  0:02:31s\n",
            "epoch 86 | loss: 0.3865  | val_0_accuracy: 0.8003  |  0:02:32s\n",
            "epoch 87 | loss: 0.38166 | val_0_accuracy: 0.80225 |  0:02:34s\n",
            "epoch 88 | loss: 0.39914 | val_0_accuracy: 0.79663 |  0:02:36s\n",
            "epoch 89 | loss: 0.39718 | val_0_accuracy: 0.79145 |  0:02:38s\n",
            "\n",
            "Early stopping occurred at epoch 89 with best_epoch = 79 and best_val_0_accuracy = 0.80332\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-04 09:08:25,105]\u001b[0m Trial 12 finished with value: 0.8033246977547496 and parameters: {'n_d': 44, 'n_a': 51, 'n_steps': 3, 'gamma': 1.998898263952073, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.36368393131019705}. Best is trial 12 with value: 0.8033246977547496.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       826\n",
            "           1       0.65      0.62      0.63       825\n",
            "           2       0.83      0.95      0.89       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.58      0.55      0.57       761\n",
            "           5       0.71      0.65      0.68       619\n",
            "\n",
            "    accuracy                           0.80      4632\n",
            "   macro avg       0.79      0.80      0.79      4632\n",
            "weighted avg       0.80      0.80      0.80      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.13553 | val_0_accuracy: 0.63428 |  0:00:01s\n",
            "epoch 1  | loss: 0.78969 | val_0_accuracy: 0.65652 |  0:00:03s\n",
            "epoch 2  | loss: 0.73441 | val_0_accuracy: 0.66645 |  0:00:04s\n",
            "epoch 3  | loss: 0.70626 | val_0_accuracy: 0.6794  |  0:00:06s\n",
            "epoch 4  | loss: 0.6911  | val_0_accuracy: 0.69365 |  0:00:07s\n",
            "epoch 5  | loss: 0.67334 | val_0_accuracy: 0.68631 |  0:00:09s\n",
            "epoch 6  | loss: 0.66247 | val_0_accuracy: 0.69365 |  0:00:10s\n",
            "epoch 7  | loss: 0.65548 | val_0_accuracy: 0.71244 |  0:00:12s\n",
            "epoch 8  | loss: 0.64157 | val_0_accuracy: 0.70531 |  0:00:13s\n",
            "epoch 9  | loss: 0.63774 | val_0_accuracy: 0.70186 |  0:00:15s\n",
            "epoch 10 | loss: 0.6359  | val_0_accuracy: 0.71308 |  0:00:16s\n",
            "epoch 11 | loss: 0.63434 | val_0_accuracy: 0.71179 |  0:00:18s\n",
            "epoch 12 | loss: 0.62556 | val_0_accuracy: 0.71654 |  0:00:19s\n",
            "epoch 13 | loss: 0.61884 | val_0_accuracy: 0.71675 |  0:00:21s\n",
            "epoch 14 | loss: 0.63546 | val_0_accuracy: 0.70812 |  0:00:22s\n",
            "epoch 15 | loss: 0.62086 | val_0_accuracy: 0.7256  |  0:00:24s\n",
            "epoch 16 | loss: 0.61099 | val_0_accuracy: 0.71891 |  0:00:25s\n",
            "epoch 17 | loss: 0.60487 | val_0_accuracy: 0.73014 |  0:00:27s\n",
            "epoch 18 | loss: 0.59849 | val_0_accuracy: 0.72884 |  0:00:28s\n",
            "epoch 19 | loss: 0.59592 | val_0_accuracy: 0.70769 |  0:00:30s\n",
            "epoch 20 | loss: 0.61952 | val_0_accuracy: 0.71438 |  0:00:31s\n",
            "epoch 21 | loss: 0.60597 | val_0_accuracy: 0.73122 |  0:00:32s\n",
            "epoch 22 | loss: 0.594   | val_0_accuracy: 0.72107 |  0:00:34s\n",
            "epoch 23 | loss: 0.59828 | val_0_accuracy: 0.7282  |  0:00:35s\n",
            "epoch 24 | loss: 0.5852  | val_0_accuracy: 0.73079 |  0:00:37s\n",
            "epoch 25 | loss: 0.58581 | val_0_accuracy: 0.74439 |  0:00:38s\n",
            "epoch 26 | loss: 0.57334 | val_0_accuracy: 0.75    |  0:00:40s\n",
            "epoch 27 | loss: 0.58026 | val_0_accuracy: 0.7364  |  0:00:41s\n",
            "epoch 28 | loss: 0.60894 | val_0_accuracy: 0.72129 |  0:00:43s\n",
            "epoch 29 | loss: 0.60515 | val_0_accuracy: 0.73748 |  0:00:44s\n",
            "epoch 30 | loss: 0.58285 | val_0_accuracy: 0.73813 |  0:00:47s\n",
            "epoch 31 | loss: 0.5711  | val_0_accuracy: 0.72474 |  0:00:48s\n",
            "epoch 32 | loss: 0.56777 | val_0_accuracy: 0.74849 |  0:00:50s\n",
            "epoch 33 | loss: 0.57388 | val_0_accuracy: 0.7513  |  0:00:51s\n",
            "epoch 34 | loss: 0.5578  | val_0_accuracy: 0.74741 |  0:00:53s\n",
            "epoch 35 | loss: 0.54554 | val_0_accuracy: 0.74201 |  0:00:54s\n",
            "epoch 36 | loss: 0.5523  | val_0_accuracy: 0.74633 |  0:00:56s\n",
            "epoch 37 | loss: 0.5486  | val_0_accuracy: 0.75065 |  0:00:57s\n",
            "epoch 38 | loss: 0.53897 | val_0_accuracy: 0.76187 |  0:00:59s\n",
            "epoch 39 | loss: 0.5431  | val_0_accuracy: 0.76187 |  0:01:00s\n",
            "epoch 40 | loss: 0.53167 | val_0_accuracy: 0.76101 |  0:01:01s\n",
            "epoch 41 | loss: 0.52605 | val_0_accuracy: 0.75497 |  0:01:03s\n",
            "epoch 42 | loss: 0.5442  | val_0_accuracy: 0.75065 |  0:01:04s\n",
            "epoch 43 | loss: 0.54389 | val_0_accuracy: 0.76123 |  0:01:06s\n",
            "epoch 44 | loss: 0.53292 | val_0_accuracy: 0.76036 |  0:01:07s\n",
            "epoch 45 | loss: 0.52916 | val_0_accuracy: 0.76252 |  0:01:09s\n",
            "epoch 46 | loss: 0.5212  | val_0_accuracy: 0.75864 |  0:01:10s\n",
            "epoch 47 | loss: 0.5145  | val_0_accuracy: 0.77245 |  0:01:12s\n",
            "epoch 48 | loss: 0.511   | val_0_accuracy: 0.77224 |  0:01:13s\n",
            "epoch 49 | loss: 0.5188  | val_0_accuracy: 0.76965 |  0:01:15s\n",
            "epoch 50 | loss: 0.51166 | val_0_accuracy: 0.76835 |  0:01:16s\n",
            "epoch 51 | loss: 0.50169 | val_0_accuracy: 0.76641 |  0:01:18s\n",
            "epoch 52 | loss: 0.49889 | val_0_accuracy: 0.78109 |  0:01:19s\n",
            "epoch 53 | loss: 0.49034 | val_0_accuracy: 0.76662 |  0:01:21s\n",
            "epoch 54 | loss: 0.50288 | val_0_accuracy: 0.76166 |  0:01:22s\n",
            "epoch 55 | loss: 0.51416 | val_0_accuracy: 0.77094 |  0:01:24s\n",
            "epoch 56 | loss: 0.49342 | val_0_accuracy: 0.77569 |  0:01:25s\n",
            "epoch 57 | loss: 0.49025 | val_0_accuracy: 0.7813  |  0:01:27s\n",
            "epoch 58 | loss: 0.48549 | val_0_accuracy: 0.77828 |  0:01:28s\n",
            "epoch 59 | loss: 0.47757 | val_0_accuracy: 0.77936 |  0:01:30s\n",
            "epoch 60 | loss: 0.47249 | val_0_accuracy: 0.78778 |  0:01:31s\n",
            "epoch 61 | loss: 0.46986 | val_0_accuracy: 0.78195 |  0:01:33s\n",
            "epoch 62 | loss: 0.46876 | val_0_accuracy: 0.7772  |  0:01:34s\n",
            "epoch 63 | loss: 0.46587 | val_0_accuracy: 0.78303 |  0:01:35s\n",
            "epoch 64 | loss: 0.4625  | val_0_accuracy: 0.7813  |  0:01:37s\n",
            "epoch 65 | loss: 0.45829 | val_0_accuracy: 0.78864 |  0:01:38s\n",
            "epoch 66 | loss: 0.45747 | val_0_accuracy: 0.78433 |  0:01:40s\n",
            "epoch 67 | loss: 0.45367 | val_0_accuracy: 0.78325 |  0:01:41s\n",
            "epoch 68 | loss: 0.45857 | val_0_accuracy: 0.78843 |  0:01:43s\n",
            "epoch 69 | loss: 0.48674 | val_0_accuracy: 0.78195 |  0:01:44s\n",
            "epoch 70 | loss: 0.46433 | val_0_accuracy: 0.77224 |  0:01:46s\n",
            "epoch 71 | loss: 0.46381 | val_0_accuracy: 0.78282 |  0:01:47s\n",
            "epoch 72 | loss: 0.44786 | val_0_accuracy: 0.78325 |  0:01:49s\n",
            "epoch 73 | loss: 0.44696 | val_0_accuracy: 0.78389 |  0:01:50s\n",
            "epoch 74 | loss: 0.45413 | val_0_accuracy: 0.78022 |  0:01:52s\n",
            "epoch 75 | loss: 0.45142 | val_0_accuracy: 0.78713 |  0:01:53s\n",
            "\n",
            "Early stopping occurred at epoch 75 with best_epoch = 65 and best_val_0_accuracy = 0.78864\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-04 09:10:19,548]\u001b[0m Trial 13 finished with value: 0.7886442141623489 and parameters: {'n_d': 45, 'n_a': 48, 'n_steps': 3, 'gamma': 1.9506646301997708, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.3978009362141671}. Best is trial 12 with value: 0.8033246977547496.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       826\n",
            "           1       0.63      0.60      0.62       825\n",
            "           2       0.81      0.95      0.87       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.54      0.55      0.55       761\n",
            "           5       0.70      0.57      0.63       619\n",
            "\n",
            "    accuracy                           0.79      4632\n",
            "   macro avg       0.78      0.78      0.78      4632\n",
            "weighted avg       0.79      0.79      0.79      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.1195  | val_0_accuracy: 0.62284 |  0:00:02s\n",
            "epoch 1  | loss: 0.80907 | val_0_accuracy: 0.64702 |  0:00:04s\n",
            "epoch 2  | loss: 0.73373 | val_0_accuracy: 0.66818 |  0:00:06s\n",
            "epoch 3  | loss: 0.70925 | val_0_accuracy: 0.64918 |  0:00:08s\n",
            "epoch 4  | loss: 0.6941  | val_0_accuracy: 0.67142 |  0:00:10s\n",
            "epoch 5  | loss: 0.69194 | val_0_accuracy: 0.67897 |  0:00:12s\n",
            "epoch 6  | loss: 0.68081 | val_0_accuracy: 0.68696 |  0:00:14s\n",
            "epoch 7  | loss: 0.67233 | val_0_accuracy: 0.67876 |  0:00:16s\n",
            "epoch 8  | loss: 0.6715  | val_0_accuracy: 0.69214 |  0:00:18s\n",
            "epoch 9  | loss: 0.65328 | val_0_accuracy: 0.69883 |  0:00:20s\n",
            "epoch 10 | loss: 0.6489  | val_0_accuracy: 0.70142 |  0:00:22s\n",
            "epoch 11 | loss: 0.63506 | val_0_accuracy: 0.70812 |  0:00:24s\n",
            "epoch 12 | loss: 0.6231  | val_0_accuracy: 0.7079  |  0:00:26s\n",
            "epoch 13 | loss: 0.61408 | val_0_accuracy: 0.71136 |  0:00:28s\n",
            "epoch 14 | loss: 0.60475 | val_0_accuracy: 0.71675 |  0:00:30s\n",
            "epoch 15 | loss: 0.60024 | val_0_accuracy: 0.72539 |  0:00:32s\n",
            "epoch 16 | loss: 0.59213 | val_0_accuracy: 0.73856 |  0:00:34s\n",
            "epoch 17 | loss: 0.58596 | val_0_accuracy: 0.73489 |  0:00:36s\n",
            "epoch 18 | loss: 0.58063 | val_0_accuracy: 0.73597 |  0:00:38s\n",
            "epoch 19 | loss: 0.57651 | val_0_accuracy: 0.73575 |  0:00:40s\n",
            "epoch 20 | loss: 0.56904 | val_0_accuracy: 0.74223 |  0:00:42s\n",
            "epoch 21 | loss: 0.57043 | val_0_accuracy: 0.74396 |  0:00:44s\n",
            "epoch 22 | loss: 0.56658 | val_0_accuracy: 0.74655 |  0:00:46s\n",
            "epoch 23 | loss: 0.57058 | val_0_accuracy: 0.74719 |  0:00:48s\n",
            "epoch 24 | loss: 0.57883 | val_0_accuracy: 0.73575 |  0:00:50s\n",
            "epoch 25 | loss: 0.5622  | val_0_accuracy: 0.74827 |  0:00:52s\n",
            "epoch 26 | loss: 0.55597 | val_0_accuracy: 0.74806 |  0:00:54s\n",
            "epoch 27 | loss: 0.55511 | val_0_accuracy: 0.74568 |  0:00:56s\n",
            "epoch 28 | loss: 0.55213 | val_0_accuracy: 0.74806 |  0:00:58s\n",
            "epoch 29 | loss: 0.55496 | val_0_accuracy: 0.74331 |  0:01:00s\n",
            "epoch 30 | loss: 0.54644 | val_0_accuracy: 0.75561 |  0:01:03s\n",
            "epoch 31 | loss: 0.53462 | val_0_accuracy: 0.76576 |  0:01:05s\n",
            "epoch 32 | loss: 0.54472 | val_0_accuracy: 0.74417 |  0:01:07s\n",
            "epoch 33 | loss: 0.5526  | val_0_accuracy: 0.75669 |  0:01:09s\n",
            "epoch 34 | loss: 0.5318  | val_0_accuracy: 0.75194 |  0:01:11s\n",
            "epoch 35 | loss: 0.53371 | val_0_accuracy: 0.74806 |  0:01:13s\n",
            "epoch 36 | loss: 0.54649 | val_0_accuracy: 0.75604 |  0:01:15s\n",
            "epoch 37 | loss: 0.52734 | val_0_accuracy: 0.75259 |  0:01:17s\n",
            "epoch 38 | loss: 0.53826 | val_0_accuracy: 0.76079 |  0:01:19s\n",
            "epoch 39 | loss: 0.52577 | val_0_accuracy: 0.76339 |  0:01:21s\n",
            "epoch 40 | loss: 0.50497 | val_0_accuracy: 0.76317 |  0:01:23s\n",
            "epoch 41 | loss: 0.49745 | val_0_accuracy: 0.76943 |  0:01:25s\n",
            "epoch 42 | loss: 0.50753 | val_0_accuracy: 0.76252 |  0:01:27s\n",
            "epoch 43 | loss: 0.5128  | val_0_accuracy: 0.76123 |  0:01:29s\n",
            "epoch 44 | loss: 0.50198 | val_0_accuracy: 0.76295 |  0:01:31s\n",
            "epoch 45 | loss: 0.53776 | val_0_accuracy: 0.76209 |  0:01:33s\n",
            "epoch 46 | loss: 0.53708 | val_0_accuracy: 0.73575 |  0:01:35s\n",
            "epoch 47 | loss: 0.55258 | val_0_accuracy: 0.75604 |  0:01:37s\n",
            "epoch 48 | loss: 0.55764 | val_0_accuracy: 0.7446  |  0:01:39s\n",
            "epoch 49 | loss: 0.53484 | val_0_accuracy: 0.76598 |  0:01:41s\n",
            "epoch 50 | loss: 0.51577 | val_0_accuracy: 0.76252 |  0:01:43s\n",
            "epoch 51 | loss: 0.52453 | val_0_accuracy: 0.74288 |  0:01:45s\n",
            "\n",
            "Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_accuracy = 0.76943\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-04 09:12:06,362]\u001b[0m Trial 14 finished with value: 0.7694300518134715 and parameters: {'n_d': 64, 'n_a': 50, 'n_steps': 3, 'gamma': 1.8231311695278785, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.3867430535034889}. Best is trial 12 with value: 0.8033246977547496.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       826\n",
            "           1       0.59      0.56      0.57       825\n",
            "           2       0.82      0.89      0.85       822\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.49      0.57      0.53       761\n",
            "           5       0.70      0.54      0.61       619\n",
            "\n",
            "    accuracy                           0.77      4632\n",
            "   macro avg       0.77      0.76      0.76      4632\n",
            "weighted avg       0.77      0.77      0.77      4632\n",
            "\n",
            " Best params for fold : [6/10]\n",
            "{'n_d': 44, 'n_a': 51, 'n_steps': 3, 'gamma': 1.998898263952073, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.36368393131019705}\n",
            "Saved best_params at : outputs/pytorch_tabnet/best_params/fold_6_best_params.txt\n",
            "Device used : cuda\n",
            "No early stopping will be performed, last training weights will be used.\n",
            "epoch 0  | loss: 1.15244 |  0:00:01s\n",
            "epoch 1  | loss: 0.83498 |  0:00:03s\n",
            "epoch 2  | loss: 0.75363 |  0:00:05s\n",
            "epoch 3  | loss: 0.71322 |  0:00:06s\n",
            "epoch 4  | loss: 0.69837 |  0:00:08s\n",
            "epoch 5  | loss: 0.67804 |  0:00:10s\n",
            "epoch 6  | loss: 0.66634 |  0:00:11s\n",
            "epoch 7  | loss: 0.65747 |  0:00:13s\n",
            "epoch 8  | loss: 0.65475 |  0:00:15s\n",
            "epoch 9  | loss: 0.65445 |  0:00:17s\n",
            "epoch 10 | loss: 0.64064 |  0:00:18s\n",
            "epoch 11 | loss: 0.63544 |  0:00:20s\n",
            "epoch 12 | loss: 0.62859 |  0:00:22s\n",
            "epoch 13 | loss: 0.61926 |  0:00:23s\n",
            "epoch 14 | loss: 0.60983 |  0:00:25s\n",
            "epoch 15 | loss: 0.60232 |  0:00:27s\n",
            "epoch 16 | loss: 0.59522 |  0:00:28s\n",
            "epoch 17 | loss: 0.58637 |  0:00:30s\n",
            "epoch 18 | loss: 0.5813  |  0:00:32s\n",
            "epoch 19 | loss: 0.57969 |  0:00:34s\n",
            "epoch 20 | loss: 0.57067 |  0:00:35s\n",
            "epoch 21 | loss: 0.5664  |  0:00:37s\n",
            "epoch 22 | loss: 0.56984 |  0:00:39s\n",
            "epoch 23 | loss: 0.55922 |  0:00:41s\n",
            "epoch 24 | loss: 0.55587 |  0:00:43s\n",
            "epoch 25 | loss: 0.55499 |  0:00:45s\n",
            "epoch 26 | loss: 0.54423 |  0:00:46s\n",
            "epoch 27 | loss: 0.53855 |  0:00:48s\n",
            "epoch 28 | loss: 0.53917 |  0:00:50s\n",
            "epoch 29 | loss: 0.52953 |  0:00:52s\n",
            "epoch 30 | loss: 0.51992 |  0:00:53s\n",
            "epoch 31 | loss: 0.52275 |  0:00:55s\n",
            "epoch 32 | loss: 0.51551 |  0:00:57s\n",
            "epoch 33 | loss: 0.51198 |  0:00:58s\n",
            "epoch 34 | loss: 0.51153 |  0:01:00s\n",
            "epoch 35 | loss: 0.51122 |  0:01:02s\n",
            "epoch 36 | loss: 0.51672 |  0:01:03s\n",
            "epoch 37 | loss: 0.50875 |  0:01:05s\n",
            "epoch 38 | loss: 0.50398 |  0:01:07s\n",
            "epoch 39 | loss: 0.50476 |  0:01:09s\n",
            "epoch 40 | loss: 0.49348 |  0:01:10s\n",
            "epoch 41 | loss: 0.49111 |  0:01:12s\n",
            "epoch 42 | loss: 0.48806 |  0:01:14s\n",
            "epoch 43 | loss: 0.47884 |  0:01:15s\n",
            "epoch 44 | loss: 0.47763 |  0:01:17s\n",
            "epoch 45 | loss: 0.47706 |  0:01:19s\n",
            "epoch 46 | loss: 0.48233 |  0:01:20s\n",
            "epoch 47 | loss: 0.47708 |  0:01:22s\n",
            "epoch 48 | loss: 0.48563 |  0:01:24s\n",
            "epoch 49 | loss: 0.47114 |  0:01:25s\n",
            "epoch 50 | loss: 0.46992 |  0:01:27s\n",
            "epoch 51 | loss: 0.46456 |  0:01:29s\n",
            "epoch 52 | loss: 0.46216 |  0:01:31s\n",
            "epoch 53 | loss: 0.45604 |  0:01:32s\n",
            "epoch 54 | loss: 0.45021 |  0:01:34s\n",
            "epoch 55 | loss: 0.44513 |  0:01:36s\n",
            "epoch 56 | loss: 0.44602 |  0:01:37s\n",
            "epoch 57 | loss: 0.43865 |  0:01:39s\n",
            "epoch 58 | loss: 0.43878 |  0:01:41s\n",
            "epoch 59 | loss: 0.43564 |  0:01:42s\n",
            "epoch 60 | loss: 0.43639 |  0:01:44s\n",
            "epoch 61 | loss: 0.43438 |  0:01:46s\n",
            "epoch 62 | loss: 0.42895 |  0:01:47s\n",
            "epoch 63 | loss: 0.42644 |  0:01:49s\n",
            "epoch 64 | loss: 0.4252  |  0:01:51s\n",
            "epoch 65 | loss: 0.42352 |  0:01:53s\n",
            "epoch 66 | loss: 0.42566 |  0:01:54s\n",
            "epoch 67 | loss: 0.41802 |  0:01:56s\n",
            "epoch 68 | loss: 0.41619 |  0:01:58s\n",
            "epoch 69 | loss: 0.41379 |  0:01:59s\n",
            "epoch 70 | loss: 0.41415 |  0:02:01s\n",
            "epoch 71 | loss: 0.40691 |  0:02:03s\n",
            "epoch 72 | loss: 0.40959 |  0:02:04s\n",
            "epoch 73 | loss: 0.41003 |  0:02:06s\n",
            "epoch 74 | loss: 0.40509 |  0:02:08s\n",
            "epoch 75 | loss: 0.40526 |  0:02:09s\n",
            "epoch 76 | loss: 0.39956 |  0:02:11s\n",
            "epoch 77 | loss: 0.3979  |  0:02:13s\n",
            "epoch 78 | loss: 0.39558 |  0:02:15s\n",
            "epoch 79 | loss: 0.39466 |  0:02:16s\n",
            "epoch 80 | loss: 0.39334 |  0:02:18s\n",
            "epoch 81 | loss: 0.39706 |  0:02:20s\n",
            "epoch 82 | loss: 0.39091 |  0:02:21s\n",
            "epoch 83 | loss: 0.39474 |  0:02:23s\n",
            "epoch 84 | loss: 0.39359 |  0:02:25s\n",
            "epoch 85 | loss: 0.39253 |  0:02:26s\n",
            "epoch 86 | loss: 0.392   |  0:02:28s\n",
            "epoch 87 | loss: 0.39478 |  0:02:30s\n",
            "epoch 88 | loss: 0.39977 |  0:02:31s\n",
            "epoch 89 | loss: 0.39446 |  0:02:33s\n",
            "epoch 90 | loss: 0.40707 |  0:02:35s\n",
            "epoch 91 | loss: 0.3933  |  0:02:37s\n",
            "epoch 92 | loss: 0.38777 |  0:02:38s\n",
            "epoch 93 | loss: 0.38397 |  0:02:40s\n",
            "epoch 94 | loss: 0.38102 |  0:02:42s\n",
            "epoch 95 | loss: 0.37972 |  0:02:43s\n",
            "epoch 96 | loss: 0.37748 |  0:02:45s\n",
            "epoch 97 | loss: 0.37265 |  0:02:47s\n",
            "epoch 98 | loss: 0.37028 |  0:02:49s\n",
            "epoch 99 | loss: 0.37413 |  0:02:50s\n",
            "[++] Saving the model and parameters in corresponding directories\n",
            "[++] Ended the training process for fold 6\n"
          ]
        }
      ],
      "source": [
        "train(fold_dict = fold_dict,\n",
        "      fold = fold,\n",
        "      model_name=model_name,\n",
        "      sc_df=use_df,\n",
        "      tar_col=tar_col,\n",
        "      optim=optimizer,\n",
        "      optim_trial = 15)\n",
        "print(f\"[++] Ended the training process for fold {fold}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja5dUXmqsCFF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afu4nJyHu-sp"
      },
      "source": [
        "Fold 0 has started running on 20-05-22 \n",
        "\n",
        "\n",
        "Fold 0 has completed sucessfully on 17:00 20-05-22\n",
        "\n",
        "Fold 1 has started running at 15:15 21-05-22\n",
        "\n",
        "Fold 2 has started running at 09:45 22-05-22\n",
        "\n",
        "Fold 2 has completed sucessfully on 10:58 22-05-22\n",
        "\n",
        "Fold 3 has started running at 18:40 22-05-22\n",
        "\n",
        "Fold 3 has completed sucessfully on 22-05-22\n",
        "\n",
        "Fold 4 completed sucessfully on 21:04 on 22-05-22\n",
        "\n",
        "Fold 5 started at 18:21 on 23-05-22\n",
        "\n",
        "Fold 5 completed sucessfully on 19:44 on 23-05-22\n",
        "\n",
        "Fold 6 started at 12:53 on 24-05-22\n",
        "\n",
        "Fold 6 has completed at 14:14 on 24-05-22\n",
        "\n",
        "Fold 7 started at 14:18 on 24-05-22\n",
        "\n",
        "Fold 7 execution failed due to colab gpu time limit\n",
        "\n",
        "Fold 7 trial 1 started at 11:00 on 25-05-22\n",
        "\n",
        "Fold 7 has completed sucessfully at 12:14 on 25-05-22 \n",
        "\n",
        "Fold 8 has started at 9:38 on 26-05-22\n",
        "\n",
        "Fold 8 filed due to interrupted internet connection\n",
        "\n",
        "Fold 8 trial 1 started at 13:38 on 26-05-22\n",
        "\n",
        "Fold 8 has successfully executed at 15:33 on 26-05-22\n",
        "\n",
        "Fold 9 has started at 13:35 on 27-05-22\n",
        "\n",
        "Fold 9 has completed at 14:55 on 27-05-22"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me85YLlzpUM8"
      },
      "source": [
        "Editing with rectified dataset witout duplicacy because of space values\n",
        "\n",
        "Fold 0 started at 13:21 on 28-05-22\n",
        "\n",
        "Fold 0 completed sucessfully at 14:46 on 28-05-22\n",
        "\n",
        "Fold 1 Failed to run due to some index error\n",
        "\n",
        "_____ Restarting the training process again due to data distribution failure____\n",
        "\n",
        "\n",
        "\n",
        "Fold 0 started at 10:47 on 30-05-22\n",
        "\n",
        "Fold 0 completed successfully at 12:30 on 30-05-22\n",
        "\n",
        "Fold 1 started at 8:27 on 31-05-22\n",
        "\n",
        "Fold 1 execution failed due to runtime disconnection\n",
        "\n",
        "Fold 1 started again at 9:38 on 31-05-22\n",
        "\n",
        "Fold 1 execution failed due to gpu disconnect \n",
        "\n",
        "Fold 1 started again at 8:36 on 1-06-22\n",
        "\n",
        "Fold 1 execution failed due to network disconnection\n",
        "\n",
        "Fold 1 started again at 13:11 on 01-06-22\n",
        "\n",
        "Fold 1 has succesfully executed at 14:25 on 01-06-22\n",
        "\n",
        "Fold 2 started at 14:29 on 01-06-22\n",
        "\n",
        "Fold 2 completed succesfully at 16:00 on 01-06-22\n",
        "\n",
        "Fold 3 started at 09:43 on 02-06-22\n",
        "\n",
        "Fold 3 execution failed due to gpu server disconnection \n",
        "\n",
        "Fold 3 started again at 13:34 on 02-06-22\n",
        "\n",
        "Fold 3 ran successfully at 14:47 on 02-06-22\n",
        "\n",
        "Fold 4 started at 14:48 on 02-06-22\n",
        "\n",
        "Fold 4 ran successfully at 04:01 on 02-06-22\n",
        "\n",
        "Fold 5 started at 13:51 on 03-06-22\n",
        "\n",
        "Fold 5 ran successfully at 03:06 on 02-06-22\n",
        "\n",
        "Fold 6 started at 15:11 on 03-06-22\n",
        "\n",
        "Fold 6 stopped due to gpu run time limit\n",
        "\n",
        "Fold 6 started again running at 13:40 on 04-06-22\n",
        "\n",
        "Fold 6 completed at 14:45 on 04-06-22"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zICGdYlFNr13"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "train_tabnet_fold_div.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}