{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5-jiYKypEVY",
        "outputId": "adaf98bf-eb1b-484c-8526-899373310939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun  1 08:59:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P0    33W /  70W |   1988MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0tPZaeupLWn",
        "outputId": "90524fe5-05f3-43d0-af9f-3d02a65b2092"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.4.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.21.6)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (4.64.0)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.11.0+cu113)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.2.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.6.0)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.2.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.1)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.9.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-tabnet optuna "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vRmDYdsCpMT-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "import optuna as opt\n",
        "import torch\n",
        "import os\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "L4HljGyopQs_"
      },
      "outputs": [],
      "source": [
        "def make_save_cv_model(i,model_name,model,best_params,optim,output_path=\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/cross_validated_models\"):\n",
        "\n",
        "    ''' This function saves cross validation model in the corresponding directory ( if the path does not exist it creates the path for it'''\n",
        "\n",
        "\n",
        "    if os.path.exists(os.path.join(output_path,f\"{i}_{model_name}_{optim}\")):\n",
        "        joblib.dump(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n",
        "        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/model_params.txt\"),\"w+\") as file:\n",
        "            file.write(str(best_params))\n",
        "    else:\n",
        "        os.mkdir(os.path.join(output_path,f\"{i}_{model_name}_{optim}\"))\n",
        "        joblib.dump(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n",
        "        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/model_params.txt\"),\"w+\") as file:\n",
        "            file.write(str(best_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "z_M5FI9PpVA_"
      },
      "outputs": [],
      "source": [
        "def train(fold_dict,fold,model_name,sc_df,tar_col,optim,optim_trial,k_folds=10,tar_cols=\"\",verbose=1):\n",
        "\n",
        "    ''' this function is used to train the model with parameters optimization using optuna and cross validation using stratified k_folds'''\n",
        "\n",
        "    y = sc_df[tar_col]\n",
        "    x = sc_df.drop([tar_col],axis=1)\n",
        "    model_name = model_name \n",
        "    def objective(trial):\n",
        "      train_index = fold_dict[fold][\"train\"]\n",
        "      test_index = fold_dict[fold][\"test\"]\n",
        "      clf = TabNetClassifier(n_d=trial.suggest_int(\"n_d\", 8, 64),\n",
        "                              n_a =trial.suggest_int(\"n_a\", 8, 64),\n",
        "                              n_steps = trial.suggest_int(\"n_steps\",3,10),\n",
        "                              gamma =trial.suggest_float(\"gamma\", 1.0, 2.0),\n",
        "                              n_independent = trial.suggest_int(\"n_independent\",1,5),\n",
        "                              n_shared = trial.suggest_int(\"n_shared\",1,5),\n",
        "                              momentum = trial.suggest_float(\"momentum\", 0.01, 0.4),\n",
        "                              optimizer_fn = torch.optim.Adam,\n",
        "                              # scheduler_fn = torch.optim.lr_scheduler,\n",
        "                              # scheduler_params = {\"gamma\" :trial.suggest_float(\"sch-gamma\", 0.5, 0.95), \"step_size\": trial.suggest_int(\"sch_step_size\", 10, 20, 2)},\n",
        "                              verbose = verbose,\n",
        "                              device_name = \"auto\"\n",
        "                              )\n",
        "      # print(f\" train_index :: {train_index}\")\n",
        "      # print(f\" test_index :: {test_index}\")\n",
        "      X_train,X_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
        "      # print(X_train.shape, X_test.shape)\n",
        "      X_train, X_test = X_train.to_numpy(dtype=np.float64), X_test.to_numpy(dtype=np.float64)\n",
        "      Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "      Y_train, Y_test = Y_train.to_numpy(dtype=np.float64), Y_test.to_numpy(dtype=np.float64)\n",
        "      print(Y_train.shape, Y_test.shape)\n",
        "      clf.fit(X_train, Y_train,\n",
        "              eval_set=[(X_test, Y_test)],\n",
        "              eval_metric=['accuracy'])\n",
        "      Y_pred = clf.predict(X_test)\n",
        "      print(classification_report(Y_test, Y_pred, labels=[x for x in range(6)]))\n",
        "      acc = accuracy_score(Y_pred, Y_test)\n",
        "      return acc\n",
        "\n",
        "    print(f\"Starting optimization for fold : [{fold}/{k_folds}]\")\n",
        "    study = opt.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=optim_trial)\n",
        "    best_params = study.best_params\n",
        "    print(f\" Best params for fold : [{fold}/{k_folds}]\")\n",
        "    print(best_params)\n",
        "    joblib.dump(best_params,f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/best_params/comp/fold_{fold}_best_params.z\")\n",
        "    with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/best_params/fold_{fold}_best_params.txt\", \"w+\") as file:file.write(str(best_params))\n",
        "    print(f\"Saved best_params at : outputs/{model_name}/best_params/fold_{fold}_best_params.txt\")\n",
        "    train_index = fold_dict[fold][\"train\"]\n",
        "    test_index = fold_dict[fold][\"test\"]\n",
        "    X_train,X_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
        "    # print(X_train.shape, X_test.shape)\n",
        "    X_train, X_test = X_train.to_numpy(dtype=np.float64), X_test.to_numpy(dtype=np.float64)\n",
        "    Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    Y_train, Y_test = Y_train.to_numpy(dtype=np.float64), Y_test.to_numpy(dtype=np.float64)\n",
        "    clf_model = TabNetClassifier(**study.best_params)\n",
        "    clf_model.fit(X_train,Y_train)\n",
        "    Y_pred = clf_model.predict(X_test)\n",
        "    clf_report = classification_report(Y_test, Y_pred, labels=[x for x in range(6)])\n",
        "    with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/classification_report/{model_name}_{fold}_classification_report.txt\",\"w+\") as file:file.write(str(clf_report))\n",
        "    accuracy = accuracy_score(Y_pred, Y_test)\n",
        "    with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/{model_name}_{fold}_accuracy_score.txt\",\"w+\") as file:file.write(f\" accuracy :: {str(accuracy)}\")\n",
        "    try:\n",
        "        print(\"[++] Saving the model and parameters in corresponding directories\")\n",
        "        make_save_cv_model(fold,model_name,clf_model,best_params,optim=optim)\n",
        "    except:\n",
        "        print(\"[-] Failed to save the model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xNlu9Ktsq6VG"
      },
      "outputs": [],
      "source": [
        "use_df = pd.read_csv(\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/data/trainable_scaled_balanced.csv\")\n",
        "tar_col = \"PCE_categorical\"\n",
        "model_name = \"pytorch_tabnet\"\n",
        "optimizer = \"Adam\"\n",
        "fold_dict = joblib.load(\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/inputs/fold_vals/fold_data.z\")\n",
        "fold = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ9h3wayrIp_",
        "outputId": "92ec8dda-cb08-4109-93b1-276951504830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 08:59:30,876]\u001b[0m A new study created in memory with name: no-name-677d8f9a-6ba3-4b0b-89cc-58fcdabc0354\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting optimization for fold : [2/10]\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.37446 | val_0_accuracy: 0.51706 |  0:00:10s\n",
            "epoch 1  | loss: 0.90234 | val_0_accuracy: 0.6237  |  0:00:18s\n",
            "epoch 2  | loss: 0.82485 | val_0_accuracy: 0.6291  |  0:00:20s\n",
            "epoch 3  | loss: 0.77242 | val_0_accuracy: 0.66278 |  0:00:23s\n",
            "epoch 4  | loss: 0.73707 | val_0_accuracy: 0.66926 |  0:00:26s\n",
            "epoch 5  | loss: 0.7262  | val_0_accuracy: 0.67163 |  0:00:29s\n",
            "epoch 6  | loss: 0.70976 | val_0_accuracy: 0.68761 |  0:00:32s\n",
            "epoch 7  | loss: 0.69685 | val_0_accuracy: 0.69624 |  0:00:34s\n",
            "epoch 8  | loss: 0.68921 | val_0_accuracy: 0.66213 |  0:00:37s\n",
            "epoch 9  | loss: 0.68039 | val_0_accuracy: 0.70509 |  0:00:40s\n",
            "epoch 10 | loss: 0.6757  | val_0_accuracy: 0.68826 |  0:00:42s\n",
            "epoch 11 | loss: 0.66988 | val_0_accuracy: 0.70488 |  0:00:45s\n",
            "epoch 12 | loss: 0.66387 | val_0_accuracy: 0.68243 |  0:00:48s\n",
            "epoch 13 | loss: 0.65537 | val_0_accuracy: 0.71136 |  0:00:51s\n",
            "epoch 14 | loss: 0.64836 | val_0_accuracy: 0.70855 |  0:00:53s\n",
            "epoch 15 | loss: 0.64114 | val_0_accuracy: 0.70639 |  0:00:56s\n",
            "epoch 16 | loss: 0.63834 | val_0_accuracy: 0.70315 |  0:00:59s\n",
            "epoch 17 | loss: 0.63293 | val_0_accuracy: 0.7215  |  0:01:01s\n",
            "epoch 18 | loss: 0.63266 | val_0_accuracy: 0.68912 |  0:01:04s\n",
            "epoch 19 | loss: 0.63339 | val_0_accuracy: 0.6576  |  0:01:07s\n",
            "epoch 20 | loss: 0.62558 | val_0_accuracy: 0.68955 |  0:01:10s\n",
            "epoch 21 | loss: 0.61684 | val_0_accuracy: 0.72884 |  0:01:12s\n",
            "epoch 22 | loss: 0.60956 | val_0_accuracy: 0.6943  |  0:01:15s\n",
            "epoch 23 | loss: 0.60489 | val_0_accuracy: 0.72863 |  0:01:18s\n",
            "epoch 24 | loss: 0.59913 | val_0_accuracy: 0.7364  |  0:01:20s\n",
            "epoch 25 | loss: 0.59529 | val_0_accuracy: 0.73769 |  0:01:23s\n",
            "epoch 26 | loss: 0.60403 | val_0_accuracy: 0.73035 |  0:01:26s\n",
            "epoch 27 | loss: 0.63155 | val_0_accuracy: 0.70963 |  0:01:29s\n",
            "epoch 28 | loss: 0.63013 | val_0_accuracy: 0.72193 |  0:01:31s\n",
            "epoch 29 | loss: 0.60185 | val_0_accuracy: 0.72712 |  0:01:34s\n",
            "epoch 30 | loss: 0.58839 | val_0_accuracy: 0.73834 |  0:01:38s\n",
            "epoch 31 | loss: 0.58213 | val_0_accuracy: 0.70833 |  0:01:40s\n",
            "epoch 32 | loss: 0.57714 | val_0_accuracy: 0.74007 |  0:01:43s\n",
            "epoch 33 | loss: 0.57314 | val_0_accuracy: 0.73921 |  0:01:46s\n",
            "epoch 34 | loss: 0.56641 | val_0_accuracy: 0.6563  |  0:01:49s\n",
            "epoch 35 | loss: 0.56004 | val_0_accuracy: 0.7092  |  0:01:51s\n",
            "epoch 36 | loss: 0.56021 | val_0_accuracy: 0.74028 |  0:01:54s\n",
            "epoch 37 | loss: 0.54961 | val_0_accuracy: 0.71524 |  0:01:57s\n",
            "epoch 38 | loss: 0.54558 | val_0_accuracy: 0.75799 |  0:02:00s\n",
            "epoch 39 | loss: 0.54364 | val_0_accuracy: 0.7405  |  0:02:03s\n",
            "epoch 40 | loss: 0.53953 | val_0_accuracy: 0.75108 |  0:02:06s\n",
            "epoch 41 | loss: 0.53657 | val_0_accuracy: 0.76101 |  0:02:08s\n",
            "epoch 42 | loss: 0.53159 | val_0_accuracy: 0.7323  |  0:02:11s\n",
            "epoch 43 | loss: 0.52658 | val_0_accuracy: 0.72712 |  0:02:14s\n",
            "epoch 44 | loss: 0.52721 | val_0_accuracy: 0.76123 |  0:02:17s\n",
            "epoch 45 | loss: 0.51734 | val_0_accuracy: 0.68934 |  0:02:20s\n",
            "epoch 46 | loss: 0.52573 | val_0_accuracy: 0.75907 |  0:02:23s\n",
            "epoch 47 | loss: 0.52561 | val_0_accuracy: 0.76166 |  0:02:25s\n",
            "epoch 48 | loss: 0.51549 | val_0_accuracy: 0.76468 |  0:02:28s\n",
            "epoch 49 | loss: 0.52517 | val_0_accuracy: 0.75108 |  0:02:31s\n",
            "epoch 50 | loss: 0.51842 | val_0_accuracy: 0.76598 |  0:02:34s\n",
            "epoch 51 | loss: 0.50648 | val_0_accuracy: 0.76468 |  0:02:36s\n",
            "epoch 52 | loss: 0.50537 | val_0_accuracy: 0.75    |  0:02:39s\n",
            "epoch 53 | loss: 0.50092 | val_0_accuracy: 0.71006 |  0:02:42s\n",
            "epoch 54 | loss: 0.4961  | val_0_accuracy: 0.73856 |  0:02:44s\n",
            "epoch 55 | loss: 0.49036 | val_0_accuracy: 0.77137 |  0:02:47s\n",
            "epoch 56 | loss: 0.4845  | val_0_accuracy: 0.76274 |  0:02:50s\n",
            "epoch 57 | loss: 0.49168 | val_0_accuracy: 0.75734 |  0:02:53s\n",
            "epoch 58 | loss: 0.48812 | val_0_accuracy: 0.71071 |  0:02:55s\n",
            "epoch 59 | loss: 0.48029 | val_0_accuracy: 0.77958 |  0:02:58s\n",
            "epoch 60 | loss: 0.47792 | val_0_accuracy: 0.76921 |  0:03:01s\n",
            "epoch 61 | loss: 0.47233 | val_0_accuracy: 0.78843 |  0:03:03s\n",
            "epoch 62 | loss: 0.47395 | val_0_accuracy: 0.75108 |  0:03:06s\n",
            "epoch 63 | loss: 0.47044 | val_0_accuracy: 0.73705 |  0:03:09s\n",
            "epoch 64 | loss: 0.48563 | val_0_accuracy: 0.76382 |  0:03:12s\n",
            "epoch 65 | loss: 0.47179 | val_0_accuracy: 0.76662 |  0:03:14s\n",
            "epoch 66 | loss: 0.46255 | val_0_accuracy: 0.78605 |  0:03:17s\n",
            "epoch 67 | loss: 0.46356 | val_0_accuracy: 0.76965 |  0:03:20s\n",
            "epoch 68 | loss: 0.45492 | val_0_accuracy: 0.73467 |  0:03:22s\n",
            "epoch 69 | loss: 0.44697 | val_0_accuracy: 0.75497 |  0:03:25s\n",
            "epoch 70 | loss: 0.44749 | val_0_accuracy: 0.79447 |  0:03:28s\n",
            "epoch 71 | loss: 0.44609 | val_0_accuracy: 0.74698 |  0:03:31s\n",
            "epoch 72 | loss: 0.4446  | val_0_accuracy: 0.73877 |  0:03:33s\n",
            "epoch 73 | loss: 0.44351 | val_0_accuracy: 0.788   |  0:03:36s\n",
            "epoch 74 | loss: 0.43535 | val_0_accuracy: 0.75281 |  0:03:39s\n",
            "epoch 75 | loss: 0.43666 | val_0_accuracy: 0.76058 |  0:03:41s\n",
            "epoch 76 | loss: 0.43446 | val_0_accuracy: 0.78735 |  0:03:44s\n",
            "epoch 77 | loss: 0.43163 | val_0_accuracy: 0.76857 |  0:03:47s\n",
            "epoch 78 | loss: 0.4286  | val_0_accuracy: 0.78454 |  0:03:49s\n",
            "epoch 79 | loss: 0.43211 | val_0_accuracy: 0.76079 |  0:03:52s\n",
            "epoch 80 | loss: 0.4294  | val_0_accuracy: 0.76813 |  0:03:55s\n",
            "\n",
            "Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_accuracy = 0.79447\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 09:03:27,707]\u001b[0m Trial 0 finished with value: 0.7944732297063903 and parameters: {'n_d': 51, 'n_a': 51, 'n_steps': 4, 'gamma': 1.373168812930887, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.1015912238579528}. Best is trial 0 with value: 0.7944732297063903.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.63      0.61      0.62       825\n",
            "           2       0.85      0.91      0.88       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.55      0.57      0.56       761\n",
            "           5       0.70      0.63      0.66       619\n",
            "\n",
            "    accuracy                           0.79      4632\n",
            "   macro avg       0.79      0.79      0.79      4632\n",
            "weighted avg       0.79      0.79      0.79      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.16749 | val_0_accuracy: 0.606   |  0:00:02s\n",
            "epoch 1  | loss: 0.86227 | val_0_accuracy: 0.62932 |  0:00:04s\n",
            "epoch 2  | loss: 0.81637 | val_0_accuracy: 0.63558 |  0:00:06s\n",
            "epoch 3  | loss: 0.76698 | val_0_accuracy: 0.66883 |  0:00:08s\n",
            "epoch 4  | loss: 0.73052 | val_0_accuracy: 0.68048 |  0:00:10s\n",
            "epoch 5  | loss: 0.72179 | val_0_accuracy: 0.68264 |  0:00:12s\n",
            "epoch 6  | loss: 0.70995 | val_0_accuracy: 0.69085 |  0:00:14s\n",
            "epoch 7  | loss: 0.69937 | val_0_accuracy: 0.68847 |  0:00:16s\n",
            "epoch 8  | loss: 0.69365 | val_0_accuracy: 0.69646 |  0:00:18s\n",
            "epoch 9  | loss: 0.68136 | val_0_accuracy: 0.70358 |  0:00:20s\n",
            "epoch 10 | loss: 0.67147 | val_0_accuracy: 0.69948 |  0:00:22s\n",
            "epoch 11 | loss: 0.66106 | val_0_accuracy: 0.71481 |  0:00:24s\n",
            "epoch 12 | loss: 0.65542 | val_0_accuracy: 0.71049 |  0:00:26s\n",
            "epoch 13 | loss: 0.65414 | val_0_accuracy: 0.71718 |  0:00:28s\n",
            "epoch 14 | loss: 0.64292 | val_0_accuracy: 0.71632 |  0:00:30s\n",
            "epoch 15 | loss: 0.63927 | val_0_accuracy: 0.72345 |  0:00:32s\n",
            "epoch 16 | loss: 0.63458 | val_0_accuracy: 0.72237 |  0:00:34s\n",
            "epoch 17 | loss: 0.6297  | val_0_accuracy: 0.72107 |  0:00:37s\n",
            "epoch 18 | loss: 0.61901 | val_0_accuracy: 0.72517 |  0:00:39s\n",
            "epoch 19 | loss: 0.61573 | val_0_accuracy: 0.72172 |  0:00:41s\n",
            "epoch 20 | loss: 0.6106  | val_0_accuracy: 0.72733 |  0:00:43s\n",
            "epoch 21 | loss: 0.61169 | val_0_accuracy: 0.73338 |  0:00:45s\n",
            "epoch 22 | loss: 0.61096 | val_0_accuracy: 0.71826 |  0:00:47s\n",
            "epoch 23 | loss: 0.6054  | val_0_accuracy: 0.72949 |  0:00:49s\n",
            "epoch 24 | loss: 0.59927 | val_0_accuracy: 0.73381 |  0:00:51s\n",
            "epoch 25 | loss: 0.59878 | val_0_accuracy: 0.72992 |  0:00:53s\n",
            "epoch 26 | loss: 0.59301 | val_0_accuracy: 0.73424 |  0:00:55s\n",
            "epoch 27 | loss: 0.58746 | val_0_accuracy: 0.73467 |  0:00:57s\n",
            "epoch 28 | loss: 0.58557 | val_0_accuracy: 0.73554 |  0:00:59s\n",
            "epoch 29 | loss: 0.58633 | val_0_accuracy: 0.74072 |  0:01:01s\n",
            "epoch 30 | loss: 0.591   | val_0_accuracy: 0.7364  |  0:01:03s\n",
            "epoch 31 | loss: 0.58936 | val_0_accuracy: 0.74331 |  0:01:05s\n",
            "epoch 32 | loss: 0.58156 | val_0_accuracy: 0.73294 |  0:01:08s\n",
            "epoch 33 | loss: 0.57985 | val_0_accuracy: 0.73316 |  0:01:10s\n",
            "epoch 34 | loss: 0.57461 | val_0_accuracy: 0.73726 |  0:01:12s\n",
            "epoch 35 | loss: 0.56679 | val_0_accuracy: 0.73813 |  0:01:14s\n",
            "epoch 36 | loss: 0.56302 | val_0_accuracy: 0.74396 |  0:01:16s\n",
            "epoch 37 | loss: 0.56072 | val_0_accuracy: 0.74396 |  0:01:18s\n",
            "epoch 38 | loss: 0.55471 | val_0_accuracy: 0.74978 |  0:01:20s\n",
            "epoch 39 | loss: 0.54985 | val_0_accuracy: 0.7513  |  0:01:22s\n",
            "epoch 40 | loss: 0.55316 | val_0_accuracy: 0.75518 |  0:01:24s\n",
            "epoch 41 | loss: 0.54556 | val_0_accuracy: 0.75194 |  0:01:26s\n",
            "epoch 42 | loss: 0.53857 | val_0_accuracy: 0.75108 |  0:01:28s\n",
            "epoch 43 | loss: 0.53787 | val_0_accuracy: 0.76123 |  0:01:30s\n",
            "epoch 44 | loss: 0.53402 | val_0_accuracy: 0.75518 |  0:01:32s\n",
            "epoch 45 | loss: 0.53336 | val_0_accuracy: 0.75065 |  0:01:34s\n",
            "epoch 46 | loss: 0.52763 | val_0_accuracy: 0.76036 |  0:01:37s\n",
            "epoch 47 | loss: 0.52512 | val_0_accuracy: 0.7554  |  0:01:39s\n",
            "epoch 48 | loss: 0.52494 | val_0_accuracy: 0.74892 |  0:01:41s\n",
            "epoch 49 | loss: 0.52426 | val_0_accuracy: 0.76403 |  0:01:43s\n",
            "epoch 50 | loss: 0.51916 | val_0_accuracy: 0.76986 |  0:01:45s\n",
            "epoch 51 | loss: 0.51237 | val_0_accuracy: 0.75907 |  0:01:47s\n",
            "epoch 52 | loss: 0.52397 | val_0_accuracy: 0.76835 |  0:01:49s\n",
            "epoch 53 | loss: 0.51396 | val_0_accuracy: 0.75993 |  0:01:51s\n",
            "epoch 54 | loss: 0.50823 | val_0_accuracy: 0.77353 |  0:01:53s\n",
            "epoch 55 | loss: 0.50491 | val_0_accuracy: 0.76554 |  0:01:55s\n",
            "epoch 56 | loss: 0.49881 | val_0_accuracy: 0.77267 |  0:01:57s\n",
            "epoch 57 | loss: 0.49407 | val_0_accuracy: 0.76425 |  0:01:59s\n",
            "epoch 58 | loss: 0.49976 | val_0_accuracy: 0.77245 |  0:02:01s\n",
            "epoch 59 | loss: 0.50008 | val_0_accuracy: 0.76446 |  0:02:03s\n",
            "epoch 60 | loss: 0.49508 | val_0_accuracy: 0.77137 |  0:02:06s\n",
            "epoch 61 | loss: 0.50041 | val_0_accuracy: 0.75993 |  0:02:08s\n",
            "epoch 62 | loss: 0.49953 | val_0_accuracy: 0.76684 |  0:02:10s\n",
            "epoch 63 | loss: 0.48659 | val_0_accuracy: 0.78217 |  0:02:12s\n",
            "epoch 64 | loss: 0.48421 | val_0_accuracy: 0.76598 |  0:02:14s\n",
            "epoch 65 | loss: 0.49018 | val_0_accuracy: 0.76598 |  0:02:16s\n",
            "epoch 66 | loss: 0.49301 | val_0_accuracy: 0.77807 |  0:02:18s\n",
            "epoch 67 | loss: 0.485   | val_0_accuracy: 0.78001 |  0:02:20s\n",
            "epoch 68 | loss: 0.47652 | val_0_accuracy: 0.76015 |  0:02:22s\n",
            "epoch 69 | loss: 0.49936 | val_0_accuracy: 0.78066 |  0:02:24s\n",
            "epoch 70 | loss: 0.48787 | val_0_accuracy: 0.77332 |  0:02:26s\n",
            "epoch 71 | loss: 0.47544 | val_0_accuracy: 0.75842 |  0:02:28s\n",
            "epoch 72 | loss: 0.47066 | val_0_accuracy: 0.78584 |  0:02:30s\n",
            "epoch 73 | loss: 0.47147 | val_0_accuracy: 0.78389 |  0:02:32s\n",
            "epoch 74 | loss: 0.47082 | val_0_accuracy: 0.78692 |  0:02:34s\n",
            "epoch 75 | loss: 0.4618  | val_0_accuracy: 0.77526 |  0:02:36s\n",
            "epoch 76 | loss: 0.45828 | val_0_accuracy: 0.75907 |  0:02:38s\n",
            "epoch 77 | loss: 0.47725 | val_0_accuracy: 0.78195 |  0:02:40s\n",
            "epoch 78 | loss: 0.4644  | val_0_accuracy: 0.75302 |  0:02:43s\n",
            "epoch 79 | loss: 0.46357 | val_0_accuracy: 0.78713 |  0:02:45s\n",
            "epoch 80 | loss: 0.45562 | val_0_accuracy: 0.76187 |  0:02:47s\n",
            "epoch 81 | loss: 0.45533 | val_0_accuracy: 0.78411 |  0:02:49s\n",
            "epoch 82 | loss: 0.46266 | val_0_accuracy: 0.78217 |  0:02:51s\n",
            "epoch 83 | loss: 0.46165 | val_0_accuracy: 0.78346 |  0:02:53s\n",
            "epoch 84 | loss: 0.44934 | val_0_accuracy: 0.78066 |  0:02:55s\n",
            "epoch 85 | loss: 0.44887 | val_0_accuracy: 0.77569 |  0:02:57s\n",
            "epoch 86 | loss: 0.45473 | val_0_accuracy: 0.77159 |  0:02:59s\n",
            "epoch 87 | loss: 0.46262 | val_0_accuracy: 0.78066 |  0:03:01s\n",
            "epoch 88 | loss: 0.44908 | val_0_accuracy: 0.77547 |  0:03:03s\n",
            "epoch 89 | loss: 0.46313 | val_0_accuracy: 0.75    |  0:03:05s\n",
            "\n",
            "Early stopping occurred at epoch 89 with best_epoch = 79 and best_val_0_accuracy = 0.78713\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 09:06:34,730]\u001b[0m Trial 1 finished with value: 0.7871329879101899 and parameters: {'n_d': 26, 'n_a': 51, 'n_steps': 4, 'gamma': 1.1541518460016769, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.38281071283129436}. Best is trial 0 with value: 0.7944732297063903.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       825\n",
            "           1       0.65      0.57      0.60       825\n",
            "           2       0.81      0.95      0.87       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.52      0.64      0.58       761\n",
            "           5       0.78      0.49      0.61       619\n",
            "\n",
            "    accuracy                           0.79      4632\n",
            "   macro avg       0.79      0.78      0.78      4632\n",
            "weighted avg       0.79      0.79      0.78      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.39807 | val_0_accuracy: 0.55268 |  0:00:03s\n",
            "epoch 1  | loss: 1.07542 | val_0_accuracy: 0.57513 |  0:00:07s\n",
            "epoch 2  | loss: 0.94537 | val_0_accuracy: 0.59974 |  0:00:11s\n",
            "epoch 3  | loss: 0.83748 | val_0_accuracy: 0.62003 |  0:00:14s\n",
            "epoch 4  | loss: 0.82548 | val_0_accuracy: 0.6073  |  0:00:18s\n",
            "epoch 5  | loss: 0.82475 | val_0_accuracy: 0.61075 |  0:00:22s\n",
            "epoch 6  | loss: 0.81427 | val_0_accuracy: 0.64227 |  0:00:25s\n",
            "epoch 7  | loss: 0.79136 | val_0_accuracy: 0.63644 |  0:00:29s\n",
            "epoch 8  | loss: 0.78263 | val_0_accuracy: 0.65285 |  0:00:33s\n",
            "epoch 9  | loss: 0.77381 | val_0_accuracy: 0.65199 |  0:00:36s\n",
            "epoch 10 | loss: 0.76343 | val_0_accuracy: 0.6671  |  0:00:40s\n",
            "epoch 11 | loss: 0.73583 | val_0_accuracy: 0.67358 |  0:00:43s\n",
            "epoch 12 | loss: 0.7192  | val_0_accuracy: 0.67573 |  0:00:47s\n",
            "epoch 13 | loss: 0.71407 | val_0_accuracy: 0.68092 |  0:00:51s\n",
            "epoch 14 | loss: 0.70384 | val_0_accuracy: 0.67746 |  0:00:54s\n",
            "epoch 15 | loss: 0.69796 | val_0_accuracy: 0.68588 |  0:00:58s\n",
            "epoch 16 | loss: 0.68915 | val_0_accuracy: 0.68782 |  0:01:02s\n",
            "epoch 17 | loss: 0.68565 | val_0_accuracy: 0.69862 |  0:01:05s\n",
            "epoch 18 | loss: 0.69541 | val_0_accuracy: 0.69516 |  0:01:09s\n",
            "epoch 19 | loss: 0.68218 | val_0_accuracy: 0.69452 |  0:01:13s\n",
            "epoch 20 | loss: 0.66926 | val_0_accuracy: 0.69732 |  0:01:16s\n",
            "epoch 21 | loss: 0.67185 | val_0_accuracy: 0.69624 |  0:01:20s\n",
            "epoch 22 | loss: 0.68183 | val_0_accuracy: 0.69711 |  0:01:24s\n",
            "epoch 23 | loss: 0.67921 | val_0_accuracy: 0.69603 |  0:01:27s\n",
            "epoch 24 | loss: 0.66149 | val_0_accuracy: 0.69711 |  0:01:31s\n",
            "epoch 25 | loss: 0.65654 | val_0_accuracy: 0.712   |  0:01:35s\n",
            "epoch 26 | loss: 0.64602 | val_0_accuracy: 0.70164 |  0:01:38s\n",
            "epoch 27 | loss: 0.65024 | val_0_accuracy: 0.70553 |  0:01:42s\n",
            "epoch 28 | loss: 0.64296 | val_0_accuracy: 0.71524 |  0:01:46s\n",
            "epoch 29 | loss: 0.63534 | val_0_accuracy: 0.71762 |  0:01:50s\n",
            "epoch 30 | loss: 0.62662 | val_0_accuracy: 0.71848 |  0:01:54s\n",
            "epoch 31 | loss: 0.62491 | val_0_accuracy: 0.71805 |  0:01:58s\n",
            "epoch 32 | loss: 0.63074 | val_0_accuracy: 0.71589 |  0:02:01s\n",
            "epoch 33 | loss: 0.63141 | val_0_accuracy: 0.72345 |  0:02:05s\n",
            "epoch 34 | loss: 0.62944 | val_0_accuracy: 0.7187  |  0:02:08s\n",
            "epoch 35 | loss: 0.6215  | val_0_accuracy: 0.71999 |  0:02:12s\n",
            "epoch 36 | loss: 0.61383 | val_0_accuracy: 0.71697 |  0:02:16s\n",
            "epoch 37 | loss: 0.61732 | val_0_accuracy: 0.71373 |  0:02:20s\n",
            "epoch 38 | loss: 0.61258 | val_0_accuracy: 0.72798 |  0:02:23s\n",
            "epoch 39 | loss: 0.61359 | val_0_accuracy: 0.7215  |  0:02:27s\n",
            "epoch 40 | loss: 0.61057 | val_0_accuracy: 0.72042 |  0:02:31s\n",
            "epoch 41 | loss: 0.60817 | val_0_accuracy: 0.73381 |  0:02:34s\n",
            "epoch 42 | loss: 0.60664 | val_0_accuracy: 0.73143 |  0:02:38s\n",
            "epoch 43 | loss: 0.60557 | val_0_accuracy: 0.73381 |  0:02:42s\n",
            "epoch 44 | loss: 0.58898 | val_0_accuracy: 0.73899 |  0:02:46s\n",
            "epoch 45 | loss: 0.59721 | val_0_accuracy: 0.72172 |  0:02:49s\n",
            "epoch 46 | loss: 0.60016 | val_0_accuracy: 0.7323  |  0:02:53s\n",
            "epoch 47 | loss: 0.59634 | val_0_accuracy: 0.72798 |  0:02:56s\n",
            "epoch 48 | loss: 0.58878 | val_0_accuracy: 0.7323  |  0:03:00s\n",
            "epoch 49 | loss: 0.58253 | val_0_accuracy: 0.74352 |  0:03:04s\n",
            "epoch 50 | loss: 0.57416 | val_0_accuracy: 0.73705 |  0:03:07s\n",
            "epoch 51 | loss: 0.59351 | val_0_accuracy: 0.7256  |  0:03:11s\n",
            "epoch 52 | loss: 0.58952 | val_0_accuracy: 0.74244 |  0:03:14s\n",
            "epoch 53 | loss: 0.57287 | val_0_accuracy: 0.74827 |  0:03:18s\n",
            "epoch 54 | loss: 0.55967 | val_0_accuracy: 0.74784 |  0:03:22s\n",
            "epoch 55 | loss: 0.55283 | val_0_accuracy: 0.74503 |  0:03:25s\n",
            "epoch 56 | loss: 0.55057 | val_0_accuracy: 0.75151 |  0:03:29s\n",
            "epoch 57 | loss: 0.54345 | val_0_accuracy: 0.75389 |  0:03:33s\n",
            "epoch 58 | loss: 0.54324 | val_0_accuracy: 0.7554  |  0:03:36s\n",
            "epoch 59 | loss: 0.53787 | val_0_accuracy: 0.75324 |  0:03:40s\n",
            "epoch 60 | loss: 0.53071 | val_0_accuracy: 0.76101 |  0:03:44s\n",
            "epoch 61 | loss: 0.53206 | val_0_accuracy: 0.76252 |  0:03:47s\n",
            "epoch 62 | loss: 0.52332 | val_0_accuracy: 0.76468 |  0:03:51s\n",
            "epoch 63 | loss: 0.52333 | val_0_accuracy: 0.7513  |  0:03:55s\n",
            "epoch 64 | loss: 0.51844 | val_0_accuracy: 0.76231 |  0:03:58s\n",
            "epoch 65 | loss: 0.51338 | val_0_accuracy: 0.76446 |  0:04:02s\n",
            "epoch 66 | loss: 0.51362 | val_0_accuracy: 0.76166 |  0:04:05s\n",
            "epoch 67 | loss: 0.50901 | val_0_accuracy: 0.77224 |  0:04:09s\n",
            "epoch 68 | loss: 0.5063  | val_0_accuracy: 0.76317 |  0:04:13s\n",
            "epoch 69 | loss: 0.49759 | val_0_accuracy: 0.77396 |  0:04:16s\n",
            "epoch 70 | loss: 0.49758 | val_0_accuracy: 0.77267 |  0:04:20s\n",
            "epoch 71 | loss: 0.49374 | val_0_accuracy: 0.76878 |  0:04:23s\n",
            "epoch 72 | loss: 0.50075 | val_0_accuracy: 0.76382 |  0:04:27s\n",
            "epoch 73 | loss: 0.49315 | val_0_accuracy: 0.77202 |  0:04:31s\n",
            "epoch 74 | loss: 0.48988 | val_0_accuracy: 0.77699 |  0:04:34s\n",
            "epoch 75 | loss: 0.48379 | val_0_accuracy: 0.78109 |  0:04:38s\n",
            "epoch 76 | loss: 0.47921 | val_0_accuracy: 0.78519 |  0:04:42s\n",
            "epoch 77 | loss: 0.47948 | val_0_accuracy: 0.78152 |  0:04:45s\n",
            "epoch 78 | loss: 0.47451 | val_0_accuracy: 0.77958 |  0:04:49s\n",
            "epoch 79 | loss: 0.47451 | val_0_accuracy: 0.77504 |  0:04:53s\n",
            "epoch 80 | loss: 0.48351 | val_0_accuracy: 0.77915 |  0:04:56s\n",
            "epoch 81 | loss: 0.47574 | val_0_accuracy: 0.78346 |  0:05:00s\n",
            "epoch 82 | loss: 0.47812 | val_0_accuracy: 0.78066 |  0:05:03s\n",
            "epoch 83 | loss: 0.4735  | val_0_accuracy: 0.78022 |  0:05:07s\n",
            "epoch 84 | loss: 0.47072 | val_0_accuracy: 0.78389 |  0:05:11s\n",
            "epoch 85 | loss: 0.46038 | val_0_accuracy: 0.78605 |  0:05:14s\n",
            "epoch 86 | loss: 0.46079 | val_0_accuracy: 0.78584 |  0:05:18s\n",
            "epoch 87 | loss: 0.45172 | val_0_accuracy: 0.79059 |  0:05:21s\n",
            "epoch 88 | loss: 0.45148 | val_0_accuracy: 0.78821 |  0:05:25s\n",
            "epoch 89 | loss: 0.45333 | val_0_accuracy: 0.78778 |  0:05:29s\n",
            "epoch 90 | loss: 0.45018 | val_0_accuracy: 0.78908 |  0:05:32s\n",
            "epoch 91 | loss: 0.48563 | val_0_accuracy: 0.77591 |  0:05:36s\n",
            "epoch 92 | loss: 0.47576 | val_0_accuracy: 0.79555 |  0:05:40s\n",
            "epoch 93 | loss: 0.4554  | val_0_accuracy: 0.79361 |  0:05:43s\n",
            "epoch 94 | loss: 0.44694 | val_0_accuracy: 0.79491 |  0:05:47s\n",
            "epoch 95 | loss: 0.44193 | val_0_accuracy: 0.78886 |  0:05:51s\n",
            "epoch 96 | loss: 0.43866 | val_0_accuracy: 0.79534 |  0:05:54s\n",
            "epoch 97 | loss: 0.43394 | val_0_accuracy: 0.79253 |  0:05:58s\n",
            "epoch 98 | loss: 0.43535 | val_0_accuracy: 0.79361 |  0:06:01s\n",
            "epoch 99 | loss: 0.43115 | val_0_accuracy: 0.79447 |  0:06:05s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 92 and best_val_0_accuracy = 0.79555\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 09:12:41,903]\u001b[0m Trial 2 finished with value: 0.7955526770293609 and parameters: {'n_d': 49, 'n_a': 52, 'n_steps': 6, 'gamma': 1.289435241512755, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.10263114338743033}. Best is trial 2 with value: 0.7955526770293609.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       825\n",
            "           1       0.61      0.67      0.64       825\n",
            "           2       0.86      0.93      0.89       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.55      0.55      0.55       761\n",
            "           5       0.75      0.56      0.64       619\n",
            "\n",
            "    accuracy                           0.80      4632\n",
            "   macro avg       0.79      0.78      0.79      4632\n",
            "weighted avg       0.80      0.80      0.79      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.77358 | val_0_accuracy: 0.52828 |  0:00:04s\n",
            "epoch 1  | loss: 1.16909 | val_0_accuracy: 0.51036 |  0:00:08s\n",
            "epoch 2  | loss: 1.11736 | val_0_accuracy: 0.55009 |  0:00:12s\n",
            "epoch 3  | loss: 1.01688 | val_0_accuracy: 0.5924  |  0:00:16s\n",
            "epoch 4  | loss: 0.9588  | val_0_accuracy: 0.5775  |  0:00:20s\n",
            "epoch 5  | loss: 0.92072 | val_0_accuracy: 0.61658 |  0:00:24s\n",
            "epoch 6  | loss: 0.8639  | val_0_accuracy: 0.62478 |  0:00:29s\n",
            "epoch 7  | loss: 0.83978 | val_0_accuracy: 0.62435 |  0:00:33s\n",
            "epoch 8  | loss: 0.82026 | val_0_accuracy: 0.63493 |  0:00:37s\n",
            "epoch 9  | loss: 0.80187 | val_0_accuracy: 0.64637 |  0:00:41s\n",
            "epoch 10 | loss: 0.78713 | val_0_accuracy: 0.64853 |  0:00:45s\n",
            "epoch 11 | loss: 0.78434 | val_0_accuracy: 0.62824 |  0:00:49s\n",
            "epoch 12 | loss: 0.77933 | val_0_accuracy: 0.64378 |  0:00:53s\n",
            "epoch 13 | loss: 0.76926 | val_0_accuracy: 0.64551 |  0:00:58s\n",
            "epoch 14 | loss: 0.75633 | val_0_accuracy: 0.65263 |  0:01:02s\n",
            "epoch 15 | loss: 0.74688 | val_0_accuracy: 0.66192 |  0:01:06s\n",
            "epoch 16 | loss: 0.73152 | val_0_accuracy: 0.65566 |  0:01:10s\n",
            "epoch 17 | loss: 0.72386 | val_0_accuracy: 0.66731 |  0:01:14s\n",
            "epoch 18 | loss: 0.71361 | val_0_accuracy: 0.67379 |  0:01:18s\n",
            "epoch 19 | loss: 0.70987 | val_0_accuracy: 0.6807  |  0:01:23s\n",
            "epoch 20 | loss: 0.70691 | val_0_accuracy: 0.67681 |  0:01:27s\n",
            "epoch 21 | loss: 0.70078 | val_0_accuracy: 0.67832 |  0:01:31s\n",
            "epoch 22 | loss: 0.69225 | val_0_accuracy: 0.68307 |  0:01:35s\n",
            "epoch 23 | loss: 0.68741 | val_0_accuracy: 0.68351 |  0:01:40s\n",
            "epoch 24 | loss: 0.68543 | val_0_accuracy: 0.68394 |  0:01:44s\n",
            "epoch 25 | loss: 0.6792  | val_0_accuracy: 0.68394 |  0:01:48s\n",
            "epoch 26 | loss: 0.67674 | val_0_accuracy: 0.68761 |  0:01:52s\n",
            "epoch 27 | loss: 0.66211 | val_0_accuracy: 0.69408 |  0:01:57s\n",
            "epoch 28 | loss: 0.65586 | val_0_accuracy: 0.68631 |  0:02:01s\n",
            "epoch 29 | loss: 0.65074 | val_0_accuracy: 0.6889  |  0:02:05s\n",
            "epoch 30 | loss: 0.65075 | val_0_accuracy: 0.68523 |  0:02:10s\n",
            "epoch 31 | loss: 0.65194 | val_0_accuracy: 0.69063 |  0:02:14s\n",
            "epoch 32 | loss: 0.64123 | val_0_accuracy: 0.69473 |  0:02:18s\n",
            "epoch 33 | loss: 0.63677 | val_0_accuracy: 0.70013 |  0:02:23s\n",
            "epoch 34 | loss: 0.63318 | val_0_accuracy: 0.68912 |  0:02:27s\n",
            "epoch 35 | loss: 0.63168 | val_0_accuracy: 0.70337 |  0:02:31s\n",
            "epoch 36 | loss: 0.62855 | val_0_accuracy: 0.68156 |  0:02:37s\n",
            "epoch 37 | loss: 0.6246  | val_0_accuracy: 0.69819 |  0:02:41s\n",
            "epoch 38 | loss: 0.62247 | val_0_accuracy: 0.69927 |  0:02:45s\n",
            "epoch 39 | loss: 0.62301 | val_0_accuracy: 0.70272 |  0:02:49s\n",
            "epoch 40 | loss: 0.61651 | val_0_accuracy: 0.71351 |  0:02:53s\n",
            "epoch 41 | loss: 0.61151 | val_0_accuracy: 0.69668 |  0:02:57s\n",
            "epoch 42 | loss: 0.60781 | val_0_accuracy: 0.68351 |  0:03:01s\n",
            "epoch 43 | loss: 0.61001 | val_0_accuracy: 0.6658  |  0:03:05s\n",
            "epoch 44 | loss: 0.60434 | val_0_accuracy: 0.68092 |  0:03:10s\n",
            "epoch 45 | loss: 0.60236 | val_0_accuracy: 0.67552 |  0:03:14s\n",
            "epoch 46 | loss: 0.59618 | val_0_accuracy: 0.6861  |  0:03:18s\n",
            "epoch 47 | loss: 0.59359 | val_0_accuracy: 0.68826 |  0:03:22s\n",
            "epoch 48 | loss: 0.59532 | val_0_accuracy: 0.67768 |  0:03:26s\n",
            "epoch 49 | loss: 0.59087 | val_0_accuracy: 0.67681 |  0:03:31s\n",
            "epoch 50 | loss: 0.58341 | val_0_accuracy: 0.69171 |  0:03:35s\n",
            "\n",
            "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_accuracy = 0.71351\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 09:16:19,380]\u001b[0m Trial 3 finished with value: 0.7135146804835925 and parameters: {'n_d': 21, 'n_a': 11, 'n_steps': 7, 'gamma': 1.4229661788675476, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.36352240225129595}. Best is trial 2 with value: 0.7955526770293609.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       825\n",
            "           1       0.51      0.38      0.44       825\n",
            "           2       0.64      0.95      0.77       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.45      0.48      0.46       761\n",
            "           5       0.64      0.40      0.49       619\n",
            "\n",
            "    accuracy                           0.71      4632\n",
            "   macro avg       0.71      0.70      0.69      4632\n",
            "weighted avg       0.71      0.71      0.70      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.18114 | val_0_accuracy: 0.61528 |  0:00:01s\n",
            "epoch 1  | loss: 0.82034 | val_0_accuracy: 0.64896 |  0:00:03s\n",
            "epoch 2  | loss: 0.77172 | val_0_accuracy: 0.65566 |  0:00:05s\n",
            "epoch 3  | loss: 0.7374  | val_0_accuracy: 0.68178 |  0:00:06s\n",
            "epoch 4  | loss: 0.73039 | val_0_accuracy: 0.67638 |  0:00:08s\n",
            "epoch 5  | loss: 0.7023  | val_0_accuracy: 0.68869 |  0:00:10s\n",
            "epoch 6  | loss: 0.69069 | val_0_accuracy: 0.69732 |  0:00:11s\n",
            "epoch 7  | loss: 0.67126 | val_0_accuracy: 0.6889  |  0:00:13s\n",
            "epoch 8  | loss: 0.66621 | val_0_accuracy: 0.70833 |  0:00:15s\n",
            "epoch 9  | loss: 0.66235 | val_0_accuracy: 0.70466 |  0:00:17s\n",
            "epoch 10 | loss: 0.6611  | val_0_accuracy: 0.69948 |  0:00:18s\n",
            "epoch 11 | loss: 0.64826 | val_0_accuracy: 0.69365 |  0:00:20s\n",
            "epoch 12 | loss: 0.63962 | val_0_accuracy: 0.71395 |  0:00:22s\n",
            "epoch 13 | loss: 0.63378 | val_0_accuracy: 0.71006 |  0:00:24s\n",
            "epoch 14 | loss: 0.62829 | val_0_accuracy: 0.71157 |  0:00:25s\n",
            "epoch 15 | loss: 0.6229  | val_0_accuracy: 0.72884 |  0:00:27s\n",
            "epoch 16 | loss: 0.61271 | val_0_accuracy: 0.72539 |  0:00:29s\n",
            "epoch 17 | loss: 0.60765 | val_0_accuracy: 0.73014 |  0:00:30s\n",
            "epoch 18 | loss: 0.61526 | val_0_accuracy: 0.72301 |  0:00:32s\n",
            "epoch 19 | loss: 0.60916 | val_0_accuracy: 0.72949 |  0:00:34s\n",
            "epoch 20 | loss: 0.60431 | val_0_accuracy: 0.72301 |  0:00:36s\n",
            "epoch 21 | loss: 0.59902 | val_0_accuracy: 0.72388 |  0:00:37s\n",
            "epoch 22 | loss: 0.59127 | val_0_accuracy: 0.72107 |  0:00:39s\n",
            "epoch 23 | loss: 0.58361 | val_0_accuracy: 0.73769 |  0:00:41s\n",
            "epoch 24 | loss: 0.58449 | val_0_accuracy: 0.74136 |  0:00:43s\n",
            "epoch 25 | loss: 0.57535 | val_0_accuracy: 0.74007 |  0:00:44s\n",
            "epoch 26 | loss: 0.569   | val_0_accuracy: 0.73683 |  0:00:46s\n",
            "epoch 27 | loss: 0.56557 | val_0_accuracy: 0.73705 |  0:00:47s\n",
            "epoch 28 | loss: 0.56129 | val_0_accuracy: 0.75108 |  0:00:49s\n",
            "epoch 29 | loss: 0.56198 | val_0_accuracy: 0.7459  |  0:00:51s\n",
            "epoch 30 | loss: 0.55162 | val_0_accuracy: 0.74914 |  0:00:52s\n",
            "epoch 31 | loss: 0.57025 | val_0_accuracy: 0.74763 |  0:00:54s\n",
            "epoch 32 | loss: 0.55968 | val_0_accuracy: 0.74525 |  0:00:56s\n",
            "epoch 33 | loss: 0.55047 | val_0_accuracy: 0.74611 |  0:00:57s\n",
            "epoch 34 | loss: 0.54391 | val_0_accuracy: 0.75173 |  0:00:59s\n",
            "epoch 35 | loss: 0.54311 | val_0_accuracy: 0.75928 |  0:01:01s\n",
            "epoch 36 | loss: 0.5387  | val_0_accuracy: 0.75583 |  0:01:03s\n",
            "epoch 37 | loss: 0.54648 | val_0_accuracy: 0.75432 |  0:01:04s\n",
            "epoch 38 | loss: 0.53679 | val_0_accuracy: 0.76015 |  0:01:06s\n",
            "epoch 39 | loss: 0.53158 | val_0_accuracy: 0.76036 |  0:01:07s\n",
            "epoch 40 | loss: 0.53798 | val_0_accuracy: 0.75151 |  0:01:09s\n",
            "epoch 41 | loss: 0.53753 | val_0_accuracy: 0.76209 |  0:01:11s\n",
            "epoch 42 | loss: 0.52525 | val_0_accuracy: 0.76123 |  0:01:13s\n",
            "epoch 43 | loss: 0.51648 | val_0_accuracy: 0.75475 |  0:01:14s\n",
            "epoch 44 | loss: 0.52087 | val_0_accuracy: 0.75734 |  0:01:16s\n",
            "epoch 45 | loss: 0.51698 | val_0_accuracy: 0.7595  |  0:01:18s\n",
            "epoch 46 | loss: 0.51887 | val_0_accuracy: 0.74655 |  0:01:19s\n",
            "epoch 47 | loss: 0.53511 | val_0_accuracy: 0.76511 |  0:01:21s\n",
            "epoch 48 | loss: 0.51608 | val_0_accuracy: 0.76706 |  0:01:23s\n",
            "epoch 49 | loss: 0.50801 | val_0_accuracy: 0.76619 |  0:01:24s\n",
            "epoch 50 | loss: 0.50453 | val_0_accuracy: 0.77051 |  0:01:26s\n",
            "epoch 51 | loss: 0.50061 | val_0_accuracy: 0.76511 |  0:01:27s\n",
            "epoch 52 | loss: 0.50033 | val_0_accuracy: 0.76965 |  0:01:29s\n",
            "epoch 53 | loss: 0.49526 | val_0_accuracy: 0.77332 |  0:01:31s\n",
            "epoch 54 | loss: 0.49529 | val_0_accuracy: 0.76533 |  0:01:33s\n",
            "epoch 55 | loss: 0.49267 | val_0_accuracy: 0.77569 |  0:01:34s\n",
            "epoch 56 | loss: 0.48686 | val_0_accuracy: 0.77655 |  0:01:36s\n",
            "epoch 57 | loss: 0.48671 | val_0_accuracy: 0.77483 |  0:01:38s\n",
            "epoch 58 | loss: 0.48616 | val_0_accuracy: 0.77763 |  0:01:39s\n",
            "epoch 59 | loss: 0.48395 | val_0_accuracy: 0.78087 |  0:01:41s\n",
            "epoch 60 | loss: 0.4781  | val_0_accuracy: 0.78195 |  0:01:43s\n",
            "epoch 61 | loss: 0.47557 | val_0_accuracy: 0.77785 |  0:01:44s\n",
            "epoch 62 | loss: 0.47823 | val_0_accuracy: 0.78303 |  0:01:46s\n",
            "epoch 63 | loss: 0.47466 | val_0_accuracy: 0.78066 |  0:01:48s\n",
            "epoch 64 | loss: 0.47242 | val_0_accuracy: 0.78627 |  0:01:49s\n",
            "epoch 65 | loss: 0.46747 | val_0_accuracy: 0.78605 |  0:01:51s\n",
            "epoch 66 | loss: 0.46696 | val_0_accuracy: 0.78649 |  0:01:53s\n",
            "epoch 67 | loss: 0.46465 | val_0_accuracy: 0.78044 |  0:01:54s\n",
            "epoch 68 | loss: 0.46118 | val_0_accuracy: 0.77958 |  0:01:56s\n",
            "epoch 69 | loss: 0.47217 | val_0_accuracy: 0.77569 |  0:01:58s\n",
            "epoch 70 | loss: 0.47499 | val_0_accuracy: 0.78174 |  0:01:59s\n",
            "epoch 71 | loss: 0.50642 | val_0_accuracy: 0.75691 |  0:02:01s\n",
            "epoch 72 | loss: 0.48644 | val_0_accuracy: 0.77396 |  0:02:03s\n",
            "epoch 73 | loss: 0.47396 | val_0_accuracy: 0.78087 |  0:02:04s\n",
            "epoch 74 | loss: 0.46414 | val_0_accuracy: 0.78756 |  0:02:06s\n",
            "epoch 75 | loss: 0.45755 | val_0_accuracy: 0.78282 |  0:02:08s\n",
            "epoch 76 | loss: 0.47243 | val_0_accuracy: 0.78649 |  0:02:09s\n",
            "epoch 77 | loss: 0.46982 | val_0_accuracy: 0.77699 |  0:02:11s\n",
            "epoch 78 | loss: 0.45134 | val_0_accuracy: 0.78238 |  0:02:13s\n",
            "epoch 79 | loss: 0.45026 | val_0_accuracy: 0.78756 |  0:02:14s\n",
            "epoch 80 | loss: 0.44395 | val_0_accuracy: 0.78692 |  0:02:16s\n",
            "epoch 81 | loss: 0.44294 | val_0_accuracy: 0.79188 |  0:02:18s\n",
            "epoch 82 | loss: 0.45246 | val_0_accuracy: 0.79123 |  0:02:19s\n",
            "epoch 83 | loss: 0.44064 | val_0_accuracy: 0.79296 |  0:02:21s\n",
            "epoch 84 | loss: 0.43775 | val_0_accuracy: 0.78476 |  0:02:23s\n",
            "epoch 85 | loss: 0.44414 | val_0_accuracy: 0.78649 |  0:02:24s\n",
            "epoch 86 | loss: 0.43827 | val_0_accuracy: 0.78735 |  0:02:26s\n",
            "epoch 87 | loss: 0.43169 | val_0_accuracy: 0.79944 |  0:02:28s\n",
            "epoch 88 | loss: 0.43414 | val_0_accuracy: 0.79123 |  0:02:29s\n",
            "epoch 89 | loss: 0.43334 | val_0_accuracy: 0.79145 |  0:02:31s\n",
            "epoch 90 | loss: 0.42835 | val_0_accuracy: 0.79253 |  0:02:33s\n",
            "epoch 91 | loss: 0.42665 | val_0_accuracy: 0.79793 |  0:02:34s\n",
            "epoch 92 | loss: 0.42318 | val_0_accuracy: 0.79534 |  0:02:36s\n",
            "epoch 93 | loss: 0.42576 | val_0_accuracy: 0.79318 |  0:02:38s\n",
            "epoch 94 | loss: 0.42387 | val_0_accuracy: 0.79879 |  0:02:39s\n",
            "epoch 95 | loss: 0.43018 | val_0_accuracy: 0.78972 |  0:02:41s\n",
            "epoch 96 | loss: 0.4313  | val_0_accuracy: 0.79253 |  0:02:43s\n",
            "epoch 97 | loss: 0.42874 | val_0_accuracy: 0.79361 |  0:02:44s\n",
            "\n",
            "Early stopping occurred at epoch 97 with best_epoch = 87 and best_val_0_accuracy = 0.79944\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 09:19:05,073]\u001b[0m Trial 4 finished with value: 0.7994386873920553 and parameters: {'n_d': 17, 'n_a': 35, 'n_steps': 3, 'gamma': 1.172587639981336, 'n_independent': 3, 'n_shared': 1, 'momentum': 0.0434013213254412}. Best is trial 4 with value: 0.7994386873920553.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.65      0.62      0.63       825\n",
            "           2       0.83      0.95      0.89       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.55      0.59      0.57       761\n",
            "           5       0.74      0.58      0.65       619\n",
            "\n",
            "    accuracy                           0.80      4632\n",
            "   macro avg       0.79      0.79      0.79      4632\n",
            "weighted avg       0.80      0.80      0.80      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.51949 | val_0_accuracy: 0.46826 |  0:00:03s\n",
            "epoch 1  | loss: 1.1004  | val_0_accuracy: 0.53152 |  0:00:06s\n",
            "epoch 2  | loss: 0.97505 | val_0_accuracy: 0.60687 |  0:00:09s\n",
            "epoch 3  | loss: 0.84093 | val_0_accuracy: 0.61701 |  0:00:12s\n",
            "epoch 4  | loss: 0.76102 | val_0_accuracy: 0.65717 |  0:00:16s\n",
            "epoch 5  | loss: 0.73164 | val_0_accuracy: 0.66969 |  0:00:19s\n",
            "epoch 6  | loss: 0.72277 | val_0_accuracy: 0.65825 |  0:00:22s\n",
            "epoch 7  | loss: 0.73796 | val_0_accuracy: 0.67228 |  0:00:25s\n",
            "epoch 8  | loss: 0.73632 | val_0_accuracy: 0.67012 |  0:00:29s\n",
            "epoch 9  | loss: 0.70552 | val_0_accuracy: 0.68761 |  0:00:32s\n",
            "epoch 10 | loss: 0.68273 | val_0_accuracy: 0.68092 |  0:00:35s\n",
            "epoch 11 | loss: 0.67593 | val_0_accuracy: 0.69322 |  0:00:38s\n",
            "epoch 12 | loss: 0.67016 | val_0_accuracy: 0.69797 |  0:00:41s\n",
            "epoch 13 | loss: 0.6606  | val_0_accuracy: 0.69236 |  0:00:45s\n",
            "epoch 14 | loss: 0.66272 | val_0_accuracy: 0.70229 |  0:00:48s\n",
            "epoch 15 | loss: 0.65455 | val_0_accuracy: 0.68934 |  0:00:51s\n",
            "epoch 16 | loss: 0.66466 | val_0_accuracy: 0.68221 |  0:00:54s\n",
            "epoch 17 | loss: 0.66304 | val_0_accuracy: 0.70056 |  0:00:58s\n",
            "epoch 18 | loss: 0.67561 | val_0_accuracy: 0.68545 |  0:01:01s\n",
            "epoch 19 | loss: 0.67471 | val_0_accuracy: 0.69732 |  0:01:04s\n",
            "epoch 20 | loss: 0.65501 | val_0_accuracy: 0.70423 |  0:01:07s\n",
            "epoch 21 | loss: 0.65037 | val_0_accuracy: 0.69797 |  0:01:10s\n",
            "epoch 22 | loss: 0.64958 | val_0_accuracy: 0.69797 |  0:01:14s\n",
            "epoch 23 | loss: 0.65612 | val_0_accuracy: 0.71373 |  0:01:17s\n",
            "epoch 24 | loss: 0.63111 | val_0_accuracy: 0.71654 |  0:01:20s\n",
            "epoch 25 | loss: 0.62099 | val_0_accuracy: 0.71675 |  0:01:23s\n",
            "epoch 26 | loss: 0.62227 | val_0_accuracy: 0.71567 |  0:01:27s\n",
            "epoch 27 | loss: 0.61926 | val_0_accuracy: 0.72755 |  0:01:30s\n",
            "epoch 28 | loss: 0.62192 | val_0_accuracy: 0.7187  |  0:01:33s\n",
            "epoch 29 | loss: 0.62456 | val_0_accuracy: 0.7079  |  0:01:36s\n",
            "epoch 30 | loss: 0.6417  | val_0_accuracy: 0.70941 |  0:01:39s\n",
            "epoch 31 | loss: 0.63342 | val_0_accuracy: 0.71006 |  0:01:42s\n",
            "epoch 32 | loss: 0.62094 | val_0_accuracy: 0.71956 |  0:01:46s\n",
            "epoch 33 | loss: 0.60423 | val_0_accuracy: 0.73359 |  0:01:49s\n",
            "epoch 34 | loss: 0.59797 | val_0_accuracy: 0.73769 |  0:01:52s\n",
            "epoch 35 | loss: 0.5922  | val_0_accuracy: 0.73273 |  0:01:55s\n",
            "epoch 36 | loss: 0.59067 | val_0_accuracy: 0.73877 |  0:01:59s\n",
            "epoch 37 | loss: 0.58397 | val_0_accuracy: 0.73748 |  0:02:02s\n",
            "epoch 38 | loss: 0.57766 | val_0_accuracy: 0.74266 |  0:02:05s\n",
            "epoch 39 | loss: 0.56904 | val_0_accuracy: 0.73769 |  0:02:08s\n",
            "epoch 40 | loss: 0.56407 | val_0_accuracy: 0.74136 |  0:02:11s\n",
            "epoch 41 | loss: 0.56463 | val_0_accuracy: 0.75259 |  0:02:15s\n",
            "epoch 42 | loss: 0.58436 | val_0_accuracy: 0.74093 |  0:02:18s\n",
            "epoch 43 | loss: 0.5701  | val_0_accuracy: 0.74914 |  0:02:21s\n",
            "epoch 44 | loss: 0.58257 | val_0_accuracy: 0.73834 |  0:02:24s\n",
            "epoch 45 | loss: 0.56796 | val_0_accuracy: 0.7513  |  0:02:28s\n",
            "epoch 46 | loss: 0.55308 | val_0_accuracy: 0.74892 |  0:02:31s\n",
            "epoch 47 | loss: 0.54685 | val_0_accuracy: 0.75604 |  0:02:34s\n",
            "epoch 48 | loss: 0.54117 | val_0_accuracy: 0.75648 |  0:02:37s\n",
            "epoch 49 | loss: 0.53611 | val_0_accuracy: 0.74763 |  0:02:40s\n",
            "epoch 50 | loss: 0.53798 | val_0_accuracy: 0.7595  |  0:02:44s\n",
            "epoch 51 | loss: 0.53561 | val_0_accuracy: 0.7554  |  0:02:48s\n",
            "epoch 52 | loss: 0.53595 | val_0_accuracy: 0.76511 |  0:02:51s\n",
            "epoch 53 | loss: 0.52913 | val_0_accuracy: 0.75648 |  0:02:54s\n",
            "epoch 54 | loss: 0.52215 | val_0_accuracy: 0.7677  |  0:02:57s\n",
            "epoch 55 | loss: 0.51952 | val_0_accuracy: 0.75453 |  0:03:01s\n",
            "epoch 56 | loss: 0.52454 | val_0_accuracy: 0.77267 |  0:03:04s\n",
            "epoch 57 | loss: 0.51296 | val_0_accuracy: 0.76295 |  0:03:07s\n",
            "epoch 58 | loss: 0.51224 | val_0_accuracy: 0.77418 |  0:03:10s\n",
            "epoch 59 | loss: 0.53738 | val_0_accuracy: 0.75022 |  0:03:14s\n",
            "epoch 60 | loss: 0.5279  | val_0_accuracy: 0.76662 |  0:03:17s\n",
            "epoch 61 | loss: 0.54621 | val_0_accuracy: 0.75756 |  0:03:20s\n",
            "epoch 62 | loss: 0.53238 | val_0_accuracy: 0.75799 |  0:03:23s\n",
            "epoch 63 | loss: 0.5473  | val_0_accuracy: 0.73856 |  0:03:27s\n",
            "epoch 64 | loss: 0.55358 | val_0_accuracy: 0.75691 |  0:03:30s\n",
            "epoch 65 | loss: 0.52463 | val_0_accuracy: 0.76468 |  0:03:33s\n",
            "epoch 66 | loss: 0.51287 | val_0_accuracy: 0.75173 |  0:03:36s\n",
            "epoch 67 | loss: 0.51353 | val_0_accuracy: 0.76641 |  0:03:39s\n",
            "epoch 68 | loss: 0.5004  | val_0_accuracy: 0.78174 |  0:03:43s\n",
            "epoch 69 | loss: 0.49725 | val_0_accuracy: 0.7744  |  0:03:46s\n",
            "epoch 70 | loss: 0.49791 | val_0_accuracy: 0.77245 |  0:03:49s\n",
            "epoch 71 | loss: 0.49768 | val_0_accuracy: 0.77699 |  0:03:52s\n",
            "epoch 72 | loss: 0.50629 | val_0_accuracy: 0.75928 |  0:03:56s\n",
            "epoch 73 | loss: 0.51494 | val_0_accuracy: 0.76295 |  0:03:59s\n",
            "epoch 74 | loss: 0.49841 | val_0_accuracy: 0.77677 |  0:04:02s\n",
            "epoch 75 | loss: 0.50581 | val_0_accuracy: 0.76684 |  0:04:05s\n",
            "epoch 76 | loss: 0.50296 | val_0_accuracy: 0.76749 |  0:04:08s\n",
            "epoch 77 | loss: 0.50477 | val_0_accuracy: 0.77807 |  0:04:12s\n",
            "epoch 78 | loss: 0.49973 | val_0_accuracy: 0.76662 |  0:04:15s\n",
            "\n",
            "Early stopping occurred at epoch 78 with best_epoch = 68 and best_val_0_accuracy = 0.78174\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 09:23:22,220]\u001b[0m Trial 5 finished with value: 0.7817357512953368 and parameters: {'n_d': 15, 'n_a': 53, 'n_steps': 7, 'gamma': 1.834917061714124, 'n_independent': 3, 'n_shared': 1, 'momentum': 0.307955370817867}. Best is trial 4 with value: 0.7994386873920553.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.61      0.57      0.59       825\n",
            "           2       0.82      0.90      0.86       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.52      0.59      0.55       761\n",
            "           5       0.74      0.57      0.64       619\n",
            "\n",
            "    accuracy                           0.78      4632\n",
            "   macro avg       0.78      0.77      0.77      4632\n",
            "weighted avg       0.78      0.78      0.78      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.46374 | val_0_accuracy: 0.52828 |  0:00:03s\n",
            "epoch 1  | loss: 1.02186 | val_0_accuracy: 0.57232 |  0:00:06s\n",
            "epoch 2  | loss: 0.93174 | val_0_accuracy: 0.60255 |  0:00:09s\n",
            "epoch 3  | loss: 0.87777 | val_0_accuracy: 0.625   |  0:00:12s\n",
            "epoch 4  | loss: 0.81615 | val_0_accuracy: 0.63493 |  0:00:15s\n",
            "epoch 5  | loss: 0.76877 | val_0_accuracy: 0.65782 |  0:00:18s\n",
            "epoch 6  | loss: 0.73951 | val_0_accuracy: 0.6712  |  0:00:21s\n",
            "epoch 7  | loss: 0.72294 | val_0_accuracy: 0.68588 |  0:00:24s\n",
            "epoch 8  | loss: 0.72674 | val_0_accuracy: 0.68199 |  0:00:27s\n",
            "epoch 9  | loss: 0.70641 | val_0_accuracy: 0.68307 |  0:00:30s\n",
            "epoch 10 | loss: 0.70658 | val_0_accuracy: 0.56801 |  0:00:33s\n",
            "epoch 11 | loss: 0.70443 | val_0_accuracy: 0.67185 |  0:00:36s\n",
            "epoch 12 | loss: 0.69333 | val_0_accuracy: 0.62889 |  0:00:39s\n",
            "epoch 13 | loss: 0.72568 | val_0_accuracy: 0.67595 |  0:00:42s\n",
            "epoch 14 | loss: 0.71814 | val_0_accuracy: 0.68199 |  0:00:45s\n",
            "epoch 15 | loss: 0.7102  | val_0_accuracy: 0.66213 |  0:00:48s\n",
            "epoch 16 | loss: 0.6954  | val_0_accuracy: 0.66127 |  0:00:52s\n",
            "epoch 17 | loss: 0.69183 | val_0_accuracy: 0.66645 |  0:00:55s\n",
            "\n",
            "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_accuracy = 0.68588\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 09:24:18,859]\u001b[0m Trial 6 finished with value: 0.685880829015544 and parameters: {'n_d': 21, 'n_a': 44, 'n_steps': 4, 'gamma': 1.7765670621855145, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.0366957331164486}. Best is trial 4 with value: 0.7994386873920553.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       825\n",
            "           1       0.45      0.47      0.46       825\n",
            "           2       0.70      0.77      0.73       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.40      0.39      0.39       761\n",
            "           5       0.52      0.41      0.46       619\n",
            "\n",
            "    accuracy                           0.69      4632\n",
            "   macro avg       0.67      0.67      0.67      4632\n",
            "weighted avg       0.68      0.69      0.68      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.48634 | val_0_accuracy: 0.5231  |  0:00:02s\n",
            "epoch 1  | loss: 1.06294 | val_0_accuracy: 0.55484 |  0:00:05s\n",
            "epoch 2  | loss: 0.96043 | val_0_accuracy: 0.60751 |  0:00:08s\n",
            "epoch 3  | loss: 0.8908  | val_0_accuracy: 0.61723 |  0:00:11s\n",
            "epoch 4  | loss: 0.83079 | val_0_accuracy: 0.63839 |  0:00:14s\n",
            "epoch 5  | loss: 0.79086 | val_0_accuracy: 0.6468  |  0:00:17s\n",
            "epoch 6  | loss: 0.76992 | val_0_accuracy: 0.66645 |  0:00:20s\n",
            "epoch 7  | loss: 0.73942 | val_0_accuracy: 0.67854 |  0:00:23s\n",
            "epoch 8  | loss: 0.73983 | val_0_accuracy: 0.67401 |  0:00:26s\n",
            "epoch 9  | loss: 0.74292 | val_0_accuracy: 0.67185 |  0:00:29s\n",
            "epoch 10 | loss: 0.73453 | val_0_accuracy: 0.54296 |  0:00:32s\n",
            "epoch 11 | loss: 0.75046 | val_0_accuracy: 0.66883 |  0:00:35s\n",
            "epoch 12 | loss: 0.72343 | val_0_accuracy: 0.68092 |  0:00:38s\n",
            "epoch 13 | loss: 0.70037 | val_0_accuracy: 0.69063 |  0:00:41s\n",
            "epoch 14 | loss: 0.68723 | val_0_accuracy: 0.7025  |  0:00:43s\n",
            "epoch 15 | loss: 0.68298 | val_0_accuracy: 0.69927 |  0:00:46s\n",
            "epoch 16 | loss: 0.6735  | val_0_accuracy: 0.70682 |  0:00:49s\n",
            "epoch 17 | loss: 0.66842 | val_0_accuracy: 0.70013 |  0:00:52s\n",
            "epoch 18 | loss: 0.66316 | val_0_accuracy: 0.69193 |  0:00:55s\n",
            "epoch 19 | loss: 0.65977 | val_0_accuracy: 0.70553 |  0:00:58s\n",
            "epoch 20 | loss: 0.65675 | val_0_accuracy: 0.70704 |  0:01:01s\n",
            "epoch 21 | loss: 0.64695 | val_0_accuracy: 0.71654 |  0:01:04s\n",
            "epoch 22 | loss: 0.64895 | val_0_accuracy: 0.663   |  0:01:06s\n",
            "epoch 23 | loss: 0.63997 | val_0_accuracy: 0.7133  |  0:01:09s\n",
            "epoch 24 | loss: 0.63766 | val_0_accuracy: 0.72107 |  0:01:12s\n",
            "epoch 25 | loss: 0.6418  | val_0_accuracy: 0.72453 |  0:01:15s\n",
            "epoch 26 | loss: 0.63904 | val_0_accuracy: 0.70509 |  0:01:18s\n",
            "epoch 27 | loss: 0.65695 | val_0_accuracy: 0.68307 |  0:01:21s\n",
            "epoch 28 | loss: 0.69577 | val_0_accuracy: 0.69689 |  0:01:23s\n",
            "epoch 29 | loss: 0.65771 | val_0_accuracy: 0.7025  |  0:01:26s\n",
            "epoch 30 | loss: 0.65012 | val_0_accuracy: 0.71287 |  0:01:29s\n",
            "epoch 31 | loss: 0.64278 | val_0_accuracy: 0.70704 |  0:01:32s\n",
            "epoch 32 | loss: 0.63728 | val_0_accuracy: 0.69797 |  0:01:35s\n",
            "epoch 33 | loss: 0.65572 | val_0_accuracy: 0.712   |  0:01:38s\n",
            "epoch 34 | loss: 0.62593 | val_0_accuracy: 0.72258 |  0:01:41s\n",
            "epoch 35 | loss: 0.61865 | val_0_accuracy: 0.72604 |  0:01:44s\n",
            "epoch 36 | loss: 0.60758 | val_0_accuracy: 0.72409 |  0:01:46s\n",
            "epoch 37 | loss: 0.60265 | val_0_accuracy: 0.73165 |  0:01:49s\n",
            "epoch 38 | loss: 0.61733 | val_0_accuracy: 0.71826 |  0:01:52s\n",
            "epoch 39 | loss: 0.6062  | val_0_accuracy: 0.71028 |  0:01:55s\n",
            "epoch 40 | loss: 0.59974 | val_0_accuracy: 0.72971 |  0:01:58s\n",
            "epoch 41 | loss: 0.58752 | val_0_accuracy: 0.73921 |  0:02:01s\n",
            "epoch 42 | loss: 0.59366 | val_0_accuracy: 0.73532 |  0:02:04s\n",
            "epoch 43 | loss: 0.58407 | val_0_accuracy: 0.73683 |  0:02:07s\n",
            "epoch 44 | loss: 0.57882 | val_0_accuracy: 0.74136 |  0:02:10s\n",
            "epoch 45 | loss: 0.5705  | val_0_accuracy: 0.74439 |  0:02:13s\n",
            "epoch 46 | loss: 0.56638 | val_0_accuracy: 0.73208 |  0:02:15s\n",
            "epoch 47 | loss: 0.58554 | val_0_accuracy: 0.74244 |  0:02:18s\n",
            "epoch 48 | loss: 0.56829 | val_0_accuracy: 0.75194 |  0:02:21s\n",
            "epoch 49 | loss: 0.55935 | val_0_accuracy: 0.74806 |  0:02:24s\n",
            "epoch 50 | loss: 0.5552  | val_0_accuracy: 0.74827 |  0:02:27s\n",
            "epoch 51 | loss: 0.56256 | val_0_accuracy: 0.75453 |  0:02:30s\n",
            "epoch 52 | loss: 0.56817 | val_0_accuracy: 0.73856 |  0:02:33s\n",
            "epoch 53 | loss: 0.56101 | val_0_accuracy: 0.7446  |  0:02:35s\n",
            "epoch 54 | loss: 0.55661 | val_0_accuracy: 0.75928 |  0:02:38s\n",
            "epoch 55 | loss: 0.54494 | val_0_accuracy: 0.74806 |  0:02:41s\n",
            "epoch 56 | loss: 0.55634 | val_0_accuracy: 0.72647 |  0:02:44s\n",
            "epoch 57 | loss: 0.59495 | val_0_accuracy: 0.73338 |  0:02:47s\n",
            "epoch 58 | loss: 0.59988 | val_0_accuracy: 0.74266 |  0:02:50s\n",
            "epoch 59 | loss: 0.56604 | val_0_accuracy: 0.73035 |  0:02:52s\n",
            "epoch 60 | loss: 0.58566 | val_0_accuracy: 0.74741 |  0:02:55s\n",
            "epoch 61 | loss: 0.56777 | val_0_accuracy: 0.7446  |  0:02:58s\n",
            "epoch 62 | loss: 0.59098 | val_0_accuracy: 0.74028 |  0:03:01s\n",
            "epoch 63 | loss: 0.5568  | val_0_accuracy: 0.7459  |  0:03:04s\n",
            "epoch 64 | loss: 0.54345 | val_0_accuracy: 0.75626 |  0:03:07s\n",
            "\n",
            "Early stopping occurred at epoch 64 with best_epoch = 54 and best_val_0_accuracy = 0.75928\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 09:27:27,482]\u001b[0m Trial 7 finished with value: 0.7592832469775475 and parameters: {'n_d': 41, 'n_a': 29, 'n_steps': 5, 'gamma': 1.7218363877241591, 'n_independent': 4, 'n_shared': 1, 'momentum': 0.02998492535513307}. Best is trial 4 with value: 0.7994386873920553.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       825\n",
            "           1       0.59      0.51      0.54       825\n",
            "           2       0.75      0.95      0.84       823\n",
            "           3       1.00      0.99      1.00       779\n",
            "           4       0.49      0.51      0.50       761\n",
            "           5       0.67      0.53      0.59       619\n",
            "\n",
            "    accuracy                           0.76      4632\n",
            "   macro avg       0.75      0.75      0.75      4632\n",
            "weighted avg       0.75      0.76      0.75      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.34765 | val_0_accuracy: 0.62737 |  0:00:04s\n",
            "epoch 1  | loss: 0.8611  | val_0_accuracy: 0.63364 |  0:00:08s\n",
            "epoch 2  | loss: 0.79595 | val_0_accuracy: 0.65976 |  0:00:12s\n",
            "epoch 3  | loss: 0.75744 | val_0_accuracy: 0.663   |  0:00:16s\n",
            "epoch 4  | loss: 0.7453  | val_0_accuracy: 0.67552 |  0:00:20s\n",
            "epoch 5  | loss: 0.72389 | val_0_accuracy: 0.68351 |  0:00:24s\n",
            "epoch 6  | loss: 0.72176 | val_0_accuracy: 0.67379 |  0:00:28s\n",
            "epoch 7  | loss: 0.72411 | val_0_accuracy: 0.66969 |  0:00:32s\n",
            "epoch 8  | loss: 0.71356 | val_0_accuracy: 0.6794  |  0:00:36s\n",
            "epoch 9  | loss: 0.71247 | val_0_accuracy: 0.67984 |  0:00:40s\n",
            "epoch 10 | loss: 0.69589 | val_0_accuracy: 0.68027 |  0:00:44s\n",
            "epoch 11 | loss: 0.68853 | val_0_accuracy: 0.69603 |  0:00:48s\n",
            "epoch 12 | loss: 0.68138 | val_0_accuracy: 0.67465 |  0:00:53s\n",
            "epoch 13 | loss: 0.67804 | val_0_accuracy: 0.69905 |  0:00:57s\n",
            "epoch 14 | loss: 0.67671 | val_0_accuracy: 0.71006 |  0:01:01s\n",
            "epoch 15 | loss: 0.67023 | val_0_accuracy: 0.70337 |  0:01:06s\n",
            "epoch 16 | loss: 0.66098 | val_0_accuracy: 0.70725 |  0:01:10s\n",
            "epoch 17 | loss: 0.65308 | val_0_accuracy: 0.68653 |  0:01:13s\n",
            "epoch 18 | loss: 0.64834 | val_0_accuracy: 0.7038  |  0:01:17s\n",
            "epoch 19 | loss: 0.64403 | val_0_accuracy: 0.71632 |  0:01:21s\n",
            "epoch 20 | loss: 0.6428  | val_0_accuracy: 0.70337 |  0:01:26s\n",
            "epoch 21 | loss: 0.638   | val_0_accuracy: 0.72193 |  0:01:30s\n",
            "epoch 22 | loss: 0.63194 | val_0_accuracy: 0.7133  |  0:01:34s\n",
            "epoch 23 | loss: 0.62698 | val_0_accuracy: 0.71611 |  0:01:38s\n",
            "epoch 24 | loss: 0.62411 | val_0_accuracy: 0.71848 |  0:01:42s\n",
            "epoch 25 | loss: 0.62125 | val_0_accuracy: 0.72085 |  0:01:46s\n",
            "epoch 26 | loss: 0.61701 | val_0_accuracy: 0.72733 |  0:01:50s\n",
            "epoch 27 | loss: 0.61524 | val_0_accuracy: 0.69819 |  0:01:54s\n",
            "epoch 28 | loss: 0.61323 | val_0_accuracy: 0.73618 |  0:01:58s\n",
            "epoch 29 | loss: 0.61049 | val_0_accuracy: 0.72863 |  0:02:02s\n",
            "epoch 30 | loss: 0.60976 | val_0_accuracy: 0.71071 |  0:02:06s\n",
            "epoch 31 | loss: 0.61694 | val_0_accuracy: 0.68696 |  0:02:10s\n",
            "epoch 32 | loss: 0.60254 | val_0_accuracy: 0.73122 |  0:02:14s\n",
            "epoch 33 | loss: 0.5964  | val_0_accuracy: 0.73165 |  0:02:18s\n",
            "epoch 34 | loss: 0.59825 | val_0_accuracy: 0.72042 |  0:02:22s\n",
            "epoch 35 | loss: 0.59885 | val_0_accuracy: 0.73748 |  0:02:26s\n",
            "epoch 36 | loss: 0.59177 | val_0_accuracy: 0.73618 |  0:02:31s\n",
            "epoch 37 | loss: 0.58918 | val_0_accuracy: 0.74201 |  0:02:34s\n",
            "epoch 38 | loss: 0.58539 | val_0_accuracy: 0.73791 |  0:02:39s\n",
            "epoch 39 | loss: 0.58395 | val_0_accuracy: 0.73661 |  0:02:43s\n",
            "epoch 40 | loss: 0.57814 | val_0_accuracy: 0.74352 |  0:02:47s\n",
            "epoch 41 | loss: 0.57299 | val_0_accuracy: 0.74136 |  0:02:51s\n",
            "epoch 42 | loss: 0.57341 | val_0_accuracy: 0.74806 |  0:02:55s\n",
            "epoch 43 | loss: 0.57309 | val_0_accuracy: 0.73683 |  0:02:59s\n",
            "epoch 44 | loss: 0.57137 | val_0_accuracy: 0.72992 |  0:03:03s\n",
            "epoch 45 | loss: 0.56608 | val_0_accuracy: 0.74568 |  0:03:07s\n",
            "epoch 46 | loss: 0.56686 | val_0_accuracy: 0.74503 |  0:03:11s\n",
            "epoch 47 | loss: 0.56365 | val_0_accuracy: 0.75108 |  0:03:15s\n",
            "epoch 48 | loss: 0.55742 | val_0_accuracy: 0.74633 |  0:03:19s\n",
            "epoch 49 | loss: 0.55805 | val_0_accuracy: 0.7582  |  0:03:23s\n",
            "epoch 50 | loss: 0.54865 | val_0_accuracy: 0.74957 |  0:03:27s\n",
            "epoch 51 | loss: 0.5518  | val_0_accuracy: 0.72841 |  0:03:31s\n",
            "epoch 52 | loss: 0.54621 | val_0_accuracy: 0.74978 |  0:03:35s\n",
            "epoch 53 | loss: 0.54424 | val_0_accuracy: 0.75907 |  0:03:39s\n",
            "epoch 54 | loss: 0.54294 | val_0_accuracy: 0.75972 |  0:03:43s\n",
            "epoch 55 | loss: 0.54163 | val_0_accuracy: 0.7446  |  0:03:47s\n",
            "epoch 56 | loss: 0.53905 | val_0_accuracy: 0.74827 |  0:03:51s\n",
            "epoch 57 | loss: 0.54128 | val_0_accuracy: 0.74978 |  0:03:55s\n",
            "epoch 58 | loss: 0.53329 | val_0_accuracy: 0.76144 |  0:03:59s\n",
            "epoch 59 | loss: 0.53367 | val_0_accuracy: 0.75194 |  0:04:03s\n",
            "epoch 60 | loss: 0.53399 | val_0_accuracy: 0.75302 |  0:04:07s\n",
            "epoch 61 | loss: 0.53146 | val_0_accuracy: 0.75194 |  0:04:11s\n",
            "epoch 62 | loss: 0.52655 | val_0_accuracy: 0.72884 |  0:04:15s\n",
            "epoch 63 | loss: 0.52607 | val_0_accuracy: 0.75648 |  0:04:19s\n",
            "epoch 64 | loss: 0.52297 | val_0_accuracy: 0.7541  |  0:04:23s\n",
            "epoch 65 | loss: 0.52408 | val_0_accuracy: 0.74396 |  0:04:27s\n",
            "epoch 66 | loss: 0.52291 | val_0_accuracy: 0.74374 |  0:04:31s\n",
            "epoch 67 | loss: 0.52249 | val_0_accuracy: 0.76187 |  0:04:35s\n",
            "epoch 68 | loss: 0.52475 | val_0_accuracy: 0.75885 |  0:04:39s\n",
            "epoch 69 | loss: 0.51676 | val_0_accuracy: 0.76943 |  0:04:43s\n",
            "epoch 70 | loss: 0.51    | val_0_accuracy: 0.76446 |  0:04:47s\n",
            "epoch 71 | loss: 0.5121  | val_0_accuracy: 0.76058 |  0:04:51s\n",
            "epoch 72 | loss: 0.50752 | val_0_accuracy: 0.76403 |  0:04:55s\n",
            "epoch 73 | loss: 0.50745 | val_0_accuracy: 0.77288 |  0:04:59s\n",
            "epoch 74 | loss: 0.50834 | val_0_accuracy: 0.76468 |  0:05:03s\n",
            "epoch 75 | loss: 0.5065  | val_0_accuracy: 0.72474 |  0:05:07s\n",
            "epoch 76 | loss: 0.5101  | val_0_accuracy: 0.77461 |  0:05:11s\n",
            "epoch 77 | loss: 0.50396 | val_0_accuracy: 0.7405  |  0:05:15s\n",
            "epoch 78 | loss: 0.50166 | val_0_accuracy: 0.76533 |  0:05:19s\n",
            "epoch 79 | loss: 0.50891 | val_0_accuracy: 0.7282  |  0:05:23s\n",
            "epoch 80 | loss: 0.49797 | val_0_accuracy: 0.73316 |  0:05:27s\n",
            "epoch 81 | loss: 0.49723 | val_0_accuracy: 0.75842 |  0:05:31s\n",
            "epoch 82 | loss: 0.49204 | val_0_accuracy: 0.72668 |  0:05:35s\n",
            "epoch 83 | loss: 0.49303 | val_0_accuracy: 0.76382 |  0:05:39s\n",
            "epoch 84 | loss: 0.48823 | val_0_accuracy: 0.76792 |  0:05:43s\n",
            "epoch 85 | loss: 0.4869  | val_0_accuracy: 0.77353 |  0:05:47s\n",
            "epoch 86 | loss: 0.48037 | val_0_accuracy: 0.75583 |  0:05:51s\n",
            "\n",
            "Early stopping occurred at epoch 86 with best_epoch = 76 and best_val_0_accuracy = 0.77461\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 09:33:20,707]\u001b[0m Trial 8 finished with value: 0.7746113989637305 and parameters: {'n_d': 36, 'n_a': 54, 'n_steps': 5, 'gamma': 1.073133721350996, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.14516274864269166}. Best is trial 4 with value: 0.7994386873920553.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.57      0.66      0.61       825\n",
            "           2       0.83      0.87      0.85       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.52      0.53      0.53       761\n",
            "           5       0.73      0.53      0.61       619\n",
            "\n",
            "    accuracy                           0.77      4632\n",
            "   macro avg       0.78      0.76      0.77      4632\n",
            "weighted avg       0.78      0.77      0.77      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.66695 | val_0_accuracy: 0.56606 |  0:00:03s\n",
            "epoch 1  | loss: 1.07845 | val_0_accuracy: 0.54383 |  0:00:06s\n",
            "epoch 2  | loss: 1.09018 | val_0_accuracy: 0.52224 |  0:00:09s\n",
            "epoch 3  | loss: 1.06724 | val_0_accuracy: 0.58096 |  0:00:13s\n",
            "epoch 4  | loss: 0.92104 | val_0_accuracy: 0.57448 |  0:00:16s\n",
            "epoch 5  | loss: 0.88897 | val_0_accuracy: 0.59111 |  0:00:19s\n",
            "epoch 6  | loss: 0.83615 | val_0_accuracy: 0.63536 |  0:00:22s\n",
            "epoch 7  | loss: 0.79386 | val_0_accuracy: 0.6386  |  0:00:25s\n",
            "epoch 8  | loss: 0.77064 | val_0_accuracy: 0.65522 |  0:00:29s\n",
            "epoch 9  | loss: 0.76106 | val_0_accuracy: 0.65868 |  0:00:32s\n",
            "epoch 10 | loss: 0.7519  | val_0_accuracy: 0.63601 |  0:00:35s\n",
            "epoch 11 | loss: 0.74795 | val_0_accuracy: 0.67314 |  0:00:38s\n",
            "epoch 12 | loss: 0.74636 | val_0_accuracy: 0.65976 |  0:00:42s\n",
            "epoch 13 | loss: 0.73562 | val_0_accuracy: 0.67746 |  0:00:45s\n",
            "epoch 14 | loss: 0.74315 | val_0_accuracy: 0.66796 |  0:00:48s\n",
            "epoch 15 | loss: 0.72574 | val_0_accuracy: 0.67142 |  0:00:51s\n",
            "epoch 16 | loss: 0.71643 | val_0_accuracy: 0.68372 |  0:00:55s\n",
            "epoch 17 | loss: 0.71749 | val_0_accuracy: 0.68372 |  0:00:58s\n",
            "epoch 18 | loss: 0.70275 | val_0_accuracy: 0.68307 |  0:01:01s\n",
            "epoch 19 | loss: 0.71009 | val_0_accuracy: 0.67681 |  0:01:04s\n",
            "epoch 20 | loss: 0.71148 | val_0_accuracy: 0.69128 |  0:01:08s\n",
            "epoch 21 | loss: 0.69775 | val_0_accuracy: 0.69128 |  0:01:11s\n",
            "epoch 22 | loss: 0.69439 | val_0_accuracy: 0.68631 |  0:01:14s\n",
            "epoch 23 | loss: 0.69721 | val_0_accuracy: 0.67314 |  0:01:17s\n",
            "epoch 24 | loss: 0.7116  | val_0_accuracy: 0.68566 |  0:01:20s\n",
            "epoch 25 | loss: 0.69842 | val_0_accuracy: 0.6766  |  0:01:24s\n",
            "epoch 26 | loss: 0.68759 | val_0_accuracy: 0.68934 |  0:01:27s\n",
            "epoch 27 | loss: 0.68118 | val_0_accuracy: 0.69214 |  0:01:30s\n",
            "epoch 28 | loss: 0.67545 | val_0_accuracy: 0.69495 |  0:01:33s\n",
            "epoch 29 | loss: 0.6671  | val_0_accuracy: 0.6956  |  0:01:37s\n",
            "epoch 30 | loss: 0.66777 | val_0_accuracy: 0.70445 |  0:01:40s\n",
            "epoch 31 | loss: 0.66215 | val_0_accuracy: 0.70661 |  0:01:43s\n",
            "epoch 32 | loss: 0.65318 | val_0_accuracy: 0.70661 |  0:01:46s\n",
            "epoch 33 | loss: 0.65421 | val_0_accuracy: 0.69797 |  0:01:50s\n",
            "epoch 34 | loss: 0.65439 | val_0_accuracy: 0.71006 |  0:01:53s\n",
            "epoch 35 | loss: 0.64768 | val_0_accuracy: 0.7038  |  0:01:56s\n",
            "epoch 36 | loss: 0.64699 | val_0_accuracy: 0.70941 |  0:01:59s\n",
            "epoch 37 | loss: 0.6449  | val_0_accuracy: 0.71287 |  0:02:02s\n",
            "epoch 38 | loss: 0.64178 | val_0_accuracy: 0.7025  |  0:02:06s\n",
            "epoch 39 | loss: 0.64227 | val_0_accuracy: 0.7025  |  0:02:10s\n",
            "epoch 40 | loss: 0.65254 | val_0_accuracy: 0.6984  |  0:02:13s\n",
            "epoch 41 | loss: 0.65637 | val_0_accuracy: 0.70466 |  0:02:16s\n",
            "epoch 42 | loss: 0.64227 | val_0_accuracy: 0.70898 |  0:02:19s\n",
            "epoch 43 | loss: 0.63705 | val_0_accuracy: 0.69193 |  0:02:23s\n",
            "epoch 44 | loss: 0.65693 | val_0_accuracy: 0.70207 |  0:02:26s\n",
            "epoch 45 | loss: 0.63373 | val_0_accuracy: 0.71718 |  0:02:29s\n",
            "epoch 46 | loss: 0.62187 | val_0_accuracy: 0.70984 |  0:02:32s\n",
            "epoch 47 | loss: 0.6357  | val_0_accuracy: 0.71244 |  0:02:36s\n",
            "epoch 48 | loss: 0.6351  | val_0_accuracy: 0.71913 |  0:02:39s\n",
            "epoch 49 | loss: 0.64169 | val_0_accuracy: 0.71546 |  0:02:42s\n",
            "epoch 50 | loss: 0.63558 | val_0_accuracy: 0.71481 |  0:02:45s\n",
            "epoch 51 | loss: 0.62933 | val_0_accuracy: 0.71891 |  0:02:49s\n",
            "epoch 52 | loss: 0.61684 | val_0_accuracy: 0.72582 |  0:02:52s\n",
            "epoch 53 | loss: 0.62896 | val_0_accuracy: 0.72431 |  0:02:55s\n",
            "epoch 54 | loss: 0.61837 | val_0_accuracy: 0.72647 |  0:02:59s\n",
            "epoch 55 | loss: 0.6171  | val_0_accuracy: 0.71805 |  0:03:02s\n",
            "epoch 56 | loss: 0.65515 | val_0_accuracy: 0.69063 |  0:03:05s\n",
            "epoch 57 | loss: 0.6496  | val_0_accuracy: 0.71114 |  0:03:08s\n",
            "epoch 58 | loss: 0.64505 | val_0_accuracy: 0.72193 |  0:03:12s\n",
            "epoch 59 | loss: 0.61541 | val_0_accuracy: 0.72172 |  0:03:15s\n",
            "epoch 60 | loss: 0.60722 | val_0_accuracy: 0.72733 |  0:03:18s\n",
            "epoch 61 | loss: 0.60241 | val_0_accuracy: 0.71978 |  0:03:21s\n",
            "epoch 62 | loss: 0.59419 | val_0_accuracy: 0.73251 |  0:03:25s\n",
            "epoch 63 | loss: 0.60575 | val_0_accuracy: 0.73143 |  0:03:28s\n",
            "epoch 64 | loss: 0.59762 | val_0_accuracy: 0.73942 |  0:03:31s\n",
            "epoch 65 | loss: 0.59013 | val_0_accuracy: 0.73618 |  0:03:34s\n",
            "epoch 66 | loss: 0.58312 | val_0_accuracy: 0.73554 |  0:03:38s\n",
            "epoch 67 | loss: 0.58097 | val_0_accuracy: 0.74806 |  0:03:41s\n",
            "epoch 68 | loss: 0.57526 | val_0_accuracy: 0.74763 |  0:03:44s\n",
            "epoch 69 | loss: 0.57321 | val_0_accuracy: 0.74676 |  0:03:48s\n",
            "epoch 70 | loss: 0.56793 | val_0_accuracy: 0.75043 |  0:03:51s\n",
            "epoch 71 | loss: 0.57403 | val_0_accuracy: 0.74698 |  0:03:54s\n",
            "epoch 72 | loss: 0.59888 | val_0_accuracy: 0.73489 |  0:03:57s\n",
            "epoch 73 | loss: 0.59298 | val_0_accuracy: 0.7405  |  0:04:00s\n",
            "epoch 74 | loss: 0.57789 | val_0_accuracy: 0.74201 |  0:04:04s\n",
            "epoch 75 | loss: 0.57315 | val_0_accuracy: 0.7446  |  0:04:07s\n",
            "epoch 76 | loss: 0.58199 | val_0_accuracy: 0.74655 |  0:04:10s\n",
            "epoch 77 | loss: 0.577   | val_0_accuracy: 0.74093 |  0:04:13s\n",
            "epoch 78 | loss: 0.56361 | val_0_accuracy: 0.75259 |  0:04:17s\n",
            "epoch 79 | loss: 0.56955 | val_0_accuracy: 0.73424 |  0:04:20s\n",
            "epoch 80 | loss: 0.57723 | val_0_accuracy: 0.74849 |  0:04:23s\n",
            "epoch 81 | loss: 0.55879 | val_0_accuracy: 0.75475 |  0:04:26s\n",
            "epoch 82 | loss: 0.55421 | val_0_accuracy: 0.75022 |  0:04:30s\n",
            "epoch 83 | loss: 0.54086 | val_0_accuracy: 0.75432 |  0:04:33s\n",
            "epoch 84 | loss: 0.53899 | val_0_accuracy: 0.75928 |  0:04:36s\n",
            "epoch 85 | loss: 0.55275 | val_0_accuracy: 0.75216 |  0:04:39s\n",
            "epoch 86 | loss: 0.53696 | val_0_accuracy: 0.76706 |  0:04:43s\n",
            "epoch 87 | loss: 0.53995 | val_0_accuracy: 0.76468 |  0:04:46s\n",
            "epoch 88 | loss: 0.53333 | val_0_accuracy: 0.76662 |  0:04:49s\n",
            "epoch 89 | loss: 0.52438 | val_0_accuracy: 0.7649  |  0:04:52s\n",
            "epoch 90 | loss: 0.52406 | val_0_accuracy: 0.76317 |  0:04:56s\n",
            "epoch 91 | loss: 0.53112 | val_0_accuracy: 0.75259 |  0:04:59s\n",
            "epoch 92 | loss: 0.54568 | val_0_accuracy: 0.7595  |  0:05:02s\n",
            "epoch 93 | loss: 0.52137 | val_0_accuracy: 0.76641 |  0:05:05s\n",
            "epoch 94 | loss: 0.51823 | val_0_accuracy: 0.76965 |  0:05:08s\n",
            "epoch 95 | loss: 0.51558 | val_0_accuracy: 0.76554 |  0:05:12s\n",
            "epoch 96 | loss: 0.51633 | val_0_accuracy: 0.7731  |  0:05:15s\n",
            "epoch 97 | loss: 0.52039 | val_0_accuracy: 0.76339 |  0:05:18s\n",
            "epoch 98 | loss: 0.51657 | val_0_accuracy: 0.77461 |  0:05:21s\n",
            "epoch 99 | loss: 0.51115 | val_0_accuracy: 0.77807 |  0:05:25s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_accuracy = 0.77807\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 09:38:47,469]\u001b[0m Trial 9 finished with value: 0.7780656303972366 and parameters: {'n_d': 13, 'n_a': 49, 'n_steps': 9, 'gamma': 1.4076351178231565, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.09440481920742703}. Best is trial 4 with value: 0.7994386873920553.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.60      0.62      0.61       825\n",
            "           2       0.81      0.92      0.87       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.52      0.53      0.52       761\n",
            "           5       0.72      0.53      0.61       619\n",
            "\n",
            "    accuracy                           0.78      4632\n",
            "   macro avg       0.77      0.77      0.77      4632\n",
            "weighted avg       0.78      0.78      0.77      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 1.3902  | val_0_accuracy: 0.56498 |  0:00:02s\n",
            "epoch 1  | loss: 0.8827  | val_0_accuracy: 0.6032  |  0:00:04s\n",
            "epoch 2  | loss: 0.81583 | val_0_accuracy: 0.63644 |  0:00:07s\n",
            "epoch 3  | loss: 0.78906 | val_0_accuracy: 0.64313 |  0:00:09s\n",
            "epoch 4  | loss: 0.77192 | val_0_accuracy: 0.65587 |  0:00:12s\n",
            "epoch 5  | loss: 0.75665 | val_0_accuracy: 0.66278 |  0:00:14s\n",
            "epoch 6  | loss: 0.74443 | val_0_accuracy: 0.65933 |  0:00:17s\n",
            "epoch 7  | loss: 0.72611 | val_0_accuracy: 0.68329 |  0:00:19s\n",
            "epoch 8  | loss: 0.70819 | val_0_accuracy: 0.68092 |  0:00:22s\n",
            "epoch 9  | loss: 0.70544 | val_0_accuracy: 0.68372 |  0:00:24s\n",
            "epoch 10 | loss: 0.69099 | val_0_accuracy: 0.68588 |  0:00:27s\n",
            "epoch 11 | loss: 0.67761 | val_0_accuracy: 0.69732 |  0:00:29s\n",
            "epoch 12 | loss: 0.67207 | val_0_accuracy: 0.70013 |  0:00:32s\n",
            "epoch 13 | loss: 0.66977 | val_0_accuracy: 0.69905 |  0:00:34s\n",
            "epoch 14 | loss: 0.663   | val_0_accuracy: 0.70207 |  0:00:37s\n",
            "epoch 15 | loss: 0.65948 | val_0_accuracy: 0.70142 |  0:00:39s\n",
            "epoch 16 | loss: 0.64841 | val_0_accuracy: 0.71244 |  0:00:41s\n",
            "epoch 17 | loss: 0.64261 | val_0_accuracy: 0.70423 |  0:00:44s\n",
            "epoch 18 | loss: 0.64477 | val_0_accuracy: 0.69538 |  0:00:46s\n",
            "epoch 19 | loss: 0.63437 | val_0_accuracy: 0.70596 |  0:00:49s\n",
            "epoch 20 | loss: 0.62995 | val_0_accuracy: 0.71632 |  0:00:51s\n",
            "epoch 21 | loss: 0.62456 | val_0_accuracy: 0.72085 |  0:00:54s\n",
            "epoch 22 | loss: 0.61979 | val_0_accuracy: 0.69301 |  0:00:56s\n",
            "epoch 23 | loss: 0.61844 | val_0_accuracy: 0.72193 |  0:00:59s\n",
            "epoch 24 | loss: 0.61762 | val_0_accuracy: 0.71308 |  0:01:01s\n",
            "epoch 25 | loss: 0.62512 | val_0_accuracy: 0.71244 |  0:01:04s\n",
            "epoch 26 | loss: 0.61182 | val_0_accuracy: 0.71697 |  0:01:06s\n",
            "epoch 27 | loss: 0.606   | val_0_accuracy: 0.72712 |  0:01:09s\n",
            "epoch 28 | loss: 0.6029  | val_0_accuracy: 0.71999 |  0:01:11s\n",
            "epoch 29 | loss: 0.60152 | val_0_accuracy: 0.73035 |  0:01:14s\n",
            "epoch 30 | loss: 0.59668 | val_0_accuracy: 0.7364  |  0:01:16s\n",
            "epoch 31 | loss: 0.59356 | val_0_accuracy: 0.7364  |  0:01:18s\n",
            "epoch 32 | loss: 0.59408 | val_0_accuracy: 0.72323 |  0:01:21s\n",
            "epoch 33 | loss: 0.58615 | val_0_accuracy: 0.73489 |  0:01:23s\n",
            "epoch 34 | loss: 0.58499 | val_0_accuracy: 0.74503 |  0:01:26s\n",
            "epoch 35 | loss: 0.57934 | val_0_accuracy: 0.74352 |  0:01:28s\n",
            "epoch 36 | loss: 0.57427 | val_0_accuracy: 0.73705 |  0:01:31s\n",
            "epoch 37 | loss: 0.5728  | val_0_accuracy: 0.74547 |  0:01:33s\n",
            "epoch 38 | loss: 0.57223 | val_0_accuracy: 0.74439 |  0:01:36s\n",
            "epoch 39 | loss: 0.56855 | val_0_accuracy: 0.74201 |  0:01:38s\n",
            "epoch 40 | loss: 0.56759 | val_0_accuracy: 0.74331 |  0:01:41s\n",
            "epoch 41 | loss: 0.56952 | val_0_accuracy: 0.73532 |  0:01:43s\n",
            "epoch 42 | loss: 0.56924 | val_0_accuracy: 0.74676 |  0:01:46s\n",
            "epoch 43 | loss: 0.56158 | val_0_accuracy: 0.73467 |  0:01:48s\n",
            "epoch 44 | loss: 0.57199 | val_0_accuracy: 0.7405  |  0:01:51s\n",
            "epoch 45 | loss: 0.56903 | val_0_accuracy: 0.74503 |  0:01:53s\n",
            "epoch 46 | loss: 0.56032 | val_0_accuracy: 0.75367 |  0:01:56s\n",
            "epoch 47 | loss: 0.55458 | val_0_accuracy: 0.75972 |  0:01:59s\n",
            "epoch 48 | loss: 0.55442 | val_0_accuracy: 0.7418  |  0:02:01s\n",
            "epoch 49 | loss: 0.57973 | val_0_accuracy: 0.73683 |  0:02:04s\n",
            "epoch 50 | loss: 0.56199 | val_0_accuracy: 0.75453 |  0:02:06s\n",
            "epoch 51 | loss: 0.55815 | val_0_accuracy: 0.74288 |  0:02:09s\n",
            "epoch 52 | loss: 0.55416 | val_0_accuracy: 0.75626 |  0:02:11s\n",
            "epoch 53 | loss: 0.5549  | val_0_accuracy: 0.76079 |  0:02:14s\n",
            "epoch 54 | loss: 0.54674 | val_0_accuracy: 0.75864 |  0:02:16s\n",
            "epoch 55 | loss: 0.53958 | val_0_accuracy: 0.76036 |  0:02:19s\n",
            "epoch 56 | loss: 0.53926 | val_0_accuracy: 0.75928 |  0:02:22s\n",
            "epoch 57 | loss: 0.53723 | val_0_accuracy: 0.76511 |  0:02:24s\n",
            "epoch 58 | loss: 0.53337 | val_0_accuracy: 0.76144 |  0:02:27s\n",
            "epoch 59 | loss: 0.52976 | val_0_accuracy: 0.76101 |  0:02:29s\n",
            "epoch 60 | loss: 0.52899 | val_0_accuracy: 0.75972 |  0:02:32s\n",
            "epoch 61 | loss: 0.52523 | val_0_accuracy: 0.76986 |  0:02:34s\n",
            "epoch 62 | loss: 0.52417 | val_0_accuracy: 0.77375 |  0:02:37s\n",
            "epoch 63 | loss: 0.53035 | val_0_accuracy: 0.76554 |  0:02:39s\n",
            "epoch 64 | loss: 0.53059 | val_0_accuracy: 0.76835 |  0:02:42s\n",
            "epoch 65 | loss: 0.52172 | val_0_accuracy: 0.76382 |  0:02:44s\n",
            "epoch 66 | loss: 0.51701 | val_0_accuracy: 0.76166 |  0:02:47s\n",
            "epoch 67 | loss: 0.51511 | val_0_accuracy: 0.76662 |  0:02:49s\n",
            "epoch 68 | loss: 0.51366 | val_0_accuracy: 0.77202 |  0:02:52s\n",
            "epoch 69 | loss: 0.51207 | val_0_accuracy: 0.77461 |  0:02:54s\n",
            "epoch 70 | loss: 0.50592 | val_0_accuracy: 0.76986 |  0:02:57s\n",
            "epoch 71 | loss: 0.50123 | val_0_accuracy: 0.77224 |  0:02:59s\n",
            "epoch 72 | loss: 0.50354 | val_0_accuracy: 0.76921 |  0:03:02s\n",
            "epoch 73 | loss: 0.50088 | val_0_accuracy: 0.78109 |  0:03:04s\n",
            "epoch 74 | loss: 0.50025 | val_0_accuracy: 0.76943 |  0:03:07s\n",
            "epoch 75 | loss: 0.5029  | val_0_accuracy: 0.77699 |  0:03:09s\n",
            "epoch 76 | loss: 0.49375 | val_0_accuracy: 0.77915 |  0:03:12s\n",
            "epoch 77 | loss: 0.49287 | val_0_accuracy: 0.77137 |  0:03:14s\n",
            "epoch 78 | loss: 0.50106 | val_0_accuracy: 0.76986 |  0:03:17s\n",
            "epoch 79 | loss: 0.49004 | val_0_accuracy: 0.78217 |  0:03:19s\n",
            "epoch 80 | loss: 0.48686 | val_0_accuracy: 0.77677 |  0:03:22s\n",
            "epoch 81 | loss: 0.48685 | val_0_accuracy: 0.78346 |  0:03:25s\n",
            "epoch 82 | loss: 0.4877  | val_0_accuracy: 0.77763 |  0:03:28s\n",
            "epoch 83 | loss: 0.48681 | val_0_accuracy: 0.78303 |  0:03:30s\n",
            "epoch 84 | loss: 0.48493 | val_0_accuracy: 0.78001 |  0:03:33s\n",
            "epoch 85 | loss: 0.48377 | val_0_accuracy: 0.78886 |  0:03:35s\n",
            "epoch 86 | loss: 0.48397 | val_0_accuracy: 0.77915 |  0:03:38s\n",
            "epoch 87 | loss: 0.47605 | val_0_accuracy: 0.78001 |  0:03:40s\n",
            "epoch 88 | loss: 0.48689 | val_0_accuracy: 0.77375 |  0:03:43s\n",
            "epoch 89 | loss: 0.48476 | val_0_accuracy: 0.78217 |  0:03:45s\n",
            "epoch 90 | loss: 0.47828 | val_0_accuracy: 0.77915 |  0:03:48s\n",
            "epoch 91 | loss: 0.47453 | val_0_accuracy: 0.7867  |  0:03:50s\n",
            "epoch 92 | loss: 0.47605 | val_0_accuracy: 0.78238 |  0:03:53s\n",
            "epoch 93 | loss: 0.47264 | val_0_accuracy: 0.78951 |  0:03:55s\n",
            "epoch 94 | loss: 0.47568 | val_0_accuracy: 0.78497 |  0:03:58s\n",
            "epoch 95 | loss: 0.46671 | val_0_accuracy: 0.78972 |  0:04:00s\n",
            "epoch 96 | loss: 0.468   | val_0_accuracy: 0.79318 |  0:04:03s\n",
            "epoch 97 | loss: 0.46971 | val_0_accuracy: 0.78303 |  0:04:05s\n",
            "epoch 98 | loss: 0.47614 | val_0_accuracy: 0.78303 |  0:04:08s\n",
            "epoch 99 | loss: 0.46644 | val_0_accuracy: 0.78389 |  0:04:10s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 96 and best_val_0_accuracy = 0.79318\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 09:42:59,324]\u001b[0m Trial 10 finished with value: 0.7931778929188256 and parameters: {'n_d': 9, 'n_a': 28, 'n_steps': 3, 'gamma': 1.011648893626244, 'n_independent': 5, 'n_shared': 2, 'momentum': 0.2231948002922462}. Best is trial 4 with value: 0.7994386873920553.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.65      0.58      0.61       825\n",
            "           2       0.84      0.94      0.89       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.52      0.66      0.58       761\n",
            "           5       0.78      0.51      0.61       619\n",
            "\n",
            "    accuracy                           0.79      4632\n",
            "   macro avg       0.80      0.78      0.78      4632\n",
            "weighted avg       0.80      0.79      0.79      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 2.09037 | val_0_accuracy: 0.538   |  0:00:05s\n",
            "epoch 1  | loss: 1.24647 | val_0_accuracy: 0.5611  |  0:00:10s\n",
            "epoch 2  | loss: 1.09133 | val_0_accuracy: 0.5788  |  0:00:15s\n",
            "epoch 3  | loss: 1.02788 | val_0_accuracy: 0.54879 |  0:00:21s\n",
            "epoch 4  | loss: 0.91617 | val_0_accuracy: 0.61183 |  0:00:26s\n",
            "epoch 5  | loss: 0.93053 | val_0_accuracy: 0.59607 |  0:00:31s\n",
            "epoch 6  | loss: 0.86959 | val_0_accuracy: 0.62155 |  0:00:36s\n",
            "epoch 7  | loss: 0.81475 | val_0_accuracy: 0.63709 |  0:00:41s\n",
            "epoch 8  | loss: 0.7929  | val_0_accuracy: 0.63817 |  0:00:47s\n",
            "epoch 9  | loss: 0.77256 | val_0_accuracy: 0.6399  |  0:00:52s\n",
            "epoch 10 | loss: 0.7564  | val_0_accuracy: 0.65134 |  0:00:57s\n",
            "epoch 11 | loss: 0.75167 | val_0_accuracy: 0.65674 |  0:01:02s\n",
            "epoch 12 | loss: 0.74274 | val_0_accuracy: 0.66105 |  0:01:07s\n",
            "epoch 13 | loss: 0.72198 | val_0_accuracy: 0.67077 |  0:01:12s\n",
            "epoch 14 | loss: 0.71086 | val_0_accuracy: 0.67962 |  0:01:18s\n",
            "epoch 15 | loss: 0.70167 | val_0_accuracy: 0.68523 |  0:01:23s\n",
            "epoch 16 | loss: 0.69432 | val_0_accuracy: 0.69603 |  0:01:28s\n",
            "epoch 17 | loss: 0.68735 | val_0_accuracy: 0.69495 |  0:01:34s\n",
            "epoch 18 | loss: 0.68459 | val_0_accuracy: 0.69214 |  0:01:39s\n",
            "epoch 19 | loss: 0.67631 | val_0_accuracy: 0.70445 |  0:01:44s\n",
            "epoch 20 | loss: 0.66608 | val_0_accuracy: 0.70898 |  0:01:49s\n",
            "epoch 21 | loss: 0.66083 | val_0_accuracy: 0.70121 |  0:01:55s\n",
            "epoch 22 | loss: 0.65453 | val_0_accuracy: 0.71524 |  0:02:00s\n",
            "epoch 23 | loss: 0.64531 | val_0_accuracy: 0.71028 |  0:02:05s\n",
            "epoch 24 | loss: 0.64204 | val_0_accuracy: 0.70725 |  0:02:10s\n",
            "epoch 25 | loss: 0.64145 | val_0_accuracy: 0.71956 |  0:02:15s\n",
            "epoch 26 | loss: 0.63837 | val_0_accuracy: 0.71546 |  0:02:21s\n",
            "epoch 27 | loss: 0.63435 | val_0_accuracy: 0.71913 |  0:02:26s\n",
            "epoch 28 | loss: 0.63721 | val_0_accuracy: 0.71697 |  0:02:31s\n",
            "epoch 29 | loss: 0.63257 | val_0_accuracy: 0.7187  |  0:02:37s\n",
            "epoch 30 | loss: 0.61895 | val_0_accuracy: 0.72129 |  0:02:42s\n",
            "epoch 31 | loss: 0.61555 | val_0_accuracy: 0.73143 |  0:02:48s\n",
            "epoch 32 | loss: 0.61588 | val_0_accuracy: 0.7256  |  0:02:53s\n",
            "epoch 33 | loss: 0.60684 | val_0_accuracy: 0.73165 |  0:02:59s\n",
            "epoch 34 | loss: 0.6082  | val_0_accuracy: 0.73661 |  0:03:04s\n",
            "epoch 35 | loss: 0.61438 | val_0_accuracy: 0.73597 |  0:03:10s\n",
            "epoch 36 | loss: 0.60125 | val_0_accuracy: 0.72927 |  0:03:15s\n",
            "epoch 37 | loss: 0.63491 | val_0_accuracy: 0.71028 |  0:03:21s\n",
            "epoch 38 | loss: 0.62814 | val_0_accuracy: 0.72927 |  0:03:26s\n",
            "epoch 39 | loss: 0.61667 | val_0_accuracy: 0.71999 |  0:03:31s\n",
            "epoch 40 | loss: 0.60719 | val_0_accuracy: 0.73683 |  0:03:37s\n",
            "epoch 41 | loss: 0.5913  | val_0_accuracy: 0.7405  |  0:03:42s\n",
            "epoch 42 | loss: 0.58092 | val_0_accuracy: 0.74482 |  0:03:48s\n",
            "epoch 43 | loss: 0.57456 | val_0_accuracy: 0.74482 |  0:03:53s\n",
            "epoch 44 | loss: 0.57278 | val_0_accuracy: 0.74417 |  0:03:58s\n",
            "epoch 45 | loss: 0.58322 | val_0_accuracy: 0.73597 |  0:04:04s\n",
            "epoch 46 | loss: 0.57891 | val_0_accuracy: 0.73726 |  0:04:09s\n",
            "epoch 47 | loss: 0.60489 | val_0_accuracy: 0.74547 |  0:04:14s\n",
            "epoch 48 | loss: 0.58381 | val_0_accuracy: 0.74957 |  0:04:20s\n",
            "epoch 49 | loss: 0.60302 | val_0_accuracy: 0.72733 |  0:04:25s\n",
            "epoch 50 | loss: 0.60992 | val_0_accuracy: 0.73769 |  0:04:30s\n",
            "epoch 51 | loss: 0.59079 | val_0_accuracy: 0.74028 |  0:04:36s\n",
            "epoch 52 | loss: 0.57998 | val_0_accuracy: 0.73877 |  0:04:41s\n",
            "epoch 53 | loss: 0.56998 | val_0_accuracy: 0.7513  |  0:04:47s\n",
            "epoch 54 | loss: 0.57253 | val_0_accuracy: 0.75626 |  0:04:52s\n",
            "epoch 55 | loss: 0.57124 | val_0_accuracy: 0.75194 |  0:04:57s\n",
            "epoch 56 | loss: 0.57146 | val_0_accuracy: 0.76295 |  0:05:03s\n",
            "epoch 57 | loss: 0.55357 | val_0_accuracy: 0.75216 |  0:05:08s\n",
            "epoch 58 | loss: 0.55583 | val_0_accuracy: 0.75777 |  0:05:13s\n",
            "epoch 59 | loss: 0.54894 | val_0_accuracy: 0.7541  |  0:05:18s\n",
            "epoch 60 | loss: 0.54167 | val_0_accuracy: 0.75885 |  0:05:24s\n",
            "epoch 61 | loss: 0.53559 | val_0_accuracy: 0.76749 |  0:05:29s\n",
            "epoch 62 | loss: 0.5332  | val_0_accuracy: 0.75842 |  0:05:34s\n",
            "epoch 63 | loss: 0.5293  | val_0_accuracy: 0.75777 |  0:05:39s\n",
            "epoch 64 | loss: 0.53277 | val_0_accuracy: 0.77051 |  0:05:44s\n",
            "epoch 65 | loss: 0.5216  | val_0_accuracy: 0.77245 |  0:05:50s\n",
            "epoch 66 | loss: 0.52324 | val_0_accuracy: 0.75065 |  0:05:56s\n",
            "epoch 67 | loss: 0.58352 | val_0_accuracy: 0.75345 |  0:06:01s\n",
            "epoch 68 | loss: 0.55062 | val_0_accuracy: 0.75691 |  0:06:06s\n",
            "epoch 69 | loss: 0.53159 | val_0_accuracy: 0.769   |  0:06:11s\n",
            "epoch 70 | loss: 0.52111 | val_0_accuracy: 0.77375 |  0:06:17s\n",
            "epoch 71 | loss: 0.51738 | val_0_accuracy: 0.77591 |  0:06:22s\n",
            "epoch 72 | loss: 0.52462 | val_0_accuracy: 0.769   |  0:06:27s\n",
            "epoch 73 | loss: 0.51677 | val_0_accuracy: 0.77051 |  0:06:32s\n",
            "epoch 74 | loss: 0.51335 | val_0_accuracy: 0.77375 |  0:06:38s\n",
            "epoch 75 | loss: 0.50573 | val_0_accuracy: 0.77547 |  0:06:43s\n",
            "epoch 76 | loss: 0.49798 | val_0_accuracy: 0.78562 |  0:06:48s\n",
            "epoch 77 | loss: 0.49407 | val_0_accuracy: 0.77915 |  0:06:53s\n",
            "epoch 78 | loss: 0.48707 | val_0_accuracy: 0.78022 |  0:06:59s\n",
            "epoch 79 | loss: 0.48369 | val_0_accuracy: 0.78584 |  0:07:04s\n",
            "epoch 80 | loss: 0.4814  | val_0_accuracy: 0.78584 |  0:07:09s\n",
            "epoch 81 | loss: 0.47756 | val_0_accuracy: 0.78411 |  0:07:14s\n",
            "epoch 82 | loss: 0.47246 | val_0_accuracy: 0.78778 |  0:07:19s\n",
            "epoch 83 | loss: 0.46799 | val_0_accuracy: 0.78713 |  0:07:24s\n",
            "epoch 84 | loss: 0.46679 | val_0_accuracy: 0.78605 |  0:07:29s\n",
            "epoch 85 | loss: 0.46604 | val_0_accuracy: 0.78346 |  0:07:35s\n",
            "epoch 86 | loss: 0.46414 | val_0_accuracy: 0.79383 |  0:07:40s\n",
            "epoch 87 | loss: 0.4573  | val_0_accuracy: 0.79167 |  0:07:45s\n",
            "epoch 89 | loss: 0.44952 | val_0_accuracy: 0.78951 |  0:07:55s\n",
            "epoch 90 | loss: 0.44702 | val_0_accuracy: 0.79512 |  0:08:00s\n",
            "epoch 91 | loss: 0.4486  | val_0_accuracy: 0.79339 |  0:08:06s\n",
            "epoch 92 | loss: 0.44576 | val_0_accuracy: 0.79512 |  0:08:11s\n",
            "epoch 93 | loss: 0.44362 | val_0_accuracy: 0.80117 |  0:08:16s\n",
            "epoch 94 | loss: 0.44078 | val_0_accuracy: 0.79275 |  0:08:21s\n",
            "epoch 95 | loss: 0.43911 | val_0_accuracy: 0.79706 |  0:08:27s\n",
            "epoch 96 | loss: 0.43747 | val_0_accuracy: 0.80138 |  0:08:32s\n",
            "epoch 97 | loss: 0.43483 | val_0_accuracy: 0.80073 |  0:08:37s\n",
            "epoch 98 | loss: 0.42302 | val_0_accuracy: 0.79469 |  0:08:43s\n",
            "epoch 99 | loss: 0.42334 | val_0_accuracy: 0.80656 |  0:08:48s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_accuracy = 0.80656\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 09:51:50,252]\u001b[0m Trial 11 finished with value: 0.8065630397236615 and parameters: {'n_d': 60, 'n_a': 64, 'n_steps': 9, 'gamma': 1.2273719163448753, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.18590202624950367}. Best is trial 11 with value: 0.8065630397236615.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.67      0.63      0.65       825\n",
            "           2       0.84      0.95      0.89       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.56      0.60      0.58       761\n",
            "           5       0.75      0.60      0.67       619\n",
            "\n",
            "    accuracy                           0.81      4632\n",
            "   macro avg       0.80      0.80      0.80      4632\n",
            "weighted avg       0.81      0.81      0.80      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 2.15642 | val_0_accuracy: 0.47409 |  0:00:05s\n",
            "epoch 1  | loss: 1.26809 | val_0_accuracy: 0.48187 |  0:00:11s\n",
            "epoch 2  | loss: 1.29878 | val_0_accuracy: 0.35427 |  0:00:17s\n",
            "epoch 3  | loss: 1.17638 | val_0_accuracy: 0.57427 |  0:00:23s\n",
            "epoch 4  | loss: 1.0159  | val_0_accuracy: 0.56563 |  0:00:28s\n",
            "epoch 5  | loss: 0.88981 | val_0_accuracy: 0.55829 |  0:00:34s\n",
            "epoch 6  | loss: 0.87551 | val_0_accuracy: 0.61118 |  0:00:40s\n",
            "epoch 7  | loss: 0.83435 | val_0_accuracy: 0.61226 |  0:00:46s\n",
            "epoch 8  | loss: 0.82068 | val_0_accuracy: 0.63515 |  0:00:52s\n",
            "epoch 9  | loss: 0.77638 | val_0_accuracy: 0.65285 |  0:00:58s\n",
            "epoch 10 | loss: 0.73991 | val_0_accuracy: 0.67919 |  0:01:04s\n",
            "epoch 11 | loss: 0.72312 | val_0_accuracy: 0.67228 |  0:01:10s\n",
            "epoch 12 | loss: 0.72838 | val_0_accuracy: 0.66343 |  0:01:17s\n",
            "epoch 13 | loss: 0.71833 | val_0_accuracy: 0.67703 |  0:01:23s\n",
            "epoch 14 | loss: 0.72417 | val_0_accuracy: 0.65436 |  0:01:29s\n",
            "epoch 15 | loss: 0.73742 | val_0_accuracy: 0.66321 |  0:01:35s\n",
            "epoch 16 | loss: 0.72014 | val_0_accuracy: 0.6563  |  0:01:41s\n",
            "epoch 17 | loss: 0.7469  | val_0_accuracy: 0.66688 |  0:01:47s\n",
            "epoch 18 | loss: 0.71288 | val_0_accuracy: 0.67034 |  0:01:53s\n",
            "epoch 19 | loss: 0.70789 | val_0_accuracy: 0.6725  |  0:01:59s\n",
            "epoch 20 | loss: 0.70173 | val_0_accuracy: 0.68092 |  0:02:05s\n",
            "epoch 21 | loss: 0.70355 | val_0_accuracy: 0.67509 |  0:02:10s\n",
            "epoch 22 | loss: 0.70291 | val_0_accuracy: 0.68178 |  0:02:16s\n",
            "epoch 23 | loss: 0.68471 | val_0_accuracy: 0.67876 |  0:02:22s\n",
            "epoch 24 | loss: 0.70535 | val_0_accuracy: 0.67854 |  0:02:28s\n",
            "epoch 25 | loss: 0.67874 | val_0_accuracy: 0.69473 |  0:02:33s\n",
            "epoch 26 | loss: 0.67186 | val_0_accuracy: 0.6848  |  0:02:39s\n",
            "epoch 27 | loss: 0.66957 | val_0_accuracy: 0.70661 |  0:02:45s\n",
            "epoch 28 | loss: 0.65873 | val_0_accuracy: 0.70833 |  0:02:51s\n",
            "epoch 29 | loss: 0.65702 | val_0_accuracy: 0.70445 |  0:02:57s\n",
            "epoch 30 | loss: 0.64675 | val_0_accuracy: 0.69711 |  0:03:03s\n",
            "epoch 31 | loss: 0.6513  | val_0_accuracy: 0.70337 |  0:03:09s\n",
            "epoch 32 | loss: 0.64297 | val_0_accuracy: 0.72129 |  0:03:14s\n",
            "epoch 33 | loss: 0.63447 | val_0_accuracy: 0.71654 |  0:03:20s\n",
            "epoch 34 | loss: 0.63268 | val_0_accuracy: 0.71999 |  0:03:26s\n",
            "epoch 35 | loss: 0.64898 | val_0_accuracy: 0.68955 |  0:03:33s\n",
            "epoch 36 | loss: 0.66003 | val_0_accuracy: 0.69668 |  0:03:39s\n",
            "epoch 37 | loss: 0.64509 | val_0_accuracy: 0.70186 |  0:03:45s\n",
            "epoch 38 | loss: 0.68023 | val_0_accuracy: 0.69344 |  0:03:51s\n",
            "epoch 39 | loss: 0.6567  | val_0_accuracy: 0.69538 |  0:03:57s\n",
            "epoch 40 | loss: 0.67166 | val_0_accuracy: 0.70035 |  0:04:02s\n",
            "epoch 41 | loss: 0.68255 | val_0_accuracy: 0.68934 |  0:04:08s\n",
            "epoch 42 | loss: 0.69552 | val_0_accuracy: 0.69171 |  0:04:14s\n",
            "\n",
            "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_accuracy = 0.72129\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 09:56:07,748]\u001b[0m Trial 12 finished with value: 0.721286701208981 and parameters: {'n_d': 62, 'n_a': 62, 'n_steps': 10, 'gamma': 1.2201726883429704, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.22351888419588145}. Best is trial 11 with value: 0.8065630397236615.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       825\n",
            "           1       0.51      0.46      0.48       825\n",
            "           2       0.77      0.82      0.79       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.44      0.62      0.51       761\n",
            "           5       0.67      0.35      0.46       619\n",
            "\n",
            "    accuracy                           0.72      4632\n",
            "   macro avg       0.73      0.71      0.71      4632\n",
            "weighted avg       0.73      0.72      0.72      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 2.22294 | val_0_accuracy: 0.43351 |  0:00:06s\n",
            "epoch 1  | loss: 1.26075 | val_0_accuracy: 0.51317 |  0:00:13s\n",
            "epoch 2  | loss: 1.18698 | val_0_accuracy: 0.56671 |  0:00:20s\n",
            "epoch 3  | loss: 0.96858 | val_0_accuracy: 0.587   |  0:00:27s\n",
            "epoch 4  | loss: 0.87435 | val_0_accuracy: 0.62457 |  0:00:34s\n",
            "epoch 5  | loss: 0.8009  | val_0_accuracy: 0.64767 |  0:00:41s\n",
            "epoch 6  | loss: 0.78162 | val_0_accuracy: 0.6522  |  0:00:48s\n",
            "epoch 7  | loss: 0.75888 | val_0_accuracy: 0.66796 |  0:00:54s\n",
            "epoch 8  | loss: 0.73589 | val_0_accuracy: 0.65177 |  0:01:01s\n",
            "epoch 9  | loss: 0.7347  | val_0_accuracy: 0.64875 |  0:01:08s\n",
            "epoch 10 | loss: 0.73531 | val_0_accuracy: 0.67487 |  0:01:14s\n",
            "epoch 11 | loss: 0.71606 | val_0_accuracy: 0.68092 |  0:01:21s\n",
            "epoch 12 | loss: 0.70609 | val_0_accuracy: 0.6671  |  0:01:27s\n",
            "epoch 13 | loss: 0.69888 | val_0_accuracy: 0.68329 |  0:01:34s\n",
            "epoch 14 | loss: 0.68262 | val_0_accuracy: 0.67919 |  0:01:41s\n",
            "epoch 15 | loss: 0.69432 | val_0_accuracy: 0.67552 |  0:01:47s\n",
            "epoch 16 | loss: 0.68955 | val_0_accuracy: 0.69257 |  0:01:54s\n",
            "epoch 17 | loss: 0.70106 | val_0_accuracy: 0.67811 |  0:02:00s\n",
            "epoch 18 | loss: 0.68678 | val_0_accuracy: 0.68005 |  0:02:07s\n",
            "epoch 19 | loss: 0.6671  | val_0_accuracy: 0.70833 |  0:02:13s\n",
            "epoch 20 | loss: 0.65388 | val_0_accuracy: 0.68653 |  0:02:20s\n",
            "epoch 21 | loss: 0.6474  | val_0_accuracy: 0.68674 |  0:02:26s\n",
            "epoch 22 | loss: 0.64281 | val_0_accuracy: 0.71438 |  0:02:33s\n",
            "epoch 23 | loss: 0.63744 | val_0_accuracy: 0.71265 |  0:02:39s\n",
            "epoch 24 | loss: 0.63783 | val_0_accuracy: 0.70423 |  0:02:46s\n",
            "epoch 25 | loss: 0.63756 | val_0_accuracy: 0.71697 |  0:02:52s\n",
            "epoch 26 | loss: 0.63102 | val_0_accuracy: 0.72237 |  0:02:59s\n",
            "epoch 27 | loss: 0.62645 | val_0_accuracy: 0.73359 |  0:03:05s\n",
            "epoch 28 | loss: 0.62048 | val_0_accuracy: 0.68243 |  0:03:12s\n",
            "epoch 29 | loss: 0.61607 | val_0_accuracy: 0.70617 |  0:03:19s\n",
            "epoch 30 | loss: 0.61546 | val_0_accuracy: 0.73554 |  0:03:25s\n",
            "epoch 31 | loss: 0.62484 | val_0_accuracy: 0.69473 |  0:03:32s\n",
            "epoch 32 | loss: 0.63284 | val_0_accuracy: 0.72927 |  0:03:38s\n",
            "epoch 33 | loss: 0.63949 | val_0_accuracy: 0.70445 |  0:03:45s\n",
            "epoch 34 | loss: 0.6194  | val_0_accuracy: 0.72712 |  0:03:52s\n",
            "epoch 35 | loss: 0.60629 | val_0_accuracy: 0.72712 |  0:03:58s\n",
            "epoch 36 | loss: 0.60274 | val_0_accuracy: 0.72021 |  0:04:05s\n",
            "epoch 37 | loss: 0.5978  | val_0_accuracy: 0.72625 |  0:04:11s\n",
            "epoch 38 | loss: 0.59739 | val_0_accuracy: 0.72193 |  0:04:18s\n",
            "epoch 39 | loss: 0.59267 | val_0_accuracy: 0.73489 |  0:04:24s\n",
            "epoch 40 | loss: 0.58421 | val_0_accuracy: 0.7174  |  0:04:31s\n",
            "\n",
            "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_accuracy = 0.73554\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 10:00:42,389]\u001b[0m Trial 13 finished with value: 0.7355354058721935 and parameters: {'n_d': 62, 'n_a': 37, 'n_steps': 8, 'gamma': 1.6272872516453727, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.1693352847966804}. Best is trial 11 with value: 0.8065630397236615.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       825\n",
            "           1       0.52      0.50      0.51       825\n",
            "           2       0.82      0.78      0.80       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.46      0.62      0.53       761\n",
            "           5       0.67      0.45      0.54       619\n",
            "\n",
            "    accuracy                           0.74      4632\n",
            "   macro avg       0.74      0.72      0.73      4632\n",
            "weighted avg       0.75      0.74      0.74      4632\n",
            "\n",
            "Device used : cuda\n",
            "(41688,) (4632,)\n",
            "epoch 0  | loss: 3.62727 | val_0_accuracy: 0.29447 |  0:00:05s\n",
            "epoch 1  | loss: 1.59169 | val_0_accuracy: 0.36788 |  0:00:11s\n",
            "epoch 2  | loss: 1.47685 | val_0_accuracy: 0.32211 |  0:00:17s\n",
            "epoch 3  | loss: 1.32925 | val_0_accuracy: 0.46136 |  0:00:22s\n",
            "epoch 4  | loss: 1.29697 | val_0_accuracy: 0.54145 |  0:00:28s\n",
            "epoch 5  | loss: 1.13888 | val_0_accuracy: 0.58787 |  0:00:34s\n",
            "epoch 6  | loss: 0.88474 | val_0_accuracy: 0.60924 |  0:00:39s\n",
            "epoch 7  | loss: 0.83126 | val_0_accuracy: 0.63515 |  0:00:45s\n",
            "epoch 8  | loss: 0.80344 | val_0_accuracy: 0.65091 |  0:00:51s\n",
            "epoch 9  | loss: 0.79172 | val_0_accuracy: 0.65026 |  0:00:56s\n",
            "epoch 10 | loss: 0.78497 | val_0_accuracy: 0.64421 |  0:01:02s\n",
            "epoch 11 | loss: 0.788   | val_0_accuracy: 0.6576  |  0:01:08s\n",
            "epoch 12 | loss: 0.7761  | val_0_accuracy: 0.66019 |  0:01:13s\n",
            "epoch 13 | loss: 0.76584 | val_0_accuracy: 0.65285 |  0:01:19s\n",
            "epoch 14 | loss: 0.74508 | val_0_accuracy: 0.66343 |  0:01:26s\n",
            "epoch 15 | loss: 0.73315 | val_0_accuracy: 0.65091 |  0:01:31s\n",
            "epoch 16 | loss: 0.73104 | val_0_accuracy: 0.6671  |  0:01:37s\n",
            "epoch 17 | loss: 0.71289 | val_0_accuracy: 0.67422 |  0:01:43s\n",
            "epoch 18 | loss: 0.70609 | val_0_accuracy: 0.66321 |  0:01:49s\n",
            "epoch 19 | loss: 0.69925 | val_0_accuracy: 0.67984 |  0:01:54s\n",
            "epoch 20 | loss: 0.69176 | val_0_accuracy: 0.69063 |  0:02:00s\n",
            "epoch 21 | loss: 0.69243 | val_0_accuracy: 0.6658  |  0:02:05s\n",
            "epoch 22 | loss: 0.68164 | val_0_accuracy: 0.69106 |  0:02:11s\n",
            "epoch 23 | loss: 0.68726 | val_0_accuracy: 0.67142 |  0:02:17s\n",
            "epoch 24 | loss: 0.68693 | val_0_accuracy: 0.68739 |  0:02:22s\n",
            "epoch 25 | loss: 0.69104 | val_0_accuracy: 0.68977 |  0:02:28s\n",
            "epoch 26 | loss: 0.67851 | val_0_accuracy: 0.67206 |  0:02:33s\n",
            "epoch 27 | loss: 0.67074 | val_0_accuracy: 0.69819 |  0:02:39s\n",
            "epoch 28 | loss: 0.66394 | val_0_accuracy: 0.69905 |  0:02:45s\n",
            "epoch 29 | loss: 0.66099 | val_0_accuracy: 0.69041 |  0:02:50s\n",
            "epoch 30 | loss: 0.66066 | val_0_accuracy: 0.69257 |  0:02:56s\n",
            "epoch 31 | loss: 0.66307 | val_0_accuracy: 0.70402 |  0:03:02s\n",
            "epoch 32 | loss: 0.65289 | val_0_accuracy: 0.70294 |  0:03:07s\n",
            "epoch 33 | loss: 0.64581 | val_0_accuracy: 0.69927 |  0:03:13s\n",
            "epoch 34 | loss: 0.64497 | val_0_accuracy: 0.70531 |  0:03:18s\n",
            "epoch 35 | loss: 0.63982 | val_0_accuracy: 0.71546 |  0:03:24s\n",
            "epoch 36 | loss: 0.63798 | val_0_accuracy: 0.69948 |  0:03:30s\n",
            "epoch 37 | loss: 0.64246 | val_0_accuracy: 0.70142 |  0:03:35s\n",
            "epoch 38 | loss: 0.64533 | val_0_accuracy: 0.70941 |  0:03:41s\n",
            "epoch 39 | loss: 0.63579 | val_0_accuracy: 0.7092  |  0:03:46s\n",
            "epoch 40 | loss: 0.63538 | val_0_accuracy: 0.71848 |  0:03:52s\n",
            "epoch 41 | loss: 0.62413 | val_0_accuracy: 0.71114 |  0:03:58s\n",
            "epoch 42 | loss: 0.62158 | val_0_accuracy: 0.70833 |  0:04:03s\n",
            "epoch 43 | loss: 0.61777 | val_0_accuracy: 0.71567 |  0:04:09s\n",
            "epoch 44 | loss: 0.61266 | val_0_accuracy: 0.72927 |  0:04:14s\n",
            "epoch 45 | loss: 0.60595 | val_0_accuracy: 0.72539 |  0:04:20s\n",
            "epoch 46 | loss: 0.59893 | val_0_accuracy: 0.70855 |  0:04:26s\n",
            "epoch 47 | loss: 0.60362 | val_0_accuracy: 0.73057 |  0:04:31s\n",
            "epoch 48 | loss: 0.60322 | val_0_accuracy: 0.72301 |  0:04:37s\n",
            "epoch 49 | loss: 0.59599 | val_0_accuracy: 0.73705 |  0:04:42s\n",
            "epoch 50 | loss: 0.58461 | val_0_accuracy: 0.73187 |  0:04:48s\n",
            "epoch 51 | loss: 0.58382 | val_0_accuracy: 0.73294 |  0:04:54s\n",
            "epoch 52 | loss: 0.58592 | val_0_accuracy: 0.72949 |  0:04:59s\n",
            "epoch 53 | loss: 0.58275 | val_0_accuracy: 0.72884 |  0:05:05s\n",
            "epoch 54 | loss: 0.57696 | val_0_accuracy: 0.73683 |  0:05:10s\n",
            "epoch 55 | loss: 0.57827 | val_0_accuracy: 0.68437 |  0:05:16s\n",
            "epoch 56 | loss: 0.56942 | val_0_accuracy: 0.74072 |  0:05:22s\n",
            "epoch 57 | loss: 0.59335 | val_0_accuracy: 0.70747 |  0:05:27s\n",
            "epoch 58 | loss: 0.60452 | val_0_accuracy: 0.73856 |  0:05:33s\n",
            "epoch 59 | loss: 0.59223 | val_0_accuracy: 0.71071 |  0:05:39s\n",
            "epoch 60 | loss: 0.57643 | val_0_accuracy: 0.73381 |  0:05:44s\n",
            "epoch 61 | loss: 0.57653 | val_0_accuracy: 0.73402 |  0:05:50s\n",
            "epoch 62 | loss: 0.56993 | val_0_accuracy: 0.73597 |  0:05:56s\n",
            "epoch 63 | loss: 0.56429 | val_0_accuracy: 0.74439 |  0:06:01s\n",
            "epoch 64 | loss: 0.56086 | val_0_accuracy: 0.7282  |  0:06:07s\n",
            "epoch 65 | loss: 0.57042 | val_0_accuracy: 0.73035 |  0:06:12s\n",
            "epoch 66 | loss: 0.56926 | val_0_accuracy: 0.74568 |  0:06:18s\n",
            "epoch 67 | loss: 0.55092 | val_0_accuracy: 0.7541  |  0:06:24s\n",
            "epoch 68 | loss: 0.54828 | val_0_accuracy: 0.74978 |  0:06:29s\n",
            "epoch 69 | loss: 0.54247 | val_0_accuracy: 0.75302 |  0:06:35s\n",
            "epoch 70 | loss: 0.53708 | val_0_accuracy: 0.75712 |  0:06:40s\n",
            "epoch 71 | loss: 0.53858 | val_0_accuracy: 0.7541  |  0:06:46s\n",
            "epoch 72 | loss: 0.54655 | val_0_accuracy: 0.7405  |  0:06:52s\n",
            "epoch 73 | loss: 0.5458  | val_0_accuracy: 0.75777 |  0:06:57s\n",
            "epoch 74 | loss: 0.53722 | val_0_accuracy: 0.75216 |  0:07:03s\n",
            "epoch 75 | loss: 0.53347 | val_0_accuracy: 0.74439 |  0:07:09s\n",
            "epoch 76 | loss: 0.52751 | val_0_accuracy: 0.76317 |  0:07:14s\n",
            "epoch 77 | loss: 0.52296 | val_0_accuracy: 0.76295 |  0:07:20s\n",
            "epoch 78 | loss: 0.52635 | val_0_accuracy: 0.76619 |  0:07:26s\n",
            "epoch 79 | loss: 0.52375 | val_0_accuracy: 0.7649  |  0:07:31s\n",
            "epoch 80 | loss: 0.52124 | val_0_accuracy: 0.76662 |  0:07:37s\n",
            "epoch 81 | loss: 0.51647 | val_0_accuracy: 0.76598 |  0:07:43s\n",
            "epoch 82 | loss: 0.51524 | val_0_accuracy: 0.77029 |  0:07:48s\n",
            "epoch 83 | loss: 0.51321 | val_0_accuracy: 0.76101 |  0:07:55s\n",
            "epoch 84 | loss: 0.51273 | val_0_accuracy: 0.77375 |  0:08:00s\n",
            "epoch 85 | loss: 0.50877 | val_0_accuracy: 0.76295 |  0:08:06s\n",
            "epoch 86 | loss: 0.51007 | val_0_accuracy: 0.76943 |  0:08:12s\n",
            "epoch 87 | loss: 0.50616 | val_0_accuracy: 0.77202 |  0:08:17s\n",
            "epoch 88 | loss: 0.50292 | val_0_accuracy: 0.7718  |  0:08:23s\n",
            "epoch 89 | loss: 0.50306 | val_0_accuracy: 0.77569 |  0:08:28s\n",
            "epoch 90 | loss: 0.50285 | val_0_accuracy: 0.75626 |  0:08:34s\n",
            "epoch 91 | loss: 0.51766 | val_0_accuracy: 0.75885 |  0:08:40s\n",
            "epoch 92 | loss: 0.5388  | val_0_accuracy: 0.75972 |  0:08:45s\n",
            "epoch 93 | loss: 0.52749 | val_0_accuracy: 0.76101 |  0:08:51s\n",
            "epoch 94 | loss: 0.51583 | val_0_accuracy: 0.76813 |  0:08:56s\n",
            "epoch 95 | loss: 0.50366 | val_0_accuracy: 0.77677 |  0:09:02s\n",
            "epoch 96 | loss: 0.50935 | val_0_accuracy: 0.76835 |  0:09:08s\n",
            "epoch 97 | loss: 0.50776 | val_0_accuracy: 0.7636  |  0:09:13s\n",
            "epoch 98 | loss: 0.50231 | val_0_accuracy: 0.77612 |  0:09:19s\n",
            "epoch 99 | loss: 0.50644 | val_0_accuracy: 0.76965 |  0:09:24s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 95 and best_val_0_accuracy = 0.77677\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 10:10:10,061]\u001b[0m Trial 14 finished with value: 0.7767702936096719 and parameters: {'n_d': 35, 'n_a': 17, 'n_steps': 10, 'gamma': 1.5587692846959118, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.2997646055972025}. Best is trial 11 with value: 0.8065630397236615.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       825\n",
            "           1       0.61      0.58      0.59       825\n",
            "           2       0.83      0.91      0.87       823\n",
            "           3       1.00      1.00      1.00       779\n",
            "           4       0.50      0.53      0.51       761\n",
            "           5       0.68      0.60      0.64       619\n",
            "\n",
            "    accuracy                           0.78      4632\n",
            "   macro avg       0.77      0.77      0.77      4632\n",
            "weighted avg       0.78      0.78      0.78      4632\n",
            "\n",
            " Best params for fold : [2/10]\n",
            "{'n_d': 60, 'n_a': 64, 'n_steps': 9, 'gamma': 1.2273719163448753, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.18590202624950367}\n",
            "Saved best_params at : outputs/pytorch_tabnet/best_params/fold_2_best_params.txt\n",
            "Device used : cuda\n",
            "No early stopping will be performed, last training weights will be used.\n",
            "epoch 0  | loss: 2.09037 |  0:00:04s\n",
            "epoch 1  | loss: 1.18932 |  0:00:09s\n",
            "epoch 2  | loss: 1.12224 |  0:00:14s\n",
            "epoch 3  | loss: 1.03255 |  0:00:19s\n",
            "epoch 4  | loss: 0.9373  |  0:00:24s\n",
            "epoch 5  | loss: 0.91473 |  0:00:29s\n",
            "epoch 6  | loss: 0.88819 |  0:00:34s\n",
            "epoch 7  | loss: 0.84061 |  0:00:39s\n",
            "epoch 8  | loss: 0.8084  |  0:00:44s\n",
            "epoch 9  | loss: 0.79308 |  0:00:49s\n",
            "epoch 10 | loss: 0.78924 |  0:00:54s\n",
            "epoch 11 | loss: 0.77781 |  0:00:59s\n",
            "epoch 12 | loss: 0.76591 |  0:01:03s\n",
            "epoch 13 | loss: 0.75213 |  0:01:09s\n",
            "epoch 14 | loss: 0.74459 |  0:01:13s\n",
            "epoch 15 | loss: 0.7286  |  0:01:18s\n",
            "epoch 16 | loss: 0.73861 |  0:01:23s\n",
            "epoch 17 | loss: 0.75183 |  0:01:28s\n",
            "epoch 18 | loss: 0.73591 |  0:01:33s\n",
            "epoch 19 | loss: 0.72414 |  0:01:38s\n",
            "epoch 20 | loss: 0.72445 |  0:01:43s\n",
            "epoch 21 | loss: 0.73824 |  0:01:48s\n",
            "epoch 22 | loss: 0.7524  |  0:01:53s\n",
            "epoch 23 | loss: 0.73119 |  0:01:58s\n",
            "epoch 24 | loss: 0.71888 |  0:02:03s\n",
            "epoch 25 | loss: 0.72112 |  0:02:08s\n",
            "epoch 26 | loss: 0.71101 |  0:02:13s\n",
            "epoch 27 | loss: 0.70105 |  0:02:18s\n",
            "epoch 28 | loss: 0.69333 |  0:02:23s\n",
            "epoch 29 | loss: 0.68629 |  0:02:27s\n",
            "epoch 30 | loss: 0.68565 |  0:02:32s\n",
            "epoch 31 | loss: 0.72108 |  0:02:37s\n",
            "epoch 32 | loss: 0.69798 |  0:02:42s\n",
            "epoch 33 | loss: 0.67659 |  0:02:47s\n",
            "epoch 34 | loss: 0.68456 |  0:02:52s\n",
            "epoch 35 | loss: 0.68068 |  0:02:57s\n",
            "epoch 36 | loss: 0.66718 |  0:03:02s\n",
            "epoch 37 | loss: 0.65945 |  0:03:07s\n",
            "epoch 38 | loss: 0.64871 |  0:03:12s\n",
            "epoch 39 | loss: 0.64153 |  0:03:17s\n",
            "epoch 40 | loss: 0.63751 |  0:03:22s\n",
            "epoch 41 | loss: 0.66612 |  0:03:27s\n",
            "epoch 42 | loss: 0.71394 |  0:03:31s\n",
            "epoch 43 | loss: 0.71434 |  0:03:36s\n",
            "epoch 44 | loss: 0.69271 |  0:03:41s\n",
            "epoch 45 | loss: 0.67047 |  0:03:46s\n",
            "epoch 46 | loss: 0.66193 |  0:03:51s\n",
            "epoch 47 | loss: 0.65825 |  0:03:56s\n",
            "epoch 48 | loss: 0.66596 |  0:04:01s\n",
            "epoch 49 | loss: 0.64105 |  0:04:06s\n",
            "epoch 50 | loss: 0.63435 |  0:04:11s\n",
            "epoch 51 | loss: 0.62377 |  0:04:16s\n",
            "epoch 52 | loss: 0.62369 |  0:04:21s\n",
            "epoch 53 | loss: 0.61771 |  0:04:25s\n",
            "epoch 54 | loss: 0.6139  |  0:04:30s\n",
            "epoch 55 | loss: 0.60567 |  0:04:35s\n",
            "epoch 56 | loss: 0.60538 |  0:04:40s\n",
            "epoch 57 | loss: 0.59439 |  0:04:45s\n",
            "epoch 58 | loss: 0.60138 |  0:04:50s\n",
            "epoch 59 | loss: 0.60071 |  0:04:55s\n",
            "epoch 60 | loss: 0.59139 |  0:05:00s\n",
            "epoch 61 | loss: 0.58196 |  0:05:05s\n",
            "epoch 62 | loss: 0.57841 |  0:05:11s\n",
            "epoch 63 | loss: 0.59411 |  0:05:16s\n",
            "epoch 64 | loss: 0.57686 |  0:05:20s\n",
            "epoch 65 | loss: 0.57462 |  0:05:25s\n",
            "epoch 66 | loss: 0.56983 |  0:05:30s\n",
            "epoch 67 | loss: 0.56248 |  0:05:35s\n",
            "epoch 68 | loss: 0.57229 |  0:05:40s\n",
            "epoch 69 | loss: 0.57034 |  0:05:45s\n",
            "epoch 70 | loss: 0.57253 |  0:05:50s\n",
            "epoch 71 | loss: 0.56305 |  0:05:55s\n",
            "epoch 72 | loss: 0.56947 |  0:06:00s\n",
            "epoch 73 | loss: 0.5703  |  0:06:05s\n",
            "epoch 74 | loss: 0.55751 |  0:06:11s\n",
            "epoch 75 | loss: 0.55209 |  0:06:16s\n",
            "epoch 76 | loss: 0.55751 |  0:06:21s\n",
            "epoch 77 | loss: 0.57269 |  0:06:26s\n",
            "epoch 78 | loss: 0.63971 |  0:06:31s\n",
            "epoch 79 | loss: 0.66373 |  0:06:36s\n",
            "epoch 80 | loss: 0.65284 |  0:06:41s\n",
            "epoch 81 | loss: 0.61222 |  0:06:46s\n",
            "epoch 82 | loss: 0.59846 |  0:06:51s\n",
            "epoch 83 | loss: 0.60206 |  0:06:56s\n",
            "epoch 84 | loss: 0.61258 |  0:07:01s\n",
            "epoch 85 | loss: 0.60045 |  0:07:06s\n",
            "epoch 86 | loss: 0.58719 |  0:07:11s\n",
            "epoch 87 | loss: 0.57893 |  0:07:16s\n",
            "epoch 88 | loss: 0.56044 |  0:07:21s\n",
            "epoch 89 | loss: 0.55844 |  0:07:26s\n",
            "epoch 90 | loss: 0.54974 |  0:07:31s\n",
            "epoch 91 | loss: 0.55485 |  0:07:36s\n",
            "epoch 92 | loss: 0.55897 |  0:07:41s\n",
            "epoch 93 | loss: 0.54905 |  0:07:46s\n",
            "epoch 94 | loss: 0.56152 |  0:07:51s\n",
            "epoch 95 | loss: 0.5571  |  0:07:55s\n",
            "epoch 96 | loss: 0.54149 |  0:08:00s\n",
            "epoch 97 | loss: 0.53123 |  0:08:05s\n",
            "epoch 98 | loss: 0.52736 |  0:08:10s\n",
            "epoch 99 | loss: 0.52546 |  0:08:15s\n",
            "[++] Saving the model and parameters in corresponding directories\n",
            "[++] Ended the training process for fold 2\n"
          ]
        }
      ],
      "source": [
        "train(fold_dict = fold_dict,\n",
        "      fold = fold,\n",
        "      model_name=model_name,\n",
        "      sc_df=use_df,\n",
        "      tar_col=tar_col,\n",
        "      optim=optimizer,\n",
        "      optim_trial = 15)\n",
        "print(f\"[++] Ended the training process for fold {fold}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ja5dUXmqsCFF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afu4nJyHu-sp"
      },
      "source": [
        "Fold 0 has started running on 20-05-22 \n",
        "\n",
        "\n",
        "Fold 0 has completed sucessfully on 17:00 20-05-22\n",
        "\n",
        "Fold 1 has started running at 15:15 21-05-22\n",
        "\n",
        "Fold 2 has started running at 09:45 22-05-22\n",
        "\n",
        "Fold 2 has completed sucessfully on 10:58 22-05-22\n",
        "\n",
        "Fold 3 has started running at 18:40 22-05-22\n",
        "\n",
        "Fold 3 has completed sucessfully on 22-05-22\n",
        "\n",
        "Fold 4 completed sucessfully on 21:04 on 22-05-22\n",
        "\n",
        "Fold 5 started at 18:21 on 23-05-22\n",
        "\n",
        "Fold 5 completed sucessfully on 19:44 on 23-05-22\n",
        "\n",
        "Fold 6 started at 12:53 on 24-05-22\n",
        "\n",
        "Fold 6 has completed at 14:14 on 24-05-22\n",
        "\n",
        "Fold 7 started at 14:18 on 24-05-22\n",
        "\n",
        "Fold 7 execution failed due to colab gpu time limit\n",
        "\n",
        "Fold 7 trial 1 started at 11:00 on 25-05-22\n",
        "\n",
        "Fold 7 has completed sucessfully at 12:14 on 25-05-22 \n",
        "\n",
        "Fold 8 has started at 9:38 on 26-05-22\n",
        "\n",
        "Fold 8 filed due to interrupted internet connection\n",
        "\n",
        "Fold 8 trial 1 started at 13:38 on 26-05-22\n",
        "\n",
        "Fold 8 has successfully executed at 15:33 on 26-05-22\n",
        "\n",
        "Fold 9 has started at 13:35 on 27-05-22\n",
        "\n",
        "Fold 9 has completed at 14:55 on 27-05-22"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me85YLlzpUM8"
      },
      "source": [
        "Editing with rectified dataset witout duplicacy because of space values\n",
        "\n",
        "Fold 0 started at 13:21 on 28-05-22\n",
        "\n",
        "Fold 0 completed sucessfully at 14:46 on 28-05-22\n",
        "\n",
        "Fold 1 Failed to run due to some index error\n",
        "\n",
        "_____ Restarting the training process again due to data distribution failure____\n",
        "\n",
        "\n",
        "\n",
        "Fold 0 started at 10:47 on 30-05-22\n",
        "\n",
        "Fold 0 completed successfully at 12:30 on 30-05-22\n",
        "\n",
        "Fold 1 started at 8:27 on 31-05-22\n",
        "\n",
        "Fold 1 execution failed due to runtime disconnection\n",
        "\n",
        "Fold 1 started again at 9:38 on 31-05-22\n",
        "\n",
        "Fold 1 execution failed due to gpu disconnect \n",
        "\n",
        "Fold 1 started again at 8:36 on 1-06-22\n",
        "\n",
        "Fold 1 execution failed due to network disconnection\n",
        "\n",
        "Fold 1 started again at 13:11 on 01-06-22\n",
        "\n",
        "Fold 1 has succesfully executed at 14:25 on 01-06-22\n",
        "\n",
        "Fold 2 started at 14:29 on 01-06-22\n",
        "\n",
        "Fold 2 completed succesfully at 16:00 on 01-06-22"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zICGdYlFNr13"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "train_tabnet_fold_div.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}