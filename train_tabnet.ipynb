{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_tabnet.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1-cYChMNNBLAXvhIKi0yg_I2bzm0XEXub","authorship_tag":"ABX9TyMLtczK9x5ozdr18CoS7K8H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XyIGy7gf5ShL","executionInfo":{"status":"ok","timestamp":1652843243831,"user_tz":-330,"elapsed":371,"user":{"displayName":"DEBASISH MOHANTY","userId":"11426739006444404647"}},"outputId":"e9af1155-4cc2-4d46-a078-8cf3efda0c12"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed May 18 03:07:27 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","source":["!pip install pytorch-tabnet optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ubY8nGH0GbhI","executionInfo":{"status":"ok","timestamp":1652858292117,"user_tz":-330,"elapsed":14975,"user":{"displayName":"DEBASISH MOHANTY","userId":"11426739006444404647"}},"outputId":"bd2c90f2-6afa-4fcf-a46d-33b23203cca4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-tabnet\n","  Downloading pytorch_tabnet-3.1.1-py3-none-any.whl (39 kB)\n","Collecting optuna\n","  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n","\u001b[K     |████████████████████████████████| 308 kB 11.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.21.6)\n","Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (4.64.0)\n","Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.0.2)\n","Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.11.0+cu113)\n","Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.2.0)\n","Collecting colorlog\n","  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n","Collecting alembic\n","  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n","\u001b[K     |████████████████████████████████| 210 kB 31.0 MB/s \n","\u001b[?25hCollecting cliff\n","  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n","\u001b[K     |████████████████████████████████| 81 kB 7.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n","Collecting cmaes>=0.8.2\n","  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n","Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n","Collecting Mako\n","  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n","Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n","Collecting stevedore>=2.0.1\n","  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n","\u001b[K     |████████████████████████████████| 49 kB 5.2 MB/s \n","\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n","  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 33.2 MB/s \n","\u001b[?25hCollecting cmd2>=1.0.0\n","  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n","\u001b[K     |████████████████████████████████| 146 kB 31.7 MB/s \n","\u001b[?25hCollecting autopage>=0.4.0\n","  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n","Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n","Collecting pyperclip>=1.6\n","  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n","Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n","Building wheels for collected packages: pyperclip\n","  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=0f9e9f597d433903969fc8031b28e6c62a4222416e11fbae38f8790ebe71a2b5\n","  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n","Successfully built pyperclip\n","Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, pytorch-tabnet, optuna\n","Successfully installed Mako-1.2.0 alembic-1.7.7 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.0 pbr-5.9.0 pyperclip-1.8.2 pytorch-tabnet-3.1.1 stevedore-3.5.0\n"]}]},{"cell_type":"markdown","source":["Working fine"],"metadata":{"id":"q02yGGTnsVqq"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from pytorch_tabnet.tab_model import TabNetClassifier\n","from sklearn.metrics import accuracy_score,classification_report\n","import optuna as opt\n","import torch\n","import os\n","import joblib"],"metadata":{"id":"ZTFVGB0e5fpU","executionInfo":{"status":"ok","timestamp":1652858300032,"user_tz":-330,"elapsed":4314,"user":{"displayName":"DEBASISH MOHANTY","userId":"11426739006444404647"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def make_save_cv_model(i,model_name,model,best_params,optim,output_path=\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/cross_validated_models\"):\n","\n","    ''' This function saves cross validation model in the corresponding directory ( if the path does not exist it creates the path for it'''\n","\n","\n","    if os.path.exists(os.path.join(output_path,f\"{i}_{model_name}_{optim}\")):\n","        joblib.dump(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n","        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/model_params.txt\"),\"w+\") as file:\n","            file.write(str(best_params))\n","    else:\n","        os.mkdir(os.path.join(output_path,f\"{i}_{model_name}_{optim}\"))\n","        joblib.dump(model, os.path.join(output_path,f\"{i}_{model_name}_{optim}/{i}_model.z\"))\n","        with open(os.path.join(output_path,f\"{i}_{model_name}_{optim}/model_params.txt\"),\"w+\") as file:\n","            file.write(str(best_params))\n"],"metadata":{"id":"pVvvYDliHSqY","executionInfo":{"status":"ok","timestamp":1652858301754,"user_tz":-330,"elapsed":6,"user":{"displayName":"DEBASISH MOHANTY","userId":"11426739006444404647"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def train(model_name,sc_df,tar_col,optim,optim_trial,k_folds=10,tar_cols=\"\",verbose=1):\n","\n","    ''' this function is used to train the model with parameters optimization using optuna and cross validation using stratified k_folds'''\n","\n","    y = sc_df[tar_col]\n","    x = sc_df.drop([tar_col],axis=1)\n","    # k_fold constructing the cross-validation framework\n","    skf = StratifiedKFold(n_splits=k_folds,shuffle=True, random_state=123 )\n","    model_name = model_name \n","    acc_scores = []\n","    for i, (train_index, test_index) in enumerate(skf.split(x,y)):   \n","        def objective(trial):\n","            clf = TabNetClassifier(n_d=trial.suggest_int(\"n_d\", 8, 64),\n","                                    n_a =trial.suggest_int(\"n_a\", 8, 64),\n","                                    n_steps = trial.suggest_int(\"n_steps\",3,10),\n","                                    gamma =trial.suggest_float(\"gamma\", 1.0, 2.0),\n","                                    n_independent = trial.suggest_int(\"n_independent\",1,5),\n","                                    n_shared = trial.suggest_int(\"n_shared\",1,5),\n","                                    momentum = trial.suggest_float(\"momentum\", 0.01, 0.4),\n","                                    optimizer_fn = torch.optim.Adam,\n","                                    # scheduler_fn = torch.optim.lr_scheduler,\n","                                    # scheduler_params = {\"gamma\" :trial.suggest_float(\"sch-gamma\", 0.5, 0.95), \"step_size\": trial.suggest_int(\"sch_step_size\", 10, 20, 2)},\n","                                    verbose = verbose,\n","                                    device_name = \"auto\"\n","                                    )\n","            # print(f\" train_index :: {train_index}\")\n","            # print(f\" test_index :: {test_index}\")\n","            X_train,X_test = x.iloc[train_index,:], x.iloc[test_index,:]\n","            # print(X_train.shape, X_test.shape)\n","            X_train, X_test = X_train.to_numpy(dtype=np.float64), X_test.to_numpy(dtype=np.float64)\n","            Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n","            Y_train, Y_test = Y_train.to_numpy(dtype=np.float64), Y_test.to_numpy(dtype=np.float64)\n","            print(Y_train.shape, Y_test.shape)\n","            clf.fit(X_train, Y_train,\n","                    eval_set=[(X_test, Y_test)],\n","                    eval_metric=['accuracy'])\n","            Y_pred = clf.predict(X_test)\n","            print(classification_report(Y_test, Y_pred, labels=[x for x in range(6)]))\n","            clf_report = classification_report(Y_test, Y_pred, labels=[x for x in range(6)])\n","            joblib.dump(clf_report,f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/classification_report/comp/{i}_{model_name}_classification_report.z\")\n","            with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/classification_report/{model_name}_{i}_classification_report.txt\",\"w+\") as file:file.write(str(clf_report))\n","            print(f\"Saved classification_report at : ./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/classification_report/{model_name}_{i}_classification_report.txt\")\n","            acc = accuracy_score(Y_pred, Y_test)\n","            return acc\n","\n","        print(f\"Starting optimization for fold : [{i}/{k_folds}]\")\n","        study = opt.create_study(direction='maximize')\n","        study.optimize(objective, n_trials=optim_trial)\n","        best_params = study.best_params\n","        print(f\" Best params for fold : [{i}/{k_folds}]\")\n","        print(best_params)\n","        joblib.dump(best_params,f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/best_params/comp/fold_{i}_best_params.z\")\n","        with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/best_params/fold_{i}_best_params.txt\", \"w+\") as file:file.write(str(best_params))\n","        print(f\"Saved best_params at : outputs/{model_name}/best_params/fold_{i}_best_params.txt\")\n","        X_train,X_test = x.iloc[train_index,:], x.iloc[test_index,:]\n","        # print(X_train.shape, X_test.shape)\n","        X_train, X_test = X_train.to_numpy(dtype=np.float64), X_test.to_numpy(dtype=np.float64)\n","        Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n","        Y_train, Y_test = Y_train.to_numpy(dtype=np.float64), Y_test.to_numpy(dtype=np.float64)\n","        clf_model = TabNetClassifier(**study.best_params)\n","        clf_model.fit(X_train,Y_train)\n","        Y_pred = clf_model.predict(X_test)\n","        accuracy = accuracy_score(Y_pred, Y_test)\n","        acc_scores.append(accuracy)\n","        with open(f\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/{model_name}/{model_name}_{i}_accuracy_score.txt\",\"w+\") as file:file.write(f\" accuracy :: {str(accuracy)}\")\n","        try:\n","            print(\"[++] Saving the model and parameters in corresponding directories\")\n","            make_save_cv_model(i,model_name,clf_model,best_params,optim=optim)\n","        except:\n","            print(\"[-] Failed to save the model\")\n","    print(f\" Average accuracy achieved : {np.mean(acc_scores)}\")"],"metadata":{"id":"_sJOVvibHkuI","executionInfo":{"status":"ok","timestamp":1652858595227,"user_tz":-330,"elapsed":4,"user":{"displayName":"DEBASISH MOHANTY","userId":"11426739006444404647"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"GYTzFAkNIKTu","executionInfo":{"status":"ok","timestamp":1652858595965,"user_tz":-330,"elapsed":8,"user":{"displayName":"DEBASISH MOHANTY","userId":"11426739006444404647"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["use_df = pd.read_csv(\"./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/outputs/data/trainable_scaled_balanced.csv\")\n","tar_col = \"PCE_categorical\"\n","model_name = \"pytorch_tabnet\"\n","optimizer = \"Adam\"\n","folds = 15"],"metadata":{"id":"EnE8-ibrGjmv","executionInfo":{"status":"ok","timestamp":1652858598632,"user_tz":-330,"elapsed":2674,"user":{"displayName":"DEBASISH MOHANTY","userId":"11426739006444404647"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["train(model_name=model_name,\n","        sc_df=use_df,\n","        tar_col=tar_col,\n","        optim=optimizer,\n","        optim_trial = 15,\n","        k_folds=folds)\n","print(\"[++] Ended the training process ...\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T9R8AQDcHLeP","outputId":"d1a47e83-40c6-4fc3-bb31-09fba4dbd52a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2022-05-18 07:23:22,028]\u001b[0m A new study created in memory with name: no-name-eacfbd82-fd68-4641-bac7-fb6ad02a02bf\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Starting optimization for fold : [0/15]\n","Device used : cuda\n","(43698,) (3122,)\n","epoch 0  | loss: 2.44829 | val_0_accuracy: 0.32928 |  0:00:14s\n","epoch 1  | loss: 1.2638  | val_0_accuracy: 0.5016  |  0:00:24s\n","epoch 2  | loss: 1.21572 | val_0_accuracy: 0.59449 |  0:00:35s\n","epoch 3  | loss: 1.02084 | val_0_accuracy: 0.57912 |  0:00:45s\n","epoch 4  | loss: 1.01739 | val_0_accuracy: 0.60378 |  0:00:56s\n","epoch 5  | loss: 0.85561 | val_0_accuracy: 0.63389 |  0:01:07s\n","epoch 6  | loss: 0.82555 | val_0_accuracy: 0.63677 |  0:01:18s\n","epoch 7  | loss: 0.79706 | val_0_accuracy: 0.63004 |  0:01:28s\n","epoch 8  | loss: 0.78679 | val_0_accuracy: 0.63901 |  0:01:39s\n","epoch 9  | loss: 0.76119 | val_0_accuracy: 0.65022 |  0:01:49s\n","epoch 10 | loss: 0.74097 | val_0_accuracy: 0.6467  |  0:01:59s\n","epoch 11 | loss: 0.73173 | val_0_accuracy: 0.65279 |  0:02:09s\n","epoch 12 | loss: 0.72052 | val_0_accuracy: 0.65663 |  0:02:19s\n","epoch 13 | loss: 0.70893 | val_0_accuracy: 0.65567 |  0:02:29s\n","epoch 14 | loss: 0.72118 | val_0_accuracy: 0.65535 |  0:02:40s\n","epoch 15 | loss: 0.70015 | val_0_accuracy: 0.66432 |  0:02:50s\n","epoch 16 | loss: 0.69407 | val_0_accuracy: 0.66912 |  0:03:01s\n","epoch 17 | loss: 0.70254 | val_0_accuracy: 0.66304 |  0:03:11s\n","epoch 18 | loss: 0.69637 | val_0_accuracy: 0.6656  |  0:03:21s\n","epoch 19 | loss: 0.68989 | val_0_accuracy: 0.68033 |  0:03:31s\n","epoch 20 | loss: 0.68121 | val_0_accuracy: 0.68001 |  0:03:42s\n","epoch 21 | loss: 0.69028 | val_0_accuracy: 0.67361 |  0:03:51s\n","epoch 22 | loss: 0.68029 | val_0_accuracy: 0.67489 |  0:04:01s\n","epoch 23 | loss: 0.66542 | val_0_accuracy: 0.69571 |  0:04:11s\n","epoch 24 | loss: 0.6586  | val_0_accuracy: 0.68065 |  0:04:22s\n","epoch 25 | loss: 0.67053 | val_0_accuracy: 0.69058 |  0:04:32s\n","epoch 26 | loss: 0.65188 | val_0_accuracy: 0.67809 |  0:04:42s\n","epoch 27 | loss: 0.65385 | val_0_accuracy: 0.68706 |  0:04:52s\n","epoch 28 | loss: 0.64528 | val_0_accuracy: 0.68418 |  0:05:02s\n","epoch 29 | loss: 0.63468 | val_0_accuracy: 0.70788 |  0:05:12s\n","epoch 30 | loss: 0.63161 | val_0_accuracy: 0.70692 |  0:05:22s\n","epoch 31 | loss: 0.62705 | val_0_accuracy: 0.71204 |  0:05:32s\n","epoch 32 | loss: 0.63247 | val_0_accuracy: 0.71172 |  0:05:43s\n","epoch 33 | loss: 0.63018 | val_0_accuracy: 0.71204 |  0:05:53s\n","epoch 34 | loss: 0.62971 | val_0_accuracy: 0.71653 |  0:06:03s\n","epoch 35 | loss: 0.62226 | val_0_accuracy: 0.72646 |  0:06:13s\n","epoch 36 | loss: 0.62027 | val_0_accuracy: 0.71557 |  0:06:24s\n","epoch 37 | loss: 0.62887 | val_0_accuracy: 0.71653 |  0:06:34s\n","epoch 38 | loss: 0.62112 | val_0_accuracy: 0.72582 |  0:06:44s\n","epoch 39 | loss: 0.62495 | val_0_accuracy: 0.69475 |  0:06:54s\n","epoch 40 | loss: 0.63637 | val_0_accuracy: 0.71172 |  0:07:04s\n","epoch 41 | loss: 0.63452 | val_0_accuracy: 0.71589 |  0:07:14s\n","epoch 42 | loss: 0.62309 | val_0_accuracy: 0.71781 |  0:07:24s\n","epoch 43 | loss: 0.61481 | val_0_accuracy: 0.71268 |  0:07:35s\n","epoch 44 | loss: 0.61037 | val_0_accuracy: 0.71525 |  0:07:45s\n","epoch 45 | loss: 0.62044 | val_0_accuracy: 0.71909 |  0:07:55s\n","\n","Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_accuracy = 0.72646\n","Best weights from best epoch are automatically used!\n","              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99       550\n","           1       0.52      0.44      0.48       551\n","           2       0.75      0.83      0.79       550\n","           3       1.00      1.00      1.00       551\n","           4       0.45      0.58      0.51       507\n","           5       0.61      0.41      0.49       413\n","\n","    accuracy                           0.73      3122\n","   macro avg       0.72      0.71      0.71      3122\n","weighted avg       0.73      0.73      0.72      3122\n","\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2022-05-18 07:31:23,067]\u001b[0m Trial 0 finished with value: 0.726457399103139 and parameters: {'n_d': 16, 'n_a': 13, 'n_steps': 10, 'gamma': 1.2173053387504842, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.30052748594944584}. Best is trial 0 with value: 0.726457399103139.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Saved classification_report at : ./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/classification_report/pytorch_tabnet_0_classification_report.txt\n","Device used : cuda\n","(43698,) (3122,)\n","epoch 0  | loss: 1.31923 | val_0_accuracy: 0.6009  |  0:00:07s\n","epoch 1  | loss: 0.90013 | val_0_accuracy: 0.6246  |  0:00:14s\n","epoch 2  | loss: 0.83923 | val_0_accuracy: 0.62684 |  0:00:21s\n","epoch 3  | loss: 0.80873 | val_0_accuracy: 0.64894 |  0:00:29s\n","epoch 4  | loss: 0.78524 | val_0_accuracy: 0.65631 |  0:00:36s\n","epoch 5  | loss: 0.77551 | val_0_accuracy: 0.65119 |  0:00:44s\n","epoch 6  | loss: 0.7766  | val_0_accuracy: 0.65311 |  0:00:52s\n","epoch 7  | loss: 0.74136 | val_0_accuracy: 0.67104 |  0:00:59s\n","epoch 8  | loss: 0.72497 | val_0_accuracy: 0.67905 |  0:01:07s\n","epoch 9  | loss: 0.70843 | val_0_accuracy: 0.67008 |  0:01:14s\n","epoch 10 | loss: 0.69759 | val_0_accuracy: 0.68962 |  0:01:22s\n","epoch 11 | loss: 0.69542 | val_0_accuracy: 0.70147 |  0:01:29s\n","epoch 12 | loss: 0.68468 | val_0_accuracy: 0.68994 |  0:01:37s\n","epoch 13 | loss: 0.68237 | val_0_accuracy: 0.68994 |  0:01:44s\n","epoch 14 | loss: 0.68265 | val_0_accuracy: 0.68962 |  0:01:52s\n","epoch 15 | loss: 0.67999 | val_0_accuracy: 0.69603 |  0:02:00s\n","epoch 16 | loss: 0.67205 | val_0_accuracy: 0.69667 |  0:02:07s\n","epoch 17 | loss: 0.66104 | val_0_accuracy: 0.69699 |  0:02:15s\n","epoch 18 | loss: 0.65673 | val_0_accuracy: 0.69891 |  0:02:22s\n","epoch 19 | loss: 0.6553  | val_0_accuracy: 0.70083 |  0:02:29s\n","epoch 20 | loss: 0.65627 | val_0_accuracy: 0.71076 |  0:02:37s\n","epoch 21 | loss: 0.64559 | val_0_accuracy: 0.70596 |  0:02:44s\n","epoch 22 | loss: 0.64358 | val_0_accuracy: 0.70884 |  0:02:52s\n","epoch 23 | loss: 0.64511 | val_0_accuracy: 0.69571 |  0:02:59s\n","epoch 24 | loss: 0.64034 | val_0_accuracy: 0.71204 |  0:03:07s\n","epoch 25 | loss: 0.6364  | val_0_accuracy: 0.70852 |  0:03:14s\n","epoch 26 | loss: 0.6287  | val_0_accuracy: 0.72486 |  0:03:22s\n","epoch 27 | loss: 0.62447 | val_0_accuracy: 0.71108 |  0:03:29s\n","epoch 28 | loss: 0.61908 | val_0_accuracy: 0.71781 |  0:03:37s\n","epoch 29 | loss: 0.61837 | val_0_accuracy: 0.72293 |  0:03:44s\n","epoch 30 | loss: 0.61752 | val_0_accuracy: 0.72486 |  0:03:51s\n","epoch 31 | loss: 0.61045 | val_0_accuracy: 0.73479 |  0:03:59s\n","epoch 32 | loss: 0.60482 | val_0_accuracy: 0.72646 |  0:04:06s\n","epoch 33 | loss: 0.60776 | val_0_accuracy: 0.7255  |  0:04:14s\n","epoch 34 | loss: 0.60256 | val_0_accuracy: 0.74247 |  0:04:21s\n","epoch 35 | loss: 0.593   | val_0_accuracy: 0.73382 |  0:04:29s\n","epoch 36 | loss: 0.59022 | val_0_accuracy: 0.72838 |  0:04:36s\n","epoch 37 | loss: 0.60021 | val_0_accuracy: 0.73479 |  0:04:44s\n","epoch 38 | loss: 0.6028  | val_0_accuracy: 0.73575 |  0:04:51s\n","epoch 39 | loss: 0.61171 | val_0_accuracy: 0.72069 |  0:04:58s\n","epoch 40 | loss: 0.61358 | val_0_accuracy: 0.7303  |  0:05:05s\n","epoch 41 | loss: 0.59838 | val_0_accuracy: 0.73447 |  0:05:13s\n","epoch 42 | loss: 0.58992 | val_0_accuracy: 0.74183 |  0:05:20s\n","epoch 43 | loss: 0.58561 | val_0_accuracy: 0.74471 |  0:05:27s\n","epoch 44 | loss: 0.5814  | val_0_accuracy: 0.73991 |  0:05:35s\n","epoch 45 | loss: 0.5763  | val_0_accuracy: 0.74888 |  0:05:42s\n","epoch 46 | loss: 0.57218 | val_0_accuracy: 0.74471 |  0:05:49s\n","epoch 47 | loss: 0.56733 | val_0_accuracy: 0.74504 |  0:05:56s\n","epoch 48 | loss: 0.56639 | val_0_accuracy: 0.75176 |  0:06:04s\n","epoch 49 | loss: 0.56144 | val_0_accuracy: 0.7524  |  0:06:11s\n","epoch 50 | loss: 0.55652 | val_0_accuracy: 0.75368 |  0:06:18s\n","epoch 51 | loss: 0.55648 | val_0_accuracy: 0.73959 |  0:06:25s\n","epoch 52 | loss: 0.5551  | val_0_accuracy: 0.75208 |  0:06:32s\n","epoch 53 | loss: 0.55253 | val_0_accuracy: 0.75336 |  0:06:39s\n","epoch 54 | loss: 0.55707 | val_0_accuracy: 0.75529 |  0:06:47s\n","epoch 55 | loss: 0.55079 | val_0_accuracy: 0.75529 |  0:06:54s\n","epoch 56 | loss: 0.54178 | val_0_accuracy: 0.75913 |  0:07:01s\n","epoch 57 | loss: 0.5393  | val_0_accuracy: 0.75657 |  0:07:09s\n","epoch 58 | loss: 0.53658 | val_0_accuracy: 0.75945 |  0:07:16s\n","epoch 59 | loss: 0.54495 | val_0_accuracy: 0.74824 |  0:07:23s\n","epoch 60 | loss: 0.55045 | val_0_accuracy: 0.75945 |  0:07:30s\n","epoch 61 | loss: 0.53169 | val_0_accuracy: 0.75368 |  0:07:38s\n","epoch 62 | loss: 0.53856 | val_0_accuracy: 0.74536 |  0:07:45s\n","epoch 63 | loss: 0.54792 | val_0_accuracy: 0.75689 |  0:07:52s\n","epoch 64 | loss: 0.53669 | val_0_accuracy: 0.77002 |  0:07:59s\n","epoch 65 | loss: 0.53643 | val_0_accuracy: 0.75817 |  0:08:06s\n","epoch 66 | loss: 0.53094 | val_0_accuracy: 0.75849 |  0:08:13s\n","epoch 67 | loss: 0.54433 | val_0_accuracy: 0.77226 |  0:08:21s\n","epoch 68 | loss: 0.52824 | val_0_accuracy: 0.76361 |  0:08:28s\n","epoch 69 | loss: 0.51701 | val_0_accuracy: 0.76169 |  0:08:35s\n","epoch 70 | loss: 0.51988 | val_0_accuracy: 0.76586 |  0:08:43s\n","epoch 71 | loss: 0.51053 | val_0_accuracy: 0.7745  |  0:08:50s\n","epoch 72 | loss: 0.50677 | val_0_accuracy: 0.77707 |  0:08:57s\n","epoch 73 | loss: 0.50786 | val_0_accuracy: 0.77867 |  0:09:05s\n","epoch 74 | loss: 0.51015 | val_0_accuracy: 0.75785 |  0:09:12s\n","epoch 75 | loss: 0.54825 | val_0_accuracy: 0.75272 |  0:09:19s\n","epoch 76 | loss: 0.52633 | val_0_accuracy: 0.77643 |  0:09:26s\n","epoch 77 | loss: 0.51848 | val_0_accuracy: 0.7729  |  0:09:33s\n","epoch 78 | loss: 0.51524 | val_0_accuracy: 0.77354 |  0:09:40s\n","epoch 79 | loss: 0.52487 | val_0_accuracy: 0.77258 |  0:09:48s\n","epoch 80 | loss: 0.50564 | val_0_accuracy: 0.77995 |  0:09:55s\n","epoch 81 | loss: 0.50048 | val_0_accuracy: 0.77835 |  0:10:02s\n","epoch 82 | loss: 0.49743 | val_0_accuracy: 0.77098 |  0:10:09s\n","epoch 83 | loss: 0.49953 | val_0_accuracy: 0.77611 |  0:10:16s\n","epoch 84 | loss: 0.48981 | val_0_accuracy: 0.77643 |  0:10:23s\n","epoch 85 | loss: 0.49245 | val_0_accuracy: 0.78219 |  0:10:30s\n","epoch 86 | loss: 0.48187 | val_0_accuracy: 0.78635 |  0:10:38s\n","epoch 87 | loss: 0.48189 | val_0_accuracy: 0.77899 |  0:10:45s\n","epoch 88 | loss: 0.48559 | val_0_accuracy: 0.78924 |  0:10:52s\n","epoch 89 | loss: 0.51299 | val_0_accuracy: 0.75689 |  0:10:59s\n","epoch 90 | loss: 0.58238 | val_0_accuracy: 0.74471 |  0:11:06s\n","epoch 91 | loss: 0.55837 | val_0_accuracy: 0.76361 |  0:11:13s\n","epoch 92 | loss: 0.53984 | val_0_accuracy: 0.77482 |  0:11:20s\n","epoch 93 | loss: 0.51316 | val_0_accuracy: 0.77931 |  0:11:27s\n","epoch 94 | loss: 0.51264 | val_0_accuracy: 0.75785 |  0:11:34s\n","epoch 95 | loss: 0.51881 | val_0_accuracy: 0.77098 |  0:11:41s\n","epoch 96 | loss: 0.49817 | val_0_accuracy: 0.77578 |  0:11:48s\n","epoch 97 | loss: 0.48996 | val_0_accuracy: 0.79212 |  0:11:55s\n","epoch 98 | loss: 0.48646 | val_0_accuracy: 0.78379 |  0:12:02s\n","epoch 99 | loss: 0.4805  | val_0_accuracy: 0.7902  |  0:12:10s\n","Stop training because you reached max_epochs = 100 with best_epoch = 97 and best_val_0_accuracy = 0.79212\n","Best weights from best epoch are automatically used!\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2022-05-18 07:43:36,646]\u001b[0m Trial 1 finished with value: 0.7921204356181935 and parameters: {'n_d': 51, 'n_a': 62, 'n_steps': 8, 'gamma': 1.0122858838282471, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.20007322455322335}. Best is trial 1 with value: 0.7921204356181935.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       550\n","           1       0.61      0.60      0.61       551\n","           2       0.79      0.93      0.86       550\n","           3       1.00      1.00      1.00       551\n","           4       0.58      0.54      0.56       507\n","           5       0.71      0.62      0.66       413\n","\n","    accuracy                           0.79      3122\n","   macro avg       0.78      0.78      0.78      3122\n","weighted avg       0.79      0.79      0.79      3122\n","\n","Saved classification_report at : ./drive/MyDrive/SOLAR_CELL/ML_PROCESSED_DATA/classification_report/pytorch_tabnet_0_classification_report.txt\n","Device used : cuda\n","(43698,) (3122,)\n","epoch 0  | loss: 1.51579 | val_0_accuracy: 0.59097 |  0:00:05s\n","epoch 1  | loss: 0.90102 | val_0_accuracy: 0.59193 |  0:00:10s\n","epoch 2  | loss: 0.86262 | val_0_accuracy: 0.62076 |  0:00:16s\n","epoch 3  | loss: 0.84078 | val_0_accuracy: 0.63197 |  0:00:21s\n","epoch 4  | loss: 0.80039 | val_0_accuracy: 0.64414 |  0:00:27s\n","epoch 5  | loss: 0.77014 | val_0_accuracy: 0.65054 |  0:00:33s\n","epoch 6  | loss: 0.74225 | val_0_accuracy: 0.66143 |  0:00:38s\n","epoch 7  | loss: 0.72311 | val_0_accuracy: 0.67201 |  0:00:44s\n","epoch 8  | loss: 0.70645 | val_0_accuracy: 0.67969 |  0:00:49s\n","epoch 9  | loss: 0.70281 | val_0_accuracy: 0.66656 |  0:00:54s\n","epoch 10 | loss: 0.69717 | val_0_accuracy: 0.67201 |  0:01:00s\n","epoch 11 | loss: 0.6868  | val_0_accuracy: 0.66656 |  0:01:05s\n","epoch 12 | loss: 0.67486 | val_0_accuracy: 0.68258 |  0:01:10s\n","epoch 13 | loss: 0.66313 | val_0_accuracy: 0.69891 |  0:01:16s\n","epoch 14 | loss: 0.66182 | val_0_accuracy: 0.69539 |  0:01:21s\n","epoch 15 | loss: 0.65555 | val_0_accuracy: 0.68097 |  0:01:27s\n","epoch 16 | loss: 0.65766 | val_0_accuracy: 0.68546 |  0:01:32s\n","epoch 17 | loss: 0.65169 | val_0_accuracy: 0.69507 |  0:01:37s\n","epoch 18 | loss: 0.64849 | val_0_accuracy: 0.705   |  0:01:43s\n","epoch 19 | loss: 0.64361 | val_0_accuracy: 0.69795 |  0:01:48s\n","epoch 20 | loss: 0.63575 | val_0_accuracy: 0.69987 |  0:01:53s\n","epoch 21 | loss: 0.63079 | val_0_accuracy: 0.71429 |  0:01:59s\n","epoch 22 | loss: 0.62751 | val_0_accuracy: 0.72293 |  0:02:04s\n","epoch 23 | loss: 0.62704 | val_0_accuracy: 0.71525 |  0:02:10s\n","epoch 24 | loss: 0.62086 | val_0_accuracy: 0.69731 |  0:02:15s\n","epoch 25 | loss: 0.62238 | val_0_accuracy: 0.69923 |  0:02:21s\n","epoch 26 | loss: 0.62114 | val_0_accuracy: 0.72069 |  0:02:26s\n"]}]}]}